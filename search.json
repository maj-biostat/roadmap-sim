[
  {
    "objectID": "notebooks/simulation-pars.html#baseline-response",
    "href": "notebooks/simulation-pars.html#baseline-response",
    "title": "Simulation setup",
    "section": "Baseline response",
    "text": "Baseline response\nThe baseline probability/log-odds of treatment success is assumed to vary by silo and site of infection as detailed below.\n\n\nBaseline probability of treatment success by silo and site of infection\n\n\nSilo\nJoint\nPr(trt success)\nlog-odds\n\n\n\n\nearly\nknee\n0.65\n0.62\n\n\nearly\nhip\n0.75\n1.10\n\n\nlate\nknee\n0.55\n0.20\n\n\nlate\nhip\n0.6\n0.41\n\n\nchronic\nknee\n0.6\n0.41\n\n\nchronic\nhip\n0.65\n0.62",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#accrual",
    "href": "notebooks/simulation-pars.html#accrual",
    "title": "Simulation setup",
    "section": "Accrual",
    "text": "Accrual\nAccrual is assumed to follow a non-homogeneous Poisson process event times with ramp up over the first 12 months of enrolment and then enrolment of around 1.5 per day.\n\n\nCode\n# events per day\nlambda = 1.52\n# ramp up over 12 months \nrho = function(t) pmin(t/360, 1)\n\nd_fig &lt;- data.table(\n  t = 0:(5 * 365),\n  # expected number enrolled\n  n = c(0, nhpp.mean(lambda, rho, t1 = 5 * 365, num.points = 5 * 365))\n)\n\nggplot(d_fig, aes(x = t/365, y = n)) +\n  geom_line() +\n  scale_x_continuous(\"Year\") +\n  scale_y_continuous(\"E[Accrual]\", breaks = seq(0, 2500, by = 500))\n\n\n\n\n\n\n\n\nFigure 1: Expected accrual",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#domain-non-membership-effects",
    "href": "notebooks/simulation-pars.html#domain-non-membership-effects",
    "title": "Simulation setup",
    "section": "Domain non-membership effects",
    "text": "Domain non-membership effects\nWe assume a small effects for not being randomised to a domain for all domains.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#missingness",
    "href": "notebooks/simulation-pars.html#missingness",
    "title": "Simulation setup",
    "section": "Missingness",
    "text": "Missingness\nMissingness is not implemented.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#non-differential-follow-up",
    "href": "notebooks/simulation-pars.html#non-differential-follow-up",
    "title": "Simulation setup",
    "section": "Non-differential follow-up",
    "text": "Non-differential follow-up\nTo avoid artifacts associated with non-differential follow-up (e.g. early vs late deaths), participants will be included in the analyses only when they reach the primary endpoints (12 months) irrespective of whether they experienced treatment failure before that time.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#simulation-scenarios",
    "href": "notebooks/simulation-pars.html#simulation-scenarios",
    "title": "Simulation setup",
    "section": "Simulation scenarios",
    "text": "Simulation scenarios\nWe consider a range of simulation settings:\n\nNull scenario - no effect of any randomised treatment in any cell (OR = 1) for all domains and silos\nAll effective - all randomised treatments in all cells effective (OR = 1.5) for all domains and silos\nSingle effective - single cell effective (OR = 1.5) for single domain and silo\nSingle harmful - single cell harmful (OR = 1/1.5) for single domain and silo",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#statistical-quantities",
    "href": "notebooks/simulation-pars.html#statistical-quantities",
    "title": "Simulation setup",
    "section": "Statistical quantities",
    "text": "Statistical quantities\nWe consider treatment superiority, inferiority and futility.\nAs a set, whatever quantities are used, need to be mutually exclusive. For example, with the current set of quantities, if a parameter is superior, then it cannot be either inferior and futile.\n\nSuperiority\n\\[\\begin{aligned}\n\\phi_{sup} = Pr(OR &gt; 1)\n\\end{aligned}\\]\nand conclude superiority if \\(\\phi_{sup} &gt; \\delta_{sup}\\).\n\n\nInferiority\n\\[\\begin{aligned}\n\\phi_{inf} = 1 - \\phi_{sup}\n\\end{aligned}\\]\nand conclude inferiority if \\(\\phi_{inf} &gt; \\delta_{inf}\\).\n\n\nFutility\nIs simply defined in relation to superiority with futility concluded if \\(\\phi_{sup} &lt; \\delta_{fut}\\).",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#decision-thresholds",
    "href": "notebooks/simulation-pars.html#decision-thresholds",
    "title": "Simulation setup",
    "section": "Decision thresholds",
    "text": "Decision thresholds\nDecision thresholds are documented with the simulation results.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/adaptations.html#interim-analyses",
    "href": "notebooks/adaptations.html#interim-analyses",
    "title": "Adaptations",
    "section": "Interim analyses",
    "text": "Interim analyses\nInterim analyses start at"
  },
  {
    "objectID": "notebooks/about.html#repository-status",
    "href": "notebooks/about.html#repository-status",
    "title": "About",
    "section": "Repository status",
    "text": "Repository status\nDetails on GitHub repository files, tags, commits follow:\n\n\nCode\nrepo &lt;- git2r::repository(path = \".\")\nsummary(repo)\n\n\nLocal:    main /Users/mark/Documents/project/roadmap/src/roadmap-sim\nRemote:   main @ origin (https://github.com/maj-biostat/roadmap-sim.git)\nHead:     [aff7694] 2024-01-24: start with interpretation commentary\n\nBranches:         2\nTags:             0\nCommits:         47\nContributors:     1\nStashes:          0\nIgnored files:   53\nUntracked files: 17\nUnstaged files:   0\nStaged files:     0\n\nLatest commits:\n[aff7694] 2024-01-24: start with interpretation commentary\n[41b6383] 2024-01-24: Ignore files w/o ext and DS_Store\n[47085a9] 2024-01-24: wip\n[a4c7d3b] 2024-01-24: wip\n[d6890f1] 2024-01-19: Add note on stat quantities",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html",
    "href": "notebooks/sim-design2-results.html",
    "title": "Simulation results 2",
    "section": "",
    "text": "The trial is performed sequentially. Entry into silo-specific (plus surgery specific) parameters is coordinated by triggers for superiority, inferiority and futility, all defined earlier.",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html#all-treatments-effective",
    "href": "notebooks/sim-design2-results.html#all-treatments-effective",
    "title": "Simulation results 2",
    "section": "All treatments effective",
    "text": "All treatments effective\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim02-sc01\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n# cfg - decision thresholds currently static but could be varied over time\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\nd_pars &lt;- melt(d_cfg[, c(\"sc\", \"v\", \"analys\", g_effs), with = F], \n               id.vars = c(\"sc\", \"v\", \"analys\"), \n               value.name = \"lor_tru\", variable.name = \"parname\")\n\n\nd_trig &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  l[[i]]$d_trig\n\n  m &lt;- melt(l[[i]]$d_trig, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"parname\")\n  # Should be right, but just in case...\n  m[is.na(value), value := FALSE]\n  m[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, parname)]\n  m &lt;- m[, .(pr_val = mean(value)), keyby = .(analys, quant, parname)]\n  m &lt;- dcast(m, parname + analys ~ quant, value.var = \"pr_val\")\n\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n\nd_est &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  l[[i]]$d_trig\n  # mean of means\n  # what if analysis not reached....?????\n  m &lt;- l[[i]]$d_par\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\nd_fig &lt;- melt(d_trig, id.vars = c(\"sc\", \"v\", \"analys\", \"parname\"), variable.name = \"quant\")\nd_fig &lt;- merge(d_fig, d_pars, by = c(\"sc\", \"v\", \"analys\", \"parname\"))\nd_fig[, quant := factor(quant, \n                        labels = c(\"superiority\", \"futility\", \"inferiority\"),\n                        levels = c(\"sup\", \"fut\", \"inf\"))]\nd_fig &lt;- merge(d_fig, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig[, or_tru := round(exp(lor_tru), 3)]\n\nd_fig[, or_tru := factor(\n  or_tru, \n  labels = c(\"OR 1/1.4\" ,\"OR 1/1.2\", \"OR 1\", \"OR 1.2\", \"OR 1.4\", \"OR 1.6\", \"OR 1.8\", \"OR 2\"),\n  levels = c(\"0.714\", \"0.833\", \"1\", \"1.2\", \"1.4\", \"1.6\", \"1.8\", \"2\"))]\n\nsetkey(d_fig, sc, v, analys, N_pt)\n\n\nTable 1 summarises the setup for the simulated effect sizes (from \\(\\log(1/1.4)\\) to \\(\\log(2)\\)). All parameters are simulated to have the same effect size such that all parameters are effective, show no effect or are harmful. Decision thresholds remain constant throughout the duration of the study.\n\n\nCode\nd_tbl &lt;- d_cfg[, .SD, .SDcols = !c(\"sc\",\"nsim\", \"mc_cores\", \"t_pri\", \"analys\")]\n\ng_tbl &lt;- d_tbl |&gt; gt(rowname_col = \"effect\") |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = g_effs,\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_a_l_2, b_a_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_b1_l_2, b_b2_l_2, b_b1_c_2, b_b2_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision thresholds\"),\n    columns = c(d_sup, d_inf, d_fut)\n  ) |&gt;\n  cols_label(\n    v = html(\"Configuration\"),\n    b_a_l_2 = html(\"revision\"),\n    b_a_c_2 = html(\"two-stage\"),\n    b_b1_l_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_l_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_b1_c_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_c_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_c_2 = html(\"rif\"),\n    d_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    d_inf = html(\"delta&lt;sub&gt;inf&lt;/sub&gt;\"),\n    d_fut = html(\"delta&lt;sub&gt;fut&lt;/sub&gt;\")\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"bottom\"), color = \"black\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = N_pt == 2500\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration\nN_pt\nSurgical (Da)\nDuration (Db)\nType (Dc)\nDecision thresholds\n\n\nrevision\ntwo-stage\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nrif\ndeltasup\ndeltainf\ndeltafut\n\n\n\n\nv01\n1000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv01\n1500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv01\n2000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv01\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv02\n1000\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv02\n1500\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv02\n2000\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv02\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv03\n1000\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv03\n1500\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv03\n2000\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv03\n2500\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv04\n1000\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv04\n1500\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv04\n2000\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv04\n2500\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv05\n1000\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv05\n1500\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv05\n2000\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv05\n2500\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv06\n1000\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv06\n1500\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv06\n2000\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv06\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv07\n1000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv07\n1500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv07\n2000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv07\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv08\n1000\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\nv08\n1500\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\nv08\n2000\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\nv08\n2500\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 shows the change in the cumulative probability of declaring each of the decision types for each parameter with changing effects size (odds ratios).\n\n\n\n\n\n\nNote\n\n\n\nThe sample size shows number of enrolled patients having reached 12-months post-randomisation.\n\n\nAs noted above, all domains are set so that the treatment effects are all equal, e.g. all set to \\(\\log(2)\\) etc. The facet labels characterise the odds ratios and the parameters reported (Table 2 is a lookup table for translating the parameter names). The interpretation of some of these parameters is quite challenging.\n\n\nCode\nd_tbl &lt;- data.table(\n  parname = as.character(unique(d_fig$parname)),\n  reflab = get_effect_ref_lev(as.character(unique(d_fig$parname))),\n  parlab = get_effect_label(as.character(unique(d_fig$parname)), do_html = F)\n)\n\ng_tbl &lt;- d_tbl |&gt; gt(rowname_col = \"parname\") |&gt; \n  cols_align(\n    columns = c(\"reflab\", \"parlab\"),\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    parname = \"Parameter\",\n    reflab = \"Ref level\",\n    parlab = \"Effect\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRef level\nEffect\n\n\n\n\nb_a_l_2\ndair\nrevision\n\n\nb_a_c_2\none-stage\ntwo-stage\n\n\nb_b1_l_2\nwk6 (post stage 1)\nwk12 (post stage 1)\n\n\nb_b2_l_2\nd7 (post stage 2)\nwk12 (post stage 2)\n\n\nb_b1_c_2\nwk6 (post stage 1)\nwk12 (post stage 1)\n\n\nb_b2_c_2\nd7 (post stage 2)\nwk12 (post stage 2)\n\n\nb_c_2\nnorif\nrif\n\n\n\n\n\n\n\n\nTable 2: Translation from parameter names to effects\n\n\n\n\nSome commentary is necessary on the interpretation of parameters. As noted previously, the baseline reference groups are defined as follows:\n\n\nGroups corresponding to baseline log-odds of treatment success\n\n\nSilo\nA\nB\nC\n\n\n\n\nearly\n-\n-\nno-rif\n\n\nlate\ndair\n-\nno-rif\n\n\nchronic\none\n6wk\nno-rif\n\n\n\n\nSpecifically:\n\n\\(\\alpha_{[early, \\cdot]}\\) term in the model describes the log-odds of treatment success for early infection silo members who were randomised1 to no-rif and had no randomisation options for domains A and B.\n\\(\\alpha_{[late, \\cdot]}\\) term in the model describes the log-odds of treatment success for late infection silo members who were randomised to dair in Domain A, had no randomisation options for Domain B2 and were randomised to no-rif in Domain C.\n\\(\\alpha_{[chronic, \\cdot]}\\) term in the model describes the log-odds of treatment success for chronic infection silo members who were randomised to one in Domain A, day07 in Domain B and to no-rif in Domain C.\n\n\n\n\n\n\n\nNote\n\n\n\nThe following are incomplete:\n\n\n\nIn the late infection patients, the effect of revision relative to dair is interpreted as …\nIn the chronic infection patients, the effect of two-stage relative to one is …\nIn the late infection patients who were randomised to revision, the effect of 12wk relative to 6wk is …\nIn the chronic infection patients who were randomised to one-stage surgery, the effect of 12wk relative to 6wk is …\nIn the chronic infection patients who were randomised to one-stage surgery, the effect of 12wk relative to 7days (both post stage 2) is …\nAcross all silos, the effect of rif relative to no rif is …\n\n\n\nCode\nggplot(d_fig, aes(x = N_pt, y = value, group = quant, col = quant)) +\n  geom_point(size = 0.5) +\n  geom_line(aes(lty = quant), lwd = 0.3) +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  scale_x_continuous(\"Sample size\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Cumulative probability\", breaks = seq(0, 1, by = 0.2)) +\n  facet_grid(parname~or_tru)\n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\nTable 3 provides the same detail as the above figure, but makes it easier to see what the magnitudes of the cumulate probabilities are.\n\n\nCode\nd_tbl &lt;- dcast(d_fig, parname + or_tru ~ quant + analys, value.var = \"value\")\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"inferiority\", \"inf\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility\", \"fut\", names(d_tbl))\nd_tbl &lt;- d_tbl[order(or_tru, parname)]\nd_tbl[, parlab := paste0(parname, \" - \", get_effect_label(as.character(parname), do_html = F))]\nd_tbl[, parname := NULL]\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"parlab\") |&gt; \n  tab_spanner(\n    label = html(\"Superiority\"),\n    columns = c(\"sup_1\", \"sup_2\", \"sup_3\", \"sup_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility\"),\n    columns = c(\"fut_1\", \"fut_2\", \"fut_3\", \"fut_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Inferiority\"),\n    columns = c(\"inf_1\", \"inf_2\", \"inf_3\", \"inf_4\")\n  ) |&gt;\n  cols_label(\n    or_tru = html(\"OR (true)\"),\n    sup_1 = html(\"1000\"),\n    sup_2 = html(\"1500\"),\n    sup_3 = html(\"2000\"),\n    sup_4 = html(\"2500\"),\n    fut_1 = html(\"1000\"),\n    fut_2 = html(\"1500\"),\n    fut_3 = html(\"2000\"),\n    fut_4 = html(\"2500\"),\n    inf_1 = html(\"1000\"),\n    inf_2 = html(\"1500\"),\n    inf_3 = html(\"2000\"),\n    inf_4 = html(\"2500\")\n  ) |&gt;\n  tab_style(\n    style = cell_borders(\n      sides = c(\"left\"),\n      weight = px(1)),\n    locations = cells_body(\n      columns = c(sup_1, fut_1, inf_1)\n      )\n    ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or_tru == \"OR 1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nOR (true)\nSuperiority\nFutility\nInferiority\n\n\n1000\n1500\n2000\n2500\n1000\n1500\n2000\n2500\n1000\n1500\n2000\n2500\n\n\n\n\nb_a_l_2 - revision\n\n\nOR 1/1.4\n0.000\n0.000\n0.000\n0.000\n0.662\n0.852\n0.946\n0.974\n0.398\n0.558\n0.646\n0.718\n\n\nOR 1/1.2\n0.006\n0.006\n0.006\n0.006\n0.342\n0.492\n0.614\n0.694\n0.156\n0.224\n0.278\n0.322\n\n\nOR 1\n0.016\n0.030\n0.042\n0.044\n0.082\n0.128\n0.154\n0.170\n0.010\n0.026\n0.036\n0.038\n\n\nOR 1.2\n0.128\n0.236\n0.292\n0.328\n0.014\n0.020\n0.020\n0.020\n0.000\n0.002\n0.002\n0.002\n\n\nOR 1.4\n0.348\n0.512\n0.604\n0.666\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.624\n0.770\n0.828\n0.862\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.788\n0.880\n0.914\n0.922\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.866\n0.936\n0.954\n0.968\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_a_c_2 - two-stage\n\n\nOR 1/1.4\n0.004\n0.006\n0.006\n0.006\n0.216\n0.390\n0.530\n0.618\n0.074\n0.130\n0.208\n0.286\n\n\nOR 1/1.2\n0.006\n0.006\n0.006\n0.010\n0.164\n0.266\n0.336\n0.400\n0.046\n0.086\n0.118\n0.134\n\n\nOR 1\n0.018\n0.038\n0.058\n0.064\n0.084\n0.120\n0.132\n0.156\n0.028\n0.034\n0.038\n0.044\n\n\nOR 1.2\n0.038\n0.078\n0.108\n0.130\n0.020\n0.030\n0.036\n0.038\n0.004\n0.004\n0.004\n0.008\n\n\nOR 1.4\n0.088\n0.166\n0.236\n0.300\n0.008\n0.010\n0.010\n0.010\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.180\n0.266\n0.328\n0.390\n0.006\n0.006\n0.006\n0.006\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.278\n0.400\n0.472\n0.504\n0.002\n0.004\n0.004\n0.004\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.336\n0.486\n0.570\n0.610\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_b1_l_2 - wk12 (post stage 1)\n\n\nOR 1/1.4\n0.000\n0.000\n0.000\n0.000\n0.384\n0.426\n0.440\n0.442\n0.164\n0.184\n0.186\n0.194\n\n\nOR 1/1.2\n0.006\n0.006\n0.006\n0.006\n0.220\n0.296\n0.348\n0.368\n0.064\n0.084\n0.096\n0.104\n\n\nOR 1\n0.012\n0.024\n0.032\n0.036\n0.060\n0.094\n0.120\n0.152\n0.010\n0.018\n0.022\n0.024\n\n\nOR 1.2\n0.082\n0.142\n0.192\n0.234\n0.028\n0.038\n0.050\n0.052\n0.002\n0.002\n0.002\n0.004\n\n\nOR 1.4\n0.160\n0.302\n0.406\n0.508\n0.008\n0.012\n0.012\n0.012\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.240\n0.452\n0.630\n0.716\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.302\n0.564\n0.738\n0.846\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.322\n0.628\n0.784\n0.878\n0.004\n0.004\n0.004\n0.004\n0.000\n0.000\n0.000\n0.000\n\n\nb_b2_l_2 - wk12 (post stage 2)\n\n\nOR 1/1.4\n0.002\n0.002\n0.002\n0.002\n0.394\n0.448\n0.466\n0.472\n0.166\n0.188\n0.208\n0.218\n\n\nOR 1/1.2\n0.000\n0.000\n0.000\n0.000\n0.216\n0.284\n0.322\n0.336\n0.050\n0.068\n0.086\n0.088\n\n\nOR 1\n0.016\n0.036\n0.046\n0.050\n0.080\n0.118\n0.150\n0.158\n0.026\n0.040\n0.048\n0.056\n\n\nOR 1.2\n0.064\n0.104\n0.144\n0.188\n0.022\n0.036\n0.042\n0.046\n0.000\n0.006\n0.006\n0.010\n\n\nOR 1.4\n0.158\n0.276\n0.380\n0.496\n0.010\n0.014\n0.016\n0.016\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.258\n0.434\n0.614\n0.740\n0.004\n0.006\n0.006\n0.006\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.300\n0.536\n0.748\n0.848\n0.002\n0.002\n0.002\n0.002\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.388\n0.662\n0.816\n0.908\n0.002\n0.002\n0.002\n0.002\n0.002\n0.002\n0.002\n0.002\n\n\nb_b1_c_2 - wk12 (post stage 1)\n\n\nOR 1/1.4\n0.004\n0.006\n0.006\n0.006\n0.226\n0.374\n0.486\n0.592\n0.060\n0.122\n0.200\n0.266\n\n\nOR 1/1.2\n0.000\n0.000\n0.004\n0.006\n0.154\n0.230\n0.312\n0.364\n0.050\n0.088\n0.118\n0.140\n\n\nOR 1\n0.024\n0.034\n0.052\n0.066\n0.080\n0.122\n0.144\n0.172\n0.018\n0.026\n0.040\n0.044\n\n\nOR 1.2\n0.054\n0.098\n0.134\n0.158\n0.032\n0.042\n0.052\n0.056\n0.002\n0.010\n0.012\n0.012\n\n\nOR 1.4\n0.104\n0.154\n0.204\n0.252\n0.016\n0.016\n0.018\n0.020\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.150\n0.222\n0.296\n0.344\n0.006\n0.006\n0.008\n0.008\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.224\n0.300\n0.366\n0.424\n0.004\n0.004\n0.004\n0.004\n0.002\n0.002\n0.002\n0.002\n\n\nOR 2\n0.246\n0.360\n0.448\n0.500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_b2_c_2 - wk12 (post stage 2)\n\n\nOR 1/1.4\n0.002\n0.002\n0.002\n0.002\n0.306\n0.420\n0.480\n0.514\n0.114\n0.162\n0.180\n0.196\n\n\nOR 1/1.2\n0.010\n0.016\n0.016\n0.016\n0.200\n0.284\n0.370\n0.428\n0.064\n0.098\n0.134\n0.150\n\n\nOR 1\n0.022\n0.036\n0.046\n0.048\n0.088\n0.126\n0.148\n0.174\n0.014\n0.022\n0.032\n0.038\n\n\nOR 1.2\n0.040\n0.070\n0.102\n0.126\n0.028\n0.038\n0.054\n0.062\n0.002\n0.002\n0.004\n0.006\n\n\nOR 1.4\n0.100\n0.164\n0.230\n0.282\n0.014\n0.022\n0.028\n0.030\n0.000\n0.000\n0.000\n0.002\n\n\nOR 1.6\n0.152\n0.238\n0.374\n0.456\n0.000\n0.004\n0.004\n0.006\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.192\n0.334\n0.494\n0.596\n0.000\n0.002\n0.002\n0.002\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.190\n0.350\n0.530\n0.678\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_c_2 - rif\n\n\nOR 1/1.4\n0.000\n0.000\n0.000\n0.000\n0.732\n0.874\n0.938\n0.964\n0.460\n0.624\n0.716\n0.792\n\n\nOR 1/1.2\n0.002\n0.002\n0.002\n0.002\n0.364\n0.524\n0.618\n0.686\n0.174\n0.262\n0.324\n0.382\n\n\nOR 1\n0.026\n0.044\n0.058\n0.064\n0.056\n0.112\n0.140\n0.154\n0.018\n0.030\n0.040\n0.040\n\n\nOR 1.2\n0.204\n0.300\n0.380\n0.472\n0.002\n0.004\n0.008\n0.008\n0.000\n0.000\n0.002\n0.002\n\n\nOR 1.4\n0.522\n0.676\n0.806\n0.880\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.756\n0.894\n0.950\n0.978\n0.002\n0.002\n0.002\n0.002\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.862\n0.964\n0.994\n0.996\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.966\n0.994\n0.998\n1.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\n\n\n\n\n\n\nTable 3: Cumulative probability of decision\n\n\n\n\nFigure 2 shows the distribution of estimated posterior means by simulated effect size, parameter and sample size.\n\n\nCode\nd_fig &lt;- d_est[, .(sc, v, sim, parname = par, analys, mu)]\nd_fig &lt;- merge(d_fig, d_pars, by = c(\"sc\", \"v\", \"analys\", \"parname\"))\nd_fig &lt;- merge(d_fig, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig[, analys := factor(analys)]\nd_fig[, N_pt := factor(N_pt)]\n\nd_fig[, or_tru := factor(\n  round(exp(lor_tru), 3), \n  labels = c(\"OR 1/1.4\" ,\"OR 1/1.2\", \"OR 1\", \"OR 1.2\", \"OR 1.4\", \"OR 1.6\", \"OR 1.8\", \"OR 2\"),\n  levels = c(\"0.714\", \"0.833\", \"1\", \"1.2\", \"1.4\", \"1.6\", \"1.8\", \"2\"))]\n\nd_fig_2 &lt;- unique(d_fig[, .(sc, or_tru, parname, lor_tru)])\n\np &lt;- ggplot(d_fig, aes(x = N_pt, y = mu)) +\n  geom_hline(data = d_fig_2, aes(yintercept = lor_tru, group = parname), col = 2) +\n  geom_boxplot() +\n  scale_x_discrete(\"\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Distribution of posterior mean\") +\n  facet_grid(parname~or_tru)\n\nsuppressWarnings(print(p))\n\n\n\n\n\n\n\n\nFigure 2: Distribution of posterior means (true log OR shown in red).",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html#single-effective-treatment",
    "href": "notebooks/sim-design2-results.html#single-effective-treatment",
    "title": "Simulation results 2",
    "section": "Single effective treatment",
    "text": "Single effective treatment\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim02-sc02\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n# cfg - decision thresholds currently static but could be varied over time\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\nd_pars &lt;- melt(d_cfg[, c(\"sc\", \"v\", \"analys\", g_effs), with = F], \n               id.vars = c(\"sc\", \"v\", \"analys\"), \n               value.name = \"lor_tru\", variable.name = \"parname\")\n\n\nd_trig &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  l[[i]]$d_trig\n\n  m &lt;- melt(l[[i]]$d_trig, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"parname\")\n  # Should be right, but just in case...\n  m[is.na(value), value := FALSE]\n  m[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, parname)]\n  m &lt;- m[, .(pr_val = mean(value)), keyby = .(analys, quant, parname)]\n  m &lt;- dcast(m, parname + analys ~ quant, value.var = \"pr_val\")\n\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\nd_fig &lt;- melt(d_trig, id.vars = c(\"sc\", \"v\", \"analys\", \"parname\"), variable.name = \"quant\")\nd_fig &lt;- merge(d_fig, d_pars, by = c(\"sc\", \"v\", \"analys\", \"parname\"))\nd_fig[, quant := factor(quant, \n                        labels = c(\"superiority\", \"futility\", \"inferiority\"),\n                        levels = c(\"sup\", \"fut\", \"inf\"))]\nd_fig &lt;- merge(d_fig, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig[, or_tru := round(exp(lor_tru), 3)]\n\nd_fig[, or_tru := factor(\n  or_tru, \n  labels = c(\"OR 1/1.4\" ,\"OR 1/1.2\", \"OR 1\", \"OR 1.2\", \"OR 1.4\", \"OR 1.6\", \"OR 1.8\", \"OR 2\"),\n  levels = c(\"0.714\", \"0.833\", \"1\", \"1.2\", \"1.4\", \"1.6\", \"1.8\", \"2\"))]\n\nsetkey(d_fig, sc, v, analys, N_pt)\n\n\n\n\nCode\nggplot(d_fig, aes(x = N_pt, y = value, group = quant, col = quant)) +\n  geom_point(size = 0.5) +\n  geom_line(aes(lty = quant), lwd = 0.3) +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  scale_x_continuous(\"Sample size\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Cumulative probability\", breaks = seq(0, 1, by = 0.2)) +\n  facet_grid(parname~or_tru)\n\n\nTable 4 provides the same detail as the above figure, but makes it easier to see what the magnitudes of the cumulate probabilities are.\n\n\n\n\nCode\nd_tbl &lt;- dcast(d_fig, parname + or_tru ~ quant + analys, value.var = \"value\")\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"inferiority\", \"inf\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility\", \"fut\", names(d_tbl))\nd_tbl &lt;- d_tbl[order(or_tru, parname)]\nd_tbl[, parlab := paste0(parname, \" - \", get_effect_label(as.character(parname), do_html = F))]\nd_tbl[, parname := NULL]\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"parlab\") |&gt; \n  tab_spanner(\n    label = html(\"Superiority\"),\n    columns = c(\"sup_1\", \"sup_2\", \"sup_3\", \"sup_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility\"),\n    columns = c(\"fut_1\", \"fut_2\", \"fut_3\", \"fut_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Inferiority\"),\n    columns = c(\"inf_1\", \"inf_2\", \"inf_3\", \"inf_4\")\n  ) |&gt;\n  cols_label(\n    or_tru = html(\"OR (true)\"),\n    sup_1 = html(\"1000\"),\n    sup_2 = html(\"1500\"),\n    sup_3 = html(\"2000\"),\n    sup_4 = html(\"2500\"),\n    fut_1 = html(\"1000\"),\n    fut_2 = html(\"1500\"),\n    fut_3 = html(\"2000\"),\n    fut_4 = html(\"2500\"),\n    inf_1 = html(\"1000\"),\n    inf_2 = html(\"1500\"),\n    inf_3 = html(\"2000\"),\n    inf_4 = html(\"2500\")\n  ) |&gt;\n  tab_style(\n    style = cell_borders(\n      sides = c(\"left\"),\n      weight = px(1)),\n    locations = cells_body(\n      columns = c(sup_1, fut_1, inf_1)\n      )\n    ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or_tru == \"OR 1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\nTable 4: Cumulative probability of decision",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html#footnotes",
    "href": "notebooks/sim-design2-results.html#footnotes",
    "title": "Simulation results 2",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThat is, not part of the 40% exclusion set from domain C↩︎\nA deterministic consequence of being randomised to dair in Domain A↩︎",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/simulation-results.html#all-treatments-effective",
    "href": "notebooks/simulation-results.html#all-treatments-effective",
    "title": "Simulation results 1",
    "section": "All treatments effective",
    "text": "All treatments effective\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc01\")\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n}\n\nd_sup &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"pr_sup\")\n\nd_inf &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_inf[, lapply(.SD, mean)])\n}))\nd_inf &lt;- melt(d_inf, id.vars = c(\"sc\", \"v\"), value.name = \"pr_inf\")\n\nd_fut &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_fut[, lapply(.SD, mean)])\n}))\nd_fut &lt;- melt(d_fut, id.vars = c(\"sc\", \"v\"), value.name = \"pr_fut\")\n\nd_cfg &lt;- rbindlist(lapply(l, function(z){\n  data.table(do.call(cbind, z$cfg)) \n}))\n# urgh - conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  mc_cores = as.numeric(mc_cores),\n  b_a_l_2 = as.numeric(b_a_l_2),\n  b_a_c_2 = as.numeric(b_a_c_2),\n  b_b1_l_2 = as.numeric(b_b1_l_2),\n  b_b2_l_2 = as.numeric(b_b2_l_2),\n  b_b1_c_2 = as.numeric(b_b1_c_2),\n  b_b2_c_2 = as.numeric(b_b2_c_2),\n  b_c_2 = as.numeric(b_c_2),\n  d_sup = as.numeric(d_sup),\n  d_inf = as.numeric(d_inf),\n  d_fut = as.numeric(d_fut)\n  )]\n\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\nd_pars &lt;- melt(d_cfg[\n  , .SD, .SDcols = c(\"sc\", \"v\", \n                     \"b_a_l_2\", \"b_a_c_2\", \n                     \"b_b1_l_2\", \"b_b2_l_2\", \"b_b1_c_2\", \"b_b2_c_2\", \n                     \"b_c_2\")], \n  id.vars = c(\"sc\", \"v\"), value.name = \"lor_tru\")\n\n\nd_sup &lt;- add_effect_field(d_sup, d_pars)\nd_inf &lt;- add_effect_field(d_inf, d_pars)\nd_fut &lt;- add_effect_field(d_fut, d_pars)\n\n\nd_fig &lt;- merge(d_sup, d_inf, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- merge(d_fig, d_fut, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- melt(d_fig, measure.vars = c(\"pr_sup\", \"pr_inf\", \"pr_fut\"), variable.name = \"decision_type\")\nd_fig[decision_type == \"pr_sup\", decision_type := \"Superiority\"]\nd_fig[decision_type == \"pr_inf\", decision_type := \"Inferiority\"]\nd_fig[decision_type == \"pr_fut\", decision_type := \"Futility\"]\n\n\nTable 1 summarises the setup for the simulated effect sizes (from \\(\\log(1/1.4)\\) to \\(\\log(2)\\)). All parameters are simulated to have the same effect size such that all parameters are effective, show no effect or are harmful.\nResults based on 500 simulations for a cohort sample size of 2500.\n\n\nCode\nd_tbl &lt;- d_cfg[, .SD, .SDcols = !c(\"sc\",\"nsim\", \"mc_cores\")]\nd_tbl &lt;- cbind(\n  effect = c(\n    \"null\", rep(\"superior\", 5), rep(\"inferior\", 2)\n  ), d_tbl\n)\n\n\ng_tbl &lt;- d_tbl |&gt; gt(rowname_col = \"effect\") |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = everything(),\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_a_l_2, b_a_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_b1_l_2, b_b2_l_2, b_b1_c_2, b_b2_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision thresholds\"),\n    columns = c(d_sup, d_inf, d_fut)\n  ) |&gt;\n  cols_label(\n    b_a_l_2 = html(\"revision\"),\n    b_a_c_2 = html(\"two-stage\"),\n    b_b1_l_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_l_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_b1_c_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_c_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_c_2 = html(\"rif\"),\n    d_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    d_inf = html(\"delta&lt;sub&gt;inf&lt;/sub&gt;\"),\n    d_fut = html(\"delta&lt;sub&gt;fut&lt;/sub&gt;\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nv\nN_pt\nSurgical (Da)\nDuration (Db)\nType (Dc)\nDecision thresholds\n\n\nrevision\ntwo-stage\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nrif\ndeltasup\ndeltainf\ndeltafut\n\n\n\n\nnull\nv01\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.050\n\n\nsuperior\nv02\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.050\n\n\nsuperior\nv03\n2500\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.050\n\n\nsuperior\nv04\n2500\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.050\n\n\nsuperior\nv05\n2500\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.050\n\n\nsuperior\nv06\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.050\n\n\ninferior\nv07\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.050\n\n\ninferior\nv08\n2500\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.050\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 summarises the variation in the probability of declaring each decision type on each parameter with increasing effects size (odds ratios). All domains are set so that the treatment effects are all equal, e.g. all set to \\(\\log(2)\\) etc. The parameters are log-odds-ratios relative to the relevant reference values.\nFor example, b_a_late_rev is the effect revision relative to dair specific to the late silo. Similarly, b_a_chronic_two is the effect of two-stage procedure relative to the one-stage specific to the chronic silo.\n\n\nCode\nggplot(d_fig, aes(x = exp(lor_tru), y = value, group = decision_type, col = decision_type)) +\n  geom_point(size = 0.5) +\n  geom_line() +\n  scale_color_discrete(\"\") +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Pr(decide superior)\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~parname, ncol = 3)\n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc02\")\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n}\n\nd_sup &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"pr_sup\")\n\nd_inf &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_inf[, lapply(.SD, mean)])\n}))\nd_inf &lt;- melt(d_inf, id.vars = c(\"sc\", \"v\"), value.name = \"pr_inf\")\n\nd_fut &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_fut[, lapply(.SD, mean)])\n}))\nd_fut &lt;- melt(d_fut, id.vars = c(\"sc\", \"v\"), value.name = \"pr_fut\")\n\nd_cfg &lt;- rbindlist(lapply(l, function(z){\n  data.table(do.call(cbind, z$cfg)) \n}))\n# urgh - conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  mc_cores = as.numeric(mc_cores),\n  b_a_l_2 = as.numeric(b_a_l_2),\n  b_a_c_2 = as.numeric(b_a_c_2),\n  b_b1_l_2 = as.numeric(b_b1_l_2),\n  b_b2_l_2 = as.numeric(b_b2_l_2),\n  b_b1_c_2 = as.numeric(b_b1_c_2),\n  b_b2_c_2 = as.numeric(b_b2_c_2),\n  b_c_2 = as.numeric(b_c_2),\n  d_sup = as.numeric(d_sup),\n  d_inf = as.numeric(d_inf),\n  d_fut = as.numeric(d_fut)\n  )]\n\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\nd_pars &lt;- melt(d_cfg[\n  , .SD, .SDcols = c(\"sc\", \"v\", \n                     \"b_a_l_2\", \"b_a_c_2\", \n                     \"b_b1_l_2\", \"b_b2_l_2\", \"b_b1_c_2\", \"b_b2_c_2\", \n                     \"b_c_2\")], \n  id.vars = c(\"sc\", \"v\"), value.name = \"lor_tru\")\n\n\nd_sup &lt;- add_effect_field(d_sup, d_pars)\nd_inf &lt;- add_effect_field(d_inf, d_pars)\nd_fut &lt;- add_effect_field(d_fut, d_pars)\n\n\nd_fig &lt;- merge(d_sup, d_inf, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- merge(d_fig, d_fut, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- melt(d_fig, measure.vars = c(\"pr_sup\", \"pr_inf\", \"pr_fut\"), variable.name = \"decision_type\")\nd_fig[decision_type == \"pr_sup\", decision_type := \"Superiority\"]\nd_fig[decision_type == \"pr_inf\", decision_type := \"Inferiority\"]\nd_fig[decision_type == \"pr_fut\", decision_type := \"Futility\"]\n\n\nRepeating the simulations (500 iterations) based on a total cohort size of 1000.\n\n\nCode\nggplot(d_fig, aes(x = exp(lor_tru), y = value, group = decision_type, col = decision_type)) +\n  geom_point(size = 0.5) +\n  geom_line() +\n  scale_color_discrete(\"\") +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Pr(decide superior)\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~parname, ncol = 3)\n\n\n\n\n\n\n\n\nFigure 2: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc03\")\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n}\n\nd_sup &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"pr_sup\")\n\nd_inf &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_inf[, lapply(.SD, mean)])\n}))\nd_inf &lt;- melt(d_inf, id.vars = c(\"sc\", \"v\"), value.name = \"pr_inf\")\n\nd_fut &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_fut[, lapply(.SD, mean)])\n}))\nd_fut &lt;- melt(d_fut, id.vars = c(\"sc\", \"v\"), value.name = \"pr_fut\")\n\nd_cfg &lt;- rbindlist(lapply(l, function(z){\n  data.table(do.call(cbind, z$cfg)) \n}))\n# urgh - conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  mc_cores = as.numeric(mc_cores),\n  b_a_l_2 = as.numeric(b_a_l_2),\n  b_a_c_2 = as.numeric(b_a_c_2),\n  b_b1_l_2 = as.numeric(b_b1_l_2),\n  b_b2_l_2 = as.numeric(b_b2_l_2),\n  b_b1_c_2 = as.numeric(b_b1_c_2),\n  b_b2_c_2 = as.numeric(b_b2_c_2),\n  b_c_2 = as.numeric(b_c_2),\n  d_sup = as.numeric(d_sup),\n  d_inf = as.numeric(d_inf),\n  d_fut = as.numeric(d_fut)\n  )]\n\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\nd_pars &lt;- melt(d_cfg[\n  , .SD, .SDcols = c(\"sc\", \"v\", \n                     \"b_a_l_2\", \"b_a_c_2\", \n                     \"b_b1_l_2\", \"b_b2_l_2\", \"b_b1_c_2\", \"b_b2_c_2\", \n                     \"b_c_2\")], \n  id.vars = c(\"sc\", \"v\"), value.name = \"lor_tru\")\n\n\nd_sup &lt;- add_effect_field(d_sup, d_pars)\nd_inf &lt;- add_effect_field(d_inf, d_pars)\nd_fut &lt;- add_effect_field(d_fut, d_pars)\n\n\nd_fig &lt;- merge(d_sup, d_inf, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- merge(d_fig, d_fut, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- melt(d_fig, measure.vars = c(\"pr_sup\", \"pr_inf\", \"pr_fut\"), variable.name = \"decision_type\")\nd_fig[decision_type == \"pr_sup\", decision_type := \"Superiority\"]\nd_fig[decision_type == \"pr_inf\", decision_type := \"Inferiority\"]\nd_fig[decision_type == \"pr_fut\", decision_type := \"Futility\"]\n\n\nRepeating the simulations (500 iterations) based on a total cohort size of 500.\n\n\nCode\nggplot(d_fig, aes(x = exp(lor_tru), y = value, group = decision_type, col = decision_type)) +\n  geom_point(size = 0.5) +\n  geom_line() +\n  scale_color_discrete(\"\") +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Pr(decide superior)\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~parname, ncol = 3)\n\n\n\n\n\n\n\n\nFigure 3: Probability of declaring decision by parameter by effect size (all pars set with same OR).",
    "crumbs": [
      "Design",
      "Simulation results 1"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html",
    "href": "notebooks/population-structure.html",
    "title": "Population structure",
    "section": "",
    "text": "The following specification is for the partially factorial structure of the study. The outcome model is specified separately.",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#silo",
    "href": "notebooks/population-structure.html#silo",
    "title": "Population structure",
    "section": "Silo",
    "text": "Silo\nThe total sample size is divided across the silos in proportion to the values described in the table below. These proportions are expectations. Each simulated dataset will vary somewhat from these proportions due to the stochastic nature of the generation process.\n\n\nSilo categories (\\(\\pi\\) denotes probability of membership)\n\n\nSilo\n\\(\\pi\\)\n\n\n\n\nearly\n0.3\n\n\nlate\n0.5\n\n\nchronic\n0.2",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#site-of-infection-joint",
    "href": "notebooks/population-structure.html#site-of-infection-joint",
    "title": "Population structure",
    "section": "Site of infection (joint)",
    "text": "Site of infection (joint)\nEach silo comprises patients assumed to have primary infection in either knee or hip (not both). The proportion of infections associated with each joint for each silo are shown below. As previously, these proportions are expectations and the empirical proportions observed in simulated datasets will vary from these.\n\n\nSite of infection (\\(\\pi\\) denotes probability of site infection conditional on silo membership)\n\n\nSilo\nJoint\n\\(\\pi\\)\n\n\n\n\n\nearly\nknee\n0.4\n\n\n\nearly\nhip\n0.6\n\n\n\nlate\nknee\n0.3\n\n\n\nlate\nhip\n0.7\n\n\n\nchronic\nknee\n0.5\n\n\n\nchronic\nhip\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-surgery-domain-a",
    "href": "notebooks/population-structure.html#randomisation-into-surgery-domain-a",
    "title": "Population structure",
    "section": "Randomisation into surgery domain (A)",
    "text": "Randomisation into surgery domain (A)\nRandomisation into domain A is conditional on silo membership as detailed below.\n\n\nRandomisation within domain A\n\n\nSilo\nRandomised (\\(e_a\\))\n\n\n\n\nearly\nN\n\n\nlate\nY\n\n\nchronic\nY",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#surgery-domain-a",
    "href": "notebooks/population-structure.html#surgery-domain-a",
    "title": "Population structure",
    "section": "Surgery domain (A)",
    "text": "Surgery domain (A)\nAllocation probabilities (conditional on entry into domain A) are shown below. Early silo does not receive randomisation and all early stage patients are assumed to receive DAIR.\n\n\nAllocation within domain A (\\(\\pi\\) denotes probability allocation to surgery type conditional on silo membership)\n\n\nSilo\nSurgery type (\\(a\\))\n\\(\\pi\\)\n\n\n\n\n\nearly\ndair\n-\n\n\n\nlate\ndair\n0.5\n\n\n\nlate\nrevision\n0.5\n\n\n\nchronic\none-stage\n0.5\n\n\n\nchronic\ntwo-stage\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#intended-surgery",
    "href": "notebooks/population-structure.html#intended-surgery",
    "title": "Population structure",
    "section": "Intended surgery",
    "text": "Intended surgery\nLate stage infections will be randomised to DAIR vs revision where revision would be planned as one or two-stage, determined by the treating clinician, i.e. not randomised. As we do not know the assignment mechanism for one vs two-stage for the late-stage infection patients allocated to revision, we simply assume an equal chance of receiving one vs two stage1.\nIn all other cases, the intended surgery is set to allocated surgery.\n\n\nIndended surgical approach (\\(\\pi\\) denotes probability allocation to surgery type conditional on silo membership)\n\n\nSilo\nAllocation (\\(a\\))\nIntended surgery (\\(q\\))\n\\(\\pi\\)\n\n\n\n\n\nearly\ndair\ndair\n-\n\n\n\nlate\ndair\ndair\n-\n\n\n\nlate\nrevision\none-stage\n0.5\n\n\n\nlate\nrevision\ntwo-stage\n0.5\n\n\n\nchronic\none-stage\none-stage\n-\n\n\n\nchronic\ntwo-stage\ntwo-stage\n-",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-duration-domain-b",
    "href": "notebooks/population-structure.html#randomisation-into-duration-domain-b",
    "title": "Population structure",
    "section": "Randomisation into duration domain (B)",
    "text": "Randomisation into duration domain (B)\nEntry into domain B is dependent on the domain A entry and allocation and is detailed below.\n\n\nRandomisation within domain B\n\n\nIntended surgery (\\(q\\))\nRandomised (\\(e_b\\))\n\n\n\n\n\ndair\nN\n\n\n\nrevision\nY\n\n\n\none-stage\nY\n\n\n\ntwo-stage\nY",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#duration-domain-b",
    "href": "notebooks/population-structure.html#duration-domain-b",
    "title": "Population structure",
    "section": "Duration domain (B)",
    "text": "Duration domain (B)\nThe treatment options and allocation probabilities for domain B are detailed below. Duration of antibiotic is conditional on allocated (intended) surgery type, see above. Patients receiving DAIR are assumed to have 12 wk duration (not randomised).\n\n\nAllocation within duration domain (\\(\\pi\\) denotes probability allocation to surgery type conditional on allocated/intended surgery)\n\n\nSilo\nAllocation/Intended surgery (\\(q\\))\nAllocation (\\(b\\))\n\\(\\pi\\)\n\n\n\n\nearly\ndair\n12 wk\n-\n\n\nlate\none-stage\n6 wk\n0.5\n\n\nlate\none-stage\n12 wk\n0.5\n\n\nlate\ntwo-stage\n7 day post 2\n0.5\n\n\nlate\ntwo-stage\n12 wk post 2\n0.5\n\n\nchronic\none-stage\n6 wk\n0.5\n\n\nchronic\none-stage\n12 wk\n0.5\n\n\nchronic\ntwo-stage\n7 day post 2\n0.5\n\n\nchronic\ntwo-stage\n12 wk post 2\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-adjunctive-domain-c",
    "href": "notebooks/population-structure.html#randomisation-into-adjunctive-domain-c",
    "title": "Population structure",
    "section": "Randomisation into adjunctive domain (C)",
    "text": "Randomisation into adjunctive domain (C)\nThe data generating process assume that 60% of the cohort enter into this domain at random, unrelated to risk factors. The remainder are held out so that we do not over-estimate the operating characteristics, such as power.\n\n\nRandomisation within domain C (\\(\\pi\\) denotes probability patient is indicated as eligible for domain)\n\n\nSilo\nRandomised (\\(e_c\\))\n\\(\\pi\\)\n\n\n\n\nearly\nY\n0.6\n\n\nlate\nY\n0.6\n\n\nchronic\nY\n0.6",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#adjunctive-domain-c",
    "href": "notebooks/population-structure.html#adjunctive-domain-c",
    "title": "Population structure",
    "section": "Adjunctive domain (C)",
    "text": "Adjunctive domain (C)\nThe treatment options and allocation probabilities for domain C are detailed below.\n\n\nAllocation within adjunctive domain (\\(\\pi\\) denotes probability that an eligible patient is allocated to no rif vs rif)\n\n\nAllocation (\\(c\\))\n\\(\\pi\\)\n\n\n\n\nno rif\n0.5\n\n\nrif\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#encoded-specification",
    "href": "notebooks/population-structure.html#encoded-specification",
    "title": "Population structure",
    "section": "Encoded specification",
    "text": "Encoded specification\nThe above specification is bundled into an R package (roadmap.data) for consistent data generation for ROADMAP.\n\n\nCode\nroadmap.data::get_pop_spec()\n\n\n$r_silo\n      silo   p\n1:   early 0.3\n2:    late 0.5\n3: chronic 0.2\n\n$r_joint\n      silo joint   p\n1:   early  knee 0.4\n2:   early   hip 0.6\n3:    late  knee 0.3\n4:    late   hip 0.7\n5: chronic  knee 0.5\n6: chronic   hip 0.5\n\n$r_ea\n      silo rand\n1:   early    N\n2:    late    Y\n3: chronic    Y\n\n$r_a\n      silo    a   p\n1:   early dair  NA\n2:    late dair 0.5\n3:    late  rev 0.5\n4: chronic  one 0.5\n5: chronic  two 0.5\n\n$r_a_q\n      silo    a   qa   p\n1:   early dair dair  NA\n2:    late dair dair  NA\n3:    late  rev  one 0.5\n4:    late  rev  two 0.5\n5: chronic  one  one  NA\n6: chronic  two  two  NA\n\n$r_eb\n     qa rand\n1: dair    N\n2:  rev    Y\n3:  one    Y\n4:  two    Y\n\n$r_b\n      silo   qa     b   p\n1:   early dair   w12 1.0\n2:    late  one w06p1 0.5\n3:    late  one w12p1 0.5\n4:    late  two d07p2 0.5\n5:    late  two w12p2 0.5\n6: chronic  one w06p1 0.5\n7: chronic  one w12p1 0.5\n8: chronic  two d07p2 0.5\n9: chronic  two w12p2 0.5\n\n$r_ec\n      silo rand   p\n1:   early    Y 0.6\n2:    late    Y 0.6\n3: chronic    Y 0.6\n\n$r_c\n       c   p\n1: norif 0.5\n2:   rif 0.5\n\n\nThe following function simulates the design matrix.\n\n\nCode\nroadmap.data::get_design\n\n\nfunction(N = 100000, pop_spec = NULL, idx_s = 1){\n\n  if(is.null(pop_spec)){\n    pop_spec &lt;- get_pop_spec()\n  }\n\n  d &lt;- data.table()\n  # pt id\n  d[, id := idx_s:(N+idx_s - 1)]\n  d[, silo := sample(pop_spec$r_silo$silo, size = N, replace = T, prob = pop_spec$r_silo$p)]\n  setkey(d, silo)\n  setkey(pop_spec$r_joint, silo)\n  setkey(pop_spec$r_ea, silo)\n  for(z in pop_spec$r_silo$silo){\n    d[z, joint :=\n        sample(pop_spec$r_joint[z, joint], size = .N, replace = T, prob = pop_spec$r_joint[z, p])\n    ]\n\n    # might as well set ea (eligibility for domain a)\n    d[z, ea := pop_spec$r_ea[z, rand]]\n  }\n\n  # Surgery domain (A)\n  setkey(pop_spec$r_a, silo)\n  d[\"early\", a := \"dair\"]\n  z &lt;- \"late\"\n  d[z, a := sample(pop_spec$r_a[z, a], size = .N, replace = T, prob = pop_spec$r_a[z, p])]\n  z &lt;- \"chronic\"\n  d[z, a := sample(pop_spec$r_a[z, a], size = .N, replace = T, prob = pop_spec$r_a[z, p])]\n\n  # introduce the intended surgical approach (for late stage allocated to revision)\n  setkey(d, silo, a)\n  setkey(pop_spec$r_a_q, silo, a)\n  d[.(\"late\", \"rev\"), qa :=\n      sample(pop_spec$r_a_q[.(\"late\", \"rev\"), qa], size = .N, replace = T, prob = pop_spec$r_a_q[.(\"late\", \"rev\"), p])]\n  d[is.na(qa), qa := copy(a)]\n\n  # Duration domain (B)\n  # eligibility based on a\n  d &lt;- merge(d, pop_spec$r_eb[, .(qa, eb = rand)], by = c(\"qa\"), all.x = T)\n  setcolorder(d, c(\"id\", \"silo\", \"joint\", \"ea\", \"a\", \"qa\",\"eb\"))\n  setkey(d, id)\n\n  setkey(d, qa)\n  setkey(pop_spec$r_b, qa)\n  # all dair get 12wk\n  d[\"dair\", b := pop_spec$r_b[\"dair\", unique(b)]]\n\n  setkey(d, silo, qa)\n  setkey(pop_spec$r_b, silo, qa)\n\n  # do these separately so that triggers can coordinate silo specific adaptations\n  d[.(\"late\", \"one\"), b := sample(\n    pop_spec$r_b[.(\"late\", \"one\"), b], size = .N, replace = T,\n    prob = pop_spec$r_b[.(\"late\", \"one\"), p])]\n  d[.(\"late\", \"two\"), b := sample(\n    pop_spec$r_b[.(\"late\", \"two\"), b], size = .N, replace = T,\n    prob = pop_spec$r_b[.(\"late\", \"two\"), p])]\n\n  d[.(\"chronic\", \"one\"), b := sample(\n    pop_spec$r_b[.(\"chronic\", \"one\"), b], size = .N, replace = T,\n    prob = pop_spec$r_b[.(\"chronic\", \"one\"), p])]\n  d[.(\"chronic\", \"two\"), b := sample(\n    pop_spec$r_b[.(\"chronic\", \"two\"), b], size = .N, replace = T,\n    prob = pop_spec$r_b[.(\"chronic\", \"two\"), p])]\n\n  setkey(d, id)\n\n  # Antibiotic type domain (C)\n\n  # Here I make eligibility random to reflect that some of our cohort will not\n  # enter into this domain, irrespective of their randomisation in other domains.\n  # Each silo is allowed to have a different proportion of pts entering into\n  # domain C.\n  setkey(d, silo)\n  setkey(pop_spec$r_ec, silo)\n\n  for(z in pop_spec$r_ec$silo){\n    d[z, ec :=\n        sample(c(\"Y\",\"N\"), size = .N, replace = T, prob = c(pop_spec$r_ec[z, p], 1- pop_spec$r_ec[z, p]))\n    ]\n  }\n\n  d[ec == \"Y\",\n    c := sample(pop_spec$r_c[, c], size = .N, replace = T, prob = pop_spec$r_c[, p])]\n  d[ec == \"N\", c := \"other\"]\n\n  setkey(d, id)\n\n  d\n}\n&lt;bytecode: 0x1104d7d28&gt;\n&lt;environment: namespace:roadmap.data&gt;\n\n\nThe data generation assumptions imply unique patients groups on which we would observe the outcome. The outcome is known to be heterogenous across these groups and yet the stated goal is to aggregate measures of effect (odds ratios) across all these groups, e.g. no rif vs rif. However, the effect of interest is assumed to be obtained from the model parameter that characterises the effect of antibiotic type conditional on the other covariates in the model.\n\n\nCode\nd &lt;- roadmap.data::get_design()\nunique(d[order(silo, joint, ea, a, qa, eb, b, ec, c), .SD, .SDcols = !c(\"id\")])\n\n\n       silo joint ea    a   qa eb     b ec     c\n 1: chronic   hip  Y  one  one  Y w06p1  N other\n 2: chronic   hip  Y  one  one  Y w06p1  Y norif\n 3: chronic   hip  Y  one  one  Y w06p1  Y   rif\n 4: chronic   hip  Y  one  one  Y w12p1  N other\n 5: chronic   hip  Y  one  one  Y w12p1  Y norif\n 6: chronic   hip  Y  one  one  Y w12p1  Y   rif\n 7: chronic   hip  Y  two  two  Y d07p2  N other\n 8: chronic   hip  Y  two  two  Y d07p2  Y norif\n 9: chronic   hip  Y  two  two  Y d07p2  Y   rif\n10: chronic   hip  Y  two  two  Y w12p2  N other\n11: chronic   hip  Y  two  two  Y w12p2  Y norif\n12: chronic   hip  Y  two  two  Y w12p2  Y   rif\n13: chronic  knee  Y  one  one  Y w06p1  N other\n14: chronic  knee  Y  one  one  Y w06p1  Y norif\n15: chronic  knee  Y  one  one  Y w06p1  Y   rif\n16: chronic  knee  Y  one  one  Y w12p1  N other\n17: chronic  knee  Y  one  one  Y w12p1  Y norif\n18: chronic  knee  Y  one  one  Y w12p1  Y   rif\n19: chronic  knee  Y  two  two  Y d07p2  N other\n20: chronic  knee  Y  two  two  Y d07p2  Y norif\n21: chronic  knee  Y  two  two  Y d07p2  Y   rif\n22: chronic  knee  Y  two  two  Y w12p2  N other\n23: chronic  knee  Y  two  two  Y w12p2  Y norif\n24: chronic  knee  Y  two  two  Y w12p2  Y   rif\n25:   early   hip  N dair dair  N   w12  N other\n26:   early   hip  N dair dair  N   w12  Y norif\n27:   early   hip  N dair dair  N   w12  Y   rif\n28:   early  knee  N dair dair  N   w12  N other\n29:   early  knee  N dair dair  N   w12  Y norif\n30:   early  knee  N dair dair  N   w12  Y   rif\n31:    late   hip  Y dair dair  N   w12  N other\n32:    late   hip  Y dair dair  N   w12  Y norif\n33:    late   hip  Y dair dair  N   w12  Y   rif\n34:    late   hip  Y  rev  one  Y w06p1  N other\n35:    late   hip  Y  rev  one  Y w06p1  Y norif\n36:    late   hip  Y  rev  one  Y w06p1  Y   rif\n37:    late   hip  Y  rev  one  Y w12p1  N other\n38:    late   hip  Y  rev  one  Y w12p1  Y norif\n39:    late   hip  Y  rev  one  Y w12p1  Y   rif\n40:    late   hip  Y  rev  two  Y d07p2  N other\n41:    late   hip  Y  rev  two  Y d07p2  Y norif\n42:    late   hip  Y  rev  two  Y d07p2  Y   rif\n43:    late   hip  Y  rev  two  Y w12p2  N other\n44:    late   hip  Y  rev  two  Y w12p2  Y norif\n45:    late   hip  Y  rev  two  Y w12p2  Y   rif\n46:    late  knee  Y dair dair  N   w12  N other\n47:    late  knee  Y dair dair  N   w12  Y norif\n48:    late  knee  Y dair dair  N   w12  Y   rif\n49:    late  knee  Y  rev  one  Y w06p1  N other\n50:    late  knee  Y  rev  one  Y w06p1  Y norif\n51:    late  knee  Y  rev  one  Y w06p1  Y   rif\n52:    late  knee  Y  rev  one  Y w12p1  N other\n53:    late  knee  Y  rev  one  Y w12p1  Y norif\n54:    late  knee  Y  rev  one  Y w12p1  Y   rif\n55:    late  knee  Y  rev  two  Y d07p2  N other\n56:    late  knee  Y  rev  two  Y d07p2  Y norif\n57:    late  knee  Y  rev  two  Y d07p2  Y   rif\n58:    late  knee  Y  rev  two  Y w12p2  N other\n59:    late  knee  Y  rev  two  Y w12p2  Y norif\n60:    late  knee  Y  rev  two  Y w12p2  Y   rif\n       silo joint ea    a   qa eb     b ec     c",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#footnotes",
    "href": "notebooks/population-structure.html#footnotes",
    "title": "Population structure",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThat is, the data generating process assumes the choice of one vs two-stage in the late acute silo is completely random (not at risk of confounding by risk). At some stage we will need to explore the consequences of non-random choice.↩︎",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "This site contains notes, data summaries and simulation results for the ROADMAP study.\nAll the code can be found on github, just use the icon to the top right. The functionality herein has a dependency on the roadmap.data R package, which can also be found via the above link (see the readme for this repo). If you find any issues, let me know and I will prioritise accordingly.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#notes",
    "href": "index.html#notes",
    "title": "Overview",
    "section": "Notes",
    "text": "Notes\n\nDoes not explore impact of effect heterogeneity on \\(C\\)",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "etc/readme.html",
    "href": "etc/readme.html",
    "title": "readme",
    "section": "",
    "text": "readme\nfile name format is\ncfg-sim&lt;sim-id&gt;-&lt;scenario-id&gt;-&lt;variant-id&gt;\nuse sed for efficient updating, e.g. \n\nChange number of simulations from 10 to 500:\n\ngsed -i 's/nsim:\\ 10/nsim:\\ 500/' cfg-sim01-sc01-0*.yml\n\nUpdate scenario label:\n\ngsed -i 's/sc01/sc02/' cfg-sim01-sc02-0*.yml"
  },
  {
    "objectID": "notebooks/model-spec.html",
    "href": "notebooks/model-spec.html",
    "title": "Model specification",
    "section": "",
    "text": "The primary outcome is treatment success at 12 months post platform entry, defined as all of:\nhereafter referred to as ‘treatment success’.\nFor each silo and site of infectioin we model the probability of treatment success as follows:\nwhere",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#priors",
    "href": "notebooks/model-spec.html#priors",
    "title": "Model specification",
    "section": "Priors",
    "text": "Priors\nAs with the linear predictor, the priors are currently targeted towards the simulation work but may be appropriate for the final model.\n\nIntercepts\nThe silo and infection site specific intercepts are given independent normal priors\n\\[\\begin{aligned}\n\\alpha_{s(i),u(i)} \\sim \\mathcal{N}(0, 1.5^2)\n\\end{aligned}\\]\nOn the probability scale, these concentrate on 0.5 with 95% of the density between 0.04 and 0.96, approximately uniform across this interval.\nWhile the intercept priors are currently independent, consideration should be given to partial pooling across site of infection. However, the concept of exchangeability is perhaps dubious for this set of parameters due to the fact that the baseline log-odds of success must be interpreted based on the domain level options available to each group.\nFor example, there are no randomisation options for early stage infection in domains A and B and therefore the baseline log-odds (intercept) refers to the cohort of patients that were not randomised within A nor B and randomised to the reference group for domain C. In contrast, for the late stage patients, the baseline log-odds of treatment success is interpreted contextually for the cohort of patients that were randomised to the reference level of domains A, B and C, see below.\n\n\nGroups corresponding to baseline log-odds of treatment success\n\n\nSilo\nA\nB\nC\n\n\n\n\nearly\n-\n-\nno-rif\n\n\nlate\ndair\n-\nno-rif\n\n\nchronic\none\n6wk\nno-rif\n\n\n\n\n\n\nDomain non-membership\nThe domain non-membership parameters are given standard normal independent priors. These parameters are pooled across all silos.\n\\[\\begin{aligned}\n\\gamma_\\mathcal{D} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\n\n\nInterventions\nA hierarchical prior structure may be appropriate for some of the intervention effects dependent on what can be assumed regarding exchangeability.\n\nSurgical domain\nSilo-specific, independent normal priors are assumed for the surgical domain. There is no pooling, we simply compare dair vs revision in the late stage patients and one vs two stage in the chronic stage patients.\n\\[\\begin{aligned}\n\\beta_{A,s,d_{A,j}} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\nThe reference level is set to 0.\n\n\nAntibiotic duration domain\nWhile a hierarchical structure could be considered for this domain, independent normal priors are currenlty assumed for the duration domain. Currently, there is no pooling. We compare 6 vs 12 weeks for late stage patients having a one stage procedure and 7 days vs 12 wks for those having a two stage procedure. Independently, we compare 6 vs 12 weeks for chronic stage patients having a one stage procedure and 7 days vs 12 wks for those having a two stage procedure.\n\\[\\begin{aligned}\n\\beta_{B_k,s,d_{B,j}} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\nThe reference level is set to 0.\nTheoretically, partial pooling could be implemented across the late and chronic silos.\n\n\nAntibiotic type domain\nA hierarchical structure could also be considered for this domain. The ‘average’ across silos could be obtained by sampling from the posterior assuming normality based on the parameter for the group variance. With three groups the extent of the partial pooling is going to be heavily influenced by the prior rather than the data.\nCurrently we adopt a standard normal prior for the treatment effects in this domain, which are completely pooled across silos.\n\\[\\begin{aligned}\n\\beta_{C,d_{C,j}} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\nThe reference level is set to 0.",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#footnotes",
    "href": "notebooks/model-spec.html#footnotes",
    "title": "Model specification",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn practice, it may be the case that non-membership for domain \\(B\\) is relevant. For example, if an early stage patient receives a one or two-stage surgical procedure.↩︎\nAs such, silo-specific decisions on antibiotic type are not possible.↩︎",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/misc-notes.html",
    "href": "notebooks/misc-notes.html",
    "title": "notes",
    "section": "",
    "text": "[JT]\nGiven that we assume the effect of revision is conditional on the nature of that revision, it’s not clear to me what “DAIR vs. Revision” means for late infection silo,\nJust thinking through it for myself…\nThe options are:\n\nA = DAIR -&gt; B = 12w\nA = Revision(one) -&gt; B in {12w, 6w}\nA = Revision(two) -&gt; B in {12w, 7d}\nC in (no rifampicin, rifampicin)\n\nCurrently, (just focusing on surgery/duration, and making 12w the reference for all groups rather than 7w/6d) cell parameters as specified in the model are:\n\\[\\begin{aligned}\n\\begin{pmatrix}\nDAIR & \\alpha \\\\\nRev (one), 12w & \\alpha + \\beta_A \\\\\nRev (two), 12w & \\alpha + \\beta_A \\\\\nRev (one), 6w & \\alpha + \\beta_A + \\beta_{B1} \\\\\nRev (two), 7d & \\alpha + \\beta_A + \\beta_{B2} \\\\\n\\end{pmatrix}\n\\end{aligned}\\]\nSo, effect of one-stage + 12 w assumed equal to the effect of two-stage + 12w, then revision type specific deviations from those. And “DAIR vs Revision” (beta_A) is really DAIR vs. weighted average of one-stage 12w and two-stage 12w, i.e. ignores the duration options.\nI’m guessing this is the only randomised comparison we can make: a weighted average of one/two + 12w is the “default” revision.\nAs an alternative, I assume it’s plausible that one-stage 12w and two-stage 12w differ due to clinician selection of one/two stage. So there may be preference (or maybe it just makes things messy) to have something like\n\\[\\begin{aligned}\n\\begin{pmatrix}\nDAIR & \\alpha \\\\\nRev (one), 12w & \\alpha + \\beta_{A1} \\\\\nRev (two), 12w & \\alpha + \\beta_{A2} \\\\\nRev (one), 6w & \\alpha + \\beta_{A1} + \\beta_{B1} \\\\\nRev (two), 7d & \\alpha + \\beta_{A2} + \\beta_{B2} \\\\\n\\end{pmatrix}\n\\end{aligned}\\]\nNoting that \\(\\beta_{A1}\\) and \\(\\beta_{A2}\\) aren’t “causal” in the sense that any differences could just be due to selection bias rather than differences in effectiveness of one/two stage.\nThe effect of revision versus DAIR will depend on what “revision” means, is it everyone gets one-stage 12 w? 25% get each of the 4 options? Everyone gets two-stage then 50/50 to 12w/7d?\nAssume that \\(p_{A1}\\) is the proportion randomised to revision who are selected to receive one-stage and \\(1 - p_{A1}\\) the proportion selected to receive two-stage. Then the comparison for any revision versus DAIR might be taken to mean\n\\[\\begin{aligned}\np_{A1} (0.5 \\beta_{A1} + 0.5 (\\beta_{A1} + \\beta_{B1})) +  (1 0 p_{A1})(0.5\\beta_{A2} + 0.5(\\beta_{A2} + \\beta_{B2}))\n\\end{aligned}\\]\nwhich just explicitly allows for the differences. Or some other combination of groups, where we assume that selection of one/two stage in the trial is the same in the population. Presumably though there are issues in interpreting such a comparison as “causal”, unless also adjust for factors determining one/two stage selection.\nNow that I’ve written this out, I think that the model as currently stated is probably the better one to use given it sticks with what’s randomised. So long as it’s clear that “DAIR vs. Revision” is really “DAIR vs weighted average of 12w one/two stage”."
  },
  {
    "objectID": "notebooks/misc-notes.html#late-infection-2024-01-19",
    "href": "notebooks/misc-notes.html#late-infection-2024-01-19",
    "title": "notes",
    "section": "",
    "text": "[JT]\nGiven that we assume the effect of revision is conditional on the nature of that revision, it’s not clear to me what “DAIR vs. Revision” means for late infection silo,\nJust thinking through it for myself…\nThe options are:\n\nA = DAIR -&gt; B = 12w\nA = Revision(one) -&gt; B in {12w, 6w}\nA = Revision(two) -&gt; B in {12w, 7d}\nC in (no rifampicin, rifampicin)\n\nCurrently, (just focusing on surgery/duration, and making 12w the reference for all groups rather than 7w/6d) cell parameters as specified in the model are:\n\\[\\begin{aligned}\n\\begin{pmatrix}\nDAIR & \\alpha \\\\\nRev (one), 12w & \\alpha + \\beta_A \\\\\nRev (two), 12w & \\alpha + \\beta_A \\\\\nRev (one), 6w & \\alpha + \\beta_A + \\beta_{B1} \\\\\nRev (two), 7d & \\alpha + \\beta_A + \\beta_{B2} \\\\\n\\end{pmatrix}\n\\end{aligned}\\]\nSo, effect of one-stage + 12 w assumed equal to the effect of two-stage + 12w, then revision type specific deviations from those. And “DAIR vs Revision” (beta_A) is really DAIR vs. weighted average of one-stage 12w and two-stage 12w, i.e. ignores the duration options.\nI’m guessing this is the only randomised comparison we can make: a weighted average of one/two + 12w is the “default” revision.\nAs an alternative, I assume it’s plausible that one-stage 12w and two-stage 12w differ due to clinician selection of one/two stage. So there may be preference (or maybe it just makes things messy) to have something like\n\\[\\begin{aligned}\n\\begin{pmatrix}\nDAIR & \\alpha \\\\\nRev (one), 12w & \\alpha + \\beta_{A1} \\\\\nRev (two), 12w & \\alpha + \\beta_{A2} \\\\\nRev (one), 6w & \\alpha + \\beta_{A1} + \\beta_{B1} \\\\\nRev (two), 7d & \\alpha + \\beta_{A2} + \\beta_{B2} \\\\\n\\end{pmatrix}\n\\end{aligned}\\]\nNoting that \\(\\beta_{A1}\\) and \\(\\beta_{A2}\\) aren’t “causal” in the sense that any differences could just be due to selection bias rather than differences in effectiveness of one/two stage.\nThe effect of revision versus DAIR will depend on what “revision” means, is it everyone gets one-stage 12 w? 25% get each of the 4 options? Everyone gets two-stage then 50/50 to 12w/7d?\nAssume that \\(p_{A1}\\) is the proportion randomised to revision who are selected to receive one-stage and \\(1 - p_{A1}\\) the proportion selected to receive two-stage. Then the comparison for any revision versus DAIR might be taken to mean\n\\[\\begin{aligned}\np_{A1} (0.5 \\beta_{A1} + 0.5 (\\beta_{A1} + \\beta_{B1})) +  (1 0 p_{A1})(0.5\\beta_{A2} + 0.5(\\beta_{A2} + \\beta_{B2}))\n\\end{aligned}\\]\nwhich just explicitly allows for the differences. Or some other combination of groups, where we assume that selection of one/two stage in the trial is the same in the population. Presumably though there are issues in interpreting such a comparison as “causal”, unless also adjust for factors determining one/two stage selection.\nNow that I’ve written this out, I think that the model as currently stated is probably the better one to use given it sticks with what’s randomised. So long as it’s clear that “DAIR vs. Revision” is really “DAIR vs weighted average of 12w one/two stage”."
  },
  {
    "objectID": "notebooks/model-implementation.html",
    "href": "notebooks/model-implementation.html",
    "title": "Model implementation",
    "section": "",
    "text": "The simplest implementation I could think of split the data into silo-specific chunks, mimicking the formulation in the model specification earlier.\n\n\ndata {\n  // early\n  int N_e;\n  array[N_e] int e_su;\n  array[N_e] int e_y;\n  array[N_e] int e_n;\n  vector[N_e] e_ec; // membership\n  vector[N_e] e_ecp; // non-membership, ie 1 - e_ec\n  array[N_e] int e_c;\n  \n  int N_l;\n  array[N_l] int l_su;\n  array[N_l] int l_y;\n  array[N_l] int l_n;\n  vector[N_l] l_ec;\n  vector[N_l] l_ecp; // 1 - l_ec\n  array[N_l] int l_c;\n  vector[N_l] l_ea;\n  vector[N_l] l_eap;\n  array[N_l] int l_a;\n  vector[N_l] l_eb1;\n  vector[N_l] l_eb2;\n  vector[N_l] l_ebp;\n  array[N_l] int l_b;\n  \n  int N_c;\n  array[N_c] int c_su;\n  array[N_c] int c_y;\n  array[N_c] int c_n;\n  vector[N_c] c_ec;\n  vector[N_c] c_ecp; // 1 - c_ec\n  array[N_c] int c_c;\n  vector[N_c] c_ea;\n  vector[N_c] c_eap;\n  array[N_c] int c_a;\n  vector[N_c] c_eb1;\n  vector[N_c] c_eb2;\n  vector[N_c] c_ebp;\n  array[N_c] int c_b;\n  \n  // priors\n  real pri_sig_b_c;\n  real pri_sig_a_l;\n  real pri_sig_b1_l;\n  real pri_sig_b2_l;\n  real pri_sig_a_c;\n  real pri_sig_b1_c;\n  real pri_sig_b2_c;\n  \n}\ntransformed data {\n  int N = N_e + N_l + N_c;\n}\nparameters {\n  vector[6] alpha;\n  // real gamma_b;\n  real gamma_c;\n  real b_a_l_raw;\n  real b_b1_l_raw;\n  real b_b2_l_raw;\n  real b_a_c_raw;\n  real b_b1_c_raw;\n  real b_b2_c_raw;\n  real b_c_raw;\n}\ntransformed parameters{\n  // Include non-randomised items in parameter vector but set to zero \n  // see b_c[3] below. Gives a simpler way to build up model without index\n  // overrun or conditionals for building linear predictor.\n  \n  vector[2] b_a_l; // dair vs revision (late silo)\n  vector[3] b_b1_l; // note length - dair vs revision (late silo, recvd one-stage)\n  vector[3] b_b2_l; // note length - dair vs revision (late silo, recvd two-stage)\n  \n  vector[2] b_a_c; // dair vs revision (chronic silo)\n  vector[2] b_b1_c; // dair vs revision (chronic silo, recvd one-stage)\n  vector[2] b_b2_c; // dair vs revision (chronic silo, recvd two-stage)\n  \n  vector[3] b_c; // note length\n\n  b_a_l[1] = 0.0;\n  b_a_l[2] = b_a_l_raw;\n\n  b_b1_l[1] = 0.0;\n  b_b1_l[2] = b_b1_l_raw;\n  b_b1_l[3] = 0.0;\n   \n  b_b2_l[1] = 0.0;\n  b_b2_l[2] = b_b2_l_raw;\n  b_b2_l[3] = 0.0;\n  \n  b_a_c[1] = 0.0;\n  b_a_c[2] = b_a_c_raw;\n\n  b_b1_c[1] = 0.0;\n  b_b1_c[2] = b_b1_c_raw;\n\n  b_b2_c[1] = 0.0;\n  b_b2_c[2] = b_b2_c_raw;\n   \n  b_c[1] = 0.0;\n  b_c[2] = b_c_raw;\n  // handles other, but this can be ignored in post-processing\n  b_c[3] = 0.0;\n}\nmodel{\n  target += normal_lpdf(alpha | 0, 1.5);\n  \n  // target += std_normal_lpdf(gamma_b);\n  target += std_normal_lpdf(gamma_c);\n  // all silos\n  target += normal_lpdf(b_c_raw | 0, pri_sig_b_c);\n  // late silo\n  target += normal_lpdf(b_a_l_raw | 0, pri_sig_a_l);\n  target += normal_lpdf(b_b1_l_raw | 0, pri_sig_b1_l);\n  target += normal_lpdf(b_b2_l_raw | 0, pri_sig_b2_l);\n  // chronic silo\n  target += normal_lpdf(b_a_c_raw | 0, pri_sig_a_c);\n  target += normal_lpdf(b_b1_c_raw | 0, pri_sig_b1_c);\n  target += normal_lpdf(b_b2_c_raw | 0, pri_sig_b2_c);\n  \n  // likelihood chunks pertaining to each silo\n  target += binomial_logit_lpmf(e_y | e_n, alpha[e_su] +\n                                      e_ecp * gamma_c + \n                                      e_ec .* b_c[e_c]) ;      \n                                    \n  target += binomial_logit_lpmf(l_y | l_n, alpha[l_su] + \n                                    l_ecp * gamma_c +\n                                    l_ea .* b_a_l[l_a] +\n                                    l_eb1 .* b_b1_l[l_b] +  \n                                    l_eb2 .* b_b2_l[l_b] +\n                                    l_ec .* b_c[l_c]\n                                    ) ;    \n                                    \n  target += binomial_logit_lpmf(c_y | c_n, alpha[c_su] +\n                                      c_ecp * gamma_c +\n                                      c_ea .* b_a_c[c_a] +\n                                      c_eb1 .* b_b1_c[c_b] + \n                                      c_eb2 .* b_b2_c[c_b] +\n                                      c_ec .* b_c[c_c]) ; \n}\ngenerated quantities{\n  vector[N_e] eta_e ;\n  vector[N_l] eta_l ;\n  vector[N_c] eta_c ;\n  vector[N] eta;\n  \n  eta_e = alpha[e_su] + e_ecp * gamma_c + e_ec .* b_c[e_c];\n  eta_l = alpha[l_su] + l_ecp * gamma_c +\n    l_ea .* b_a_l[l_a] + \n    l_eb1 .* b_b1_l[l_b] + l_eb2 .* b_b2_l[l_b] +\n    l_ec .* b_c[l_c];\n  eta_c = alpha[c_su] + c_ecp * gamma_c +\n    c_ea .* b_a_c[c_a] +\n    c_eb1 .* b_b1_c[c_b] + c_eb2 .* b_b2_c[c_b] +\n    c_ec .* b_c[c_c];\n    \n  eta = append_row(eta_e, append_row(eta_l, eta_c));\n\n}\n\n\nBelow I create a data set with a million patients (orders of magnitude more than we will have available) to see if we can get anywhere close to recovering the parameters - if we cannot recover the parameters with this many records, we are certainly not going to be able to do so with 2500 patients.\nThen I fit the stan model and extract and summarise the posterior.\n\n\nCode\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-02.stan\")\n\nset.seed(1)\nll &lt;- get_trial_data(N = 1e6)\nlsd &lt;- get_stan_data(ll$d_i)\nld &lt;- lsd$ld\n# cbind(ld$l_su, ld$l_y, ld$l_n, ld$l_ea, ld$l_eap, ld$l_a)\nd_b &lt;- copy(lsd$d_b)\n\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.5 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.6 seconds.\n\n\nCode\npost &lt;- data.table(f2$draws(variables = c(\n  \"eta\"\n), format = \"matrix\"))\n\n# create index field\npost &lt;- melt(post, measure.vars = names(post))\npost[, idx := gsub(\".*\\\\[\", \"\", variable)]\npost[, idx := gsub(\"\\\\]\", \"\", idx)]\npost[, idx := as.integer(idx)]\n\nd_fig &lt;- cbind(d_b, post[, .(eta_med = median(value), \n         eta_q025 = quantile(value, prob = 0.025),\n         eta_q975 = quantile(value, prob = 0.975)), keyby = idx])\n\n\nFigure 1 shows a comparison between the true log-odds of treatment success with the 95% credible interval obtained from the model. It suggests a strong association between the true and estimated log-odds of treatment success for this particular dataset.\n\n\nCode\nggplot(d_fig, aes(x = eta, y = eta_med)) +\n  # geom_point() +\n  geom_linerange(aes(ymin = eta_q025, ymax = eta_q975)) +\n  geom_abline(intercept = 0, slope = 1, lwd = 0.1) +\n  scale_x_continuous(\"True log-odds success\") +\n  scale_y_continuous(\"Posterior log-odds success (95% credible interval)\") +\n  facet_grid(silo ~ joint) +\n  ggtitle(\"True log-odds success vs 95% credible interval\")\n\n\n\n\n\n\n\n\nFigure 1: Scatter plot comparing true vs estimated 95% credible interval for log-odds treatment success.\n\n\n\n\n\n\n\nCode\npost &lt;- data.table(f2$draws(variables = c(\n    \"alpha\", \"gamma_c\", \n    \"b_a_l\", \n    \"b_b1_l\", \n    \"b_b2_l\",\n    \"b_a_c\",\n    \"b_b1_c\", \n    \"b_b2_c\",\n    \"b_c\"\n  ), format = \"matrix\"))\n  \n\n# test outcome\ncols &lt;- names(post)\ncols &lt;- gsub(\"[\",\"_\",cols,fixed = T)\ncols &lt;- gsub(\"]\",\"\",cols,fixed = T)\nnames(post) &lt;- cols\n  \n# effects\neffs &lt;- c(\n  # domain a, late (revision) and chronic (two-stage)\n  \"b_a_l_2\", \"b_a_c_2\", \n  # domain b, (late/revision one stage pts)\n  # wk12p1 (ref is wk6p1)\n  \"b_b1_l_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_l_2\", \n  # wk12p1 (ref is wk6p1)\n  \"b_b1_c_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_c_2\",\n  # rif (ref is no-rif)\n  \"b_c_2\")\n  \nd_beta &lt;- post[, .SD, .SDcols = effs]\nd_beta &lt;- melt(d_beta, measure.vars = names(d_beta))\n# unique(d_beta$variable)\n\n\nparname_map &lt;- roadmap.data::get_par_effects_mapping()\nd_beta[, parname := parname_map[variable]]\nd_beta[, parname := factor(parname, levels = roadmap.data::get_par_effects_mapping())]\n\nd_fig &lt;- d_beta[, .(\n  lor_med = median(value), \n  lor_q025 = quantile(value, prob = 0.025),\n  lor_q975 = quantile(value, prob = 0.975)), keyby = parname]\n\nd_effects &lt;- roadmap.data::get_sim_spec_effects(roadmap.data::get_sim_spec())\nd_effects &lt;- melt(d_effects, measure.vars = names(d_effects), value.name = \"lor\")\n\nd_fig &lt;- merge(d_fig, d_effects, by.x = \"parname\", by.y = \"variable\")\n\n\nFigure 1 shows a comparison between the true log-odds of treatment success with the 95% credible interval obtained from the model. It suggests a strong association between the true and estimated log-odds of treatment success for this particular dataset.\n\n\nCode\nggplot(d_fig, aes(x = parname, y = lor_med)) +\n  geom_point() +\n  geom_point(data = d_fig, aes(x = parname, y = lor), pch = 2) +\n  geom_linerange(aes(ymin = lor_q025, ymax = lor_q975))  +\n  scale_x_discrete(\"\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Posterior log-odds-ratio (95% credible interval)\") \n\n\n\n\n\n\n\n\nFigure 2: Posterior estimates for log-odds-ratios (true values shown as triangles).\n\n\n\n\n\n\n\nCode\npost &lt;- data.table(f2$draws(variables = c(\n    \"alpha\", \"gamma_c\", \n    \"b_a_l\", \n    \"b_b1_l\", \n    \"b_b2_l\",\n    \"b_a_c\",\n    \"b_b1_c\", \n    \"b_b2_c\",\n    \"b_c\"\n  ), format = \"matrix\"))\n  \n\n# test outcome\ncols &lt;- names(post)\ncols &lt;- gsub(\"[\",\"_\",cols,fixed = T)\ncols &lt;- gsub(\"]\",\"\",cols,fixed = T)\nnames(post) &lt;- cols\n  \n# effects\npars &lt;- c(\n  \"alpha\", \"gamma_c\", \n  # domain a, late (revision) and chronic (two-stage)\n  \"b_a_l_2\", \"b_a_c_2\", \n  # domain b, (late/revision one stage pts)\n  # wk12p1 (ref is wk6p1)\n  \"b_b1_l_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_l_2\", \n  # wk12p1 (ref is wk6p1)\n  \"b_b1_c_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_c_2\",\n  # rif (ref is no-rif)\n  \"b_c_2\")\n  \nd_pars &lt;- post[, .SD, .SDcols = effs]\nm_cor &lt;- d_pars[, cor(.SD)]\nd_cor &lt;- data.table(cbind(var1 = rownames(m_cor), m_cor))\nd_cor &lt;- melt(d_cor, id.vars = \"var1\", variable.name = \"var2\")\nd_cor[, value := as.numeric(value)]\n\nd_cor[, `:=`(\n  var1 = factor(var1, levels = c(pars[length(pars):1])),\n  var2 = factor(var2, levels = c(pars[length(pars):1]))\n)]\n\n\nFigure 3 shows the correlation between parameters estimated from the model.\n\n\nCode\nggplot(d_cor, aes(x = var1, y = var2, fill = value)) +\n  geom_tile(color = \"white\",\n            lwd = 1.5,\n            linetype = 1) +\n  geom_text(aes(label = round(value, 2)), color = \"white\", size = 4) +\n  scale_x_discrete(\"\",position = \"top\", limits=rev) +\n  scale_y_discrete(\"\") + \n  scale_fill_gradient2(\"Pearson correlation\") +\n  coord_fixed()\n\n\n\n\n\n\n\n\nFigure 3: Parameter correlation (white indicates zero correlation)",
    "crumbs": [
      "Design",
      "Model implementation"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html",
    "href": "notebooks/example-trials.html",
    "title": "Example trials",
    "section": "",
    "text": "Example trials are provided to give insight into the cell sizes as well as the level of uncertainty associated with the parameter estimation process. Examples are from trials at their maximum sample size with all follow up completed. Sequential variants with adaptations will be added later.",
    "crumbs": [
      "Design",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html#null-scenario",
    "href": "notebooks/example-trials.html#null-scenario",
    "title": "Example trials",
    "section": "Null scenario",
    "text": "Null scenario\nTable 1 shows a summary of the treatment sucesses based on the \\(n\\) patients associated with each combination of design variables when no treatment effects (non-membership effects still retained) in the simulated data of 2500 patients. Given that this is a summary of a single data set, some variation from the underlying simulation parameters is to be expected.\n\n\nCode\nsim_spec &lt;- get_sim_spec()\nsim_spec$b_a_late[\"rev\"] &lt;- 0\nsim_spec$b_a_chronic[\"two\"] &lt;- 0\nsim_spec$b_b1_late_one[\"w12p1\"] &lt;- 0\nsim_spec$b_b2_late_two[\"w12p2\"] &lt;- 0\nsim_spec$b_b1_chronic_one[\"w12p1\"] &lt;- 0\nsim_spec$b_b2_chronic_two[\"w12p2\"] &lt;- 0\nsim_spec$b_c[\"rif\"] &lt;- 0\n\nset.seed(15)\nll &lt;- get_trial_data(N = 2500, pop_spec = NULL, sim_spec = sim_spec)\n\ngt_tbl &lt;- tbl_ex_trial(ll$d)\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSurgical Da\nDuration Db\nType Dc\nResponse\n\n\nmember\nassigned\nplan\nmember\nassigned1\nmember\nassigned\ny\nn\nMLE (py)\nTRUE (py)2\n\n\n\n\nearly - knee\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n77\n122\n0.63\n0.63\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n62\n93\n0.67\n0.65\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n60\n93\n0.65\n0.65\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n199\n308\n0.65\n—\n\n\nearly - hip\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n147\n199\n0.74\n0.73\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n108\n137\n0.79\n0.75\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n85\n123\n0.69\n0.75\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n340\n459\n0.74\n—\n\n\nlate - knee\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n29\n58\n0.50\n0.52\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n26\n55\n0.47\n0.55\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n32\n47\n0.68\n0.55\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n15\n30\n0.50\n0.52\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n7\n14\n0.50\n0.55\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n9\n17\n0.53\n0.55\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n8\n20\n0.40\n0.52\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n6\n10\n0.60\n0.55\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n6\n12\n0.50\n0.55\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n11\n22\n0.50\n0.52\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n8\n15\n0.53\n0.55\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n10\n18\n0.56\n0.55\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n16\n26\n0.62\n0.52\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n4\n6\n0.67\n0.55\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n5\n8\n0.62\n0.55\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n192\n358\n0.54\n—\n\n\nlate - hip\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n88\n170\n0.52\n0.57\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n76\n120\n0.63\n0.60\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n80\n127\n0.63\n0.60\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n22\n37\n0.59\n0.57\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n16\n26\n0.62\n0.60\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n18\n33\n0.55\n0.60\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n32\n52\n0.62\n0.57\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n13\n28\n0.46\n0.60\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n14\n28\n0.50\n0.60\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n21\n37\n0.57\n0.57\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n17\n33\n0.52\n0.60\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n23\n33\n0.70\n0.60\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n23\n44\n0.52\n0.57\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n18\n29\n0.62\n0.60\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n20\n30\n0.67\n0.60\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n481\n827\n0.58\n—\n\n\nchronic - knee\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n15\n27\n0.56\n0.57\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n11\n25\n0.44\n0.60\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n11\n16\n0.69\n0.60\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n14\n20\n0.70\n0.57\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n15\n22\n0.68\n0.60\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n16\n26\n0.62\n0.60\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n22\n34\n0.65\n0.57\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n13\n22\n0.59\n0.60\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n9\n24\n0.38\n0.60\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n14\n28\n0.50\n0.57\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n5\n15\n0.33\n0.60\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n13\n23\n0.57\n0.60\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n158\n282\n0.56\n—\n\n\nchronic - hip\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n19\n27\n0.70\n0.63\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n14\n24\n0.58\n0.65\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n13\n17\n0.76\n0.65\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n8\n19\n0.42\n0.63\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n15\n24\n0.62\n0.65\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n17\n22\n0.77\n0.65\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n10\n22\n0.45\n0.63\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n16\n27\n0.59\n0.65\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n10\n19\n0.53\n0.65\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n21\n29\n0.72\n0.63\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n13\n23\n0.57\n0.65\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n7\n13\n0.54\n0.65\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n163\n266\n0.61\n—\n\n\ntotal\n—\n—\n—\n—\n—\n—\n—\n1533\n2500\n0.61\n—\n\n\n\n1 w06p1 = 6 weeks following one-stage procedure, w12p1 = 12 weeks following one-stage procedure etc\n\n\n2 Transformed from the log-odds of response as used in the linear predictor to simulate data.\n\n\n\n\n\n\n\n\n\nTable 1: Summary of simulated trial data when no treatment effects present\n\n\n\n\nModel the simulated data first using standard normal priors on the domain level treatment effects, then increasing the prior standard deviation to ten in order to see if there is any movement in the posterior summary.\n\n\nCode\nlsd &lt;- get_stan_data(ll$d_i)\nld &lt;- lsd$ld\nd_b &lt;- copy(lsd$d_b)\n\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-02.stan\")\n\nf_null_1 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.5 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.6 seconds.\n\n\nCode\npost_1 &lt;- data.table(f_null_1$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n# compare when prior sd is set to 10 for trt effects\n\npri_sd &lt;- 10\nld$pri_sig_b_c &lt;- pri_sd\nld$pri_sig_a_l &lt;- pri_sd\nld$pri_sig_b1_l &lt;- pri_sd\nld$pri_sig_b2_l &lt;- pri_sd\nld$pri_sig_a_c &lt;- pri_sd\nld$pri_sig_b1_c &lt;- pri_sd\nld$pri_sig_b2_c &lt;- pri_sd\n\nf_null_2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.5 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.5 seconds.\n\n\nCode\npost_2 &lt;- data.table(f_null_2$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n\n\n\nCode\nd_fig1 &lt;- post_alpha(post_1)\nd_fig2 &lt;- post_alpha(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = grp, y = a, group = prior_sd, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-odds treatment success\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = grp, y = a_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = a_q025, ymax = a_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = grp, y = a), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 1: Posterior median and 95% CI for baseline log-odds of treatment success (triangles show true values).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_a(post_1)\nd_fig2 &lt;- post_dom_a(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 2: Posterior median and 95% CI for baseline log-odds of treatment success domain A (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_b(post_1)\nd_fig2 &lt;- post_dom_b(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(paste0(\"Planned/assigned surgery: \", qa, \"-stage\")~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 3: Posterior median and 95% CI for baseline log-odds of treatment success domain B (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_c(post_1)\nd_fig2 &lt;- post_dom_c(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 4: Posterior median and 95% CI for baseline log-odds of treatment success in domain C (effect is pooled across all silos).",
    "crumbs": [
      "Design",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html#all-domains-effective-scenario",
    "href": "notebooks/example-trials.html#all-domains-effective-scenario",
    "title": "Example trials",
    "section": "All domains effective scenario",
    "text": "All domains effective scenario\nshows a summary of the treatment sucesses based on the \\(n\\) patients associated with each combination of design variables when all treatment effects set to log(2) (with non-membership effects retained as before) in the simulated data of 2500 patients.\n\n\nCode\nsim_spec &lt;- get_sim_spec()\nsim_spec$b_a_late[\"rev\"] &lt;- log(2)\nsim_spec$b_a_chronic[\"two\"] &lt;- log(2)\nsim_spec$b_b1_late_one[\"w12p1\"] &lt;- log(2)\nsim_spec$b_b2_late_two[\"w12p2\"] &lt;- log(2)\nsim_spec$b_b1_chronic_one[\"w12p1\"] &lt;- log(2)\nsim_spec$b_b2_chronic_two[\"w12p2\"] &lt;- log(2)\nsim_spec$b_c[\"rif\"] &lt;- log(2)\n\nset.seed(222)\nll &lt;- get_trial_data(N = 2500, pop_spec = NULL, sim_spec = sim_spec)\n\n# just wrapped table generation up into a function to save space and min repitition, see util.R\ngt_tbl &lt;- tbl_ex_trial(ll$d)\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSurgical Da\nDuration Db\nType Dc\nResponse\n\n\nmember\nassigned\nplan\nmember\nassigned1\nmember\nassigned\ny\nn\nMLE (py)\nTRUE (py)2\n\n\n\n\nearly - knee\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n99\n137\n0.72\n0.63\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n73\n103\n0.71\n0.65\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n68\n81\n0.84\n0.79\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n240\n321\n0.75\n—\n\n\nearly - hip\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n147\n189\n0.78\n0.73\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n112\n144\n0.78\n0.75\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n117\n135\n0.87\n0.86\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n376\n468\n0.80\n—\n\n\nlate - knee\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n48\n80\n0.60\n0.52\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n20\n48\n0.42\n0.55\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n37\n51\n0.73\n0.71\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n13\n25\n0.52\n0.69\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n11\n15\n0.73\n0.71\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n15\n16\n0.94\n0.83\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n10\n11\n0.91\n0.81\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n12\n16\n0.75\n0.83\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n12\n13\n0.92\n0.91\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n8\n16\n0.50\n0.69\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n10\n12\n0.83\n0.71\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n17\n19\n0.89\n0.83\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n18\n21\n0.86\n0.81\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n9\n12\n0.75\n0.83\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n10\n10\n1.00\n0.91\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n250\n365\n0.68\n—\n\n\nlate - hip\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n83\n154\n0.54\n0.57\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n69\n114\n0.61\n0.60\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n91\n124\n0.73\n0.75\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n36\n47\n0.77\n0.73\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n29\n44\n0.66\n0.75\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n40\n42\n0.95\n0.86\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n36\n44\n0.82\n0.84\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n38\n44\n0.86\n0.86\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n23\n25\n0.92\n0.92\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n21\n32\n0.66\n0.73\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n22\n32\n0.69\n0.75\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n30\n35\n0.86\n0.86\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n47\n56\n0.84\n0.84\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n34\n37\n0.92\n0.86\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n34\n37\n0.92\n0.92\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n633\n867\n0.73\n—\n\n\nchronic - knee\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n16\n25\n0.64\n0.57\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n9\n17\n0.53\n0.60\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n12\n15\n0.80\n0.75\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n17\n22\n0.77\n0.73\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n10\n13\n0.77\n0.75\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n16\n18\n0.89\n0.86\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n14\n23\n0.61\n0.73\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n11\n16\n0.69\n0.75\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n12\n13\n0.92\n0.86\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n21\n24\n0.88\n0.84\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n16\n19\n0.84\n0.86\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n12\n13\n0.92\n0.92\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n166\n218\n0.76\n—\n\n\nchronic - hip\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n12\n19\n0.63\n0.63\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n13\n21\n0.62\n0.65\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n12\n19\n0.63\n0.79\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n25\n30\n0.83\n0.77\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n10\n11\n0.91\n0.79\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n20\n23\n0.87\n0.88\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n21\n26\n0.81\n0.77\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n19\n24\n0.79\n0.79\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n12\n12\n1.00\n0.88\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n28\n31\n0.90\n0.87\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n24\n28\n0.86\n0.88\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n15\n17\n0.88\n0.94\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n211\n261\n0.81\n—\n\n\ntotal\n—\n—\n—\n—\n—\n—\n—\n1876\n2500\n0.75\n—\n\n\n\n1 w06p1 = 6 weeks following one-stage procedure, w12p1 = 12 weeks following one-stage procedure etc\n\n\n2 Transformed from the log-odds of response as used in the linear predictor to simulate data.\n\n\n\n\n\n\n\n\n\nTable 2: Summary of simulated trial data when no treatment effects present\n\n\n\n\n\n\nCode\nlsd &lt;- get_stan_data(ll$d_i)\nld &lt;- lsd$ld\nd_b &lt;- copy(lsd$d_b)\n\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-02.stan\")\n\nf_alleff_1 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.5 seconds.\nChain 2 finished in 0.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.5 seconds.\n\n\nCode\npost_1 &lt;- data.table(f_alleff_1$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n# compare when prior sd is set to 10 for trt effects\n\npri_sd &lt;- 10\nld$pri_sig_b_c &lt;- pri_sd\nld$pri_sig_a_l &lt;- pri_sd\nld$pri_sig_b1_l &lt;- pri_sd\nld$pri_sig_b2_l &lt;- pri_sd\nld$pri_sig_a_c &lt;- pri_sd\nld$pri_sig_b1_c &lt;- pri_sd\nld$pri_sig_b2_c &lt;- pri_sd\n\nf_alleff_2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.5 seconds.\n\n\nCode\npost_2 &lt;- data.table(f_alleff_2$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n\n\n\nCode\nd_fig1 &lt;- post_alpha(post_1)\nd_fig2 &lt;- post_alpha(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = grp, y = a, group = prior_sd, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-odds treatment success\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = grp, y = a_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = a_q025, ymax = a_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = grp, y = a), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 5: Posterior median and 95% CI for baseline log-odds of treatment success (triangles show true values).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_a(post_1)\nd_fig2 &lt;- post_dom_a(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 6: Posterior median and 95% CI for baseline log-odds of treatment success domain A (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_b(post_1)\nd_fig2 &lt;- post_dom_b(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(paste0(\"Planned/assigned surgery: \", qa, \"-stage\")~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 7: Posterior median and 95% CI for baseline log-odds of treatment success domain B (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_c(post_1)\nd_fig2 &lt;- post_dom_c(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 8: Posterior median and 95% CI for baseline log-odds of treatment success in domain C (effect is pooled across all silos).",
    "crumbs": [
      "Design",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/trial-data.html",
    "href": "notebooks/trial-data.html",
    "title": "Simulated trial data",
    "section": "",
    "text": "Trial data is simulated under the model specification, see earlier section.\n\n\nCode\nll &lt;- get_trial_data(N = 2500)\n\nd_a &lt;- ll$d[silo %in% c(\"late\", \"chronic\"), .(y = sum(y), .N), keyby = .(silo, joint, ea, a, qa)]\nd_b_late &lt;- ll$d[silo %in% c(\"late\") & a == \"rev\", .(y = sum(y), .N), keyby = .(silo, joint, qa, eb, b)]\nd_b_chronic &lt;- ll$d[silo %in% c(\"chronic\") , .(y = sum(y), .N), keyby = .(silo, joint, qa, eb, b)]\n\nd_b &lt;- rbind(d_b_late, d_b_chronic)\nd_c &lt;- ll$d[ec == \"Y\", .(y = sum(y), .N), keyby = .(silo, joint, ec, c)]\n\nd_all_grps &lt;- ll$d[, .(y = sum(y), .N), keyby = .(silo, joint, ea, a, qa, eb, b, ec, c)]\n\n\nTable 1 shows a summary of simulated trial data for surgical domain. Each row comprises patients allocated to the surgical domain intervention along with whatever their duration and type interventions were.\nFor example, late stage patients with knee joint infections receiving revision would include patients allocated to the duration options dependent on the planned surgical procedure and type options dependent on whether they were eligible for the type domain.\n\n\nCode\ncols &lt;- c(\"Silo\", \"Infection site\", \"Surgery\", \"Planned\", \"Success\", \"N\", \"Pr(success)\")\nnames(cols) &lt;- names(d_a[, .(silo, joint, a, qa, y, N, p_obs = y/N)])\n\ngt_tbl &lt;- d_a[, .(silo, joint, a, qa, y, N, p_obs = y/N)] |&gt; \n  gt(\n  ) |&gt; \n  cols_align(\n    align = \"left\",\n    columns = starts_with(c(\"silo\", \"joint\"))\n  ) |&gt; \n  fmt_number(\n    columns = starts_with(c(\"p_obs\")),\n    decimals = 2\n  ) |&gt;\n  grand_summary_rows(\n    columns = c(\"y\", \"N\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSilo\nInfection site\nSurgery\nPlanned\nSuccess\nN\nPr(success)\n\n\n\n\n\nchronic\nhip\none\none\n100\n149\n0.67\n\n\n\nchronic\nhip\ntwo\ntwo\n108\n121\n0.89\n\n\n\nchronic\nknee\none\none\n90\n125\n0.72\n\n\n\nchronic\nknee\ntwo\ntwo\n88\n123\n0.72\n\n\n\nlate\nhip\ndair\ndair\n280\n431\n0.65\n\n\n\nlate\nhip\nrev\none\n173\n224\n0.77\n\n\n\nlate\nhip\nrev\ntwo\n142\n198\n0.72\n\n\n\nlate\nknee\ndair\ndair\n111\n185\n0.60\n\n\n\nlate\nknee\nrev\none\n70\n97\n0.72\n\n\n\nlate\nknee\nrev\ntwo\n73\n98\n0.74\n\n\nsubtotal\n—\n—\n—\n—\n1235\n1751\n—\n\n\n\n\n\n\n\n\nTable 1: Summary of simulated trial data for surgical domain\n\n\n\n\nTable 2 shows the analogous summary of simulated trial data for the duration domain.\n\n\nCode\ncols &lt;- c(\"Silo\", \"Infection site\", \"Revision\", \"Duration\", \"Success\", \"N\", \"Pr(success)\")\nnames(cols) &lt;- names(d_b[, .(silo, joint, qa, b, y, N, p_obs = y/N)])\n\ngt_tbl &lt;- d_b[, .(silo, joint, qa, b, y, N, p_obs = y/N)] |&gt; \n  gt(\n  ) |&gt; \n  cols_align(\n    align = \"left\",\n    columns = starts_with(c(\"silo\", \"joint\"))\n  ) |&gt; \n  fmt_number(\n    columns = starts_with(c(\"p_obs\")),\n    decimals = 2\n  ) |&gt;\n  grand_summary_rows(\n    columns = c(\"y\", \"N\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSilo\nInfection site\nRevision\nDuration\nSuccess\nN\nPr(success)\n\n\n\n\n\nlate\nhip\none\nw06p1\n73\n108\n0.68\n\n\n\nlate\nhip\none\nw12p1\n100\n116\n0.86\n\n\n\nlate\nhip\ntwo\nd07p2\n72\n97\n0.74\n\n\n\nlate\nhip\ntwo\nw12p2\n70\n101\n0.69\n\n\n\nlate\nknee\none\nw06p1\n31\n50\n0.62\n\n\n\nlate\nknee\none\nw12p1\n39\n47\n0.83\n\n\n\nlate\nknee\ntwo\nd07p2\n41\n61\n0.67\n\n\n\nlate\nknee\ntwo\nw12p2\n32\n37\n0.86\n\n\n\nchronic\nhip\none\nw06p1\n46\n74\n0.62\n\n\n\nchronic\nhip\none\nw12p1\n54\n75\n0.72\n\n\n\nchronic\nhip\ntwo\nd07p2\n54\n60\n0.90\n\n\n\nchronic\nhip\ntwo\nw12p2\n54\n61\n0.89\n\n\n\nchronic\nknee\none\nw06p1\n37\n60\n0.62\n\n\n\nchronic\nknee\none\nw12p1\n53\n65\n0.82\n\n\n\nchronic\nknee\ntwo\nd07p2\n43\n62\n0.69\n\n\n\nchronic\nknee\ntwo\nw12p2\n45\n61\n0.74\n\n\nsubtotal\n—\n—\n—\n—\n844\n1135\n—\n\n\n\n\n\n\n\n\nTable 2: Summary of simulated trial data for duration domain\n\n\n\n\nTable 3 shows the analogous summary of simulated trial data for the type domain.\n\n\nCode\ncols &lt;- c(\"Silo\", \"Infection site\", \"Type\", \"Success\", \"N\", \"Pr(success)\")\nnames(cols) &lt;- names(d_c[, .(silo, joint, c, y, N, p_obs = y/N)])\n\ngt_tbl &lt;- d_c[, .(silo, joint, c, y, N, p_obs = y/N)] |&gt; \n  gt(\n  ) |&gt; \n  cols_align(\n    align = \"left\",\n    columns = starts_with(c(\"silo\", \"joint\"))\n  ) |&gt; \n  fmt_number(\n    columns = starts_with(c(\"p_obs\")),\n    decimals = 2\n  ) |&gt;\n  grand_summary_rows(\n    columns = c(\"y\", \"N\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSilo\nInfection site\nType\nSuccess\nN\nPr(success)\n\n\n\n\n\nchronic\nhip\nnorif\n62\n81\n0.77\n\n\n\nchronic\nhip\nrif\n65\n81\n0.80\n\n\n\nchronic\nknee\nnorif\n55\n80\n0.69\n\n\n\nchronic\nknee\nrif\n50\n68\n0.74\n\n\n\nearly\nhip\nnorif\n115\n151\n0.76\n\n\n\nearly\nhip\nrif\n109\n140\n0.78\n\n\n\nearly\nknee\nnorif\n56\n89\n0.63\n\n\n\nearly\nknee\nrif\n60\n87\n0.69\n\n\n\nlate\nhip\nnorif\n175\n254\n0.69\n\n\n\nlate\nhip\nrif\n199\n256\n0.78\n\n\n\nlate\nknee\nnorif\n86\n123\n0.70\n\n\n\nlate\nknee\nrif\n78\n111\n0.70\n\n\nsubtotal\n—\n—\n—\n1110\n1521\n—\n\n\n\n\n\n\n\n\nTable 3: Summary of simulated trial data for type domain\n\n\n\n\nTable 4 shows the analogous summary of simulated trial data across all the combinations of silo, site of infection, domain membership and treatment allocation. It gives a better sense of the structure of the data as seen by the model, but unfortunately, it is not possible to produce dynamic totals based on the filtered data.\n\n\nCode\nd_tbl &lt;- d_all_grps[, .(silo, joint, ea, a, qa, eb, b, ec, c, y, N, p_obs = round(y/N, 2))]\nd_tbl[, silo := factor(silo, levels = c(\"early\", \"late\", \"chronic\"))]\nd_tbl[, joint := factor(joint, levels = c(\"knee\", \"hip\"))]\n\nsetkey(d_tbl, silo, joint)\n\nopts &lt;- list(\n  pageLength = 20, autoWidth = TRUE\n  )\n\ndatatable(d_tbl,\n          rownames = FALSE,\n          colnames = c(\n            'Silo' = 1, \n            'Infection site' = 2,\n            'A' = 3,\n            'A (trt)' = 4,\n            'A (plan)' = 5,\n            'B' = 6,\n            'B (trt)' = 7,\n            'C' = 8,\n            'C (trt)' = 9,\n            'Success' = 10,\n            'N' = 11,\n            'Pr(success)' = 12\n            ),\n          filter = 'top', options = opts\n          )\n\n\n\n\n\n\n\n\n\n\nTable 4: Summary of all groupings from simulated trial data",
    "crumbs": [
      "Design",
      "Simulated trial data"
    ]
  },
  {
    "objectID": "notebooks/estimands.html",
    "href": "notebooks/estimands.html",
    "title": "Estimands in complex designs",
    "section": "",
    "text": "Are designed to permit the evaluation of multiple interventions in a perpetual manner under a single protocol establishing a common infrastructure and analysis plan. Interventions can be added and withdrawn at different times based on need and the control group may be revised as the trial progresses. Platform trials can include adaptive elements (commonly stopping rules and adaptive randomisations) that allow design variations based on accruing evidence."
  },
  {
    "objectID": "notebooks/estimands.html#platform-trials",
    "href": "notebooks/estimands.html#platform-trials",
    "title": "Estimands in complex designs",
    "section": "",
    "text": "Are designed to permit the evaluation of multiple interventions in a perpetual manner under a single protocol establishing a common infrastructure and analysis plan. Interventions can be added and withdrawn at different times based on need and the control group may be revised as the trial progresses. Platform trials can include adaptive elements (commonly stopping rules and adaptive randomisations) that allow design variations based on accruing evidence."
  },
  {
    "objectID": "notebooks/estimands.html#estimands",
    "href": "notebooks/estimands.html#estimands",
    "title": "Estimands in complex designs",
    "section": "Estimands",
    "text": "Estimands\nCausal estimands are population quantities describing causal effects of treatments. The estimand framework facilitates a precise description of the treatment effect of interest in clinical trials. The estimand is the thing targeted for estimation which will address a question of interest intrinsic to the trial. In other words, setting objectives leads to estimands which, once clear, can lead to identifying a suitable method for estimation.\n\n\n\n\n\n\nNote\n\n\n\nIf you do not have a clear definition of an estimand, how do you derive an appropriate estimator?\n\n\nEstimands comprise:\n\na population of interest\na treatment strategy\na variable to be measured for each patient\nstrategies for handing intercurrent events (IE)\na population summary measure\n\nPer FDA, endpoint measures are developed to assess clinical outcomes, but things do seem to get mixed up.\nNevertheless - the endpoint is an outcome obtained for each patient that will be statistically analyzed to address the scientific question; this may include data from multiple variables.\nWhile the usual suspects for defining analysis populations (specifically for dealing with IE) were intention-to-treat ITT and per-protocol, the ICH expanded this set of strategies. Loosely, ITT analyses all patients as randomised, irrespective of what actually happened (e.g. deviations). PP analyses, only those who follow the protocol are used, the otherse are excluded. PP is commonly cited as being subject to bias, ITT less so. ICH defines:\n\nICH treatment strategies\n\n\n\n\n\n\nCommand\nDescription of common use\n\n\n\n\ntreatment policy\nMost common, similar to ITT; data collected is used regardless of whether IE occur. In other words, the IE is not a considered a departure from the treatment regimen of interest. TP preserves the randomisation, hence its attraction. Death can lead to TP being undefineable unless death is the (or a component of the) primary.\n\n\ncomposite policy\nIncorporates the IE as a component of the variable, e.g. alive at 29 days without use of rescue medication.\n\n\nhypothetical\nComplicated - envisages a scenario where the IE does not occur. The observed outcomes of patients without IE correspond to the outcome of interest, but the outcome of patients with IE is considered missing and needs to be imputed.\n\n\nwhile on treatment\nApplicable where there are repeat measures. The data is used up to the point where treatement was ended.\n\n\nprincipal stratum\nInvolves defining sub-populations according to the specific IEs on one or all treatments.\n\n\n\nas analyses strategies with some loose and brief descriptions provided above.\nIntercurrent events are just post-randomisation events that impact our measurements or interpretation of measurements in some way (e.g. intercurrent events arise through discontinuation of medication).\nFor the population-level summary, it is ususally relevant to provide within and between-arm measures, e.g. within-arm being overall survival at 28 days vs between-arm hazard ratio etc.\nPlatform trials introduce complexity into the specification of estimands and is not well considered in the literature. For example, what are the implications of addring treatment arms or modifying the control or implementing further data-driven adaptive features?"
  }
]