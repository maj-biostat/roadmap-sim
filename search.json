[
  {
    "objectID": "notebooks/sim-design8-results.html",
    "href": "notebooks/sim-design8-results.html",
    "title": "Simulation results 8",
    "section": "",
    "text": "Libraries and globals\nsource(\"./R/init.R\")\n\n\nWarning: package 'cmdstanr' was built under R version 4.4.3\n\n\nLibraries and globals\nsource(\"./R/util.R\")\nsource(\"./R/data.R\")\nlog_info(\"Called simulation-results 8 notebook\")\n\ntoks &lt;- unlist(tstrsplit(getwd(), \"/\")) \nif(toks[length(toks)] == \"roadmap-sim\"){\n  prefix_cfg &lt;- \"./etc/sim08/\"\n  prefix_stan &lt;- \"./stan\"\n  prefix_fig &lt;- \"./fig\"\n} else {\n  prefix_cfg &lt;- \"../etc/sim08/\"\n  prefix_stan &lt;- \"../stan\"\n  prefix_fig &lt;- \"../fig\"\n}\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\nsim_lab &lt;- \"sim08-01\"\n\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim08\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}",
    "crumbs": [
      "Simulations",
      "Simulation results 8"
    ]
  },
  {
    "objectID": "notebooks/sim-design8-results.html#introduction",
    "href": "notebooks/sim-design8-results.html#introduction",
    "title": "Simulation results 8",
    "section": "Introduction",
    "text": "Introduction\n\nData generation\nData is generated based on the empirical distributions obtained mostly from the PIANO study.\nWe simulate silo membership from a multinomial distribution with probabilities 0.3, 0.5 and 0.2 for early, late and chronic.\nConditional on silo membership, we generate domain level allocations and entry indicators that are independent of the design but parameterised to silo specific probabilities. In contrast to the previous simulations, we have simplified the model by ignoring joint level heterogeneity. Adjustment for joint will be reintroduced in the actual analysis model.\nFor the early silo, we assume:\n\nallocation to revision with probability 0.15\npreference for two-stage revision, rev(2), with probability 0.35\nentry into antibiotic duration domain with probability 0.7\nwithin antibiotic duration domain, allocation to 6 weeks with probability 0.5\nentry into extended prophylaxis domain with probability 0.9\nwithin extended prophylaxis domain, allocation to 12 weeks with probability 0.5\nentry into antibiotic choice domain with probability 0.6\nwithin antibiotic choice domain, allocation to rifampicin with probability 0.5\n\nSimilalry, for the late acute silo, we assume:\n\nallocation to revision with probability 0.5\npreference for two-stage revision, rev(2), with probability 0.7\nentry into antibiotic duration domain with probability 0.7\nwithin antibiotic duration domain, allocation to 6 weeks with probability 0.5\nentry into extended prophylaxis domain with probability 0.9\nwithin extended prophylaxis domain, allocation to 12 weeks with probability 0.5\nentry into antibiotic choice domain with probability 0.6\nwithin antibiotic choice domain, allocation to rifampicin with probability 0.5\n\nFor the chronic silo, we assume:\n\nallocation to revision with probability 0.8\npreference for two-stage revision, rev(2), with probability 0.75\nentry into antibiotic duration domain with probability 0.7\nwithin antibiotic duration domain, allocation to 6 weeks with probability 0.5\nentry into extended prophylaxis domain with probability 0.9\nwithin extended prophylaxis domain, allocation to 12 weeks with probability 0.5\nentry into antibiotic choice domain with probability 0.6\nwithin antibiotic choice domain, allocation to rifampicin with probability 0.5\n\nAfter the design independent allocations are made, we finalise the participant level domain entry and allocation based on the known design dependencies.\nAs the trial progresses, decisions may be made which would lead to some allocations being shut off. For example, if revision is deemed superiori to DAIR, then subsequent allocations within the late acute silo would direct all participants to revision with a split between one-stage and two-stage continuing to be based on the clinical preferences.\nThe underlying unit level log-odds of response is calculated as the sum of the relevant parameters per the indexing described above. Treatment success is simulated as a bernoulli random variable with probability equal to the inverse logit transform of the log-odds from the linear predictor. However, to speed up the model, we aggregate number of successes and number of trials by covariate group which gives the analogous binomial random variable representation.\nIn contrast to simulation 7, this simulation returns to decisions made on the log odds scale\n\n\nModel\nWe adopt a revised model where we allow for silo-specific effects in the surgical domain.\nIf, for whatever reason, the early or chronic silo show variation in the surgical domain effects, adjustment for silo is inadequate to account for this, and we end up with a polluted version of the surgical domain parameters. The remainder of the model is analogous to the previous versions. The model is used to compute unit level risk (probability) and assesses decisions based on risk difference for the intervention comparisons by domain.\nFor the simulations, we have a single, multivariable logistic regression model with a linear predictor that incorporates all domains and is specified as follows:\n\\[\n\\begin{aligned}\nY &\\sim \\text{Binomial}(n, p) \\\\\n\\text{logit}(p) &= \\begin{cases}\n  \\mu + \\beta_{s} + \\beta_{p} + \\beta_{d1[k_{d1}, s]} + \\beta_{d4[k_{d4}]} & \\text{(dair)} \\\\\n  \\mu + \\beta_{s} + \\beta_{d1[k_{d1}, s]} + \\beta_{d2[k_{d2}]} + \\beta_{d4[k_{d4}]} & \\text{(one-stage)} \\\\\n  \\mu + \\beta_{s} + \\beta_{p} + \\beta_{d1[k_{d1}, s]} + \\beta_{d3[k_{d3}]} + \\beta_{d4[k_{d4}]} & \\text{(two-stage)}\n         \\end{cases}\n\\end{aligned}\n\\]\nfor each distinct covariate grouping where:\n\n\\(\\mu\\) represents an overall reference level from which all covariates deviate\n\\(\\beta_{s}\\) represents the silo deviations, which can be thought of as a seriousness of disease adjustment. We fix the first parameter (early) to zero for identifiability and the components are for early, late and chronic silo membership.\n\\(\\beta_{p}\\) represents the (pre-revealed) preference adjustment, assuming revision was allocated but included irrespective of silo and what the assignment ultimately turned out to be. This accounts for heterogeneity in outcome due to clinical preference for revision type, which can be thought of as expert elicitation on aspects of the patient state and clinicial experience. We fix the first parameter (preference one-stage revision) in this vector to zero for identifiability and the components are preference for one-stage or two-stage. The preference indicators are also used to compute the sample weights for aggregating one and two-stage revision into a single overall revision effect.\n\\(\\beta_{d1[k_{d1}, s]}\\) represents the silo-specific deviations associated with the surgery type. This accounts for heterogeneity in outcome due to surgery type and with the late-acute deviations taken as a randomised comparison of dair vs revision after the agreed weighting is applied. We fix the first parameter (dair in the early cohort) in this vector to zero for identifiability and the components are dair, rev(1), rev(2) for each silo. The reason for the silo-specific context is that if revision effects exist in one silo but not another, then without this conditioning, we will end up with biased inference. For example, if (for whatever reason) there is an revision effect in the early domain but not the late-acute cohort then without this level of adjustment, we would end up reporting a revision effect when we shouldn’t be; adjustment for silo doesn’t protect us from this, even though it is perfectly collinear with a unit receiving non-randomised or randomised surgical treatment.\n\\(\\beta_{d2[k_{d2}]}\\) represents the deviations associated with backbone antibiotic duration. This accounts for heterogeneity in outcome due to the assigned backbone antibiotic duration. The first parameter (non-randomised treatment) in this vector is set to zero for identifiability and the components are non-randomised, 12 weeks and 6 weeks. The term is undefined for DAIR and rev(2) participants. Units that receive rev(1) but do not enter into d2 contribute to the non-randomised set. We are assuming that there is no silo-specific (or any other) hetereogeneity for this comparison.\n\\(\\beta_{d3[k_{d3}]}\\) represents the deviations associated with extended prophylaxis duration. This accounts for heterogeneity in outcome due to the assigned extended prophylaxis duration. The first parameter (non-randomised treatment) in this vector is set to zero for identifiability and the components are non-randomised, no ext-proph and 12 weeks. The term is undefined for DAIR and rev(1) participants. Units that receive rev(2) but do not enter into d3 contribute to the non-randomised set. We are assuming that there is no silo-specific hetereogeneity for this comparison.\n\\(\\beta_{d4[k_{d4}]}\\) represents the deviations associated with antibiotic choice. This accounts for heterogeneity in outcome due to the assigned antibiotic choice. The first parameter (non-randomised treatment) in this vector is set to zero for identifiability and the components are non-randomised, no rifampicin and rifampicin. The term is included for all units for which rifampicin may be indicated. The other units contribute to the non-randomised set. We are assuming that there is no silo-specific hetereogeneity for this comparison.\n\nThe way that terms enter the model is somewhat convoluted and understanding the dependency implications and consequently interpretations is fairly challenging. For the actual trial analysis, the model will be revised to an equivalent Bernoulli likelihood on unit level data but extended to account for joint, site, randomisation period (if required) and prognostic covariates. Bar the surgical domain, for which ‘by silo’ deviations are implicit in the existing parameterisation, no further interactions are included. Given that heterogeneity by site of infection (joint) is of interest (primarily in the surgical domain) the analysis plan will include specification to account for this.\n\n\nDecision\nAt each interim, we assess the posterior and if a decision threshold is met, we act. For example, if a superiority decision is reached in one of the domains for which this decision type is relevant, then we consider that domain dealt with and all subsequent participants are assigned to receive the superior intervention. We can (and presently do) continue to update the posterior inference for the comparison that has stopped in subsequent interim analyses until we get to the point where all questions have been answered in all domains, at which point the trial will stop.\nSuperiority and non-inferiority are applicable to some domains and not others, however, we define reference and threshold values for all domains, just in case. Decisions are made with respect to the average within any `random-effect’ terms that might exist within the model.\nFor the superiority decision, a reference value of 0 was used and the probability thresholds were:\n\n0.93 for surgical domain\n0.93 for antibiotic duration domain\n0.93 for extended prophylaxis domain\n0.99 for antibiotic choice domain\n\nThere was no particular reason for the choice of these thresholds bar the fact that they lead to preferred operating characteristics and give nominal control of the type-i assertion probabilities.\nFor the futility decision (in relation to superiority) a reference value of 0.18 was used and the probability thresholds were:\n\n0.3 for surgical domain\n0.3 for antibiotic duration domain\n0.3 for extended prophylaxis domain\n0.3 for antibiotic choice domain\n\nThe above means, for example, that if the probability that the risk difference is greater than 0.18 is less than in the surgical domain comparison, then we say the superiority goal is futile.\nFor the ni decision, a reference value of -0.18 was used and the probability thresholds were:\n\n0.975 for surgical domain\n0.925 for antibiotic duration domain\n0.975 for extended prophylaxis domain\n0.975 for antibiotic choice domain\n\nThe above means, for example, that if the probability that the risk difference is greater than -0.18 is greater than 0.925, in the antibiotic duration domain, then we will say the intervention is non-inferior.\nThe futility decision (in relation to non-inferiority) has a reference value of 0 and the probability thresholds were:\n\n0.25 for surgical domain\n0.1 for antibiotic duration domain\n0.25 for extended prophylaxis domain\n0.25 for antibiotic choice domain\n\nThis means, for example, that if the probability that the risk difference is greater than 0 is less than 0.1, in the antibiotic duration domain, then we say the non-inferiority goal is futile.\n\n\nPrior\nThe priors were as follows:\n\nReference log-odds of response: logistic distribution, mean 0.7 and scale 0.7\nSilo effects: normal distribution, mean 0 and scale 1\nPreference effects: normal distribution, mean 0 and scale 1\nTreatment effects (domain 1): normal distribution, mean 0 and scale 1\nTreatment effects (domain 2): normal distribution, mean 0 and scale 1\nTreatment effects (domain 3): normal distribution, mean 0 and scale 1\nTreatment effects (domain 4): normal distribution, mean 0 and scale 1\n\nThe prior predictive distribution is consistent with a mean probability across of response over the covariate groupings that covers the entire support on the probability scale, is centred around 0.6 and has first and third quarters at 0.4 to 0.8.",
    "crumbs": [
      "Simulations",
      "Simulation results 8"
    ]
  },
  {
    "objectID": "notebooks/sim-design8-results.html#simulation-results",
    "href": "notebooks/sim-design8-results.html#simulation-results",
    "title": "Simulation results 8",
    "section": "Simulation results",
    "text": "Simulation results\nFor this set of simulations, the number of simulated trials per scenario was 500, the simulation label is sim08-01.\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(ia = seq_along(l_cfg$N_pt), N = cumsum(l_cfg$N_pt))\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"ia\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"ia\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(ia, N, quant, domain)]\n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected enrolment progression\n# Expected sample size\n\n# Similar to above but focus on expected sample size\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 2\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(ia = seq_along(l_cfg$N_pt), N = cumsum(l_cfg$N_pt))\n  \n  # long version of decision\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"ia\", \"quant\"), \n                  variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"ia\")\n  \n  # First instance of any decision rule being hit by sim and domain.\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  \n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(d_dec_stop[, .SD, .SDcols = !c(\"ia\")], \n                      # all combinations of sim and domain \n                      # which with leave non-stoppers with NA\n                      unique(d_dec_2[, .(sim, domain)]),\n                      by = c(\"sim\", \"domain\"), all.y = T)\n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"na\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise these \n# posterior means, they would be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n\n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# our estimates is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 1\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(ia = seq_along(l_cfg$N_pt), N = cumsum(l_cfg$N_pt))\n  \n  d_pars &lt;- dcast(d_pars, sim + ia + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"ia\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(ia, sim, domain, N, mu_lor, se_lor)]\n      )\n  )\n\n}\n\n\n\n\nNumber of participants for each randomised comparison over time\n# \n\ni &lt;- 1\nd_N_by_arm &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # long version of decisions\n  d_dec_2 &lt;- melt(\n    d_dec_1, id.vars = c(\"sim\", \"ia\", \"quant\"), variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_enrolment &lt;- data.table(ia = seq_along(l_cfg$N_pt), N_enrol = cumsum(l_cfg$N_pt))\n  # observed trial data sets\n  d_tru &lt;- copy(l[[i]]$d_all)\n  d_tru[, `:=`(\n    d1 = as.integer(d1),\n    d2 = as.integer(d2),\n    d3 = as.integer(d3),\n    d4 = as.integer(d4))]\n  \n  \n  # late acute, surgical arms\n  # *** silo isn't included in the keyby because we want to average across \n  # the entire trial population, not silo specific sample sizes.\n  d_1_tmp &lt;- d_tru[\n    s == 2, .(N = sum(N), domain = 1), keyby = .(sim, ia, d1)]\n  d_1_tmp[, N := cumsum(N), keyby = .(sim, d1)]\n  setnames(d_1_tmp, old = \"d1\", \"arm\")\n  d_1_tmp &lt;- merge(\n    d_1_tmp, \n    CJ(sim = 1:max(d_tru$sim), ia = 1:5, arm = 1:3, domain = 1), \n    by = c(\"sim\", \"ia\", \"arm\", \"domain\"),\n    all.y = T)\n  d_1_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_1_tmp, sim, ia, arm)\n  \n  # one-stage revision, ab duration randomised arms\n  d_2_tmp &lt;- d_tru[\n    d1 == 2 & d2 %in% 2:3, \n    .(N = sum(N), domain = 2), keyby = .(sim, ia, d2)]\n  d_2_tmp[, N := cumsum(N), keyby = .(sim, d2)]\n  setnames(d_2_tmp, old = \"d2\", \"arm\")\n  d_2_tmp &lt;- merge(\n    d_2_tmp, \n    CJ(sim = 1:max(d_tru$sim), ia = 1:5, arm = 2:3, domain = 2), \n    by = c(\"sim\", \"ia\", \"arm\", \"domain\"),\n    all.y = T)\n  d_2_tmp[ia == 1 & is.na(N), N := 0]\n  d_2_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_2_tmp, sim, ia, arm)\n  \n  # two-stage revision, extended prophy randomised arms\n  d_3_tmp &lt;- d_tru[\n    d1 == 3 & d3 %in% 2:3, \n    .(N = sum(N), domain = 3), keyby = .(sim, ia, d3)]\n  d_3_tmp[, N := cumsum(N), keyby = .(sim, d3)]\n  setnames(d_3_tmp, old = \"d3\", \"arm\")\n  d_3_tmp &lt;- merge(\n    d_3_tmp, \n    CJ(sim = 1:max(d_tru$sim), ia = 1:5, arm = 2:3, domain = 3), \n    by = c(\"sim\", \"ia\", \"arm\", \"domain\"),\n    all.y = T)\n  d_3_tmp[ia == 1 & is.na(N), N := 0]\n  d_3_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_3_tmp, sim, ia, arm)\n  \n  # ab choice randomised arms\n  d_4_tmp &lt;- d_tru[\n    d4 %in% 2:3, .(N = sum(N), domain = 4), keyby = .(sim, ia, d4)]\n  d_4_tmp[, N := cumsum(N), keyby = .(sim, d4)]\n  setnames(d_4_tmp, old = \"d4\", \"arm\")\n  d_4_tmp &lt;- merge(\n    d_4_tmp, \n    CJ(sim = 1:max(d_tru$sim), ia = 1:5, arm = 2:3, domain = 4), \n    by = c(\"sim\", \"ia\", \"arm\", \"domain\"),\n    all.y = T)\n  d_4_tmp[ia == 1 & is.na(N), N := 0]\n  d_4_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_4_tmp, sim, ia, arm)\n  \n  d_arm_tmp &lt;- rbind(d_1_tmp, d_2_tmp, d_3_tmp, d_4_tmp)\n\n  \n  d_arm_tmp[, `:=`(\n    scenario = i, desc = l_cfg$desc\n  )]\n  \n  d_arm_tmp &lt;- merge(\n    d_arm_tmp,\n    d_enrolment,\n    by = \"ia\")\n  \n  d_N_by_arm &lt;- rbind(d_N_by_arm, d_arm_tmp)\n\n}\n\n\n\n\nSummaries of empirical probability of treatment success\ni &lt;- 1\nd_tbl_4 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_enrolment &lt;- data.table(ia = seq_along(l_cfg$N_pt), N_enrol = cumsum(l_cfg$N_pt))\n  # observed data\n  d_all &lt;- copy(l[[i]]$d_all)\n  \n  d_all &lt;- merge(d_all, d_enrolment , by = \"ia\")\n  # long version of decision\n  d_dec_2 &lt;- melt(\n    d_dec_1, id.vars = c(\"sim\", \"ia\", \"quant\"), variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"ia\")\n  \n  # First instance of any decision rule being hit by sim and domain.\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  \n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"ia\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_domain_1 &lt;- d_all[\n    s == 2 & d1 %in% 1:3, .(sim, ia, s, pref, arm = d1, y, N, N_enrol)]\n  d_domain_1 &lt;- merge(d_domain_1, d_dec_stop[domain == 1], by = c(\"sim\"))\n  d_domain_1 &lt;- d_domain_1[N_enrol &lt;= N_stopped, ]\n  d_domain_1 &lt;- d_domain_1[, .(domain = 1, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_1[, p_hat := y / N]\n  \n  d_domain_2 &lt;- d_all[\n    d1 == 2 & d2 %in% 2:3, .(sim, ia, s, pref, arm = d2, y, N, N_enrol)]\n  d_domain_2 &lt;- merge(d_domain_2, d_dec_stop[domain == 2], by = c(\"sim\"))\n  d_domain_2 &lt;- d_domain_2[N_enrol &lt;= N_stopped, ]\n  d_domain_2 &lt;- d_domain_2[, .(domain = 2, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_2[, p_hat := y / N]\n  \n  d_domain_3 &lt;- d_all[\n    d1 == 3 & d3 %in% 2:3, .(sim, ia, s, pref, arm = d3, y, N, N_enrol)]\n  d_domain_3 &lt;- merge(d_domain_3, d_dec_stop[domain == 3], by = c(\"sim\"))\n  d_domain_3 &lt;- d_domain_3[N_enrol &lt;= N_stopped, ]\n  d_domain_3 &lt;- d_domain_3[, .(domain = 3, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_3[, p_hat := y / N]\n  \n  d_domain_4 &lt;- d_all[\n    d4 %in% 2:3, .(sim, ia, s, pref, arm = d4, y, N, N_enrol)]\n  d_domain_4 &lt;- merge(d_domain_4, d_dec_stop[domain == 4], by = c(\"sim\"))\n  d_domain_4 &lt;- d_domain_4[N_enrol &lt;= N_stopped, ]\n  d_domain_4 &lt;- d_domain_4[, .(domain = 4, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_4[, p_hat := y / N]\n  \n  d_domain &lt;- rbind(\n    d_domain_1, d_domain_2, d_domain_3, d_domain_4\n  )\n  \n  d_tbl_4 &lt;- rbind(\n    d_tbl_4, \n    cbind(scenario = i, desc = l_cfg$desc, d_domain)\n  )\n  \n}\n\n\n\nProbability of triggering decision\nTable 1 shows the cumulative probability of a superiority decision across each of the scenarios simulated (the same information is shown in Figure 1). Operating characteristics are shown only for the relevant domains and the futility of a superiority decision is included in parentheses.\n\nSuperiority decision - tabulatedSuperiority decision - visualisation\n\n\n\n\n\nCode\nd_tbl_1_cur &lt;- d_tbl_1[quant %in% c(\"sup\", \"fut_sup\") & domain %in% c(1, 3, 4), .SD]\nsetorderv(d_tbl_1_cur, cols = c(\"scenario\", \"domain\", \"ia\", \"quant\"), \n          order = c(1, 1, 1, -1))\nd_tbl_1_cur &lt;- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = \"pr_val\")\nd_tbl_1_cur &lt;- d_tbl_1_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nd_tbl_1_cur[, domain := factor(domain, \n                               levels = c(1, 3, 4), \n                               labels = c(\"Surgical\", \"AB Ext-proph\", \"AB Choice\"))]\n\ng_tbl &lt;- d_tbl_1_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_1_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_500\", \"fut_sup_500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )   |&gt; \n  cols_merge(\n    columns = c(\"sup_1000\", \"fut_sup_1000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  cols_merge(\n    columns = c(\"sup_1500\", \"fut_sup_1500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_2000\", \"fut_sup_2000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_2500\", \"fut_sup_2500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt;\n  tab_spanner(\n    label = md(\"Cumulative probability of **superiority** (futility) decision\"),\n    columns = 3:ncol(d_tbl_1_cur)\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    sup_500 = html(\"500\"),\n    sup_1000 = html(\"1000\"),\n    sup_1500 = html(\"1500\"),\n    sup_2000 = html(\"2000\"),\n    sup_2500 = html(\"2500\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain\n\nCumulative probability of superiority (futility) decision\n\n\n\n500\n1000\n1500\n2000\n2500\n\n\n\n\nLOR = 0 in all domains +silo specific d1\n\n\nSurgical\n0.046 (0.466)\n0.08 (0.612)\n0.092 (0.718)\n0.098 (0.77)\n0.108 (0.806)\n\n\nAB Ext-proph\n0.072 (0.506)\n0.122 (0.63)\n0.14 (0.694)\n0.16 (0.734)\n0.176 (0.754)\n\n\nAB Choice\n0.008 (0.608)\n0.016 (0.79)\n0.026 (0.884)\n0.028 (0.918)\n0.028 (0.94)\n\n\nLOR = 0.44: surgical revision (one and two-stage) +silo specific d1\n\n\nSurgical\n0.334 (0.096)\n0.584 (0.126)\n0.684 (0.134)\n0.762 (0.142)\n0.804 (0.144)\n\n\nAB Ext-proph\n0.078 (0.452)\n0.116 (0.644)\n0.138 (0.732)\n0.158 (0.78)\n0.166 (0.804)\n\n\nAB Choice\n0.006 (0.6)\n0.01 (0.776)\n0.014 (0.874)\n0.018 (0.92)\n0.022 (0.94)\n\n\nLOR = 0.45: surgical revision (one-stage only) +silo specific d1\n\n\nSurgical\n0.098 (0.314)\n0.172 (0.422)\n0.224 (0.5)\n0.276 (0.546)\n0.316 (0.586)\n\n\nAB Ext-proph\n0.074 (0.488)\n0.098 (0.67)\n0.108 (0.75)\n0.118 (0.788)\n0.13 (0.824)\n\n\nAB Choice\n0.008 (0.566)\n0.016 (0.762)\n0.024 (0.858)\n0.036 (0.9)\n0.036 (0.924)\n\n\nLOR = 0.45: surgical revision (two-stage only) +silo specific d1\n\n\nSurgical\n0.228 (0.154)\n0.402 (0.22)\n0.504 (0.26)\n0.572 (0.282)\n0.622 (0.292)\n\n\nAB Ext-proph\n0.098 (0.498)\n0.144 (0.638)\n0.166 (0.734)\n0.178 (0.778)\n0.182 (0.802)\n\n\nAB Choice\n0.006 (0.576)\n0.01 (0.782)\n0.018 (0.878)\n0.02 (0.908)\n0.02 (0.948)\n\n\nLOR = 0.48: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0.04 (0.45)\n0.072 (0.598)\n0.102 (0.68)\n0.13 (0.738)\n0.144 (0.768)\n\n\nAB Ext-proph\n0.076 (0.502)\n0.116 (0.662)\n0.126 (0.73)\n0.136 (0.768)\n0.138 (0.794)\n\n\nAB Choice\n0.006 (0.622)\n0.012 (0.808)\n0.012 (0.896)\n0.016 (0.93)\n0.018 (0.956)\n\n\nLOR = 0.43: ext-proph 12wk effect +silo specific d1\n\n\nSurgical\n0.05 (0.48)\n0.072 (0.646)\n0.092 (0.73)\n0.116 (0.784)\n0.122 (0.808)\n\n\nAB Ext-proph\n0.422 (0.112)\n0.61 (0.14)\n0.708 (0.152)\n0.764 (0.162)\n0.788 (0.166)\n\n\nAB Choice\n0.012 (0.604)\n0.02 (0.764)\n0.022 (0.852)\n0.022 (0.886)\n0.024 (0.916)\n\n\nLOR = 0.44: abx choice rif effect +silo specific d1\n\n\nSurgical\n0.036 (0.44)\n0.082 (0.612)\n0.108 (0.708)\n0.124 (0.752)\n0.128 (0.782)\n\n\nAB Ext-proph\n0.05 (0.5)\n0.082 (0.646)\n0.102 (0.72)\n0.116 (0.766)\n0.12 (0.798)\n\n\nAB Choice\n0.306 (0.044)\n0.66 (0.054)\n0.824 (0.056)\n0.89 (0.056)\n0.928 (0.056)\n\n\nLOR = 0.45, 0.56, 0.49, 0.48: domains 1:4 +silo specific d1\n\n\nSurgical\n0.384 (0.046)\n0.614 (0.068)\n0.748 (0.078)\n0.826 (0.088)\n0.852 (0.092)\n\n\nAB Ext-proph\n0.434 (0.072)\n0.698 (0.088)\n0.832 (0.098)\n0.874 (0.1)\n0.894 (0.1)\n\n\nAB Choice\n0.348 (0.02)\n0.712 (0.026)\n0.858 (0.028)\n0.93 (0.03)\n0.958 (0.032)\n\n\nLOR = -0.22: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0.066 (0.502)\n0.098 (0.66)\n0.112 (0.728)\n0.132 (0.776)\n0.144 (0.792)\n\n\nAB Ext-proph\n0.056 (0.516)\n0.084 (0.658)\n0.102 (0.738)\n0.116 (0.784)\n0.122 (0.812)\n\n\nAB Choice\n0.006 (0.582)\n0.01 (0.762)\n0.012 (0.846)\n0.014 (0.89)\n0.014 (0.926)\n\n\nLOR = 0.46, 0.36 surgical, RD = 0.08 abx choice +silo specific d1\n\n\nSurgical\n0.398 (0.06)\n0.604 (0.106)\n0.708 (0.12)\n0.782 (0.126)\n0.834 (0.13)\n\n\nAB Ext-proph\n0.072 (0.46)\n0.112 (0.638)\n0.13 (0.732)\n0.156 (0.78)\n0.164 (0.802)\n\n\nAB Choice\n0.214 (0.118)\n0.436 (0.132)\n0.622 (0.148)\n0.726 (0.154)\n0.784 (0.154)\n\n\n\n\n\n\n\n\nTable 1: Cumulative probability of superiority (futility in parentheses) decision at each interim (shown by total enrolment by interim)\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_1[quant %in% c(\"sup\", \"fut_sup\") & domain %in% c(1, 3, 4), .SD]\nsetorderv(d_fig, cols = c(\"scenario\", \"domain\", \"ia\", \"quant\"), \n          order = c(1, 1, 1, -1))\n\nd_fig[, domain := factor(domain, \n                         levels = c(1, 3, 4), \n                         labels = c(\"Surgical\", \"AB Ext-proph\", \"AB Choice\"))]\n\nd_fig[, quant := factor(quant, \n                        levels = c(\"sup\", \"fut_sup\"), \n                        labels = c(\"Superiority\", \"Futility\"))]\n\nd_fig[, desc := factor(desc, \n                        levels = unique(d_fig$desc), \n                        labels = unique(d_fig$desc))]\n\n\nggplot(d_fig, aes(x = N, y = pr_val, group = quant, col = quant)) +\n  geom_line(lwd = 0.25) +\n  scale_y_continuous(\"\") +\n  scale_color_discrete(\"\") +\n  # facet_grid(desc ~ domain) + \n  # facet_grid2(desc ~ domain, render_empty = FALSE)\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 1: Cumulative probabilities for superiority assessments\n\n\n\n\n\n\n\n\nTable 2 shows the cumulative probability of a non-inferiority decision with futility shown in parentheses (the same information is shown in Figure 2). The results are only shown for the domains for which non-inferiority is evaluated.\nThe “Null effect in all domains” is actually a bit of a misnomer as the true null with regards to the NI decision would be at the NI margin, whereas the scenario refers to the setting where all effects are set to zero. Thus an inflation over the usual type-i assertion probability is to be expected.\n\nNon-inferiority - tabulatedNon-inferiority - visualisation\n\n\n\n\nCode\nd_tbl_1_cur &lt;- d_tbl_1[quant %in% c(\"ni\", \"fut_ni\") & domain %in% c(2), .SD]\nsetorderv(d_tbl_1_cur, cols = c(\"scenario\", \"domain\", \"ia\", \"quant\"), \n          order = c(1, 1, 1, -1))\nd_tbl_1_cur &lt;- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = \"pr_val\")\nd_tbl_1_cur &lt;- d_tbl_1_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nd_tbl_1_cur[, domain := factor(domain, \n                               levels = c(2), \n                               labels = c(\"AB Duration\"))]\n\ng_tbl &lt;- d_tbl_1_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_1_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_500\", \"fut_ni_500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )   |&gt; \n  cols_merge(\n    columns = c(\"ni_1000\", \"fut_ni_1000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  cols_merge(\n    columns = c(\"ni_1500\", \"fut_ni_1500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_2000\", \"fut_ni_2000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_2500\", \"fut_ni_2500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt;\n  tab_spanner(\n    label = md(\"Cumulative probability of **NI** (futility) decision\"),\n    columns = 3:ncol(d_tbl_1_cur)\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    ni_500 = html(\"500\"),\n    ni_1000 = html(\"1000\"),\n    ni_1500 = html(\"1500\"),\n    ni_2000 = html(\"2000\"),\n    ni_2500 = html(\"2500\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain\n\nCumulative probability of NI (futility) decision\n\n\n\n500\n1000\n1500\n2000\n2500\n\n\n\n\nLOR = 0 in all domains +silo specific d1\n\n\nAB Duration\n0.118 (0.098)\n0.206 (0.14)\n0.252 (0.16)\n0.284 (0.19)\n0.31 (0.21)\n\n\nLOR = 0.44: surgical revision (one and two-stage) +silo specific d1\n\n\nAB Duration\n0.11 (0.084)\n0.19 (0.132)\n0.26 (0.17)\n0.324 (0.202)\n0.37 (0.22)\n\n\nLOR = 0.45: surgical revision (one-stage only) +silo specific d1\n\n\nAB Duration\n0.152 (0.078)\n0.212 (0.12)\n0.272 (0.154)\n0.3 (0.19)\n0.338 (0.204)\n\n\nLOR = 0.45: surgical revision (two-stage only) +silo specific d1\n\n\nAB Duration\n0.136 (0.098)\n0.208 (0.138)\n0.27 (0.182)\n0.32 (0.194)\n0.362 (0.216)\n\n\nLOR = 0.48: abx duration 6wk effect +silo specific d1\n\n\nAB Duration\n0.348 (0.02)\n0.532 (0.026)\n0.642 (0.036)\n0.718 (0.036)\n0.772 (0.036)\n\n\nLOR = 0.43: ext-proph 12wk effect +silo specific d1\n\n\nAB Duration\n0.108 (0.1)\n0.192 (0.166)\n0.246 (0.188)\n0.286 (0.21)\n0.318 (0.226)\n\n\nLOR = 0.44: abx choice rif effect +silo specific d1\n\n\nAB Duration\n0.12 (0.074)\n0.18 (0.114)\n0.236 (0.156)\n0.276 (0.174)\n0.306 (0.196)\n\n\nLOR = 0.45, 0.56, 0.49, 0.48: domains 1:4 +silo specific d1\n\n\nAB Duration\n0.36 (0.008)\n0.624 (0.018)\n0.802 (0.02)\n0.886 (0.02)\n0.93 (0.02)\n\n\nLOR = -0.22: abx duration 6wk effect +silo specific d1\n\n\nAB Duration\n0.058 (0.152)\n0.096 (0.27)\n0.124 (0.33)\n0.142 (0.38)\n0.152 (0.416)\n\n\nLOR = 0.46, 0.36 surgical, RD = 0.08 abx choice +silo specific d1\n\n\nAB Duration\n0.14 (0.084)\n0.228 (0.126)\n0.28 (0.16)\n0.312 (0.188)\n0.37 (0.21)\n\n\n\n\n\n\n\n\nTable 2: Cumulative probability of NI (futility in parentheses) decision at each interim (shown by total enrolment by interim)\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_1[quant %in% c(\"ni\", \"fut_ni\") & domain %in% c(2), .SD]\nsetorderv(d_fig, cols = c(\"scenario\", \"domain\", \"ia\", \"quant\"), \n          order = c(1, 1, 1, -1))\n\nd_fig[, domain := factor(domain, \n                               levels = c(2), \n                               labels = c(\"AB Duration\"))]\n\nd_fig[, quant := factor(quant, \n                        levels = c(\"ni\", \"fut_ni\"), \n                        labels = c(\"NI\", \"Futility for NI\"))]\n\nd_fig[, desc := factor(desc, \n                        levels = unique(d_fig$desc), \n                        labels = unique(d_fig$desc))]\n\n\nggplot(d_fig, aes(x = N, y = pr_val, group = quant, col = quant)) +\n  geom_line(lwd = 0.25) +\n  scale_y_continuous(\"\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  # facet_grid(desc ~ domain, space = \"free\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  \n  ggh4x::force_panelsizes(cols = unit(c(4), \"cm\"), TRUE) +\n  # facet_manual(\n  #   . ~ desc, design = matrix(1:17, ncol = 1),\n  #   widths = unit(3, \"cm\")\n  # ) +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 2: Cumulative probabilities for NI assessments\n\n\n\n\n\n\n\n\n\n\nSample sizes\nTable 3 shows the mean number of enrolments into the platform until a stopping rule is hit for each of the domains by scenario and stopping rule. In parentheses are the percentage of sims for each decision type and those that were not stopped early (last row) run to the maximum sample size (2500).\nFigure 3 shows the number of participants entering into each of the randomised comparisons by domain and scenario. The expected cumulative sample sizes (Figure 3) are calculated by extracting the number of participants entering into each randomised comparison (i.e. restricted to the relevant strata) and taking the cumulative sum of these over time. For example, the domain 1 (surgical) expected values are based on the participants in the late acute silo that receive randomised surgical intervention. Similarly, the domain 2 (antibiotic duration) expected values are based on the participants across all silos that received one-stage revision and then receive one of the randomised treatment allocations (i.e. are not in the non-randomised treatment group for any reason).\nIf a decision was made in a domain, then subsequent enrolments would be assigned to the remaining arms and so the allocation would be expected to deviate away from 1:1. For example, if a superiority decision was made for domain 1 (and the trial was still ongoing) then all subsequent participants are assigned to the superior intervention. Finally, if a decision was made for all research questions, the trial stops early. To avoid any bias in the calculation, we use LOCF to propagate the expectations forward through to the maximum number of enrolments.\n\nEnrolments to stoppingSample size of randomised comparisons\n\n\n\n\nCode\nd_tbl_2_cur &lt;- d_tbl_2[\n  , .(N_mu = mean(N_stopped), \n      pct_sims = sprintf(\"%.0f%%\", 100*.N/l[[1]]$cfg$nsim)), \n  keyby = .(scenario, desc, domain, quant)]\nd_tbl_2_cur &lt;- dcast(d_tbl_2_cur, scenario + desc + quant ~ domain, value.var = list(\"N_mu\", \"pct_sims\"))\n\nd_tbl_2_cur[, quant := factor(\n  quant, \n  levels = c(\"sup\", \"fut_sup\", \"ni\", \"fut_ni\", \"na\"),\n  labels = c(\"superiority\", \"futility (sup)\", \"ni\", \"futility (ni)\", \"-\"))]\n\nd_tbl_2_cur &lt;- d_tbl_2_cur[order(scenario, quant)]\nd_tbl_2_cur &lt;- d_tbl_2_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nsetcolorder(d_tbl_2_cur, c(\"desc\", \"quant\",\n                           \"N_mu_1\", \"pct_sims_1\", \n                           \"N_mu_2\", \"pct_sims_2\", \n                           \"N_mu_3\", \"pct_sims_3\", \n                           \"N_mu_4\", \"pct_sims_4\"\n                           ))\n\ng_tbl &lt;- d_tbl_2_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1:2,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 3:ncol(d_tbl_2_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"N_mu_1\", \"pct_sims_1\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"N_mu_2\", \"pct_sims_2\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"N_mu_3\", \"pct_sims_3\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"N_mu_4\", \"pct_sims_4\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  tab_spanner(\n    label = html(\"Expected number of total enrolments to hit stopping rule by domain\"),\n    columns = 3:ncol(d_tbl_2_cur)\n  )  |&gt;\n  cols_label(\n    N_mu_1 = \"Surgical\",\n    N_mu_2 = \"AB Duration\",\n    N_mu_3 = \"AB Ext-proph\",\n    N_mu_4 = \"AB choice\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 0, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nquant\n\nExpected number of total enrolments to hit stopping rule by domain\n\n\n\nSurgical\nAB Duration\nAB Ext-proph\nAB choice\n\n\n\n\nLOR = 0 in all domains +silo specific d1\n\n\nsuperiority\n1,037 (11%)\n\n1,097 (18%)\n1,107 (3%)\n\n\nfutility (sup)\n901 (80%)\n\n800 (75%)\n798 (94%)\n\n\nni\n\n1,113 (31%)\n\n\n\n\nfutility (ni)\n\n1,100 (21%)\n\n\n\n\n-\n2,500 (9%)\n2,500 (48%)\n2,500 (7%)\n2,500 (3%)\n\n\nLOR = 0.44: surgical revision (one and two-stage) +silo specific d1\n\n\nsuperiority\n1,020 (80%)\n\n1,012 (16%)\n1,409 (2%)\n\n\nfutility (sup)\n771 (14%)\n\n874 (80%)\n810 (94%)\n\n\nni\n\n1,305 (37%)\n\n\n\n\nfutility (ni)\n\n1,164 (22%)\n\n\n\n\n-\n2,500 (6%)\n2,500 (41%)\n2,500 (4%)\n2,500 (4%)\n\n\nLOR = 0.45: surgical revision (one-stage only) +silo specific d1\n\n\nsuperiority\n1,271 (31%)\n\n969 (13%)\n1,333 (4%)\n\n\nfutility (sup)\n965 (58%)\n\n860 (82%)\n826 (92%)\n\n\nni\n\n1,115 (34%)\n\n\n\n\nfutility (ni)\n\n1,172 (20%)\n\n\n\n\n-\n2,500 (11%)\n2,500 (46%)\n2,500 (5%)\n2,500 (4%)\n\n\nLOR = 0.45: surgical revision (two-stage only) +silo specific d1\n\n\nsuperiority\n1,123 (62%)\n\n889 (18%)\n1,150 (2%)\n\n\nfutility (sup)\n904 (28%)\n\n829 (79%)\n838 (95%)\n\n\nni\n\n1,210 (36%)\n\n\n\n\nfutility (ni)\n\n1,083 (22%)\n\n\n\n\n-\n2,500 (10%)\n2,500 (42%)\n2,500 (3%)\n2,500 (3%)\n\n\nLOR = 0.48: abx duration 6wk effect +silo specific d1\n\n\nsuperiority\n1,275 (14%)\n\n821 (13%)\n1,222 (2%)\n\n\nfutility (sup)\n890 (77%)\n\n822 (79%)\n797 (96%)\n\n\nni\n\n1,049 (77%)\n\n\n\n\nfutility (ni)\n\n861 (4%)\n\n\n\n\n-\n2,500 (10%)\n2,500 (19%)\n2,500 (7%)\n2,500 (3%)\n\n\nLOR = 0.43: ext-proph 12wk effect +silo specific d1\n\n\nsuperiority\n1,119 (12%)\n\n905 (78%)\n917 (2%)\n\n\nfutility (sup)\n856 (80%)\n\n795 (17%)\n805 (92%)\n\n\nni\n\n1,185 (31%)\n\n\n\n\nfutility (ni)\n\n1,031 (23%)\n\n\n\n\n-\n2,500 (8%)\n2,500 (46%)\n2,500 (5%)\n2,500 (6%)\n\n\nLOR = 0.44: abx choice rif effect +silo specific d1\n\n\nsuperiority\n1,127 (13%)\n\n1,042 (12%)\n1,054 (92%)\n\n\nfutility (sup)\n882 (77%)\n\n845 (79%)\n625 (6%)\n\n\nni\n\n1,173 (31%)\n\n\n\n\nfutility (ni)\n\n1,179 (20%)\n\n\n\n\n-\n2,500 (10%)\n2,500 (50%)\n2,500 (9%)\n2,500 (2%)\n\n\nLOR = 0.45, 0.56, 0.49, 0.48: domains 1:4 +silo specific d1\n\n\nsuperiority\n987 (85%)\n\n908 (89%)\n1,014 (96%)\n\n\nfutility (sup)\n978 (9%)\n\n710 (10%)\n875 (3%)\n\n\nni\n\n1,063 (93%)\n\n\n\n\nfutility (ni)\n\n850 (2%)\n\n\n\n\n-\n2,500 (6%)\n2,500 (5%)\n2,500 (1%)\n2,500 (1%)\n\n\nLOR = -0.22: abx duration 6wk effect +silo specific d1\n\n\nsuperiority\n1,083 (14%)\n\n1,033 (12%)\n1,000 (1%)\n\n\nfutility (sup)\n806 (78%)\n\n836 (81%)\n837 (93%)\n\n\nni\n\n1,118 (15%)\n\n\n\n\nfutility (ni)\n\n1,139 (42%)\n\n\n\n\n-\n2,500 (7%)\n2,500 (43%)\n2,500 (7%)\n2,500 (6%)\n\n\nLOR = 0.46, 0.36 surgical, RD = 0.08 abx choice +silo specific d1\n\n\nsuperiority\n979 (82%)\n\n1,026 (15%)\n1,225 (78%)\n\n\nfutility (sup)\n897 (13%)\n\n871 (80%)\n708 (15%)\n\n\nni\n\n1,203 (37%)\n\n\n\n\nfutility (ni)\n\n1,171 (21%)\n\n\n\n\n-\n2,500 (6%)\n2,500 (42%)\n2,500 (5%)\n2,500 (6%)\n\n\n\n\n\n\n\n\nTable 3: Expected number of enrolments to hit any stopping rule (including reaching maximum sample size)\n\n\n\n\n\n\n\n\nCode\nd_fig_1 &lt;- d_N_by_arm[, .(mu_N = mean(N)), keyby = .(desc, domain, arm, N_enrol)]\nd_fig_1[, desc := factor(\n  desc,\n  levels = unique(d_N_by_arm$desc))]\nd_fig_1[\n  , domain := factor(\n    domain,\n    levels = 1:4,\n    labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\nd_fig_2 &lt;- d_N_by_arm[\n  domain == 1 & arm %in% 2:3, \n  .(N = sum(N), arm = 4), \n  keyby = .(ia, sim, domain, scenario, desc, N_enrol)]\nd_fig_2 &lt;- d_fig_2[, .(mu_N = mean(N)), keyby = .(desc, domain, arm, N_enrol)]\n\nd_fig_2[, desc := factor(\n  desc,\n  levels = unique(d_N_by_arm$desc))]\nd_fig_2[\n  , domain := factor(\n    domain,\n    levels = 1:4,\n    labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n  \nd_fig_1[, arm := factor(arm)]\nggplot(d_fig_1, aes(x = N_enrol, y = mu_N, col = arm)) +\n  geom_line(lwd = 0.2) +\n  geom_point(size = 0.4) +\n  geom_line(\n    data = d_fig_2, \n    aes(x = N_enrol, y = mu_N), lwd = 0.2, lty = 2, inherit.aes = F) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Expected number of participants\") +\n  scale_color_discrete(\"Treatment arm: \") +\n  ggh4x::facet_grid2(\n    desc ~ domain, \n    labeller = labeller(desc = label_wrap_gen(35)), \n    scales = \"free_y\", independent = \"y\") +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.title.y=element_text(size = 5),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 3: Expected number of participants on domain arms\n\n\n\n\n\n\n\n\n\n\nParameter estimation\nFigure 4 shows the median value and 95% quantiles from the posterior mean odds ratios obtained from the simulations by each domain and scenario. The estimates are unconditional, in that they ignore the stopping rule and propagate estimates forward with LOCF so that we are working from a random sample (albeit with static imputation) rather than a dependent sample of simulations.\nThe AB duration domain has high variance in the distribution of posterior means that we anticipate to observe.\n\nTreatment effects - odds ratios\n\n\n\n\nCode\n# ggplot2::theme_update(text = element_text(size = 8))\n# ggplot2::theme_update(legend.position = \"bottom\")\n# # ggplot2::theme_update(legend.title = element_blank())\n# ggplot2::theme_update(axis.text.x = element_text(size = 8))\n# ggplot2::theme_update(axis.text.y = element_text(size = 8))\n\nd_fig &lt;- d_tbl_3[,\n                 .(or = median(exp(mu_lor)),\n                   q_025 = quantile(exp(mu_lor), prob = 0.025),\n                   q_975 = quantile(exp(mu_lor), prob = 0.975)), \n                 keyby = .(scenario, desc, ia, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_fig[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_fig[, domain := factor(domain, \n                         levels = 1:4, \n                         labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\n# d_tbl_3[scenario == 8, range(lor)]\n\nggplot(data = d_fig,  \n       aes(x = N, y = or)) +\n  geom_line(lwd = 0.25) +\n  geom_errorbar(aes(ymin = q_025, ymax = q_975), lwd = 0.25, width = 50) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n        strip.text.x = element_text(angle = 0, size = 5),\n        axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),\n        axis.text.y = element_text(size = 5),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1))\n\n\n\n\n\n\n\n\nFigure 4: Median value of posterior means for odds-ratio treatment effects by domain and simulation scenario\n\n\n\n\n\n\n\n\n\n\nProportion with treatment success\nTable 4 shows the empirical proportion having treatment success within the randomised comparisons subsets averaged over the simulations. For example, the values for the surgical domain shows the empirical proportion having treatment success within the late acute silo by treatment arm (dair, rev(1), rev(2)).\n\n\nCode\nd_tbl_4_cur &lt;- dcast(d_tbl_4, scenario + desc + domain ~ arm, value.var = \"p_hat\")\nd_tbl_4_cur[, domain := factor(\n  domain, \n  levels = c(1, 2, 3, 4), \n  labels = c(\"Surgical\", \"AB Duration\",  \"AB Ext-proph\", \"AB Choice\"))]\nd_tbl_4_cur &lt;- d_tbl_4_cur[, .(desc, domain, `1`, `2`, `3`)]\n\ng_tbl &lt;- d_tbl_4_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_4_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_label(\n    domain = \"Domain\"\n  )  |&gt;\n  tab_spanner(\n    label = html(\"Empirical risk by domain and treatment arm\"),\n    columns = 2:ncol(d_tbl_4_cur)\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 2, drop_trailing_zeros = TRUE) |&gt;\n  sub_missing(\n    columns = everything(),\n    rows = everything(),\n    missing_text = \"-\"\n  )\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpirical risk by domain and treatment arm\n\n\n\nDomain\n1\n2\n3\n\n\n\n\nLOR = 0 in all domains +silo specific d1\n\n\nSurgical\n0.58\n0.62\n0.57\n\n\nAB Duration\n-\n0.65\n0.65\n\n\nAB Ext-proph\n-\n0.59\n0.6\n\n\nAB Choice\n-\n0.62\n0.62\n\n\nLOR = 0.44: surgical revision (one and two-stage) +silo specific d1\n\n\nSurgical\n0.56\n0.7\n0.65\n\n\nAB Duration\n-\n0.68\n0.69\n\n\nAB Ext-proph\n-\n0.64\n0.64\n\n\nAB Choice\n-\n0.64\n0.64\n\n\nLOR = 0.45: surgical revision (one-stage only) +silo specific d1\n\n\nSurgical\n0.56\n0.7\n0.55\n\n\nAB Duration\n-\n0.68\n0.68\n\n\nAB Ext-proph\n-\n0.59\n0.58\n\n\nAB Choice\n-\n0.61\n0.61\n\n\nLOR = 0.45: surgical revision (two-stage only) +silo specific d1\n\n\nSurgical\n0.56\n0.6\n0.65\n\n\nAB Duration\n-\n0.63\n0.63\n\n\nAB Ext-proph\n-\n0.64\n0.64\n\n\nAB Choice\n-\n0.63\n0.63\n\n\nLOR = 0.48: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0.59\n0.65\n0.57\n\n\nAB Duration\n-\n0.63\n0.73\n\n\nAB Ext-proph\n-\n0.6\n0.6\n\n\nAB Choice\n-\n0.63\n0.62\n\n\nLOR = 0.43: ext-proph 12wk effect +silo specific d1\n\n\nSurgical\n0.59\n0.62\n0.61\n\n\nAB Duration\n-\n0.66\n0.65\n\n\nAB Ext-proph\n-\n0.58\n0.68\n\n\nAB Choice\n-\n0.63\n0.63\n\n\nLOR = 0.44: abx choice rif effect +silo specific d1\n\n\nSurgical\n0.61\n0.65\n0.6\n\n\nAB Duration\n-\n0.68\n0.67\n\n\nAB Ext-proph\n-\n0.62\n0.62\n\n\nAB Choice\n-\n0.6\n0.7\n\n\nLOR = 0.45, 0.56, 0.49, 0.48: domains 1:4 +silo specific d1\n\n\nSurgical\n0.59\n0.75\n0.72\n\n\nAB Duration\n-\n0.69\n0.8\n\n\nAB Ext-proph\n-\n0.64\n0.75\n\n\nAB Choice\n-\n0.64\n0.74\n\n\nLOR = -0.22: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0.59\n0.62\n0.57\n\n\nAB Duration\n-\n0.67\n0.62\n\n\nAB Ext-proph\n-\n0.6\n0.6\n\n\nAB Choice\n-\n0.62\n0.62\n\n\nLOR = 0.46, 0.36 surgical, RD = 0.08 abx choice +silo specific d1\n\n\nSurgical\n0.58\n0.71\n0.67\n\n\nAB Duration\n-\n0.7\n0.7\n\n\nAB Ext-proph\n-\n0.66\n0.66\n\n\nAB Choice\n-\n0.62\n0.7\n\n\n\n\n\n\n\n\nTable 4: Expected number of enrolments to hit any stopping rule (including reaching maximum sample size)",
    "crumbs": [
      "Simulations",
      "Simulation results 8"
    ]
  },
  {
    "objectID": "notebooks/sim-design7-ex01.html",
    "href": "notebooks/sim-design7-ex01.html",
    "title": "Simulation 7 - example 1",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\nsim_lab &lt;- \"sim07-04\"\n# files of interest\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim07\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\nix_scenario &lt;- 6\n\nix_trial &lt;- l[[ix_scenario]]$cfg$ex_trial_ix[1]",
    "crumbs": [
      "Simulations",
      "Simulation 7 - example 1"
    ]
  },
  {
    "objectID": "notebooks/sim-design7-ex01.html#results-from-example-trial",
    "href": "notebooks/sim-design7-ex01.html#results-from-example-trial",
    "title": "Simulation 7 - example 1",
    "section": "Results from example trial",
    "text": "Results from example trial\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(ia = seq_along(l_cfg$N_pt), N = cumsum(l_cfg$N_pt))\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"ia\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"ia\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(ia, N, quant, domain)]\n  \n  \n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected number of enrolments\n# Similar to above but focus on expected number of enrolments\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 1\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix that contains the stopping decision by \n  # quantity (superiority, ni, futility, etc) for each domain by analysis\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(ia = seq_along(l_cfg$N_pt), N = cumsum(l_cfg$N_pt))\n  # long version of decision, e.g.\n  #      sim analys  quant domain  value\n  #    &lt;int&gt;  &lt;int&gt; &lt;char&gt; &lt;fctr&gt; &lt;lgcl&gt;\n  # 1:     1      1    sup     d1  FALSE\n  # 2:     1      2    sup     d1  FALSE\n  # 3:     1      3    sup     d1  FALSE\n  # 4:     1      4    sup     d1  FALSE\n  # 5:     1      5    sup     d1  FALSE\n  # 6:     2      1    sup     d1  FALSE\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"ia\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case we had a sim fall over, fill in value\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"ia\")\n  \n  # Extract the first instance of any decision occurring by sim and domain.\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"ia\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise the \n# posterior means, they would thus be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# what we estimate is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 2\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(ia = seq_along(l_cfg$N_pt), N = cumsum(l_cfg$N_pt))\n  \n  d_pars &lt;- dcast(d_pars, sim + ia + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"ia\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(ia, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nCumulative probability of each decision type for example trial\n# &gt; names(l[[ix_scenario]])\n#  [1] \"cfg\"           \"d_pr_sup\"      \"d_pr_ni\"       \"d_pr_sup_fut\"  \"d_pr_ni_fut\"   \"d_decision\"   \n#  [7] \"d_post_smry_1\" \"d_all\"         \"d_n_units\"     \"d_n_assign\" \n\n# extract the decision matrix - sim, analysis, quantity, domain level decision\n\n\nd_N &lt;- data.table(\n  ia = 0:5,\n  N = seq(0, 2500, by = 500)\n)\n\n# Extract example trial specific data\nl_cfg &lt;- copy(l[[ix_scenario]]$cfg)\nd_dat &lt;- copy(l[[ix_scenario]]$d_all[sim == ix_trial])\n# Parameter summaries from analysis\nd_mod &lt;- copy(l[[ix_scenario]]$d_post_smry_1[sim == ix_trial])\n# Decision matrix for this trial\nd_dec &lt;- copy(l[[ix_scenario]]$d_decision[sim == ix_trial])\n# Probability level reached by domain and analysis\nd_pr_sup &lt;- copy(l[[ix_scenario]]$d_pr_sup[sim == ix_trial])\nd_pr_sup_fut &lt;- copy(l[[ix_scenario]]$d_pr_sup_fut[sim == ix_trial])\nd_pr_ni &lt;- copy(l[[ix_scenario]]$d_pr_ni[sim == ix_trial])\nd_pr_ni_fut &lt;- copy(l[[ix_scenario]]$d_pr_ni_fut[sim == ix_trial])\n\n\n\nd_mod &lt;- merge(d_mod, d_N, by = \"ia\")\n\nd_pr_sup &lt;- merge(d_pr_sup, d_N, by = \"ia\")\nd_pr_sup &lt;- melt(d_pr_sup[, .(ia, d1, d3, d4, N)], \n                 id.vars = c(\"ia\", \"N\"), variable.name = \"domain\")\nd_pr_sup[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup[, quant := \"sup\"]\n\nd_pr_sup_fut &lt;- merge(d_pr_sup_fut, d_N, by = \"ia\")\nd_pr_sup_fut &lt;- melt(d_pr_sup_fut[, .(ia, d1, d3, d4, N)], \n                 id.vars = c(\"ia\", \"N\"), variable.name = \"domain\")\nd_pr_sup_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup_fut[, quant := \"sup_fut\"]\n\nd_pr_ni &lt;- merge(d_pr_ni, d_N, by = \"ia\")\nd_pr_ni &lt;- melt(d_pr_ni[, .(ia, d2, N)], \n                 id.vars = c(\"ia\", \"N\"), variable.name = \"domain\")\nd_pr_ni[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni[, quant := \"ni\"]\n\nd_pr_ni_fut &lt;- merge(d_pr_ni_fut, d_N, by = \"ia\")\nd_pr_ni_fut &lt;- melt(d_pr_ni_fut[, .(ia, d2, N)], \n                 id.vars = c(\"ia\", \"N\"), variable.name = \"domain\")\nd_pr_ni_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni_fut[, quant := \"ni_fut\"]\n\nd_pr_dec &lt;- rbind(d_pr_sup, d_pr_sup_fut, d_pr_ni, d_pr_ni_fut  )\nd_pr_dec[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_pr_dec[domain %in% c(2), question := \"Non-inferiority\"]\n\n# domain 1 relates only to the late acute silo\nd_dat_d1 &lt;- d_dat[\n  s == 2, .(y = sum(y), n = sum(N)), keyby = .(s, ia, d1)]\nd_dat_d1[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(s, d1)]\nd_dat_d1[, p_obs := cy/cn]\nd_dat_d1[, d1 := factor(d1, labels = c(\"DAIR\", \"One-stage\", \"Two-stage\"))]\n\n# domain 2 relates only to the group that receive one-stage\nd_dat_d2 &lt;- d_dat[\n  d1 == 2, .(y = sum(y), n = sum(N)), keyby = .(s, ia, d2)]\nd_dat_d2[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(s, d2)]\nd_dat_d2[, p_obs := cy/cn]\nd_dat_d2[, d2 := factor(d2, labels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\n# domain 3 relates only to the group that receive two-stage\nd_dat_d3 &lt;- d_dat[\n  d1 == 3, .(y = sum(y), n = sum(N)), keyby = .(s, ia, d3)]\nd_dat_d3[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(s, d3)]\nd_dat_d3[, p_obs := cy/cn]\nd_dat_d3[, d3 := factor(d3, labels = c(\"Selected\", \"none\", \"12wk\"))]\n\n# domain 4 relates only to the group that receive two-stage\nd_dat_d4 &lt;- d_dat[\n  , .(y = sum(y), n = sum(N)), keyby = .(s, ia, d4)]\nd_dat_d4[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(s, d4)]\nd_dat_d4[, p_obs := cy/cn]\nd_dat_d4[, d4 := factor(d4, labels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\nd_dec &lt;- melt(d_dec, measure.vars = paste0(\"d\", 1:4), variable.name = \"domain\")\nd_dec[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n# Subset to the decisions that are evaluated by domain\nd_dec &lt;- rbind(\n  d_dec[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n  d_dec[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n)\n\n\nd_dec_thres &lt;- data.table(\n  quant = rep(c(\"sup\", \"sup_fut\", \"ni\", \"ni_fut\"), each = 4),\n  domain = rep(1:4, len = 16)\n  )\nd_dec_thres[, threshold := c(\n    l_cfg$dec_thresh_sup,\n    l_cfg$dec_thresh_fut_sup,\n    l_cfg$dec_thresh_ni,\n    l_cfg$dec_thresh_fut_ni\n  )]\n\n\n## State transition through the different states of knowledge based on decisions\n\nd_dec_timeline &lt;- merge(\n  CJ(domain = 1:4, ia = 0:5),\n  d_N, by = \"ia\", all.y = T\n)\nsetorder(d_dec_timeline, domain, ia)\nd_dec_timeline[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_dec_timeline[domain %in% c(2), question := \"Non-inferiority\"]\nd_dec_timeline[N == 0, decision := \"Indeterminate\"]\n\n\ni &lt;- j &lt;- 1\n# For i across domains\nfor(i in 1:4){\n  # For j across analyses\n  for(j in 1:5){\n    \n    if(i %in% c(1, 3, 4)){\n      \n      if(d_dec[domain == i & ia == j & quant == \"sup\", value])  {\n        d_dec_timeline[domain == i & ia == j, decision := \"Superior\"] \n      } else if (d_dec[domain == i & ia == j & quant == \"fut_sup\", value]) {\n        d_dec_timeline[domain == i & ia == j, decision := \"Futile (sup)\"] \n      } else {\n        d_dec_timeline[domain == i & ia == j, decision := \"Indeterminate\"] \n      }\n      \n    } else {\n      \n      if(d_dec[domain == i & ia == j & quant == \"ni\", value])  {\n        d_dec_timeline[domain == i & ia == j, decision := \"NI\"] \n      } else if (d_dec[domain == i & ia == j & quant == \"fut_ni\", value]) {\n        d_dec_timeline[domain == i & ia == j, decision := \"Futile (NI)\"] \n      } else {\n        d_dec_timeline[domain == i & ia == j, decision := \"Indeterminate\"] \n      }\n      \n    }\n    \n  }\n  \n}\n\nd_dec_timeline[, decision := factor(decision, levels = c(\n  \"Indeterminate\", \"Superior\", \"Futile (sup)\", \"NI\", \"Futile (NI)\"\n))]\n\n\n# Dealing with those for which a decision was not reached.\nd_decision &lt;- data.table(\n  domain = 1:4,\n  N = 2500\n)\nif(any(d_dec_timeline$decision != \"Indeterminate\")){\n  d_decision &lt;- d_dec_timeline[\n    decision != \"Indeterminate\", .(N = min(N)), keyby = .(domain, decision)]\n}\n\nd_decision &lt;- merge(\n  d_decision, \n  data.table(domain = 1:4),\n  by = \"domain\", all.y = T\n)\nd_decision[is.na(decision), `:=`(\n  decision = \"Intermediate\", N = 2500  \n)]\n\n\nd_dec_timeline &lt;- d_dec_timeline[N &lt;= max(d_decision$N)]\n\n\nTable 1 shows the decisions made for each domain (or indeterminate if no decisions were made).\n\n\nCode\ng_tbl &lt;- d_decision |&gt; \n  gt() |&gt; \n  cols_align(\n    columns = 1:2,\n    align = \"center\"\n  )  |&gt; \n  cols_align(\n    columns = 3,\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    decision = \"Decision\",\n    N = \"Enrolment\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nDomain\nDecision\nEnrolment\n\n\n\n\n1\nFutile (sup)\n500\n\n\n2\nIntermediate\n2,500\n\n\n3\nSuperior\n1,500\n\n\n4\nFutile (sup)\n500\n\n\n\n\n\n\n\n\nTable 1: Trial decisions by domain\n\n\n\n\nFigure 1 shows the knowledge transitions based on the decisions made for each domain by sample size up to the point where the trial was stopped either due to running out of resources or having addressed all the questions.\nInitially, all domains start in an indeterminate state in that neither treatment arm is preferred. As the data accrues and analyses progresses, the knowledge state for each domain may transition to, superiority, non-inferiority or futility.\n\n\nCode\np1 &lt;- ggplot(d_dec_timeline, aes(x = N, y = decision)) +\n  geom_point() +\n  scale_y_discrete(\"\", drop=FALSE) +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 1: Decision timeline\n\n\n\n\n\nFigure 2 through to Figure 5 show sample size for each domains.\n\nDomain 1: Sample sizeDomain 2: Sample sizeDomain 3: Sample sizeDomain 4: Sample size\n\n\nAny decision rule only applies to the late acute silo (silo 2).\n\n\nCode\nd_fig &lt;- copy(d_dat_d1)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(s = factor(1:3), ia = 1:5, d1 = c(\"DAIR\", \"One-stage\", \"Two-stage\")),\n  by = c(\"s\", \"ia\", \"d1\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(s, d1)]\n\np_d1 &lt;- ggplot(d_fig, aes(x = d1, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\", breaks = seq(0, 800, by = 200)) +\n  facet_grid(s ~ ia, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(print(p_d1))\n\n\n\n\n\n\n\n\nFigure 2: Domain 1: Surgical sample size\n\n\n\n\n\n\n\nOf those receiving one-stage (see figure for domain 1) and irrespective of silo membership, approximately 70% are assumed to enter the AB duration domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d2)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(s = factor(1:3), ia = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"s\", \"ia\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(s, d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_a &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(s ~ ia, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d2)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(ia, d2)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(ia = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"ia\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_b &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ ia, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d2_a, p_d2_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\nOf those receiving two-stage (see figure for domain 1) and irrespective of silo membership, approximately 90% are assumed to enter the AB ext-proph domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d3)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(s = factor(1:3), ia = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"s\", \"ia\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(s, d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_a &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(s ~ ia, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d3)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(ia, d3)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(ia = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"ia\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_b &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ ia, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d3_a, p_d3_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 4: Domain 3: AB Expt-proph sample size\n\n\n\n\n\n\n\nAcross the entire trial sample, approximately 60% are assumed to enter the AB choice domain.\nHere, we know there is an effect of AB choice and would hope that a decision for superiority is made such that new participants are directed to receive rifampacin.\n\n\nCode\nd_fig &lt;- copy(d_dat_d4)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(s = factor(1:3), ia = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"s\", \"ia\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(s, d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\np_d4_a &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(s ~ ia, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6))\n\nd_fig &lt;- copy(d_dat_d4)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(ia, d4)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(ia = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"ia\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\np_d4_b &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ ia, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d4_a, p_d4_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 5: AB Choice sample size\n\n\n\n\n\n\n\n\nFigure 6 and Figure 7 show the parameter estimates.\nNote:\nParameter estimates will only be reported up until the simulated trial was stopped due to all questions having been answered.\n\nPosterior odds-ratio summaryPosterior risk-difference summary\n\n\nFigure 6 shows the posterior odds-ratios for the randomised comparisons by domain and enrolment progression.\n\n\nCode\n# late acute, surgical effects\nd_d1_n &lt;- d_dat[s == 2, \n                .(n = sum(N), domain = 1), keyby = .(ia, d1)]\nsetnames(d_d1_n, \"d1\", \"trt\")\n# those receiving one-stage and randomised treatment in domain 2\nd_d2_n &lt;- d_dat[d1 == 2 & d2 %in% 2:3, \n                .(n = sum(N), domain = 2), keyby = .(ia, d2)]\nsetnames(d_d2_n, \"d2\", \"trt\")\n# those receiving two-stage and randomised treatment in domain 3\nd_d3_n &lt;- d_dat[d1 == 3 & d3 %in% 2:3, \n                .(n = sum(N), domain = 3), keyby = .(ia, d3)]\nsetnames(d_d3_n, \"d3\", \"trt\")\n# those receiving randomised treatment in domain 4\nd_d4_n &lt;- d_dat[d4 %in% 2:3, \n                .(n = sum(N), domain = 4), keyby = .(ia, d4)]\nsetnames(d_d4_n, \"d4\", \"trt\")\n\nd_n_trt &lt;- rbind(\n  d_d1_n, d_d2_n, d_d3_n, d_d4_n\n)\nd_n_trt &lt;- merge(\n  d_n_trt,\n  d_N[ia != 0],\n  by = \"ia\"\n)\n\nd_n_trt &lt;- d_n_trt[, .(n = sum(n)), keyby = .(N, domain)]\nd_n_trt[, n := cumsum(n), keyby = domain]\n\np1 &lt;- ggplot(d_mod[par == \"lor\"], aes(x = N, y = exp(med))) +\n  geom_point() +\n  geom_linerange(aes(ymin = exp(q_025), ymax = exp(q_975)), lwd = 0.25) +\n  geom_text(\n    data = d_n_trt, \n    aes(x = N, y = -0.5, label = n), col = 2, size = 2\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 6: Posterior summary measures\n\n\n\n\n\n\n\nFigure 7 shows the posterior risk differences for the randomised comparisons by domain and enrolment progression.\n\n\nCode\np1 &lt;- ggplot(d_mod[par == \"rd\"], aes(x = N, y = med)) +\n  geom_point() +\n  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 7: Posterior summary measures\n\n\n\n\n\n\n\n\nFigure 8 shows the probability associated with each decision type for the randomised comparisons by domain and enrolment progression.\nFor example, for domain 1 in analysis 1, the probability of revision being superior to DAIR (per the definition of superiority, which is a measure that is relative to nominated reference level for superiority) is approxiamtely 0.48. To make a superiority decision, this probability needs to exceed .\nSimilarly, for domain 1 in analysis 1, the probability of the superiority decision being futile (per the relevant definition) is approximately 0.28. To make a futility decision (related to superiority) this probability has to fall below .\nNote:\n\nThe futility probabilities are based on being below a given threshold (rather than above).\n\n\n\nCode\np1 &lt;- ggplot(d_fig_1, aes(x = N, y = value)) +\n  geom_point(aes(col=quant), position = position_dodge2(width = 100), size = 0.6) + \n  geom_linerange(aes(ymin = 0, ymax = value, col=quant), \n                 position = position_dodge2(width = 100), lwd = 0.25)+\n  geom_hline(\n    data = d_fig_2,\n    aes(yintercept = threshold, col=quant), lwd = 0.25\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Decision probability\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 8: Probability decision summaries\n\n\n\n\n\n\n\n\n\n\n\nReveal scenario\n\n\n\n\n\nThe results are from a simulated trial picked from scenario 6: RD = 0.12: ext-proph 12wk effect +silo specific d1.\n\n\nCode\nl_cfg\n\n\n$bs\n$bs[[1]]\n[1] 0\n\n$bs[[2]]\n[1] -0.3\n\n$bs[[3]]\n[1] -0.2\n\n\n$bp\n$bp[[1]]\n[1] 0\n\n$bp[[2]]\n[1] -0.2\n\n\n$bed1\n$bed1[[1]]\n[1] 0\n\n$bed1[[2]]\n[1] 0.1\n\n$bed1[[3]]\n[1] 0.1\n\n\n$bd3\n$bd3[[1]]\n[1] 0\n\n$bd3[[2]]\n[1] -0.1\n\n$bd3[[3]]\n[1] 0.42\n\n\n$desc\n[1] \"RD = 0.12: ext-proph 12wk effect +silo specific d1\"\n\n$nsim\n[1] 2500\n\n$mc_cores\n[1] 40\n\n$nex\n[1] 3\n\n$N_pt\n[1] 500 500 500 500 500\n\n$e_p_d1_alloc\n[1] 0.15\n\n$e_p_d2_entry\n[1] 0.7\n\n$e_p_d2_alloc\n[1] 0.5\n\n$e_p_d3_entry\n[1] 0.9\n\n$e_p_d3_alloc\n[1] 0.5\n\n$e_p_d4_entry\n[1] 0.6\n\n$e_p_d4_alloc\n[1] 0.5\n\n$e_p_pref\n[1] 0.35\n\n$l_p_d1_alloc\n[1] 0.5\n\n$l_p_d2_entry\n[1] 0.7\n\n$l_p_d2_alloc\n[1] 0.5\n\n$l_p_d3_entry\n[1] 0.9\n\n$l_p_d3_alloc\n[1] 0.5\n\n$l_p_d4_entry\n[1] 0.6\n\n$l_p_d4_alloc\n[1] 0.5\n\n$l_p_pref\n[1] 0.7\n\n$c_p_d1_alloc\n[1] 0.8\n\n$c_p_d2_entry\n[1] 0.7\n\n$c_p_d2_alloc\n[1] 0.5\n\n$c_p_d3_entry\n[1] 0.9\n\n$c_p_d3_alloc\n[1] 0.5\n\n$c_p_d4_entry\n[1] 0.6\n\n$c_p_d4_alloc\n[1] 0.5\n\n$c_p_pref\n[1] 0.75\n\n$bmu\n[1] 0.789\n\n$bld1\n[1] 0 0 0\n\n$bcd1\n[1] -0.1  0.0  0.1\n\n$bd2\n[1] 0 0 0\n\n$bd4\n[1] 0 0 0\n\n$pri_bmu\n[1] 0.7 0.7\n\n$pri_bs\n[1] 0 1\n\n$pri_bp\n[1] 0 1\n\n$pri_bd1\n[1] 0 1\n\n$pri_bd2\n[1] 0 1\n\n$pri_bd3\n[1] 0 1\n\n$pri_bd4\n[1] 0 1\n\n$dec_delta_sup\n[1] 0\n\n$dec_delta_sup_fut\n[1] 0.05\n\n$dec_delta_ni\n[1] -0.05\n\n$dec_delta_ni_fut\n[1] 0\n\n$dec_thresh_sup\n[1] 0.96 0.96 0.96 0.99\n\n$dec_thresh_ni\n[1] 0.975 0.925 0.975 0.975\n\n$dec_thresh_fut_sup\n[1] 0.3 0.3 0.3 0.3\n\n$dec_thresh_fut_ni\n[1] 0.25 0.10 0.25 0.25\n\n$ex_trial_ix\n[1]   94  600 2039",
    "crumbs": [
      "Simulations",
      "Simulation 7 - example 1"
    ]
  },
  {
    "objectID": "notebooks/sim-design6-ex03.html",
    "href": "notebooks/sim-design6-ex03.html",
    "title": "Simulation 6 - example 3",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\nsim_lab &lt;- \"sim06-05\"\n# files of interest\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim06\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\nix_scenario &lt;- 3\nix_trial &lt;- 22",
    "crumbs": [
      "Simulations",
      "Simulation 6 - example 3"
    ]
  },
  {
    "objectID": "notebooks/sim-design6-ex03.html#results-from-example-trial",
    "href": "notebooks/sim-design6-ex03.html#results-from-example-trial",
    "title": "Simulation 6 - example 3",
    "section": "Results from example trial",
    "text": "Results from example trial\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(analys, N, quant, domain)]\n  \n  \n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected number of enrolments\n# Similar to above but focus on expected number of enrolments\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 1\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix that contains the stopping decision by \n  # quantity (superiority, ni, futility, etc) for each domain by analysis\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  # long version of decision, e.g.\n  #      sim analys  quant domain  value\n  #    &lt;int&gt;  &lt;int&gt; &lt;char&gt; &lt;fctr&gt; &lt;lgcl&gt;\n  # 1:     1      1    sup     d1  FALSE\n  # 2:     1      2    sup     d1  FALSE\n  # 3:     1      3    sup     d1  FALSE\n  # 4:     1      4    sup     d1  FALSE\n  # 5:     1      5    sup     d1  FALSE\n  # 6:     2      1    sup     d1  FALSE\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case we had a sim fall over, fill in value\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # Extract the first instance of any decision occurring by sim and domain.\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise the \n# posterior means, they would thus be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# what we estimate is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 2\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  d_pars &lt;- dcast(d_pars, sim + id_analys + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  setnames(d_pars, \"id_analys\", \"analys\")\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"analys\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(analys, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nCumulative probability of each decision type for example trial\n# &gt; names(l[[ix_scenario]])\n#  [1] \"cfg\"           \"d_pr_sup\"      \"d_pr_ni\"       \"d_pr_sup_fut\"  \"d_pr_ni_fut\"   \"d_decision\"   \n#  [7] \"d_post_smry_1\" \"d_all\"         \"d_n_units\"     \"d_n_assign\" \n\n# extract the decision matrix - sim, analysis, quantity, domain level decision\n\n\nd_N &lt;- data.table(\n  analys = 0:5,\n  N = seq(0, 2500, by = 500)\n)\n\n# Extract example trial specific data\nl_cfg &lt;- copy(l[[ix_scenario]]$cfg)\nd_dat &lt;- copy(l[[ix_scenario]]$d_all[sim == ix_trial])\n# Parameter summaries from analysis\nd_mod &lt;- copy(l[[ix_scenario]]$d_post_smry_1[sim == ix_trial])\n# Decision matrix for this trial\nd_dec &lt;- copy(l[[ix_scenario]]$d_decision[sim == ix_trial])\n# Probability level reached by domain and analysis\nd_pr_sup &lt;- copy(l[[ix_scenario]]$d_pr_sup[sim == ix_trial])\nd_pr_sup_fut &lt;- copy(l[[ix_scenario]]$d_pr_sup_fut[sim == ix_trial])\nd_pr_ni &lt;- copy(l[[ix_scenario]]$d_pr_ni[sim == ix_trial])\nd_pr_ni_fut &lt;- copy(l[[ix_scenario]]$d_pr_ni_fut[sim == ix_trial])\n\n# observed data\nsetnames(d_dat, \"id_analys\", \"analys\")\nsetnames(d_mod, \"id_analys\", \"analys\")\n\nd_mod &lt;- merge(d_mod, d_N, by = \"analys\")\n\nd_pr_sup &lt;- merge(d_pr_sup, d_N, by = \"analys\")\nd_pr_sup &lt;- melt(d_pr_sup[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup[, quant := \"sup\"]\n\nd_pr_sup_fut &lt;- merge(d_pr_sup_fut, d_N, by = \"analys\")\nd_pr_sup_fut &lt;- melt(d_pr_sup_fut[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup_fut[, quant := \"sup_fut\"]\n\nd_pr_ni &lt;- merge(d_pr_ni, d_N, by = \"analys\")\nd_pr_ni &lt;- melt(d_pr_ni[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni[, quant := \"ni\"]\n\nd_pr_ni_fut &lt;- merge(d_pr_ni_fut, d_N, by = \"analys\")\nd_pr_ni_fut &lt;- melt(d_pr_ni_fut[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni_fut[, quant := \"ni_fut\"]\n\nd_pr_dec &lt;- rbind(d_pr_sup, d_pr_sup_fut, d_pr_ni, d_pr_ni_fut  )\nd_pr_dec[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_pr_dec[domain %in% c(2), question := \"Non-inferiority\"]\n\n# domain 1 relates only to the late acute silo\nd_dat_d1 &lt;- d_dat[\n  silo == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d1)]\nd_dat_d1[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d1)]\nd_dat_d1[, p_obs := cy/cn]\nd_dat_d1[, d1 := factor(d1, labels = c(\"DAIR\", \"One-stage\", \"Two-stage\"))]\n\n# domain 2 relates only to the group that receive one-stage\nd_dat_d2 &lt;- d_dat[\n  d1 == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d2)]\nd_dat_d2[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d2)]\nd_dat_d2[, p_obs := cy/cn]\nd_dat_d2[, d2 := factor(d2, labels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\n# domain 3 relates only to the group that receive two-stage\nd_dat_d3 &lt;- d_dat[\n  d1 == 3, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d3)]\nd_dat_d3[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d3)]\nd_dat_d3[, p_obs := cy/cn]\nd_dat_d3[, d3 := factor(d3, labels = c(\"Selected\", \"none\", \"12wk\"))]\n\n# domain 4 relates only to the group that receive two-stage\nd_dat_d4 &lt;- d_dat[\n  , .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d4)]\nd_dat_d4[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d4)]\nd_dat_d4[, p_obs := cy/cn]\nd_dat_d4[, d4 := factor(d4, labels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\nd_dec &lt;- melt(d_dec, measure.vars = paste0(\"d\", 1:4), variable.name = \"domain\")\nd_dec[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n# Subset to the decisions that are evaluated by domain\nd_dec &lt;- rbind(\n  d_dec[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n  d_dec[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n)\n\n\nd_dec_thres &lt;- data.table(\n  quant = rep(c(\"sup\", \"sup_fut\", \"ni\", \"ni_fut\"), each = 4),\n  domain = rep(1:4, len = 16)\n  )\nd_dec_thres[, threshold := c(\n    l_cfg$dec_probs$thresh_sup,\n    l_cfg$dec_probs$thresh_fut_sup,\n    l_cfg$dec_probs$thresh_ni,\n    l_cfg$dec_probs$thresh_fut_ni\n  )]\n\n\n## State transition through the different states of knowledge based on decisions\n\nd_dec_timeline &lt;- merge(\n  CJ(domain = 1:4, analys = 0:5),\n  d_N, by = \"analys\", all.y = T\n)\nsetorder(d_dec_timeline, domain, analys)\nd_dec_timeline[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_dec_timeline[domain %in% c(2), question := \"Non-inferiority\"]\nd_dec_timeline[N == 0, decision := \"Indeterminate\"]\n\n\ni &lt;- j &lt;- 1\n# For i across domains\nfor(i in 1:4){\n  # For j across analyses\n  for(j in 1:5){\n    \n    if(i %in% c(1, 3, 4)){\n      \n      if(d_dec[domain == i & analys == j & quant == \"sup\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"Superior\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_sup\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (sup)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    } else {\n      \n      if(d_dec[domain == i & analys == j & quant == \"ni\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"NI\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_ni\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (NI)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    }\n    \n  }\n  \n}\n\nd_dec_timeline[, decision := factor(decision, levels = c(\n  \"Indeterminate\", \"Superior\", \"Futile (sup)\", \"NI\", \"Futile (NI)\"\n))]\n\n\n# Dealing with those for which a decision was not reached.\nd_decision &lt;- data.table(\n  domain = 1:4,\n  N = 2500\n)\nif(any(d_dec_timeline$decision != \"Indeterminate\")){\n  d_decision &lt;- d_dec_timeline[\n    decision != \"Indeterminate\", .(N = min(N)), keyby = .(domain, decision)]\n}\n\nd_decision &lt;- merge(\n  d_decision, \n  data.table(domain = 1:4),\n  by = \"domain\", all.y = T\n)\nd_decision[is.na(decision), `:=`(\n  decision = \"Intermediate\", N = 2500  \n)]\n\n\nd_dec_timeline &lt;- d_dec_timeline[N &lt;= max(d_decision$N)]\n\n\nTable 1 shows the decisions made for each domain (or indeterminate if no decisions were made).\n\n\nCode\ng_tbl &lt;- d_decision |&gt; \n  gt() |&gt; \n  cols_align(\n    columns = 1:2,\n    align = \"center\"\n  )  |&gt; \n  cols_align(\n    columns = 3,\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    decision = \"Decision\",\n    N = \"Enrolment\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nDomain\nDecision\nEnrolment\n\n\n\n\n1\nFutile (sup)\n500\n\n\n2\nIntermediate\n2,500\n\n\n3\nFutile (sup)\n500\n\n\n4\nFutile (sup)\n1,000\n\n\n\n\n\n\n\n\nTable 1: Trial decisions by domain\n\n\n\n\nFigure 1 shows the knowledge transitions based on the decisions made for each domain by sample size up to the point where the trial was stopped either due to running out of resources or having addressed all the questions.\nInitially, all domains start in an indeterminate state in that neither treatment arm is preferred. As the data accrues and analyses progresses, the knowledge state for each domain may transition to, superiority, non-inferiority or futility.\n\n\nCode\np1 &lt;- ggplot(d_dec_timeline, aes(x = N, y = decision)) +\n  geom_point() +\n  scale_y_discrete(\"\", drop=FALSE) +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 1: Decision timeline\n\n\n\n\n\nFigure 2 through to Figure 5 show sample size for each domains.\n\nDomain 1: Sample sizeDomain 2: Sample sizeDomain 3: Sample sizeDomain 4: Sample size\n\n\nAny decision rule only applies to the late acute silo (silo 2).\n\n\nCode\nd_fig &lt;- copy(d_dat_d1)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d1 = c(\"DAIR\", \"One-stage\", \"Two-stage\")),\n  by = c(\"silo\", \"analys\", \"d1\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d1)]\n\np_d1 &lt;- ggplot(d_fig, aes(x = d1, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\", breaks = seq(0, 800, by = 200)) +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(print(p_d1))\n\n\n\n\n\n\n\n\nFigure 2: Domain 1: Surgical sample size\n\n\n\n\n\n\n\nOf those receiving one-stage (see figure for domain 1) and irrespective of silo membership, approximately 70% are assumed to enter the AB duration domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d2)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"silo\", \"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_a &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d2)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d2)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_b &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d2_a, p_d2_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\nOf those receiving two-stage (see figure for domain 1) and irrespective of silo membership, approximately 90% are assumed to enter the AB ext-proph domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d3)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"silo\", \"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_a &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d3)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d3)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_b &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d3_a, p_d3_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 4: Domain 3: AB Expt-proph sample size\n\n\n\n\n\n\n\nAcross the entire trial sample, approximately 60% are assumed to enter the AB choice domain.\nHere, we know there is an effect of AB choice and would hope that a decision for superiority is made such that new participants are directed to receive rifampacin.\n\n\nCode\nd_fig &lt;- copy(d_dat_d4)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"silo\", \"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\np_d4_a &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6))\n\nd_fig &lt;- copy(d_dat_d4)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d4)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\np_d4_b &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d4_a, p_d4_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 5: AB Choice sample size\n\n\n\n\n\n\n\n\nFigure 6 and Figure 7 show the parameter estimates.\nNote:\nParameter estimates will only be reported up until the simulated trial was stopped due to all questions having been answered.\n\nPosterior odds-ratio summaryPosterior risk-difference summary\n\n\nFigure 6 shows the posterior odds-ratios for the randomised comparisons by domain and enrolment progression.\n\n\nCode\n# late acute, surgical effects\nd_d1_n &lt;- d_dat[silo == 2, \n                .(n = sum(N), domain = 1), keyby = .(analys, d1)]\nsetnames(d_d1_n, \"d1\", \"trt\")\n# those receiving one-stage and randomised treatment in domain 2\nd_d2_n &lt;- d_dat[d1 == 2 & d2 %in% 2:3, \n                .(n = sum(N), domain = 2), keyby = .(analys, d2)]\nsetnames(d_d2_n, \"d2\", \"trt\")\n# those receiving two-stage and randomised treatment in domain 3\nd_d3_n &lt;- d_dat[d1 == 3 & d3 %in% 2:3, \n                .(n = sum(N), domain = 3), keyby = .(analys, d3)]\nsetnames(d_d3_n, \"d3\", \"trt\")\n# those receiving randomised treatment in domain 4\nd_d4_n &lt;- d_dat[d4 %in% 2:3, \n                .(n = sum(N), domain = 4), keyby = .(analys, d4)]\nsetnames(d_d4_n, \"d4\", \"trt\")\n\nd_n_trt &lt;- rbind(\n  d_d1_n, d_d2_n, d_d3_n, d_d4_n\n)\nd_n_trt &lt;- merge(\n  d_n_trt,\n  d_N[analys != 0],\n  by = \"analys\"\n)\n\nd_n_trt &lt;- d_n_trt[, .(n = sum(n)), keyby = .(N, domain)]\nd_n_trt[, n := cumsum(n), keyby = domain]\n\np1 &lt;- ggplot(d_mod[par == \"lor\"], aes(x = N, y = exp(med))) +\n  geom_point() +\n  geom_linerange(aes(ymin = exp(q_025), ymax = exp(q_975)), lwd = 0.25) +\n  geom_text(\n    data = d_n_trt, \n    aes(x = N, y = -0.5, label = n), col = 2, size = 2\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 6: Posterior summary measures\n\n\n\n\n\n\n\nFigure 7 shows the posterior risk differences for the randomised comparisons by domain and enrolment progression.\n\n\nCode\np1 &lt;- ggplot(d_mod[par == \"rd\"], aes(x = N, y = med)) +\n  geom_point() +\n  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 7: Posterior summary measures\n\n\n\n\n\n\n\n\nFigure 8 shows the probability associated with each decision type for the randomised comparisons by domain and enrolment progression.\nFor example, for domain 1 in analysis 1, the probability of revision being superior to DAIR (per the definition of superiority, which is a measure that is relative to nominated reference level for superiority) is approxiamtely 0.53. To make a superiority decision, this probability needs to exceed 0.920.\nSimilarly, for domain 1 in analysis 1, the probability of the superiority decision being futile (per the relevant definition) is approximately 0.29. To make a futility decision (related to superiority) this probability has to fall below 0.300.\nNote:\n\nThe futility probabilities are based on being below a given threshold (rather than above).\n\n\n\nCode\np1 &lt;- ggplot(d_fig_1, aes(x = N, y = value)) +\n  geom_point(aes(col=quant), position = position_dodge2(width = 100), size = 0.6) + \n  geom_linerange(aes(ymin = 0, ymax = value, col=quant), \n                 position = position_dodge2(width = 100), lwd = 0.25)+\n  geom_hline(\n    data = d_fig_2,\n    aes(yintercept = threshold, col=quant), lwd = 0.25\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Decision probability\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 8: Probability decision summaries\n\n\n\n\n\n\n\n\n\n\n\nReveal scenario\n\n\n\n\n\nThe results are from a simulated trial picked from scenario 3: Moderate (OR 1.75) surgical revision effect (one-stage) +silo specific effects.\n\n\nCode\nl_cfg\n\n\n$cov\n$cov$silo\n$cov$silo[[1]]\n[1] 0\n\n$cov$silo[[2]]\n[1] -0.3\n\n$cov$silo[[3]]\n[1] -0.2\n\n\n$cov$jnt\n$cov$jnt[[1]]\n[1] 0\n\n$cov$jnt[[2]]\n[1] 0.4\n\n\n$cov$pref\n$cov$pref[[1]]\n[1] 0\n\n$cov$pref[[2]]\n[1] -0.2\n\n\n$cov$mu\n[1] 0.7\n\n\n$d1\n$d1[[1]]\n[1] 0\n\n$d1[[2]]\n[1] 0.693\n\n$d1[[3]]\n[1] 0.693\n\n$d1[[4]]\n[1] -0.1\n\n$d1[[5]]\n[1] 0.4596\n\n$d1[[6]]\n[1] -0.1\n\n$d1[[7]]\n[1] 0.1\n\n$d1[[8]]\n[1] 0.693\n\n$d1[[9]]\n[1] 0.693\n\n\n$pri\n$pri$mu\n[1] 0.7 0.7\n\n$pri$b_silo\n[1] 0 1\n\n$pri$b_jnt\n[1] 0 1\n\n$pri$b_prf\n[1] 0 1\n\n$pri$b_trt\n[1] 0 1\n\n\n$dec_ref\n$dec_ref$delta_sup\n[1] 0\n\n$dec_ref$delta_sup_fut\n[1] 0.05\n\n$dec_ref$delta_ni\n[1] -0.05\n\n$dec_ref$delta_ni_fut\n[1] 0\n\n\n$dec_probs\n$dec_probs$thresh_sup\n[1] 0.920 0.950 0.950 0.995\n\n$dec_probs$thresh_ni\n[1] 0.975 0.925 0.975 0.975\n\n$dec_probs$thresh_fut_sup\n[1] 0.30 0.25 0.25 0.25\n\n$dec_probs$thresh_fut_ni\n[1] 0.25 0.10 0.25 0.25\n\n\n$desc\n[1] \"Moderate (OR 1.75) surgical revision effect (one-stage) +silo specific effects\"\n\n$nsim\n[1] 2500\n\n$mc_cores\n[1] 40\n\n$N_pt\n[1]  500 1000 1500 2000 2500\n\n$d2\n[1] 0 0 0\n\n$d3\n[1] 0 0 0\n\n$d4\n[1] 0 0 0",
    "crumbs": [
      "Simulations",
      "Simulation 6 - example 3"
    ]
  },
  {
    "objectID": "notebooks/sim-design6-ex01.html",
    "href": "notebooks/sim-design6-ex01.html",
    "title": "Simulation 6 - example 1",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\nsim_lab &lt;- \"sim06-05\"\n# files of interest\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim06\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\nix_scenario &lt;- 7\nix_trial &lt;- 83",
    "crumbs": [
      "Simulations",
      "Simulation 6 - example 1"
    ]
  },
  {
    "objectID": "notebooks/sim-design6-ex01.html#results-from-example-trial",
    "href": "notebooks/sim-design6-ex01.html#results-from-example-trial",
    "title": "Simulation 6 - example 1",
    "section": "Results from example trial",
    "text": "Results from example trial\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(analys, N, quant, domain)]\n  \n  \n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected number of enrolments\n# Similar to above but focus on expected number of enrolments\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 1\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix that contains the stopping decision by \n  # quantity (superiority, ni, futility, etc) for each domain by analysis\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  # long version of decision, e.g.\n  #      sim analys  quant domain  value\n  #    &lt;int&gt;  &lt;int&gt; &lt;char&gt; &lt;fctr&gt; &lt;lgcl&gt;\n  # 1:     1      1    sup     d1  FALSE\n  # 2:     1      2    sup     d1  FALSE\n  # 3:     1      3    sup     d1  FALSE\n  # 4:     1      4    sup     d1  FALSE\n  # 5:     1      5    sup     d1  FALSE\n  # 6:     2      1    sup     d1  FALSE\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case we had a sim fall over, fill in value\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # Extract the first instance of any decision occurring by sim and domain.\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise the \n# posterior means, they would thus be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# what we estimate is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 2\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  d_pars &lt;- dcast(d_pars, sim + id_analys + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  setnames(d_pars, \"id_analys\", \"analys\")\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"analys\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(analys, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nCumulative probability of each decision type for example trial\n# &gt; names(l[[ix_scenario]])\n#  [1] \"cfg\"           \"d_pr_sup\"      \"d_pr_ni\"       \"d_pr_sup_fut\"  \"d_pr_ni_fut\"   \"d_decision\"   \n#  [7] \"d_post_smry_1\" \"d_all\"         \"d_n_units\"     \"d_n_assign\" \n\n# extract the decision matrix - sim, analysis, quantity, domain level decision\n\n\nd_N &lt;- data.table(\n  analys = 0:5,\n  N = seq(0, 2500, by = 500)\n)\n\n# Extract example trial specific data\nl_cfg &lt;- copy(l[[ix_scenario]]$cfg)\nd_dat &lt;- copy(l[[ix_scenario]]$d_all[sim == ix_trial])\n# Parameter summaries from analysis\nd_mod &lt;- copy(l[[ix_scenario]]$d_post_smry_1[sim == ix_trial])\n# Decision matrix for this trial\nd_dec &lt;- copy(l[[ix_scenario]]$d_decision[sim == ix_trial])\n# Probability level reached by domain and analysis\nd_pr_sup &lt;- copy(l[[ix_scenario]]$d_pr_sup[sim == ix_trial])\nd_pr_sup_fut &lt;- copy(l[[ix_scenario]]$d_pr_sup_fut[sim == ix_trial])\nd_pr_ni &lt;- copy(l[[ix_scenario]]$d_pr_ni[sim == ix_trial])\nd_pr_ni_fut &lt;- copy(l[[ix_scenario]]$d_pr_ni_fut[sim == ix_trial])\n\n# observed data\nsetnames(d_dat, \"id_analys\", \"analys\")\nsetnames(d_mod, \"id_analys\", \"analys\")\n\nd_mod &lt;- merge(d_mod, d_N, by = \"analys\")\n\nd_pr_sup &lt;- merge(d_pr_sup, d_N, by = \"analys\")\nd_pr_sup &lt;- melt(d_pr_sup[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup[, quant := \"sup\"]\n\nd_pr_sup_fut &lt;- merge(d_pr_sup_fut, d_N, by = \"analys\")\nd_pr_sup_fut &lt;- melt(d_pr_sup_fut[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup_fut[, quant := \"sup_fut\"]\n\nd_pr_ni &lt;- merge(d_pr_ni, d_N, by = \"analys\")\nd_pr_ni &lt;- melt(d_pr_ni[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni[, quant := \"ni\"]\n\nd_pr_ni_fut &lt;- merge(d_pr_ni_fut, d_N, by = \"analys\")\nd_pr_ni_fut &lt;- melt(d_pr_ni_fut[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni_fut[, quant := \"ni_fut\"]\n\nd_pr_dec &lt;- rbind(d_pr_sup, d_pr_sup_fut, d_pr_ni, d_pr_ni_fut  )\nd_pr_dec[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_pr_dec[domain %in% c(2), question := \"Non-inferiority\"]\n\n# domain 1 relates only to the late acute silo\nd_dat_d1 &lt;- d_dat[\n  silo == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d1)]\nd_dat_d1[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d1)]\nd_dat_d1[, p_obs := cy/cn]\nd_dat_d1[, d1 := factor(d1, labels = c(\"DAIR\", \"One-stage\", \"Two-stage\"))]\n\n# domain 2 relates only to the group that receive one-stage\nd_dat_d2 &lt;- d_dat[\n  d1 == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d2)]\nd_dat_d2[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d2)]\nd_dat_d2[, p_obs := cy/cn]\nd_dat_d2[, d2 := factor(d2, labels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\n# domain 3 relates only to the group that receive two-stage\nd_dat_d3 &lt;- d_dat[\n  d1 == 3, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d3)]\nd_dat_d3[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d3)]\nd_dat_d3[, p_obs := cy/cn]\nd_dat_d3[, d3 := factor(d3, labels = c(\"Selected\", \"none\", \"12wk\"))]\n\n# domain 4 relates only to the group that receive two-stage\nd_dat_d4 &lt;- d_dat[\n  , .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d4)]\nd_dat_d4[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d4)]\nd_dat_d4[, p_obs := cy/cn]\nd_dat_d4[, d4 := factor(d4, labels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\nd_dec &lt;- melt(d_dec, measure.vars = paste0(\"d\", 1:4), variable.name = \"domain\")\nd_dec[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n# Subset to the decisions that are evaluated by domain\nd_dec &lt;- rbind(\n  d_dec[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n  d_dec[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n)\n\n\nd_dec_thres &lt;- data.table(\n  quant = rep(c(\"sup\", \"sup_fut\", \"ni\", \"ni_fut\"), each = 4),\n  domain = rep(1:4, len = 16)\n  )\nd_dec_thres[, threshold := c(\n    l_cfg$dec_probs$thresh_sup,\n    l_cfg$dec_probs$thresh_fut_sup,\n    l_cfg$dec_probs$thresh_ni,\n    l_cfg$dec_probs$thresh_fut_ni\n  )]\n\n\n## State transition through the different states of knowledge based on decisions\n\nd_dec_timeline &lt;- merge(\n  CJ(domain = 1:4, analys = 0:5),\n  d_N, by = \"analys\", all.y = T\n)\nsetorder(d_dec_timeline, domain, analys)\nd_dec_timeline[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_dec_timeline[domain %in% c(2), question := \"Non-inferiority\"]\nd_dec_timeline[N == 0, decision := \"Indeterminate\"]\n\n\ni &lt;- j &lt;- 1\n# For i across domains\nfor(i in 1:4){\n  # For j across analyses\n  for(j in 1:5){\n    \n    if(i %in% c(1, 3, 4)){\n      \n      if(d_dec[domain == i & analys == j & quant == \"sup\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"Superior\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_sup\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (sup)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    } else {\n      \n      if(d_dec[domain == i & analys == j & quant == \"ni\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"NI\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_ni\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (NI)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    }\n    \n  }\n  \n}\n\nd_dec_timeline[, decision := factor(decision, levels = c(\n  \"Indeterminate\", \"Superior\", \"Futile (sup)\", \"NI\", \"Futile (NI)\"\n))]\n\n\n# Dealing with those for which a decision was not reached.\nd_decision &lt;- data.table(\n  domain = 1:4,\n  N = 2500\n)\nif(any(d_dec_timeline$decision != \"Indeterminate\")){\n  d_decision &lt;- d_dec_timeline[\n    decision != \"Indeterminate\", .(N = min(N)), keyby = .(domain, decision)]\n}\n\nd_decision &lt;- merge(\n  d_decision, \n  data.table(domain = 1:4),\n  by = \"domain\", all.y = T\n)\nd_decision[is.na(decision), `:=`(\n  decision = \"Intermediate\", N = 2500  \n)]\n\n\nd_dec_timeline &lt;- d_dec_timeline[N &lt;= max(d_decision$N)]\n\n\nTable 1 shows the decisions made for each domain (or indeterminate if no decisions were made).\n\n\nCode\ng_tbl &lt;- d_decision |&gt; \n  gt() |&gt; \n  cols_align(\n    columns = 1:2,\n    align = \"center\"\n  )  |&gt; \n  cols_align(\n    columns = 3,\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    decision = \"Decision\",\n    N = \"Enrolment\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nDomain\nDecision\nEnrolment\n\n\n\n\n1\nFutile (sup)\n500\n\n\n2\nIntermediate\n2,500\n\n\n3\nIntermediate\n2,500\n\n\n4\nSuperior\n1,000\n\n\n\n\n\n\n\n\nTable 1: Trial decisions by domain\n\n\n\n\nFigure 1 shows the knowledge transitions based on the decisions made for each domain by sample size up to the point where the trial was stopped either due to running out of resources or having addressed all the questions.\nInitially, all domains start in an indeterminate state in that neither treatment arm is preferred. As the data accrues and analyses progresses, the knowledge state for each domain may transition to, superiority, non-inferiority or futility.\n\n\nCode\np1 &lt;- ggplot(d_dec_timeline, aes(x = N, y = decision)) +\n  geom_point() +\n  scale_y_discrete(\"\", drop=FALSE) +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 1: Decision timeline\n\n\n\n\n\nFigure 2 through to Figure 5 show sample size for each domains.\n\nDomain 1: Sample sizeDomain 2: Sample sizeDomain 3: Sample sizeDomain 4: Sample size\n\n\nAny decision rule only applies to the late acute silo (silo 2).\n\n\nCode\nd_fig &lt;- copy(d_dat_d1)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d1 = c(\"DAIR\", \"One-stage\", \"Two-stage\")),\n  by = c(\"silo\", \"analys\", \"d1\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d1)]\n\np_d1 &lt;- ggplot(d_fig, aes(x = d1, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\", breaks = seq(0, 800, by = 200)) +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(print(p_d1))\n\n\n\n\n\n\n\n\nFigure 2: Domain 1: Surgical sample size\n\n\n\n\n\n\n\nOf those receiving one-stage (see figure for domain 1) and irrespective of silo membership, approximately 70% are assumed to enter the AB duration domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d2)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"silo\", \"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_a &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d2)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d2)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_b &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d2_a, p_d2_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\nOf those receiving two-stage (see figure for domain 1) and irrespective of silo membership, approximately 90% are assumed to enter the AB ext-proph domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d3)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"silo\", \"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_a &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d3)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d3)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_b &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d3_a, p_d3_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 4: Domain 3: AB Expt-proph sample size\n\n\n\n\n\n\n\nAcross the entire trial sample, approximately 60% are assumed to enter the AB choice domain.\nHere, we know there is an effect of AB choice and would hope that a decision for superiority is made such that new participants are directed to receive rifampacin.\n\n\nCode\nd_fig &lt;- copy(d_dat_d4)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"silo\", \"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\np_d4_a &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6))\n\nd_fig &lt;- copy(d_dat_d4)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d4)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\np_d4_b &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d4_a, p_d4_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 5: AB Choice sample size\n\n\n\n\n\n\n\n\nFigure 6 and Figure 7 show the parameter estimates.\nNote:\nParameter estimates will only be reported up until the simulated trial was stopped due to all questions having been answered.\n\nPosterior odds-ratio summaryPosterior risk-difference summary\n\n\nFigure 6 shows the posterior odds-ratios for the randomised comparisons by domain and enrolment progression.\n\n\nCode\n# late acute, surgical effects\nd_d1_n &lt;- d_dat[silo == 2, \n                .(n = sum(N), domain = 1), keyby = .(analys, d1)]\nsetnames(d_d1_n, \"d1\", \"trt\")\n# those receiving one-stage and randomised treatment in domain 2\nd_d2_n &lt;- d_dat[d1 == 2 & d2 %in% 2:3, \n                .(n = sum(N), domain = 2), keyby = .(analys, d2)]\nsetnames(d_d2_n, \"d2\", \"trt\")\n# those receiving two-stage and randomised treatment in domain 3\nd_d3_n &lt;- d_dat[d1 == 3 & d3 %in% 2:3, \n                .(n = sum(N), domain = 3), keyby = .(analys, d3)]\nsetnames(d_d3_n, \"d3\", \"trt\")\n# those receiving randomised treatment in domain 4\nd_d4_n &lt;- d_dat[d4 %in% 2:3, \n                .(n = sum(N), domain = 4), keyby = .(analys, d4)]\nsetnames(d_d4_n, \"d4\", \"trt\")\n\nd_n_trt &lt;- rbind(\n  d_d1_n, d_d2_n, d_d3_n, d_d4_n\n)\nd_n_trt &lt;- merge(\n  d_n_trt,\n  d_N[analys != 0],\n  by = \"analys\"\n)\n\nd_n_trt &lt;- d_n_trt[, .(n = sum(n)), keyby = .(N, domain)]\nd_n_trt[, n := cumsum(n), keyby = domain]\n\np1 &lt;- ggplot(d_mod[par == \"lor\"], aes(x = N, y = exp(med))) +\n  geom_point() +\n  geom_linerange(aes(ymin = exp(q_025), ymax = exp(q_975)), lwd = 0.25) +\n  geom_text(\n    data = d_n_trt, \n    aes(x = N, y = -0.5, label = n), col = 2, size = 2\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 6: Posterior summary measures\n\n\n\n\n\n\n\nFigure 7 shows the posterior risk differences for the randomised comparisons by domain and enrolment progression.\n\n\nCode\np1 &lt;- ggplot(d_mod[par == \"rd\"], aes(x = N, y = med)) +\n  geom_point() +\n  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 7: Posterior summary measures\n\n\n\n\n\n\n\n\nFigure 8 shows the probability associated with each decision type for the randomised comparisons by domain and enrolment progression.\nFor example, for domain 1 in analysis 1, the probability of revision being superior to DAIR (per the definition of superiority, which is a measure that is relative to nominated reference level for superiority) is approxiamtely 0.06. To make a superiority decision, this probability needs to exceed 0.920.\nSimilarly, for domain 1 in analysis 1, the probability of the superiority decision being futile (per the relevant definition) is approximately 0.01. To make a futility decision (related to superiority) this probability has to fall below 0.300.\nNote:\n\nThe futility probabilities are based on being below a given threshold (rather than above).\n\n\n\nCode\np1 &lt;- ggplot(d_fig_1, aes(x = N, y = value)) +\n  geom_point(aes(col=quant), position = position_dodge2(width = 100), size = 0.6) + \n  geom_linerange(aes(ymin = 0, ymax = value, col=quant), \n                 position = position_dodge2(width = 100), lwd = 0.25)+\n  geom_hline(\n    data = d_fig_2,\n    aes(yintercept = threshold, col=quant), lwd = 0.25\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Decision probability\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 8: Probability decision summaries\n\n\n\n\n\n\n\n\n\n\n\nReveal scenario\n\n\n\n\n\nThe results are from a simulated trial picked from scenario 7: Moderate (OR 1.75) antibiotic choice rifampacin effect +silo specific effects.\n\n\nCode\nl_cfg\n\n\n$cov\n$cov$silo\n$cov$silo[[1]]\n[1] 0\n\n$cov$silo[[2]]\n[1] -0.3\n\n$cov$silo[[3]]\n[1] -0.2\n\n\n$cov$jnt\n$cov$jnt[[1]]\n[1] 0\n\n$cov$jnt[[2]]\n[1] 0.4\n\n\n$cov$pref\n$cov$pref[[1]]\n[1] 0\n\n$cov$pref[[2]]\n[1] -0.2\n\n\n$cov$mu\n[1] 0.7\n\n\n$d1\n$d1[[1]]\n[1] 0\n\n$d1[[2]]\n[1] 0.693\n\n$d1[[3]]\n[1] 0.693\n\n$d1[[4]]\n[1] 0\n\n$d1[[5]]\n[1] 0\n\n$d1[[6]]\n[1] 0\n\n$d1[[7]]\n[1] 0.1\n\n$d1[[8]]\n[1] 0.693\n\n$d1[[9]]\n[1] 0.693\n\n\n$d4\n$d4[[1]]\n[1] 0\n\n$d4[[2]]\n[1] -0.1\n\n$d4[[3]]\n[1] 0.4596\n\n\n$pri\n$pri$mu\n[1] 0.7 0.7\n\n$pri$b_silo\n[1] 0 1\n\n$pri$b_jnt\n[1] 0 1\n\n$pri$b_prf\n[1] 0 1\n\n$pri$b_trt\n[1] 0 1\n\n\n$dec_ref\n$dec_ref$delta_sup\n[1] 0\n\n$dec_ref$delta_sup_fut\n[1] 0.05\n\n$dec_ref$delta_ni\n[1] -0.05\n\n$dec_ref$delta_ni_fut\n[1] 0\n\n\n$dec_probs\n$dec_probs$thresh_sup\n[1] 0.920 0.950 0.950 0.995\n\n$dec_probs$thresh_ni\n[1] 0.975 0.925 0.975 0.975\n\n$dec_probs$thresh_fut_sup\n[1] 0.30 0.25 0.25 0.25\n\n$dec_probs$thresh_fut_ni\n[1] 0.25 0.10 0.25 0.25\n\n\n$desc\n[1] \"Moderate (OR 1.75) antibiotic choice rifampacin effect +silo specific effects\"\n\n$nsim\n[1] 2500\n\n$mc_cores\n[1] 40\n\n$N_pt\n[1]  500 1000 1500 2000 2500\n\n$d2\n[1] 0 0 0\n\n$d3\n[1] 0 0 0",
    "crumbs": [
      "Simulations",
      "Simulation 6 - example 1"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-ex03.html",
    "href": "notebooks/sim-design5-ex03.html",
    "title": "Simulation 5 - example 3",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\n\nsim_lab &lt;- \"sim05-15\"\n# files of interest\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim05\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\nix_scenario &lt;- 9\nix_trial = 599",
    "crumbs": [
      "Simulations",
      "Simulation 5 - example 3"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-ex03.html#results-from-example-trial",
    "href": "notebooks/sim-design5-ex03.html#results-from-example-trial",
    "title": "Simulation 5 - example 3",
    "section": "Results from example trial",
    "text": "Results from example trial\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(analys, N, quant, domain)]\n  \n  \n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected number of enrolments\n# Similar to above but focus on expected number of enrolments\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 1\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix that contains the stopping decision by \n  # quantity (superiority, ni, futility, etc) for each domain by analysis\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  # long version of decision, e.g.\n  #      sim analys  quant domain  value\n  #    &lt;int&gt;  &lt;int&gt; &lt;char&gt; &lt;fctr&gt; &lt;lgcl&gt;\n  # 1:     1      1    sup     d1  FALSE\n  # 2:     1      2    sup     d1  FALSE\n  # 3:     1      3    sup     d1  FALSE\n  # 4:     1      4    sup     d1  FALSE\n  # 5:     1      5    sup     d1  FALSE\n  # 6:     2      1    sup     d1  FALSE\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case we had a sim fall over, fill in value\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # Extract the first instance of any decision occurring by sim and domain.\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise the \n# posterior means, they would thus be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# what we estimate is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 2\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  d_pars &lt;- dcast(d_pars, sim + id_analys + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  setnames(d_pars, \"id_analys\", \"analys\")\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"analys\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(analys, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nCumulative probability of each decision type\n# &gt; names(l[[ix_scenario]])\n#  [1] \"cfg\"           \"d_pr_sup\"      \"d_pr_ni\"       \"d_pr_sup_fut\"  \"d_pr_ni_fut\"   \"d_decision\"   \n#  [7] \"d_post_smry_1\" \"d_all\"         \"d_n_units\"     \"d_n_assign\" \n\n# extract the decision matrix - sim, analysis, quantity, domain level decision\n\n\nd_N &lt;- data.table(\n  analys = 0:5,\n  N = seq(0, 2500, by = 500)\n)\n\n# Extract example trial specific data\nl_cfg &lt;- copy(l[[ix_scenario]]$cfg)\nd_dat &lt;- copy(l[[ix_scenario]]$d_all[sim == ix_trial])\n# Parameter summaries from analysis\nd_mod &lt;- copy(l[[ix_scenario]]$d_post_smry_1[sim == ix_trial])\n# Decision matrix for this trial\nd_dec &lt;- copy(l[[ix_scenario]]$d_decision[sim == ix_trial])\n# Probability level reached by domain and analysis\nd_pr_sup &lt;- copy(l[[ix_scenario]]$d_pr_sup[sim == ix_trial])\nd_pr_sup_fut &lt;- copy(l[[ix_scenario]]$d_pr_sup_fut[sim == ix_trial])\nd_pr_ni &lt;- copy(l[[ix_scenario]]$d_pr_ni[sim == ix_trial])\nd_pr_ni_fut &lt;- copy(l[[ix_scenario]]$d_pr_ni_fut[sim == ix_trial])\n\n# observed data\nsetnames(d_dat, \"id_analys\", \"analys\")\nsetnames(d_mod, \"id_analys\", \"analys\")\n\nd_mod &lt;- merge(d_mod, d_N, by = \"analys\")\n\nd_pr_sup &lt;- merge(d_pr_sup, d_N, by = \"analys\")\nd_pr_sup &lt;- melt(d_pr_sup[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup[, quant := \"sup\"]\n\nd_pr_sup_fut &lt;- merge(d_pr_sup_fut, d_N, by = \"analys\")\nd_pr_sup_fut &lt;- melt(d_pr_sup_fut[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup_fut[, quant := \"sup_fut\"]\n\nd_pr_ni &lt;- merge(d_pr_ni, d_N, by = \"analys\")\nd_pr_ni &lt;- melt(d_pr_ni[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni[, quant := \"ni\"]\n\nd_pr_ni_fut &lt;- merge(d_pr_ni_fut, d_N, by = \"analys\")\nd_pr_ni_fut &lt;- melt(d_pr_ni_fut[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni_fut[, quant := \"ni_fut\"]\n\nd_pr_dec &lt;- rbind(d_pr_sup, d_pr_sup_fut, d_pr_ni, d_pr_ni_fut  )\nd_pr_dec[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_pr_dec[domain %in% c(2), question := \"Non-inferiority\"]\n\n# domain 1 relates only to the late acute silo\nd_dat_d1 &lt;- d_dat[\n  silo == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d1)]\nd_dat_d1[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d1)]\nd_dat_d1[, p_obs := cy/cn]\nd_dat_d1[, d1 := factor(d1, labels = c(\"DAIR\", \"One-stage\", \"Two-stage\"))]\n\n# domain 2 relates only to the group that receive one-stage\nd_dat_d2 &lt;- d_dat[\n  d1 == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d2)]\nd_dat_d2[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d2)]\nd_dat_d2[, p_obs := cy/cn]\nd_dat_d2[, d2 := factor(d2, labels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\n# domain 3 relates only to the group that receive two-stage\nd_dat_d3 &lt;- d_dat[\n  d1 == 3, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d3)]\nd_dat_d3[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d3)]\nd_dat_d3[, p_obs := cy/cn]\nd_dat_d3[, d3 := factor(d3, labels = c(\"Selected\", \"none\", \"12wk\"))]\n\n# domain 4 relates only to the group that receive two-stage\nd_dat_d4 &lt;- d_dat[\n  , .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d4)]\nd_dat_d4[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d4)]\nd_dat_d4[, p_obs := cy/cn]\nd_dat_d4[, d4 := factor(d4, labels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\nd_dec &lt;- melt(d_dec, measure.vars = paste0(\"d\", 1:4), variable.name = \"domain\")\nd_dec[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n# Subset to the decisions that are evaluated by domain\nd_dec &lt;- rbind(\n  d_dec[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n  d_dec[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n)\n\n\nd_dec_thres &lt;- data.table(\n  quant = rep(c(\"sup\", \"sup_fut\", \"ni\", \"ni_fut\"), each = 4),\n  domain = rep(1:4, len = 16)\n  )\nd_dec_thres[, threshold := c(\n    l_cfg$dec_probs$thresh_sup,\n    l_cfg$dec_probs$thresh_fut_sup,\n    l_cfg$dec_probs$thresh_ni,\n    l_cfg$dec_probs$thresh_fut_ni\n  )]\n\n\n## State transition through the different states of knowledge based on decisions\n\nd_dec_timeline &lt;- merge(\n  CJ(domain = 1:4, analys = 0:5),\n  d_N, by = \"analys\", all.y = T\n)\nsetorder(d_dec_timeline, domain, analys)\nd_dec_timeline[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_dec_timeline[domain %in% c(2), question := \"Non-inferiority\"]\nd_dec_timeline[N == 0, decision := \"Indeterminate\"]\n\n\ni &lt;- j &lt;- 1\n# For i across domains\nfor(i in 1:4){\n  # For j across analyses\n  for(j in 1:5){\n    \n    if(i %in% c(1, 3, 4)){\n      \n      if(d_dec[domain == i & analys == j & quant == \"sup\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"Superior\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_sup\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (sup)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    } else {\n      \n      if(d_dec[domain == i & analys == j & quant == \"ni\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"NI\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_ni\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (NI)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    }\n    \n  }\n  \n}\n\nd_dec_timeline[, decision := factor(decision, levels = c(\n  \"Indeterminate\", \"Superior\", \"Futile (sup)\", \"NI\", \"Futile (NI)\"\n))]\n\n\n# Dealing with those for which a decision was not reached.\nd_decision &lt;- data.table(\n  domain = 1:4,\n  N = 2500\n)\nif(any(d_dec_timeline$decision != \"Indeterminate\")){\n  d_decision &lt;- d_dec_timeline[\n    decision != \"Indeterminate\", .(N = min(N)), keyby = .(domain, decision)]\n}\n\nd_decision &lt;- merge(\n  d_decision, \n  data.table(domain = 1:4),\n  by = \"domain\", all.y = T\n)\nd_decision[is.na(decision), `:=`(\n  decision = \"Intermediate\", N = 2500  \n)]\n\n\nd_dec_timeline &lt;- d_dec_timeline[N &lt;= max(d_decision$N)]\n\n\nTable 1 shows the decisions made for each domain (or indeterminate if no decisions were made).\n\n\nCode\ng_tbl &lt;- d_decision |&gt; \n  gt() |&gt; \n  cols_align(\n    columns = 1:2,\n    align = \"center\"\n  )  |&gt; \n  cols_align(\n    columns = 3,\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    decision = \"Decision\",\n    N = \"Enrolment\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nDomain\nDecision\nEnrolment\n\n\n\n\n1\nFutile (sup)\n500\n\n\n2\nIntermediate\n2,500\n\n\n3\nFutile (sup)\n500\n\n\n4\nFutile (sup)\n500\n\n\n\n\n\n\n\n\nTable 1: Trial decisions by domain\n\n\n\n\nFigure 1 shows the knowledge transitions based on the decisions made for each domain by sample size up to the point where the trial was stopped either due to running out of resources or having addressed all the questions.\nInitially, all domains start in an indeterminate state in that neither treatment arm is preferred. As the data accrues and analyses progresses, the knowledge state for each domain may transition to, superiority, non-inferiority or futility.\n\n\nCode\np1 &lt;- ggplot(d_dec_timeline, aes(x = N, y = decision)) +\n  geom_point() +\n  scale_y_discrete(\"\", drop=FALSE) +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 1: Decision timeline\n\n\n\n\n\nFigure 2 through to Figure 5 show sample size for each domains.\n\nDomain 1: Sample sizeDomain 2: Sample sizeDomain 3: Sample sizeDomain 4: Sample size\n\n\nAny decision rule only applies to the late acute silo (silo 2).\n\n\nCode\nd_fig &lt;- copy(d_dat_d1)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d1 = c(\"DAIR\", \"One-stage\", \"Two-stage\")),\n  by = c(\"silo\", \"analys\", \"d1\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d1)]\n\np_d1 &lt;- ggplot(d_fig, aes(x = d1, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\", breaks = seq(0, 800, by = 200)) +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(print(p_d1))\n\n\n\n\n\n\n\n\nFigure 2: Domain 1: Surgical sample size\n\n\n\n\n\n\n\nOf those receiving one-stage (see figure for domain 1) and irrespective of silo membership, approximately 70% are assumed to enter the AB duration domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d2)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"silo\", \"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_a &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d2)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d2)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_b &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d2_a, p_d2_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\nOf those receiving two-stage (see figure for domain 1) and irrespective of silo membership, approximately 90% are assumed to enter the AB ext-proph domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d3)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"silo\", \"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_a &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d3)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d3)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_b &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d3_a, p_d3_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 4: Domain 3: AB Expt-proph sample size\n\n\n\n\n\n\n\nAcross the entire trial sample, approximately 60% are assumed to enter the AB choice domain.\nHere, we know there is an effect of AB choice and would hope that a decision for superiority is made such that new participants are directed to receive rifampacin.\n\n\nCode\nd_fig &lt;- copy(d_dat_d4)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"silo\", \"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\np_d4_a &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6))\n\nd_fig &lt;- copy(d_dat_d4)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d4)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\np_d4_b &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d4_a, p_d4_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 5: AB Choice sample size\n\n\n\n\n\n\n\n\nFigure 6 and Figure 7 show the parameter estimates.\nNote:\nParameter estimates will only be reported up until the simulated trial was stopped due to all questions having been answered.\n\nPosterior odds-ratio summaryPosterior risk-difference summary\n\n\nFigure 6 shows the posterior odds-ratios for the randomised comparisons by domain and enrolment progression.\n\n\nCode\n# late acute, surgical effects\nd_d1_n &lt;- d_dat[silo == 2, \n                .(n = sum(N), domain = 1), keyby = .(analys, d1)]\nsetnames(d_d1_n, \"d1\", \"trt\")\n# those receiving one-stage and randomised treatment in domain 2\nd_d2_n &lt;- d_dat[d1 == 2 & d2 %in% 2:3, \n                .(n = sum(N), domain = 2), keyby = .(analys, d2)]\nsetnames(d_d2_n, \"d2\", \"trt\")\n# those receiving two-stage and randomised treatment in domain 3\nd_d3_n &lt;- d_dat[d1 == 3 & d3 %in% 2:3, \n                .(n = sum(N), domain = 3), keyby = .(analys, d3)]\nsetnames(d_d3_n, \"d3\", \"trt\")\n# those receiving randomised treatment in domain 4\nd_d4_n &lt;- d_dat[d4 %in% 2:3, \n                .(n = sum(N), domain = 4), keyby = .(analys, d4)]\nsetnames(d_d4_n, \"d4\", \"trt\")\n\nd_n_trt &lt;- rbind(\n  d_d1_n, d_d2_n, d_d3_n, d_d4_n\n)\nd_n_trt &lt;- merge(\n  d_n_trt,\n  d_N[analys != 0],\n  by = \"analys\"\n)\n\nd_n_trt &lt;- d_n_trt[, .(n = sum(n)), keyby = .(N, domain)]\nd_n_trt[, n := cumsum(n), keyby = domain]\n\np1 &lt;- ggplot(d_mod[par == \"lor\"], aes(x = N, y = exp(med))) +\n  geom_point() +\n  geom_linerange(aes(ymin = exp(q_025), ymax = exp(q_975)), lwd = 0.25) +\n  geom_text(\n    data = d_n_trt, \n    aes(x = N, y = -0.5, label = n), col = 2, size = 2\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 6: Posterior summary measures\n\n\n\n\n\n\n\nFigure 7 shows the posterior risk differences for the randomised comparisons by domain and enrolment progression.\n\n\nCode\np1 &lt;- ggplot(d_mod[par == \"rd\"], aes(x = N, y = med)) +\n  geom_point() +\n  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 7: Posterior summary measures\n\n\n\n\n\n\n\n\nFigure 8 shows the probability associated with each decision type for the randomised comparisons by domain and enrolment progression.\nFor example, for domain 1 in analysis 1, the probability of revision being superior to DAIR (per the definition of superiority, which is a measure that is relative to nominated reference level for superiority) is approxiamtely 0.55. To make a superiority decision, this probability needs to exceed 0.920.\nSimilarly, for domain 1 in analysis 1, the probability of the superiority decision being futile (per the relevant definition) is approximately 0.30. To make a futility decision (related to superiority) this probability has to fall below 0.300.\nNote:\n\nThe futility probabilities are based on being below a given threshold (rather than above).\n\n\n\nCode\np1 &lt;- ggplot(d_fig_1, aes(x = N, y = value)) +\n  geom_point(aes(col=quant), position = position_dodge2(width = 100), size = 0.6) + \n  geom_linerange(aes(ymin = 0, ymax = value, col=quant), \n                 position = position_dodge2(width = 100), lwd = 0.25)+\n  geom_hline(\n    data = d_fig_2,\n    aes(yintercept = threshold, col=quant), lwd = 0.25\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Decision probability\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 8: Probability decision summaries\n\n\n\n\n\n\n\n\n\n\n\nReveal scenario\n\n\n\n\n\nThe results are from a simulated trial picked from scenario 9: Null effect in all domains +silo specific effects.\n\n\nCode\nl_cfg\n\n\n$cov\n$cov$silo\n$cov$silo[[1]]\n[1] 0\n\n$cov$silo[[2]]\n[1] -0.3\n\n$cov$silo[[3]]\n[1] -0.2\n\n\n$cov$jnt\n$cov$jnt[[1]]\n[1] 0\n\n$cov$jnt[[2]]\n[1] 0.4\n\n\n$cov$pref\n$cov$pref[[1]]\n[1] 0\n\n$cov$pref[[2]]\n[1] -0.2\n\n\n$cov$mu\n[1] 0.7\n\n\n$d1\n$d1[[1]]\n[1] 0\n\n$d1[[2]]\n[1] 0.5596\n\n$d1[[3]]\n[1] 0\n\n$d1[[4]]\n[1] 0\n\n$d1[[5]]\n[1] 0\n\n$d1[[6]]\n[1] 0\n\n$d1[[7]]\n[1] 0.1\n\n$d1[[8]]\n[1] 0.693\n\n$d1[[9]]\n[1] 0.693\n\n\n$pri\n$pri$mu\n[1] 0.7 0.7\n\n$pri$b_silo\n[1] 0 1\n\n$pri$b_jnt\n[1] 0 1\n\n$pri$b_prf\n[1] 0 1\n\n$pri$b_trt\n[1] 0 1\n\n\n$dec_ref\n$dec_ref$delta_sup\n[1] 0\n\n$dec_ref$delta_sup_fut\n[1] 0.05\n\n$dec_ref$delta_ni\n[1] -0.05\n\n$dec_ref$delta_ni_fut\n[1] 0\n\n\n$dec_probs\n$dec_probs$thresh_sup\n[1] 0.920 0.950 0.950 0.995\n\n$dec_probs$thresh_ni\n[1] 0.975 0.925 0.975 0.975\n\n$dec_probs$thresh_fut_sup\n[1] 0.30 0.25 0.25 0.25\n\n$dec_probs$thresh_fut_ni\n[1] 0.25 0.10 0.25 0.25\n\n\n$desc\n[1] \"Null effect in all domains +silo specific effects\"\n\n$nsim\n[1] 1000\n\n$mc_cores\n[1] 40\n\n$N_pt\n[1]  500 1000 1500 2000 2500\n\n$d2\n[1] 0 0 0\n\n$d3\n[1] 0 0 0\n\n$d4\n[1] 0 0 0",
    "crumbs": [
      "Simulations",
      "Simulation 5 - example 3"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-ex01.html",
    "href": "notebooks/sim-design5-ex01.html",
    "title": "Simulation 5 - example 1",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\n\nsim_lab &lt;- \"sim05-15\"\n# files of interest\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim05\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n\n\n\nix_scenario &lt;- 7\nix_trial = 83",
    "crumbs": [
      "Simulations",
      "Simulation 5 - example 1"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-ex01.html#results-from-example-trial",
    "href": "notebooks/sim-design5-ex01.html#results-from-example-trial",
    "title": "Simulation 5 - example 1",
    "section": "Results from example trial",
    "text": "Results from example trial\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(analys, N, quant, domain)]\n  \n  \n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected number of enrolments\n# Similar to above but focus on expected number of enrolments\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 1\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix that contains the stopping decision by \n  # quantity (superiority, ni, futility, etc) for each domain by analysis\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  # long version of decision, e.g.\n  #      sim analys  quant domain  value\n  #    &lt;int&gt;  &lt;int&gt; &lt;char&gt; &lt;fctr&gt; &lt;lgcl&gt;\n  # 1:     1      1    sup     d1  FALSE\n  # 2:     1      2    sup     d1  FALSE\n  # 3:     1      3    sup     d1  FALSE\n  # 4:     1      4    sup     d1  FALSE\n  # 5:     1      5    sup     d1  FALSE\n  # 6:     2      1    sup     d1  FALSE\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case we had a sim fall over, fill in value\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # Extract the first instance of any decision occurring by sim and domain.\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise the \n# posterior means, they would thus be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# what we estimate is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 2\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  d_pars &lt;- dcast(d_pars, sim + id_analys + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  setnames(d_pars, \"id_analys\", \"analys\")\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"analys\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(analys, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nCumulative probability of each decision type for example trial\n# &gt; names(l[[ix_scenario]])\n#  [1] \"cfg\"           \"d_pr_sup\"      \"d_pr_ni\"       \"d_pr_sup_fut\"  \"d_pr_ni_fut\"   \"d_decision\"   \n#  [7] \"d_post_smry_1\" \"d_all\"         \"d_n_units\"     \"d_n_assign\" \n\n# extract the decision matrix - sim, analysis, quantity, domain level decision\n\n\nd_N &lt;- data.table(\n  analys = 0:5,\n  N = seq(0, 2500, by = 500)\n)\n\n# Extract example trial specific data\nl_cfg &lt;- copy(l[[ix_scenario]]$cfg)\nd_dat &lt;- copy(l[[ix_scenario]]$d_all[sim == ix_trial])\n# Parameter summaries from analysis\nd_mod &lt;- copy(l[[ix_scenario]]$d_post_smry_1[sim == ix_trial])\n# Decision matrix for this trial\nd_dec &lt;- copy(l[[ix_scenario]]$d_decision[sim == ix_trial])\n# Probability level reached by domain and analysis\nd_pr_sup &lt;- copy(l[[ix_scenario]]$d_pr_sup[sim == ix_trial])\nd_pr_sup_fut &lt;- copy(l[[ix_scenario]]$d_pr_sup_fut[sim == ix_trial])\nd_pr_ni &lt;- copy(l[[ix_scenario]]$d_pr_ni[sim == ix_trial])\nd_pr_ni_fut &lt;- copy(l[[ix_scenario]]$d_pr_ni_fut[sim == ix_trial])\n\n# observed data\nsetnames(d_dat, \"id_analys\", \"analys\")\nsetnames(d_mod, \"id_analys\", \"analys\")\n\nd_mod &lt;- merge(d_mod, d_N, by = \"analys\")\n\nd_pr_sup &lt;- merge(d_pr_sup, d_N, by = \"analys\")\nd_pr_sup &lt;- melt(d_pr_sup[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup[, quant := \"sup\"]\n\nd_pr_sup_fut &lt;- merge(d_pr_sup_fut, d_N, by = \"analys\")\nd_pr_sup_fut &lt;- melt(d_pr_sup_fut[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup_fut[, quant := \"sup_fut\"]\n\nd_pr_ni &lt;- merge(d_pr_ni, d_N, by = \"analys\")\nd_pr_ni &lt;- melt(d_pr_ni[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni[, quant := \"ni\"]\n\nd_pr_ni_fut &lt;- merge(d_pr_ni_fut, d_N, by = \"analys\")\nd_pr_ni_fut &lt;- melt(d_pr_ni_fut[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni_fut[, quant := \"ni_fut\"]\n\nd_pr_dec &lt;- rbind(d_pr_sup, d_pr_sup_fut, d_pr_ni, d_pr_ni_fut  )\nd_pr_dec[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_pr_dec[domain %in% c(2), question := \"Non-inferiority\"]\n\n# domain 1 relates only to the late acute silo\nd_dat_d1 &lt;- d_dat[\n  silo == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d1)]\nd_dat_d1[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d1)]\nd_dat_d1[, p_obs := cy/cn]\nd_dat_d1[, d1 := factor(d1, labels = c(\"DAIR\", \"One-stage\", \"Two-stage\"))]\n\n# domain 2 relates only to the group that receive one-stage\nd_dat_d2 &lt;- d_dat[\n  d1 == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d2)]\nd_dat_d2[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d2)]\nd_dat_d2[, p_obs := cy/cn]\nd_dat_d2[, d2 := factor(d2, labels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\n# domain 3 relates only to the group that receive two-stage\nd_dat_d3 &lt;- d_dat[\n  d1 == 3, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d3)]\nd_dat_d3[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d3)]\nd_dat_d3[, p_obs := cy/cn]\nd_dat_d3[, d3 := factor(d3, labels = c(\"Selected\", \"none\", \"12wk\"))]\n\n# domain 4 relates only to the group that receive two-stage\nd_dat_d4 &lt;- d_dat[\n  , .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d4)]\nd_dat_d4[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d4)]\nd_dat_d4[, p_obs := cy/cn]\nd_dat_d4[, d4 := factor(d4, labels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\nd_dec &lt;- melt(d_dec, measure.vars = paste0(\"d\", 1:4), variable.name = \"domain\")\nd_dec[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n# Subset to the decisions that are evaluated by domain\nd_dec &lt;- rbind(\n  d_dec[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n  d_dec[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n)\n\n\nd_dec_thres &lt;- data.table(\n  quant = rep(c(\"sup\", \"sup_fut\", \"ni\", \"ni_fut\"), each = 4),\n  domain = rep(1:4, len = 16)\n  )\nd_dec_thres[, threshold := c(\n    l_cfg$dec_probs$thresh_sup,\n    l_cfg$dec_probs$thresh_fut_sup,\n    l_cfg$dec_probs$thresh_ni,\n    l_cfg$dec_probs$thresh_fut_ni\n  )]\n\n\n## State transition through the different states of knowledge based on decisions\n\nd_dec_timeline &lt;- merge(\n  CJ(domain = 1:4, analys = 0:5),\n  d_N, by = \"analys\", all.y = T\n)\nsetorder(d_dec_timeline, domain, analys)\nd_dec_timeline[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_dec_timeline[domain %in% c(2), question := \"Non-inferiority\"]\nd_dec_timeline[N == 0, decision := \"Indeterminate\"]\n\n\ni &lt;- j &lt;- 1\n# For i across domains\nfor(i in 1:4){\n  # For j across analyses\n  for(j in 1:5){\n    \n    if(i %in% c(1, 3, 4)){\n      \n      if(d_dec[domain == i & analys == j & quant == \"sup\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"Superior\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_sup\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (sup)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    } else {\n      \n      if(d_dec[domain == i & analys == j & quant == \"ni\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"NI\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_ni\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (NI)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    }\n    \n  }\n  \n}\n\nd_dec_timeline[, decision := factor(decision, levels = c(\n  \"Indeterminate\", \"Superior\", \"Futile (sup)\", \"NI\", \"Futile (NI)\"\n))]\n\n\n# Dealing with those for which a decision was not reached.\nd_decision &lt;- data.table(\n  domain = 1:4,\n  N = 2500\n)\nif(any(d_dec_timeline$decision != \"Indeterminate\")){\n  d_decision &lt;- d_dec_timeline[\n    decision != \"Indeterminate\", .(N = min(N)), keyby = .(domain, decision)]\n}\n\nd_decision &lt;- merge(\n  d_decision, \n  data.table(domain = 1:4),\n  by = \"domain\", all.y = T\n)\nd_decision[is.na(decision), `:=`(\n  decision = \"Intermediate\", N = 2500  \n)]\n\n\nd_dec_timeline &lt;- d_dec_timeline[N &lt;= max(d_decision$N)]\n\n\nTable 1 shows the decisions made for each domain (or indeterminate if no decisions were made).\n\n\nCode\ng_tbl &lt;- d_decision |&gt; \n  gt() |&gt; \n  cols_align(\n    columns = 1:2,\n    align = \"center\"\n  )  |&gt; \n  cols_align(\n    columns = 3,\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    decision = \"Decision\",\n    N = \"Enrolment\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nDomain\nDecision\nEnrolment\n\n\n\n\n1\nSuperior\n500\n\n\n2\nIntermediate\n2,500\n\n\n3\nFutile (sup)\n500\n\n\n4\nSuperior\n1,500\n\n\n\n\n\n\n\n\nTable 1: Trial decisions by domain\n\n\n\n\nFigure 1 shows the knowledge transitions based on the decisions made for each domain by sample size up to the point where the trial was stopped either due to running out of resources or having addressed all the questions.\nInitially, all domains start in an indeterminate state in that neither treatment arm is preferred. As the data accrues and analyses progresses, the knowledge state for each domain may transition to, superiority, non-inferiority or futility.\n\n\nCode\np1 &lt;- ggplot(d_dec_timeline, aes(x = N, y = decision)) +\n  geom_point() +\n  scale_y_discrete(\"\", drop=FALSE) +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 1: Decision timeline\n\n\n\n\n\nFigure 2 through to Figure 5 show sample size for each domains.\n\nDomain 1: Sample sizeDomain 2: Sample sizeDomain 3: Sample sizeDomain 4: Sample size\n\n\nAny decision rule only applies to the late acute silo (silo 2).\n\n\nCode\nd_fig &lt;- copy(d_dat_d1)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d1 = c(\"DAIR\", \"One-stage\", \"Two-stage\")),\n  by = c(\"silo\", \"analys\", \"d1\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d1)]\n\np_d1 &lt;- ggplot(d_fig, aes(x = d1, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\", breaks = seq(0, 800, by = 200)) +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(print(p_d1))\n\n\n\n\n\n\n\n\nFigure 2: Domain 1: Surgical sample size\n\n\n\n\n\n\n\nOf those receiving one-stage (see figure for domain 1) and irrespective of silo membership, approximately 70% are assumed to enter the AB duration domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d2)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"silo\", \"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_a &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d2)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d2)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_b &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d2_a, p_d2_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\nOf those receiving two-stage (see figure for domain 1) and irrespective of silo membership, approximately 90% are assumed to enter the AB ext-proph domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d3)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"silo\", \"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_a &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d3)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d3)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_b &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d3_a, p_d3_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 4: Domain 3: AB Expt-proph sample size\n\n\n\n\n\n\n\nAcross the entire trial sample, approximately 60% are assumed to enter the AB choice domain.\nHere, we know there is an effect of AB choice and would hope that a decision for superiority is made such that new participants are directed to receive rifampacin.\n\n\nCode\nd_fig &lt;- copy(d_dat_d4)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"silo\", \"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\np_d4_a &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6))\n\nd_fig &lt;- copy(d_dat_d4)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d4)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\np_d4_b &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d4_a, p_d4_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 5: AB Choice sample size\n\n\n\n\n\n\n\n\nFigure 6 and Figure 7 show the parameter estimates.\nNote:\nParameter estimates will only be reported up until the simulated trial was stopped due to all questions having been answered.\n\nPosterior odds-ratio summaryPosterior risk-difference summary\n\n\nFigure 6 shows the posterior odds-ratios for the randomised comparisons by domain and enrolment progression.\n\n\nCode\n# late acute, surgical effects\nd_d1_n &lt;- d_dat[silo == 2, \n                .(n = sum(N), domain = 1), keyby = .(analys, d1)]\nsetnames(d_d1_n, \"d1\", \"trt\")\n# those receiving one-stage and randomised treatment in domain 2\nd_d2_n &lt;- d_dat[d1 == 2 & d2 %in% 2:3, \n                .(n = sum(N), domain = 2), keyby = .(analys, d2)]\nsetnames(d_d2_n, \"d2\", \"trt\")\n# those receiving two-stage and randomised treatment in domain 3\nd_d3_n &lt;- d_dat[d1 == 3 & d3 %in% 2:3, \n                .(n = sum(N), domain = 3), keyby = .(analys, d3)]\nsetnames(d_d3_n, \"d3\", \"trt\")\n# those receiving randomised treatment in domain 4\nd_d4_n &lt;- d_dat[d4 %in% 2:3, \n                .(n = sum(N), domain = 4), keyby = .(analys, d4)]\nsetnames(d_d4_n, \"d4\", \"trt\")\n\nd_n_trt &lt;- rbind(\n  d_d1_n, d_d2_n, d_d3_n, d_d4_n\n)\nd_n_trt &lt;- merge(\n  d_n_trt,\n  d_N[analys != 0],\n  by = \"analys\"\n)\n\nd_n_trt &lt;- d_n_trt[, .(n = sum(n)), keyby = .(N, domain)]\nd_n_trt[, n := cumsum(n), keyby = domain]\n\np1 &lt;- ggplot(d_mod[par == \"lor\"], aes(x = N, y = exp(med))) +\n  geom_point() +\n  geom_linerange(aes(ymin = exp(q_025), ymax = exp(q_975)), lwd = 0.25) +\n  geom_text(\n    data = d_n_trt, \n    aes(x = N, y = -0.5, label = n), col = 2, size = 2\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 6: Posterior summary measures\n\n\n\n\n\n\n\nFigure 7 shows the posterior risk differences for the randomised comparisons by domain and enrolment progression.\n\n\nCode\np1 &lt;- ggplot(d_mod[par == \"rd\"], aes(x = N, y = med)) +\n  geom_point() +\n  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 7: Posterior summary measures\n\n\n\n\n\n\n\n\nFigure 8 shows the probability associated with each decision type for the randomised comparisons by domain and enrolment progression.\nFor example, for domain 1 in analysis 1, the probability of revision being superior to DAIR (per the definition of superiority, which is a measure that is relative to nominated reference level for superiority) is approxiamtely 0.96. To make a superiority decision, this probability needs to exceed 0.920.\nSimilarly, for domain 1 in analysis 1, the probability of the superiority decision being futile (per the relevant definition) is approximately 0.85. To make a futility decision (related to superiority) this probability has to fall below 0.300.\nNote:\n\nThe futility probabilities are based on being below a given threshold (rather than above).\n\n\n\nCode\np1 &lt;- ggplot(d_fig_1, aes(x = N, y = value)) +\n  geom_point(aes(col=quant), position = position_dodge2(width = 100), size = 0.6) + \n  geom_linerange(aes(ymin = 0, ymax = value, col=quant), \n                 position = position_dodge2(width = 100), lwd = 0.25)+\n  geom_hline(\n    data = d_fig_2,\n    aes(yintercept = threshold, col=quant), lwd = 0.25\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Decision probability\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 8: Probability decision summaries\n\n\n\n\n\n\n\n\n\n\n\nReveal scenario\n\n\n\n\n\nThe results are from a simulated trial picked from scenario 7: Moderate (OR 1.75) antibiotic choice rifampacin effect.\n\n\nCode\nl_cfg\n\n\n$cov\n$cov$silo\n$cov$silo[[1]]\n[1] 0\n\n$cov$silo[[2]]\n[1] -0.3\n\n$cov$silo[[3]]\n[1] -0.2\n\n\n$cov$jnt\n$cov$jnt[[1]]\n[1] 0\n\n$cov$jnt[[2]]\n[1] 0.4\n\n\n$cov$pref\n$cov$pref[[1]]\n[1] 0\n\n$cov$pref[[2]]\n[1] -0.2\n\n\n$cov$mu\n[1] 0.7\n\n\n$d4\n$d4[[1]]\n[1] 0\n\n$d4[[2]]\n[1] -0.1\n\n$d4[[3]]\n[1] 0.4596\n\n\n$pri\n$pri$mu\n[1] 0.7 0.7\n\n$pri$b_silo\n[1] 0 1\n\n$pri$b_jnt\n[1] 0 1\n\n$pri$b_prf\n[1] 0 1\n\n$pri$b_trt\n[1] 0 1\n\n\n$dec_ref\n$dec_ref$delta_sup\n[1] 0\n\n$dec_ref$delta_sup_fut\n[1] 0.05\n\n$dec_ref$delta_ni\n[1] -0.05\n\n$dec_ref$delta_ni_fut\n[1] 0\n\n\n$dec_probs\n$dec_probs$thresh_sup\n[1] 0.920 0.950 0.950 0.995\n\n$dec_probs$thresh_ni\n[1] 0.975 0.925 0.975 0.975\n\n$dec_probs$thresh_fut_sup\n[1] 0.30 0.25 0.25 0.25\n\n$dec_probs$thresh_fut_ni\n[1] 0.25 0.10 0.25 0.25\n\n\n$desc\n[1] \"Moderate (OR 1.75) antibiotic choice rifampacin effect\"\n\n$nsim\n[1] 1000\n\n$mc_cores\n[1] 40\n\n$N_pt\n[1]  500 1000 1500 2000 2500\n\n$d1\n[1] 0 0 0 0 0 0 0 0 0\n\n$d2\n[1] 0 0 0\n\n$d3\n[1] 0 0 0",
    "crumbs": [
      "Simulations",
      "Simulation 5 - example 1"
    ]
  },
  {
    "objectID": "notebooks/sim-design1-results.html",
    "href": "notebooks/sim-design1-results.html",
    "title": "Simulation results 1",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\n\n\nSimulation 1 is a fixed sized trial with decision criteria for superiority, and non-inferiority and also for futility with respect to both superiority and non-inferiority.\nWe provide summaries of each simulation scenario and the results that were obtained.\n\n\nLoad simulation results\n# files of interest\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc01\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n\n\n\nConfiguration used for each simulated scenario\n# cfg used in each scenario\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\n# conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  N_pt = as.numeric(N_pt),\n  b_r1 = as.numeric(b_r1),\n  b_r2 = as.numeric(b_r2),\n  w_srp2 = as.numeric(w_srp2),\n  b_r1d = as.numeric(b_r1d),\n  b_r2d = as.numeric(b_r2d),\n  b_f = as.numeric(b_f),\n  d_sup = as.numeric(thresh_sup),\n  d_ni = as.numeric(thresh_non_inf),\n  d_fut_sup = as.numeric(thresh_fut_sup),\n  d_fut_ni = as.numeric(thresh_fut_ni)\n  )]\n\nd_cfg[, `:=`(w_srp2 = NULL)]\n\n\n\n\nProcess simulation results for variables of interest\n# Decisions\ni &lt;- 1\n\n\nd_sup &lt;- rbindlist(lapply(seq_along(l), function(i){\n  cbind(sc = d_cfg[i, sc], v = d_cfg[i, v], l[[i]]$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"p\")\nd_sup[, type := \"sup\"]\n\nd_trt_ni_ref &lt;- rbindlist(lapply(seq_along(l), function(i){\n  cbind(sc = d_cfg[i, sc], v = d_cfg[i, v], l[[i]]$d_pr_trt_ni_ref[, lapply(.SD, mean)])\n}))\nd_trt_ni_ref &lt;- melt(d_trt_ni_ref, id.vars = c(\"sc\", \"v\"), value.name = \"p\")\nd_trt_ni_ref[, type := \"trt_ni_ref\"]\n\nd_fut_sup &lt;- rbindlist(lapply(seq_along(l), function(i){\n  cbind(sc = d_cfg[i, sc], v = d_cfg[i, v], l[[i]]$d_fut_sup[, lapply(.SD, mean)])\n}))\nd_fut_sup &lt;- melt(d_fut_sup, id.vars = c(\"sc\", \"v\"), value.name = \"p\")\nd_fut_sup[, type := \"fut_sup\"]\n\nd_fut_ni &lt;- rbindlist(lapply(seq_along(l), function(i){\n  cbind(sc = d_cfg[i, sc], v = d_cfg[i, v], l[[i]]$d_fut_trt_ni_ref[, lapply(.SD, mean)])\n}))\nd_fut_ni &lt;- melt(d_fut_ni, id.vars = c(\"sc\", \"v\"), value.name = \"p\")\nd_fut_ni[, type := \"fut_ni\"]\n\nd_dec &lt;- rbind(\n  d_sup, d_trt_ni_ref, d_fut_sup, d_fut_ni\n)\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\n# Posterior summaries on effects of interest\nd_post_smry_2 &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- l[[i]]$d_post_smry_2\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n# Participant data from trial (grouped)\nd_all &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- l[[i]]$d_grp\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n\nTable 1 summarises the configurations used in each simulated scenario. Each treatment effect parameter is set to have the same magnitude of effect. The effects range from \\(\\log(1/2)\\) in scenario 1 to \\(\\log(2)\\) in scenario 7. Decision rules and thresholds remain constant over the entire enrolment period.\nRevision effects are computed as a weighted combination of the log-odds ratios for the one-stage and two-stage revision effects. The weights are the sample proportion receiving one-stage and two-stage surgery in those patients receiving randomised surgical treatment and randomised to revision.\n\n\nCode\nd_tbl &lt;- d_cfg[, .(v, N_pt, b_r1, b_r2, b_r1d, b_r2d, b_f, \n                   delta_sup = delta_sup,\n                   delta_sup_fut = delta_sup_fut,\n                   delta_ni = 1/delta_ni,\n                   thresh_sup, thresh_non_inf, thresh_fut_sup, thresh_fut_ni)]\n\ng_tbl &lt;- d_tbl |&gt; gt() |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = c(b_r1, b_r2, b_r1d, b_r2d, b_f,\n                delta_ni\n                ),\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_r1, b_r2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_r1d, b_r2d)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_f)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision setup\"),\n    columns = c(delta_sup, thresh_sup, \n                delta_sup_fut, thresh_fut_sup, \n                delta_ni, thresh_non_inf, thresh_fut_ni)\n  ) |&gt;\n  cols_label(\n    v = html(\"Configuration\"),\n    b_r1 = html(\"rev&lt;br&gt;(one-stage)\"),\n    b_r2 = html(\"rev&lt;br&gt;(two-stage)\"),\n    b_r1d = html(\"short&lt;br&gt;(one-stage)\"),\n    b_r2d = html(\"short&lt;br&gt;(two-stage)\"),\n    b_f = html(\"rif\"),\n    delta_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    thresh_sup = html(\"p&lt;sub&gt;sup&lt;/sub&gt;\"),\n    delta_sup_fut = html(\"delta&lt;sub&gt;fut-sup&lt;/sub&gt;\"),\n    thresh_fut_sup = html(\"p&lt;sub&gt;fut-sup&lt;/sub&gt;\"),\n    delta_ni = html(\"delta&lt;sub&gt;ni&lt;/sub&gt;\"),\n    thresh_non_inf = html(\"p&lt;sub&gt;ni&lt;/sub&gt;\"),\n    thresh_fut_ni = html(\"p&lt;sub&gt;fut-ni&lt;/sub&gt;\")\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"bottom\"), color = \"black\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = N_pt == 2500\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Surgical effects only applies to late silo, effect is relative to response under DAIR.\",\n    locations = cells_column_labels(columns = c(b_r1, b_r2))\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under long duration.\",\n    locations = cells_column_labels(columns = b_r1d)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under short duration.\",\n    locations = cells_column_labels(columns = b_r2d)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under no-rifampicin\",\n    locations = cells_column_labels(columns = b_f)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating superiority\",\n    locations = cells_column_labels(columns = delta_sup)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Probability threshold above which superiority is concluded\",\n    locations = cells_column_labels(columns = thresh_sup)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating futility wrt the superiority decision\",\n    locations = cells_column_labels(columns = delta_sup_fut)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold below which futility is concluded\",\n    locations = cells_column_labels(columns = thresh_fut_sup)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating non-inferiority\",\n    locations = cells_column_labels(columns = delta_ni)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold above which non-inferiority is concluded\",\n    locations = cells_column_labels(columns = thresh_non_inf)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold below which non-inferiority decision is deemed futile\",\n    locations = cells_column_labels(columns = thresh_fut_ni)\n  )   \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration\nN_pt\n\nSurgical (Da)\n\n\nDuration (Db)\n\n\nType (Dc)\n\n\nDecision setup\n\n\n\nrev\n(one-stage)1\nrev\n(two-stage)1\nshort\n(one-stage)2\nshort\n(two-stage)3\nrif4\ndeltasup5\npsup6\ndeltafut-sup7\npfut-sup8\ndeltani9\npni10\npfut-ni11\n\n\n\n\nv01\n2500\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv02\n2500\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv03\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv04\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv05\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv06\n2500\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv07\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\n\n1 Surgical effects only applies to late silo, effect is relative to response under DAIR.\n\n\n2 Applies to all silos, effect is relative to response under long duration.\n\n\n3 Applies to all silos, effect is relative to response under short duration.\n\n\n4 Applies to all silos, effect is relative to response under no-rifampicin\n\n\n5 Reference OR for evaluating superiority\n\n\n6 Probability threshold above which superiority is concluded\n\n\n7 Reference OR for evaluating futility wrt the superiority decision\n\n\n8 Probability threshold below which futility is concluded\n\n\n9 Reference OR for evaluating non-inferiority\n\n\n10 Probability threshold above which non-inferiority is concluded\n\n\n11 Probability threshold below which non-inferiority decision is deemed futile\n\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 summarises the variation in the probability of declaring each decision type on each parameter with increasing effects size (odds ratios). The results based on 5000 simulations for a cohort sample size of 2500.\n\n\nCode\nd_fig &lt;- copy(d_dec)\n\nd_fig[, or := g_or_num[v]]\n\nd_fig[, type := factor(\n  type, levels = c(\"sup\", \"fut_sup\", \"trt_ni_ref\", \"fut_ni\"),\n  labels = c(\"sup\", \"fut_sup\", \"ni\", \"fut_ni\"))]\n\nggplot(d_fig, aes(x = or, y = p, group = type, col = type)) +\n  geom_point(size = 0.5) +\n  geom_line(lwd = 0.4) +\n  geom_hline(yintercept = 0.05, lwd = 0.4) +\n  ggthemes::scale_colour_tableau(\n    \"\", palette = \"Tableau 10\",\n  type = \"regular\",\n  direction = 1) +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Proportion sims with decision\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~variable, ncol = 2, scales = \"free\") \n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\nTable 2 shows the same detail as the above figure, but makes it easier to see what the magnitudes of the probabilities are.\n\n\nCode\n# Widen data so that power is shown by col with each col corresponding to an\n# analysis\nd_tbl &lt;- copy(d_fig)\nd_tbl &lt;- dcast(d_tbl, variable + or ~ type, value.var = \"p\")\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility\", \"fut\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"trt ni ref\", \"trt_ni_ref\", names(d_tbl))\nd_tbl &lt;- d_tbl[order(variable, or)]\n\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"variable\") |&gt; \n  cols_label(\n    or = html(\"Odds ratio&lt;br&gt;(true)\"),\n    sup = html(\"Superiority\"),\n    fut_sup = html(\"Futility (sup)\"),\n    ni = html(\"NI (trt ni ref)\"),\n    fut_ni = html(\"Futility (ni)\"),\n  )  |&gt;\n  fmt_number(\n    columns = everything(),\n    decimals = 3\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or == \"1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOdds ratio\n(true)\nSuperiority\nFutility (sup)\nNI (trt ni ref)\nFutility (ni)\n\n\n\n\nb_r\n\n\n0.500\n0.000\n1.000\n0.003\n0.988\n\n\n0.667\n0.000\n0.998\n0.113\n0.522\n\n\n0.833\n0.000\n0.883\n0.508\n0.046\n\n\n1.000\n0.024\n0.406\n0.847\n0.002\n\n\n1.200\n0.294\n0.043\n0.979\n0.000\n\n\n1.500\n0.864\n0.000\n0.999\n0.000\n\n\n2.000\n1.000\n0.000\n1.000\n0.000\n\n\nb_r1d\n\n\n0.500\n0.000\n0.991\n0.053\n0.735\n\n\n0.667\n0.000\n0.877\n0.226\n0.267\n\n\n0.833\n0.002\n0.554\n0.496\n0.043\n\n\n1.000\n0.021\n0.204\n0.737\n0.005\n\n\n1.200\n0.135\n0.041\n0.891\n0.000\n\n\n1.500\n0.437\n0.002\n0.971\n0.000\n\n\n2.000\n0.809\n0.000\n0.995\n0.000\n\n\nb_r2d\n\n\n0.500\n0.000\n1.000\n0.011\n0.945\n\n\n0.667\n0.000\n0.990\n0.147\n0.429\n\n\n0.833\n0.001\n0.795\n0.505\n0.043\n\n\n1.000\n0.022\n0.337\n0.812\n0.001\n\n\n1.200\n0.209\n0.049\n0.956\n0.000\n\n\n1.500\n0.711\n0.001\n0.996\n0.000\n\n\n2.000\n0.977\n0.000\n1.000\n0.000\n\n\nb_f\n\n\n0.500\n0.000\n1.000\n0.000\n0.999\n\n\n0.667\n0.000\n1.000\n0.072\n0.663\n\n\n0.833\n0.000\n0.967\n0.507\n0.047\n\n\n1.000\n0.030\n0.518\n0.894\n0.000\n\n\n1.200\n0.397\n0.053\n0.991\n0.000\n\n\n1.500\n0.954\n0.000\n1.000\n0.000\n\n\n2.000\n1.000\n0.000\n1.000\n0.000\n\n\n\n\n\n\n\n\nTable 2: Probability of decision\n\n\n\n\nFigure 2 shows the distribution of estimated posterior means by simulated effect size, parameter and scenario.\n\n\n\n\n\n\n\n\nFigure 2: Distribution of posterior means (true log OR shown in red).",
    "crumbs": [
      "Simulations",
      "Simulation results 1"
    ]
  },
  {
    "objectID": "notebooks/principal-strata.html",
    "href": "notebooks/principal-strata.html",
    "title": "Principal strata analyses",
    "section": "",
    "text": "Libraries and globals\nsource(\"./R/init.R\")\n\n\nWarning: package 'cmdstanr' was built under R version 4.4.3\n\n\nLibraries and globals\nsource(\"./R/util.R\")\nsource(\"./R/data.R\")"
  },
  {
    "objectID": "notebooks/principal-strata.html#introduction",
    "href": "notebooks/principal-strata.html#introduction",
    "title": "Principal strata analyses",
    "section": "Introduction",
    "text": "Introduction\nConsider post-treatment confounding arising as a result of non-compliance (due to switchover) from revision to DAIR or vice versa.\nAdopt principal strata \\(S_i = (D_i(0), D_i(1))\\) as the treatment level that ultimately occurs under the reference and the intervention arm respectively, with \\(D_i\\) corresponding to the treatment actually received. \\(D_i\\) arises after the treatment assignment \\(Z_i\\) and before the outcome \\(Y_i\\). Also assume the existence of other baseline variables, \\(X_i\\).\nThe outcome \\(Y_i\\) has two potential outcomes, only one of which is observed; \\(Y_i = Y_i(Z_i, D_i(Z_i)) = Y_i(z_i)\\).\nDefine:\n\n\\(S_i = (0, 0)\\) as never-takers; irrespective of assignment, the unit always has a DAIR procedure\n\\(S_i = (0, 1)\\) as compliers, the unit has the intervention type that was assigned\n\\(S_i = (1, 0)\\) as defiers, the unit always has the opposite treatment\n\\(S_i = (1, 1)\\) as always-takers; irrespective of assignment, the unit always has revision\n\nWhile ITT gives us the effect of assignment, we are interested in the effect of revision. Since principal strata can be viewed as baseline variables, the comparisons within each strata can be treated as causal. We are interested in the complier effects.\nIn order to untangle the mixture of units associated with each strata, we need to make assumptions. First, we assume unconfounded assignment, which is a statement that the treatment assignment is unconfounded conditional on pre-treatment variables. In English, this means that the groups are exchangeable in the sense that if we swapped the units, we would observe the same values. Formally, \\(E[Y(0)] | Z = 0, X] = E[Y(0)] | Z = 1, X]\\), \\(E[D(0)] | Z = 0, X] = E[D(0)] | Z = 1, X]\\) etc.\nAnother assumption is monotonicity, which says that the probability that unit is a defier is zero. This allows us to get rid of one of the strata and is fairly reasonable here.\nThe final assumption is exclusion restriction, which basically says that the effect size in both the never takers and always takers is zero.\nWith the above assumptions, a latent mixture model can be specified that comprises a silo membership model and an outcome model.\n\n\nCode\nmc_cores &lt;- 1\nif(unname(Sys.info()[1]) == \"Darwin\"){\n  log_info(\"On mac, reset cores to 5\")\n  mc_cores &lt;- 5\n  N_sim &lt;- 250\n} else if (unname(Sys.info()[1]) == \"Linux\"){\n  log_info(\"On linux, reset cores to 40\")\n  mc_cores &lt;- 40\n  N_sim &lt;- 5000\n}\n\ndec_sup = list(\n  surg = NA,\n  ext_proph = NA,\n  ab_choice = NA\n)\ndec_ni = list(\n  ab_dur = NA\n)\ndec_sup_fut = list(\n  surg = NA,\n  ext_proph = NA,\n  ab_choice = NA\n)\ndec_ni_fut = list(\n  ab_dur = NA\n)\n\nmu &lt;- 0\nb_silo &lt;- c(0.0, -0.3, -0.2)\nb_jnt &lt;- c(0, 0.4)\nb_pref &lt;- c(0.0, -0.2)\n\n# dair, one, two-stage, we compare avg of one and two stage rev to dair\n\n# null (late acute silo)\n# b_d1 &lt;- c(0, 0.693, 0.693, 0, 0, 0, 0, 0.693, 0.693)\n# \"Moderate (OR 1.75) surgical revision effect (one-stage only)\"\nb_d1 &lt;- c(0, 0.693, 0.693, -0.1, 0.4596, -0.1, 0.1, 0.4, 0.2)\n\n# always ref, 12wk, 6wk as we are assessing if 6wk ni to 12wk\nb_d2 &lt;- c(0, -0.25, 0.5)\n# always ref, 0, 12wk as we are assessing if 12wk sup to none\nb_d3 &lt;- c(0, -0.25, 0.5)\n# always ref, none, rif as we are assessing if rif is sup to none\nb_d4 &lt;- c(0, -0.25, 0.5)\nN &lt;- 2500\n\nl_new &lt;- get_trial_data_int(\n      N = N, \n      \n      # reference level log odds of response\n      mu = mu,\n      # silo effects\n      # silo 1 as the one for late acute\n      # silo 2 as the one for late acute\n      # silo 3 is LATE ACUTE\n      b_silo = b_silo,\n      b_jnt = b_jnt,\n      b_pref = b_pref,\n      # dair, one, two-stage\n      b_d1 = b_d1,\n      b_d2 = b_d2,\n      b_d3 = b_d3,\n      b_d4 = b_d4,\n      \n      dec_sup = dec_sup,\n      dec_ni = dec_ni,\n      dec_sup_fut = dec_sup_fut,\n      dec_ni_fut = dec_ni_fut,\n      \n      idx_s = 1,\n      t0 = rep(1, N),\n      id_analys = 1\n    )\n\n\nimplement data function to create data directed by principal strata membership\n\n\nCode\n# Assume probability of being in each PS ( n=(0,0), c=(0,1), a=(1,1) )\n# has same distribution across all silos.\n\nl_new$d[, ps := sample(1:3, .N, replace = TRUE, prob = c(0.2, 0.6, 0.2))]\n\n# never\nl_new$d[ps == 1, d1_rec := 1]\n# complier\nl_new$d[ps == 2, d1_rec := copy(d1)]\n# always\nl_new$d[ps == 3 & silo == 1, d1_rec := sample(2:3, .N, replace = T, prob = g_pr_e_pref[2, 2:3])]\nl_new$d[ps == 3 & silo == 2, d1_rec := sample(2:3, .N, replace = T, prob = g_pr_l_pref[2, 2:3])]\nl_new$d[ps == 3 & silo == 3, d1_rec := sample(2:3, .N, replace = T, prob = g_pr_c_pref[2, 2:3])]\n\n# recompute a revised version of y based on the revised view of d1\n\nl_new$d[, d1_ix := d1_rec + (l_new$K_d1 * (silo - 1))]\n# Outcome\nl_new$d[, mu := mu]\nl_new$d[, b_silo := b_silo[silo]]\nl_new$d[, b_jnt := b_jnt[jnt]]\nl_new$d[, b_pref := b_pref[pref_rev]]\n# use calculated index to pick up correct silo specific parameter\nl_new$d[, b_d1 := b_d1[d1_ix]]\nl_new$d[, b_d2 := b_d2[d2]]\nl_new$d[, b_d3 := b_d3[d3]]\nl_new$d[, b_d4 := b_d4[d4]]\n  \n# Think about preference as something that is induced in the clinician by\n# the status of the patient, i.e. it is a kind of baseline adjustment.\nl_new$d[, eta := mu + b_silo + b_jnt + b_pref + b_d1 + b_d2 + b_d3 + b_d4      ]\n\nl_new$d[, y := rbinom(.N, 1, plogis(eta))]\n  \n  \nl_new$d[]\n\n\nIndices: &lt;silo&gt;, &lt;d1&gt;, &lt;ps&gt;, &lt;silo__ps&gt;\n         id    t0 id_analys  silo   jnt pref_rev    d1    d2    d3    d4 d1_ix\n      &lt;int&gt; &lt;num&gt;     &lt;num&gt; &lt;int&gt; &lt;int&gt;    &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n   1:     1     1         1     2     1        2     1     1     1     1     4\n   2:     2     1         1     3     2        2     1     1     1     1     7\n   3:     3     1         1     2     1        1     2     2     1     2     6\n   4:     4     1         1     2     1        1     1     1     1     3     4\n   5:     5     1         1     2     1        2     1     1     1     1     4\n  ---                                                                         \n2496:  2496     1         1     1     1        1     1     1     1     3     1\n2497:  2497     1         1     3     1        2     3     1     3     1     9\n2498:  2498     1         1     1     2        2     1     1     1     3     1\n2499:  2499     1         1     3     2        2     1     1     1     3     7\n2500:  2500     1         1     3     1        2     3     1     2     1     7\n         mu b_silo b_jnt b_pref   b_d1  b_d2  b_d3  b_d4    eta     y    ps\n      &lt;num&gt;  &lt;num&gt; &lt;num&gt;  &lt;num&gt;  &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;  &lt;num&gt; &lt;int&gt; &lt;int&gt;\n   1:     0   -0.2   0.0   -0.2 -0.100     0     0  0.00 -0.500     1     2\n   2:     0   -0.3   0.4   -0.2  0.000     0     0  0.00 -0.100     1     2\n   3:     0   -0.2   0.0   -0.2  0.693     0     0  0.00  0.293     0     3\n   4:     0   -0.2   0.0   -0.2 -0.100     0     0 -0.25 -0.750     1     1\n   5:     0   -0.2   0.0   -0.2 -0.100     0     0  0.00 -0.500     0     2\n  ---                                                                      \n2496:     0   -0.3   0.0   -0.2 -0.100     0     0 -0.25 -0.850     0     1\n2497:     0   -0.3   0.0   -0.2  0.200     0     0  0.00 -0.300     1     2\n2498:     0   -0.3   0.4   -0.2 -0.100     0     0 -0.25 -0.450     0     2\n2499:     0   -0.3   0.4   -0.2  0.000     0     0 -0.25 -0.350     1     2\n2500:     0   -0.3   0.0   -0.2  0.000     0     0  0.00 -0.500     0     1\n      d1_rec\n       &lt;num&gt;\n   1:      1\n   2:      1\n   3:      3\n   4:      1\n   5:      1\n  ---       \n2496:      1\n2497:      3\n2498:      1\n2499:      1\n2500:      1"
  },
  {
    "objectID": "notebooks/ni-vs-equivalence.html",
    "href": "notebooks/ni-vs-equivalence.html",
    "title": "Simulation results 5",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\n\n\nsimulate data at 2500 with no effect then 0.05 risk diff\nevaluate probability of ni\nevaluate probability of equivalence\n\n\nCode\np0 &lt;- 0.7\np1 &lt;- 0.7\n\nn0 &lt;- 200\nn1 &lt;- 200\n\nn_sim &lt;- 1000\n\ny0 &lt;- rbinom(n_sim, n0, p0)\ny1 &lt;- rbinom(n_sim, n1, p1)\n\npr_ni &lt;- numeric(n_sim)\npr_eq &lt;- numeric(n_sim)\n\nwin_ni &lt;- numeric(n_sim)\nwin_eq &lt;- numeric(n_sim)\n\ni &lt;- 1\n\nfor(i in 1:n_sim){\n  \n  post_p0 &lt;- rbeta(1e4, 1 + y0[i], 1 + n0 - y0[i])\n  post_p1 &lt;- rbeta(1e4, 1 + y1[i], 1 + n1 - y1[i])\n  \n  rd &lt;- post_p1 - post_p0\n  \n  # arbitrary NI margin\n  pr_ni[i] &lt;- mean(rd &gt; -0.05)\n  pr_eq[i] &lt;- mean(rd &gt; -0.05 & rd &lt; 0.05)\n  \n  win_ni[i] &lt;- pr_ni[i] &gt; 0.9\n  win_eq[i] &lt;- pr_eq[i] &gt; 0.7 \n  \n}\n\nmean(win_ni)\n\n\n[1] 0.444\n\n\nCode\nmean(win_eq)\n\n\n[1] 0.255"
  },
  {
    "objectID": "notebooks/misc-notes.html",
    "href": "notebooks/misc-notes.html",
    "title": "Reminders",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nJust some brief notes/examples to act as basics stats reminders.",
    "crumbs": [
      "Design notes",
      "Reminders"
    ]
  },
  {
    "objectID": "notebooks/misc-notes.html#example---lotplote",
    "href": "notebooks/misc-notes.html#example---lotplote",
    "title": "Reminders",
    "section": "Example - LOTP/LOTE",
    "text": "Example - LOTP/LOTE\nAssume the following true joint distribution for some outcome \\(Y\\) and its distribution conditional on sex, smoking and vegetarianism.\n\n\nCode\nset.seed(1)\nd_tru &lt;- CJ(sex = 0:1, smk = 0:1, veg = 0:1)\ng &lt;- function(sex, smk, veg){\n  -1 + 2 * sex - 1 * smk + 3 * veg +\n    -1 * sex * smk - 3 * sex * veg + 1 * smk * veg +\n    0.5 * sex * smk * veg\n}\n# probability of group membership\nq &lt;- rnorm(nrow(d_tru))\nd_tru[, p_grp := exp(q)/sum(exp(q))]\n# probability of outcome\nd_tru[, p_y := plogis(g(sex,smk,veg))]\nd_tru\n\n\nKey: &lt;sex, smk, veg&gt;\n     sex   smk   veg      p_grp       p_y\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;num&gt;     &lt;num&gt;\n1:     0     0     0 0.04225019 0.2689414\n2:     0     0     1 0.09498377 0.8807971\n3:     0     1     0 0.03427561 0.1192029\n4:     0     1     1 0.38968687 0.8807971\n5:     1     0     0 0.10989996 0.7310586\n6:     1     0     1 0.03479920 0.7310586\n7:     1     1     0 0.12870098 0.2689414\n8:     1     1     1 0.16540341 0.6224593\n\n\nTake a random sample from the population:\n\n\nCode\nn &lt;- 1e7\ni &lt;- sample(1:nrow(d_tru), n, T, prob = d_tru$p_grp)\nd &lt;- d_tru[i]\nd[, y := rbinom(.N, 1, p_y)]\n\n\nRecover the distribution of the covariates (the p_grp)\n\n\nCode\n# recover distribution of covariates\nd[, .(.N/nrow(d)), keyby = .(sex, smk, veg)]\n\n\nKey: &lt;sex, smk, veg&gt;\n     sex   smk   veg        V1\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;num&gt;\n1:     0     0     0 0.0421805\n2:     0     0     1 0.0950815\n3:     0     1     0 0.0343139\n4:     0     1     1 0.3898065\n5:     1     0     0 0.1096864\n6:     1     0     1 0.0348148\n7:     1     1     0 0.1288739\n8:     1     1     1 0.1652425\n\n\nRecover the joint distribution of the outcome (the p_y)\n\n\nCode\n# recover distribution of outcome\nd[, .(mu_y = mean(y)), keyby = .(sex, smk, veg)]\n\n\nKey: &lt;sex, smk, veg&gt;\n     sex   smk   veg      mu_y\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;num&gt;\n1:     0     0     0 0.2693899\n2:     0     0     1 0.8812230\n3:     0     1     0 0.1189314\n4:     0     1     1 0.8805292\n5:     1     0     0 0.7309010\n6:     1     0     1 0.7311000\n7:     1     1     0 0.2692407\n8:     1     1     1 0.6217244\n\n\nEstimate the probability of outcome by sex\n\n\nCode\nd[, .(mu_y = mean(y)), keyby = sex]\n\n\nKey: &lt;sex&gt;\n     sex      mu_y\n   &lt;int&gt;     &lt;num&gt;\n1:     0 0.7881758\n2:     1 0.5541419\n\n\nWe are interested in \\(\\mathbb{E}[y | sex]\\). Can we get to this via iterated expectation/LOTE?\nThink - is all we need LOTP (with extra conditioning), e.g.\n\\[\n\\begin{aligned}\nPr(y | sex = s) &= Pr(y | sex = s, smk = 0, veg = 0) Pr(smk = 0, veg = 0|sex = s) + \\\\\n& \\quad Pr(y | sex = s, smk = 0, veg = 1) Pr(smk = 0, veg = 1|sex = s) + \\\\\n& \\quad Pr(y | sex = s, smk = 1, veg = 0) Pr(smk = 1, veg = 0|sex = s) + \\\\\n& \\quad Pr(y | sex = s, smk = 1, veg = 1) Pr(smk = 1, veg = 1|sex = s)\n\\end{aligned}\n\\tag{1}\\]\nOperationalised, based on the known distributions, we get:\n\n\nCode\nc(\n  \"Pr(Y | sex = 0)\" = sum(d_tru[sex == 0, p_y] * d_tru[sex == 0, p_grp / sum(p_grp)] ),\n  \"Pr(Y | sex = 1)\" = sum(d_tru[sex == 1, p_y] * d_tru[sex == 1, p_grp / sum(p_grp)] )\n)\n\n\nPr(Y | sex = 0) Pr(Y | sex = 1) \n      0.7882179       0.5545841 \n\n\nAnd which can be estimated from the simulated data:\n\n\nCode\nc(\n  \"Pr(Y | sex = 0)\" = \n    sum(d[sex == 0, mean(y)] * \n          d[sex == 0, .(p_grp = .N/nrow(d[sex == 0])), keyby = .(smk, veg)]$p_grp ),\n  \"Pr(Y | sex = 1)\" = \n    sum(d[sex == 1, mean(y)] * \n          d[sex == 1, .(p_grp = .N/nrow(d[sex == 1])), keyby = .(smk, veg)]$p_grp)\n)\n\n\nPr(Y | sex = 0) Pr(Y | sex = 1) \n      0.7881758       0.5541419 \n\n\nTake Equation 1, multiply both sides by \\(y\\) and then sum over all \\(y\\)\n\\[\n\\begin{aligned}\n\\sum_y y Pr(y | sex = s) &= \\sum_y y Pr(y | sex = s, smk = 0, veg = 0) Pr(smk = 0, veg = 0|sex = s) + \\\\\n& \\quad \\sum_y y Pr(y | sex = s, smk = 0, veg = 1) Pr(smk = 0, veg = 1|sex = s) + \\\\\n& \\quad \\sum_y y Pr(y | sex = s, smk = 1, veg = 0) Pr(smk = 1, veg = 0|sex = s) + \\\\\n& \\quad \\sum_y y Pr(y | sex = s, smk = 1, veg = 1) Pr(smk = 1, veg = 1|sex = s)  \n\\end{aligned}\n\\tag{2}\\]\nwhich (I think) can be re-stated as\n\\[\n\\begin{aligned}\n\\mathbb{E}(Y|sex=s) &= \\mathbb{E}(Y|sex = s, smk = 0, veg = 0) Pr(smk = 0, veg = 0|sex = s) + \\\\\n& \\quad \\mathbb{E}(Y|sex = s, smk = 0, veg = 1)  Pr(smk = 0, veg = 1|sex = s)  + \\\\\n& \\quad \\mathbb{E}(Y|sex = s, smk = 1, veg = 0)  Pr(smk = 1, veg = 0|sex = s)  + \\\\\n& \\quad \\mathbb{E}(Y|sex = s, smk = 1, veg = 1)  Pr(smk = 1, veg = 1|sex = s)  \\\\\n&= \\sum_{smk,veg} \\mathbb{E}(Y|sex = s, smk, veg) Pr(smk, veg|sex = s)\n\\end{aligned}\n\\tag{3}\\]\nalso note1 (just in case one is easier to determine than another):\n\\[\nPr(smk, veg|sex) = Pr(smk|veg, sex) Pr(veg | sex)\n\\]\nso (perhaps) alternatively:\n\\[\n\\begin{aligned}\n\\mathbb{E}(Y|sex=s) &= \\sum_{smk,veg} \\mathbb{E}(Y|sex = s, smk, veg) Pr(smk|veg, sex = s) Pr(veg | sex = s)\n\\end{aligned}\n\\tag{4}\\]",
    "crumbs": [
      "Design notes",
      "Reminders"
    ]
  },
  {
    "objectID": "notebooks/misc-notes.html#footnotes",
    "href": "notebooks/misc-notes.html#footnotes",
    "title": "Reminders",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the proof, consider \\(P(Y,X|Z) = \\frac{Pr(X,Y,Z)}{Pr(Z)}\\), \\(P(Y|X,Z) = \\frac{Pr(X,Y,Z)}{Pr(X,Z)}\\) and \\(Pr(X|Z) = \\frac{Pr(X,Z)}{Pr(Z)}\\).↩︎",
    "crumbs": [
      "Design notes",
      "Reminders"
    ]
  },
  {
    "objectID": "notebooks/design-notes-08.html",
    "href": "notebooks/design-notes-08.html",
    "title": "MLM vs static regularisation",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\n\n\nProvides a cursory examination of the differences between static regularisation via L1 and L2 penalty vs multilevel approach which achieves dynamic shrinkage. Definitely no free lunch. The model we consider simply examines discrete group means with differential allocation across the groups.\n\n\nParameter specification\nget_par &lt;- function(\n    n_grp = 9,\n    mu = 1,\n    s_y = 0.3\n    ){\n  \n  l &lt;- list()\n  l$n_grp &lt;- n_grp\n\n  # overall mean effect across all intervention types\n  l$mu &lt;- mu\n  # within intervention variation attributable to group membership\n  l$s_y &lt;- s_y\n  # intervention type specific mean\n  l$mu_j &lt;- rnorm(n_grp, 0, l$s_y)\n\n  l$d_par &lt;- CJ(\n    j = factor(1:l$n_grp, levels = 1:l$n_grp)\n  )\n  l$d_par[, mu := l$mu]\n  l$d_par[, mu_j := l$mu_j[j]]\n  \n  l\n}\n\n\n\n\nData generation function\nget_data &lt;- function(\n    N = 2000, \n    par = NULL,\n    ff = function(par, j){\n      eta = par$mu + par$mu_j[j] \n      eta\n    }){\n  \n  # strata\n  d &lt;- data.table()\n  \n  # intervention - even allocation\n  z &lt;- rnorm(par$n_grp, 0, 0.5)\n  d[, j := sample(1:par$n_grp, size = N, replace = T, prob = exp(z)/sum(exp(z)))]\n  d[, eta := ff(par, j)]\n  d[, y := rbinom(.N, 1, plogis(eta))]\n  \n  d  \n}\n\n\n\n\nCode\nset.seed(1)\npar &lt;- get_par(n_grp = 3, mu = 1, s_y = 0.0)\n# 100 people per group - will this overcome the prior?\nn_per_grp &lt;- 100\nd &lt;- get_data(N = n_per_grp * par$n_grp, par)\n\n\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-04.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-05.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-06.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y,  J = length(unique(d$j)),  j = d$j, # intervention\n  pri_s_norm = 1, \n  pri_s_exp = 1, \n  pri_r = 1/2, \n  # when alpha = 1, we have pure lasso regression (double exp)\n  # when alpha = 0, we have pure ridge regression (normal with 1/lambda scale).\n  pri_alpha = 0.6,\n  pri_lambda = 1, # scale is 1/pri_lambda\n  prior_only = 1\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 5000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\nCode\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 5000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\nCode\nf3 &lt;- m3$sample(\n  ld, iter_warmup = 1000, iter_sampling = 5000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\nThe priors on the group level offsets. The elastic net priors are a preset combination of ridge and lasso regression.\n\n\nImplied priors on the group level deviations from the grand mean\nd_1 &lt;- data.table(f1$draws(variables = \"z_eta\", format = \"matrix\"))\nd_1 &lt;- melt(d_1, measure.vars = names(d_1))\nd_1[, desc := \"unpooled\"]\n\nd_2 &lt;- data.table(f2$draws(variables = \"z_eta\", format = \"matrix\"))\nd_2 &lt;- melt(d_2, measure.vars = names(d_2))\nd_2[, desc := \"elastic-net\"]\n\nd_3 &lt;- data.table(f3$draws(variables = \"z_eta\", format = \"matrix\"))\nd_3 &lt;- melt(d_3, measure.vars = names(d_3))\nd_3[, desc := \"mlm\"]\n\nd_fig &lt;- rbind(d_1, d_2, d_3)\nd_fig[, desc := factor(desc, levels = c(\"unpooled\", \"elastic-net\", \"mlm\"))]\n\nx &lt;- seq(min(d_fig$value), max(d_fig$value), len = 1000)\n# for ridge\nden_2a &lt;- dnorm(x, 0, 1/ld$pri_lambda)\n# for lasso\nden_2b &lt;- extraDistr::dlaplace(x, 0, 1/ld$pri_lambda)\n\nd_sta &lt;- rbind(\n  data.table(desc = \"elastic-net\", mod = \"ridge\", x = x, y = den_2a),\n  data.table(desc = \"elastic-net\", mod = \"lasso\", x = x, y = den_2b)\n)\nd_sta[, desc := factor(desc, levels = c(\"unpooled\", \"elastic-net\", \"mlm\"))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_line(\n    data = d_sta[mod == \"lasso\"],\n    aes(x = x, y = y, group = desc), inherit.aes = F,\n    col = 2, lty = 2, lwd = 0.7) +\n  geom_line(\n    data = d_sta[mod == \"ridge\"],\n    aes(x = x, y = y, group = desc), inherit.aes = F,\n    col = 3, lty = 5, lwd = 0.7) +\n  geom_density(lwd = 0.2) +\n  facet_wrap(~desc, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 1: Implied priors on the group level deviations from the grand mean\n\n\n\n\n\n\n\nCode\nset.seed(1)\npar &lt;- get_par(n_grp = 10, mu = 1, s_y = 0.5)\n# 100 people per group - will this overcome the prior?\nn_per_grp &lt;- 100\nd &lt;- get_data(N = n_per_grp * par$n_grp, par)\n\n\n\n\nCode\nld &lt;- list(\n  N = nrow(d), \n  y = d$y,  J = length(unique(d$j)),  j = d$j, # intervention\n  pri_s_norm = 2, \n  pri_s_exp = 1, \n  pri_r = 1/2,  \n  # when alpha = 1, we have pure lasso regression (double exp)\n  # when alpha = 0, we have pure ridge regression (normal with 1/lambda scale).\n  pri_alpha = 0.9,\n  pri_lambda = 0.76, # scale is 1/pri_lambda for both ridge and lasso\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 1.1 seconds.\nChain 2 finished in 1.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 1.1 seconds.\nTotal execution time: 1.2 seconds.\n\n\nCode\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.8 seconds.\nChain 2 finished in 0.8 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.8 seconds.\nTotal execution time: 0.9 seconds.\n\n\nCode\nf3 &lt;- m3$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.7 seconds.\nChain 2 finished in 0.8 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.7 seconds.\nTotal execution time: 0.9 seconds.\n\n\nTreatment group posteriors. By adjusting \\(\\alpha\\) and \\(\\lambda\\) in the elastic net model we can a-priori determine the magnitude of regularisation we want to achieve. In practice, the quantities should be pre-specified and a sensitivity analysis on the main analysis based on varying these quantities.\n\n\nPosterior inference on the group level means\nd_0 &lt;- d[, .(desc = \"observed\", eta = qlogis(mean(y))), keyby = j]\n\nd_1 &lt;- data.table(f1$draws(variables = \"eta\", format = \"matrix\"))\nd_1 &lt;- melt(d_1, measure.vars = names(d_1), value.name = \"eta\")\nd_1[, desc := \"unpooled\"]\n\nd_2 &lt;- data.table(f2$draws(variables = \"eta\", format = \"matrix\"))\nd_2 &lt;- melt(d_2, measure.vars = names(d_2), value.name = \"eta\")\nd_2[, desc := \"elastic-net\"]\n\nd_3 &lt;- data.table(f3$draws(variables = \"eta\", format = \"matrix\"))\nd_3 &lt;- melt(d_3, measure.vars = names(d_3), value.name = \"eta\")\nd_3[, desc := \"mlm\"]\n\nd_fig &lt;- rbind(d_1, d_2, d_3)\nd_fig[, j := gsub(\"eta[\", \"\", variable, fixed = T)]\nd_fig[, j := gsub(\"]\", \"\", j, fixed = T)]\nd_fig[, variable := NULL]\nd_fig[, desc := factor(\n  desc, levels = c(\"observed\", \"unpooled\", \"elastic-net\", \"mlm\"))]\nd_fig &lt;- rbind(d_fig, d_0)\n\nd_fig &lt;- d_fig[, .(\n  mu = mean(eta), \n  q5 = quantile(eta, prob = 0.05),\n  q95 = quantile(eta, prob = 0.95)), keyby = .(desc, j)]\n\nd_fig[, j := factor(j, levels = paste0(1:par$n_grp))]\n\nggplot(d_fig, aes(x = j, y = mu, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(\n    aes(ymin = q5, ymax = q95),\n    position = position_dodge2(width = 0.6)) +\n  scale_color_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_fig$q5, na.rm = T) - 0.2, \n                label = N), inherit.aes = F) \n\n\n\n\n\n\n\n\nFigure 2: Posterior inference on the group level means\n\n\n\n\n\n\n\nCode\nset.seed(2)\npar &lt;- get_par(n_grp = 10, mu = 1, s_y = 0.5)\nn_per_grp &lt;- 500\nd &lt;- get_data(N = n_per_grp * par$n_grp, par)\n\n\n\n\nCode\nld &lt;- list(\n  N = nrow(d), \n  y = d$y,  J = length(unique(d$j)),  j = d$j, # intervention\n  pri_s_norm = 2, \n  pri_s_exp = 1, \n  pri_r = 1/2,  \n  # when alpha = 1, we have pure lasso regression (double exp)\n  # when alpha = 0, we have pure ridge regression (normal with 1/lambda scale).\n  pri_alpha = 0.9,\n  pri_lambda = 0.76, # scale is 1/pri_lambda for both ridge and lasso\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 6.3 seconds.\nChain 2 finished in 6.9 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 6.6 seconds.\nTotal execution time: 7.0 seconds.\n\n\nCode\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 5.1 seconds.\nChain 1 finished in 5.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 5.1 seconds.\nTotal execution time: 5.3 seconds.\n\n\nCode\nf3 &lt;- m3$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 5.7 seconds.\nChain 2 finished in 6.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 5.9 seconds.\nTotal execution time: 6.2 seconds.\n\n\nHowever, note that larger data sets will still overwhelm the static regularisation as shown in Figure 3.\n\n\nPosterior inference on the group level means\nd_0 &lt;- d[, .(desc = \"observed\", eta = qlogis(mean(y))), keyby = j]\n\nd_1 &lt;- data.table(f1$draws(variables = \"eta\", format = \"matrix\"))\nd_1 &lt;- melt(d_1, measure.vars = names(d_1), value.name = \"eta\")\nd_1[, desc := \"unpooled\"]\n\nd_2 &lt;- data.table(f2$draws(variables = \"eta\", format = \"matrix\"))\nd_2 &lt;- melt(d_2, measure.vars = names(d_2), value.name = \"eta\")\nd_2[, desc := \"elastic-net\"]\n\nd_3 &lt;- data.table(f3$draws(variables = \"eta\", format = \"matrix\"))\nd_3 &lt;- melt(d_3, measure.vars = names(d_3), value.name = \"eta\")\nd_3[, desc := \"mlm\"]\n\nd_fig &lt;- rbind(d_1, d_2, d_3)\nd_fig[, j := gsub(\"eta[\", \"\", variable, fixed = T)]\nd_fig[, j := gsub(\"]\", \"\", j, fixed = T)]\nd_fig[, variable := NULL]\nd_fig[, desc := factor(\n  desc, levels = c(\"observed\", \"unpooled\", \"elastic-net\", \"mlm\"))]\nd_fig &lt;- rbind(d_fig, d_0)\n\nd_fig &lt;- d_fig[, .(\n  mu = mean(eta), \n  q5 = quantile(eta, prob = 0.05),\n  q95 = quantile(eta, prob = 0.95)), keyby = .(desc, j)]\n\nd_fig[, j := factor(j, levels = paste0(1:par$n_grp))]\n\nggplot(d_fig, aes(x = j, y = mu, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(\n    aes(ymin = q5, ymax = q95),\n    position = position_dodge2(width = 0.6)) +\n  scale_color_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_fig$q5, na.rm = T) - 0.2, \n                label = N), inherit.aes = F) \n\n\n\n\n\n\n\n\nFigure 3: Posterior inference on the group level means\n\n\n\n\n\n\n\nCode\nset.seed(7)\npar &lt;- get_par(n_grp = 2, mu = 1, s_y = 0.5)\nn_per_grp &lt;- 200\nd &lt;- get_data(N = n_per_grp * par$n_grp, par)\n\n\n\n\nCode\nld &lt;- list(\n  N = nrow(d), \n  y = d$y,  J = length(unique(d$j)),  j = d$j, # intervention\n  pri_s_norm = 2, \n  pri_s_exp = 1, \n  pri_r = 1/2,  \n  # when alpha = 1, we have pure lasso regression (double exp)\n  # when alpha = 0, we have pure ridge regression (normal with 1/lambda scale).\n  pri_alpha = 0.9,\n  pri_lambda = 0.76, # scale is 1/pri_lambda for both ridge and lasso\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.6 seconds.\n\n\nCode\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.5 seconds.\n\n\nCode\nf3 &lt;- m3$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.7 seconds.\nChain 2 finished in 0.7 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.7 seconds.\nTotal execution time: 0.8 seconds.\n\n\nAnd in the case with smaller number of groups, there is probably immaterial differences between the approaches as shown in Figure 4.\n\n\nPosterior inference on the group level means\nd_0 &lt;- d[, .(desc = \"observed\", eta = qlogis(mean(y))), keyby = j]\n\nd_1 &lt;- data.table(f1$draws(variables = \"eta\", format = \"matrix\"))\nd_1 &lt;- melt(d_1, measure.vars = names(d_1), value.name = \"eta\")\nd_1[, desc := \"unpooled\"]\n\nd_2 &lt;- data.table(f2$draws(variables = \"eta\", format = \"matrix\"))\nd_2 &lt;- melt(d_2, measure.vars = names(d_2), value.name = \"eta\")\nd_2[, desc := \"elastic-net\"]\n\nd_3 &lt;- data.table(f3$draws(variables = \"eta\", format = \"matrix\"))\nd_3 &lt;- melt(d_3, measure.vars = names(d_3), value.name = \"eta\")\nd_3[, desc := \"mlm\"]\n\nd_fig &lt;- rbind(d_1, d_2, d_3)\nd_fig[, j := gsub(\"eta[\", \"\", variable, fixed = T)]\nd_fig[, j := gsub(\"]\", \"\", j, fixed = T)]\nd_fig[, variable := NULL]\nd_fig[, desc := factor(\n  desc, levels = c(\"observed\", \"unpooled\", \"elastic-net\", \"mlm\"))]\nd_fig &lt;- rbind(d_fig, d_0)\n\nd_fig &lt;- d_fig[, .(\n  mu = mean(eta), \n  q5 = quantile(eta, prob = 0.05),\n  q95 = quantile(eta, prob = 0.95)), keyby = .(desc, j)]\n\nd_fig[, j := factor(j, levels = paste0(1:par$n_grp))]\n\nggplot(d_fig, aes(x = j, y = mu, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(\n    aes(ymin = q5, ymax = q95),\n    position = position_dodge2(width = 0.6)) +\n  scale_color_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_fig$q5, na.rm = T) - 0.2, \n                label = N), inherit.aes = F) \n\n\n\n\n\n\n\n\nFigure 4: Posterior inference on the group level means",
    "crumbs": [
      "Design notes",
      "MLM vs static regularisation"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html",
    "href": "notebooks/design-notes-06.html",
    "title": "Multi-level model perspective",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nThe central idea with modeling discrete heterogeneity in multilevel models is that the variation is assumed to arise within the context of a dependency structure. Under a complete pooling model, the variation is ignored and we assume that the effect is captured within a single parameter such as modeling a treatment effect across groups. For example, consider the model\n\\[\n\\begin{aligned}\n\\text{logit}(p_i) &= \\alpha + \\beta x_i\n\\end{aligned}\n\\]\nwhere \\(p\\) parameterises a bernoulli observational model conditional on some exposure \\(x\\) and we are taking a monolithic perspective on the treatment effect. To account for discrete heterogeneity we would replace \\(\\beta\\) with \\(\\{ \\beta_1, \\beta_2, \\dots \\beta_K \\}\\). However, to complete the model we neeed to place a prior on \\(\\beta_k\\). Under the assumption of no latent interactions (as in no pooling) we would adopt \\(\\pi(\\beta_1, \\dots, \\beta_K) = \\pi_1(\\beta_1)\\dots\\pi_K(\\beta_K)\\). Under a partial pooling perspective, we would assume some structure to the prior.\nREMAP-CAP uses a multilevel perspective for modeling treatment effects within a domain, across strata, that I have translated to the ROADMAP context although I have made some simplifications for the purposes of illustration.\nAssume the following structure for the linear predictor\n\\[\n\\begin{aligned}\n\\text{logit}(p) &= \\beta_0 + \\beta_{d1[x], j}\n\\end{aligned}\n\\]\nwhere the second term represents a joint specific effect of exposure \\(x\\) within the first domain (I am ignoring silo for the moment and treating everything as generic).\nThe parameters and priors are structured as follows\nThe idea is to produce a structure whereby estimation of the variance components produces dynamic shrinkage of the treatment effect estimates.\nSpecifically, when the variance components are estimated to be large then more variation in the strata specific treatment effects is permitted. However, to estimate the variance components well, you will need multiple groups (more than two).",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html#example---large-number-of-groups-and-exposure-levels",
    "href": "notebooks/design-notes-06.html#example---large-number-of-groups-and-exposure-levels",
    "title": "Multi-level model perspective",
    "section": "Example - large number of groups and exposure levels",
    "text": "Example - large number of groups and exposure levels\nFor the sake of an example, assume you have a setting with 8 treatment arms to which patients are randomised and within each treatment arm are a mix of participants with respect to some characteristic that could influence the response. I am only using this many treatment arms because it allows us to see a clear difference between the different analysis approaches. We are interested in the overall treatment effect and heterogeneity due to some membership to a group.\nWithin this setting there are multiple levels of variation. There is the between treatment arm variation that characterises how different the treatment arms are. There is also the within treatment arm variation due to the subgroup.\nWe could adopt a range of assumptions to model the responses for each combination of treatment and subgroup.\n\nModel the responses for each treatment arm by subgroup combination independently; no information is shared between any of the combinations. This approach will recover the observed point estimates and could be achieved using a logistic regression to estimate each combination’s mean response.\nModel the treatment groups independently, but estimate the variation within each treatment arm due to subgroup membership by sharing a common variance parameter across all the treatment arms. This will reflect the observed mean response in each treatment arm but shrink the subgroup variation towards these means. It will only do this if there is sufficient data to inform the relevant variance estimate.\nModel both the between treatment arm variation and the within treatment arm variation by partitioning the total variation. This will tend to shrink the treatment arm means towards an overall mean and the subgroup estimates towards each treatment arm mean. The within group variation could be modelled for each treatment arm independently or be shared across all treatments.\n\nPlus variations on these themes. All of the variance partition approaches require that there are sufficient groups to informed the variance parameters.\nHere I assume the following represents the true model\n\\[\n\\begin{aligned}\ny_{ijk} &\\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\nu_{jk})) \\\\\n\\nu_{jk} &\\sim \\text{Normal}(\\delta_j, \\tau) \\\\\n\\delta_j &\\sim \\text{Normal}(\\mu, \\sigma)\n\\end{aligned}\n\\]\nand adopt hyper priors and hyper parameters\n\\[\n\\begin{aligned}\n\\mu &\\sim \\text{Normal}(0, 1) \\\\\n\\tau &\\sim \\text{Student-t}(\\text{df} = 3,0, \\text{scale} = 2) \\\\\n\\sigma &\\sim \\text{Student-t}(3,0,2) \\\\\n\\end{aligned}\n\\]",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html#parameter-specificationgeneration",
    "href": "notebooks/design-notes-06.html#parameter-specificationgeneration",
    "title": "Multi-level model perspective",
    "section": "Parameter specification/generation",
    "text": "Parameter specification/generation\nAssume that the true treatment group means are normally distributed around some non-zero mean with standard deviation \\(s\\) and that the subgroup means are normally distributed around each treatment group mean with a common standard deviation \\(s_j\\).\n\n\nParameter specification\nget_par &lt;- function(\n    n_grp = 4, n_trt = 9,\n    mu = 1,\n    s = 0.1, s_j = 0.3\n    ){\n  \n  l &lt;- list()\n  l$n_grp &lt;- n_grp\n  l$n_trt &lt;- n_trt\n\n  # overall mean effect across all intervention types\n  l$mu &lt;- mu\n  # between intervention type variation\n  l$s &lt;- s\n  # intervention type specific mean\n  l$mu_j &lt;- l$mu + rnorm(n_trt, 0, l$s)\n  # within intervention variation attributable to group membership\n  l$s_j &lt;- s_j\n\n  # trt x group effects\n  l$mu_j_k &lt;- do.call(rbind, lapply(seq_along(l$mu_j), function(i){\n    rnorm(n_grp, l$mu_j[i], l$s_j)\n  }))\n  colnames(l$mu_j_k) &lt;- paste0(\"strata\", 1:ncol(l$mu_j_k))\n  rownames(l$mu_j_k) &lt;- paste0(1:nrow(l$mu_j_k))\n  \n  l$d_par &lt;- CJ(\n    j = factor(1:l$n_trt, levels = 1:l$n_trt),\n    k = factor(1:l$n_grp, levels = 1:l$n_grp)\n  )\n  l$d_par[, mu := l$mu]\n  l$d_par[, mu_j := l$mu_j[j]]\n  l$d_par[, mu_j_k := l$mu_j_k[cbind(j,k)]]\n  \n  l\n}\n\n\nAny single data set will not allow us to recover the parameters exactly, but the differences between the estimates from the various modelling assumptions is informative as to the general patterns that arise.\n\n\nData generation function\nget_data &lt;- function(\n    N = 2000, \n    par = NULL,\n    ff = function(par, j, k){\n      \n      m1 &lt;- cbind(j, k)\n      eta = par$mu_j_k[m1] \n      eta\n      \n    }){\n  \n  # strata\n  d &lt;- data.table()\n  \n  # intervention - even allocation\n  d[, j := sample(1:par$n_trt, size = N, replace = T)]\n  # table(d$j)\n  # uneven distribution of groups in the pop\n  z &lt;- rnorm(par$n_grp, 0, 0.5)\n  d[, k := sample(1:par$n_grp, size = N, replace = T, prob = exp(z)/sum(exp(z)))]\n  # d[, k := sample(1:par$n_grp, size = N, replace = T)]\n  # table(d$j, d$k)\n  \n  d[, eta := ff(par, j, k)]\n  \n  d[, y := rbinom(.N, 1, plogis(eta))]\n  \n  d  \n}\n\n\nGenerate data assuming the parameters below with the underlying truth shown in Figure 1. The dashed line shows the overall mean response, the crosses show the treatment arm means and the points show the subgroup heterogeneity around the treatment arm means. Within this first setup, all the treatment arms have the same response and none of the subgroups show any treatment effect either.\n\n\nTrue treatment arm by subgroup mean response\nset.seed(1)\npar &lt;- get_par(n_grp = 5, n_trt = 8, mu = 1, s = 0.0, s_j = 0)\nd &lt;- get_data(N = 3000, par)\n\n\nd_fig_2 &lt;- unique(par$d_par[, .(mu_j, j)])\nd_fig_2[1, label := \"Treatment mean\"]\n       \nd_fig_3 &lt;- copy(par$d_par)\nd_fig_3[6, label := \"Subgroup mean\"]\n\n\np_fig &lt;- ggplot(d_fig_3, aes(x = j, y = mu_j_k, col = k)) +\n  geom_jitter(width = 0.2, height = 0.01) +\n  geom_hline(yintercept = par$mu, lwd = 0.25, lty = 2) +\n  geom_text_repel(\n    aes(label = label),\n                  nudge_x = 0.5,\n                  nudge_y = -0.2,\n                  segment.curvature = -0.1,\n                  segment.ncp = 3,\n                  segment.angle = 20,\n                  box.padding = 2, max.overlaps = Inf, col = 1) +\n  geom_text_repel(\n    data = data.table(\n      x = 2.5, y = par$mu, label = \"Overall mean\"\n    ),\n    aes(x = x, y = y, label = label),\n                  inherit.aes = F,\n                  nudge_x = 0.4,\n                  nudge_y = 0.1,\n                  segment.curvature = -0.1,\n                  segment.ncp = 3,\n                  segment.angle = 20,\n                  box.padding = 2, max.overlaps = Inf, col = 1) +\n  geom_text_repel(data = d_fig_2,\n                  aes(x = j, y = mu_j, label = label), \n                  inherit.aes = F,\n                  nudge_x = 0.4,\n                  nudge_y = -0.05,\n                  segment.curvature = -0.1,\n                  segment.ncp = 3,\n                  segment.angle = 20,\n                  box.padding = 2, max.overlaps = Inf, col = 1) +\n  geom_point(data = d_fig_2,\n             aes(x = j, y = mu_j),\n             inherit.aes = F, pch = 3, size = 3) +\n  scale_x_discrete(\"Treatment type\") +\n  scale_y_continuous(\"Odds of success (log-odds)\", \n                     breaks = seq(\n                       0.5, \n                       1.5, \n                       by = 0.1), limits = c(0.5, 1.5)) +\n  scale_color_discrete(\"Subgroup membership\")\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 1: True treatment arm by subgroup mean response",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html#parameter-estimation",
    "href": "notebooks/design-notes-06.html#parameter-estimation",
    "title": "Multi-level model perspective",
    "section": "Parameter estimation",
    "text": "Parameter estimation\nBelow are models that provide the observed, ML, unpooled and partially pooled estimates.\n\n\nFit model to simulated data\n# mle - reference point\nd_lm &lt;- copy(d)\nd_lm[, `:=`(j = factor(j), k = factor(k))]\nf0 &lt;- glm(y ~ j*k, data = d_lm, family = binomial)\nX &lt;- model.matrix(f0)\n# CI\nn_sim &lt;- 1000\nd_lm_j &lt;- matrix(NA, nrow = par$n_trt, ncol = n_sim)\nd_lm_j_k &lt;- matrix(NA, nrow = par$n_trt * par$n_grp, ncol = n_sim)\nfor(i in 1:n_sim){\n  ix &lt;- sort(sample(1:nrow(d_lm), replace = T))\n  f_boot &lt;- glm(y ~ j*k, data = d_lm[ix], family = binomial)\n  d_tmp_p &lt;- cbind(\n    d_lm[ix],\n    mu = predict(f_boot)\n  )\n  d_lm_j[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = j][, mean]\n  d_lm_j_k[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = .(k, j)][, mean]\n}\n# bootstrapped intervals for means on j and within group means\nd_lm_j &lt;- data.table(d_lm_j)\nd_lm_j[, j := 1:.N]\nd_lm_j &lt;- melt(d_lm_j, id.vars = \"j\")\nd_lm_j[, j := factor(j)]\n# d_lm_j[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = j]\n\nd_lm_j_k &lt;- data.table(d_lm_j_k)\nd_lm_j_k &lt;- cbind(CJ(k = 1:par$n_grp, j = 1:par$n_trt), d_lm_j_k)\nd_lm_j_k &lt;- melt(d_lm_j_k, id.vars = c(\"j\", \"k\"))\nd_lm_j_k[, `:=`(j = factor(j), k = factor(k))]\n# d_lm_j_k[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = .(k,j)]\nd_lm[, eta_hat := predict(f0)]\n\n# bayes\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-01.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-02.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-03.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y, \n  J = length(unique(d$j)), K = length(unique(d$k)),\n  j = d$j, # intervention\n  k = d$k, # subgroup\n  P = ncol(X),\n  X = X,\n  s = 3,\n  s_j = 3, # for the indep means offsets\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 13.1 seconds.\nChain 1 finished in 15.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 14.3 seconds.\nTotal execution time: 15.7 seconds.\n\n\nFit model to simulated data\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 3.5 seconds.\nChain 2 finished in 3.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 3.6 seconds.\nTotal execution time: 3.7 seconds.\n\n\nFit model to simulated data\nf3 &lt;- m3$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 4.1 seconds.\nChain 2 finished in 4.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 4.1 seconds.\nTotal execution time: 4.1 seconds.\n\n\nFigure 2 shows the estimated treatment arm means. The mlm correctly identifies the absence of between treatment variation and as a result, the means are pulled towards the grand mean.\n\n\nParameter estimates vs true values\nd_1 &lt;- data.table(t(f1$draws(variables = \"eta\", format = \"matrix\")))\nd_1 &lt;- cbind(d, d_1)\nd_1 &lt;- melt(d_1, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_2 &lt;- data.table(t(f2$draws(variables = \"eta\", format = \"matrix\")))\nd_2 &lt;- cbind(d, d_2)\nd_2 &lt;- melt(d_2, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_3 &lt;- data.table(t(f3$draws(variables = \"eta\", format = \"matrix\")))\nd_3 &lt;- cbind(d, d_3)\nd_3 &lt;- melt(d_3, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_mu_j &lt;- rbind(\n  d_1[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_2[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_3[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j]\n)\n  \n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j[, .(q5 = quantile(value, prob =0.05),\n           q95 = quantile(value, prob = 0.95)), keyby = j], \n  by = \"j\"\n)\n\nd_mu_j &lt;- rbind(d_mu_j, d_mle, fill = T)\n\n# Observed\n# Due to the imbalance between the subgroups, need to weight the\n# contributions to align (approx) with mle.\n# Easy here because only one other variable that we need to average\n# over.\nd_obs &lt;- merge(\n  d[, .(N_j = .N), keyby = .(j)],\n  d[, .(mu = qlogis(mean(y)), .N), keyby = .(j, k)],\n  by = \"j\"\n)\nd_mu_j &lt;- rbind(\n  d_mu_j,\n  d_obs[, .(\n    desc = \"observed\", \n    mean = sum(mu * N / N_j)), keyby = j]\n  , fill = T\n  )\n\n\nd_mu_j[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \n  \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n  \n\n\nd_mu &lt;- d[, .(mu = qlogis(mean(y)), \n         w = .N/nrow(d)), keyby = .(j, k)][\n           , .(desc = \"observed\", mean = sum(mu * w))]\n\n\np_fig &lt;- ggplot(d_mu_j, aes(x = j, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  geom_hline(data = d_mu,\n             aes(yintercept = mean, lty = desc),\n             lwd = 0.3, col = 1) +\n  scale_x_discrete(\"Treatment arm\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2))  +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_mu_j$q5, na.rm = T) - 0.1, \n                label = N), inherit.aes = F) +\n  theme(legend.position=\"bottom\", legend.box=\"vertical\", legend.margin=margin())\n\nsuppressWarnings(print(p_fig))  \n\n\n\n\n\n\n\n\nFigure 2: Parameter estimates vs true values\n\n\n\n\n\nFigure 3 shows the estimated treatment by subgroup means. Similar to above, the mlm has determined that the within group variance is negligible and has pulled the subgroup estimates towards the treatment means. In contrast, the ML and independent models follow the data leading to suggest some material subgroup effects.\n\n\nParameter estimates vs true values\n# Posterior\n# d_mu_j_k &lt;- rbind(\n#   data.table(f2$summary(variables = c(\n#     \"mu_j_k\"\n#     )))[, .(desc = \"partial pool (trt)\", variable, mean, q5, q95)],\n#   data.table(f3$summary(variables = c(\n#     \"mu_j_k\"\n#     )))[, .(desc = \"partial pool (trt+subgrp)\", variable, mean, q5, q95)]\n# )\n# d_mu_j_k[, j := substr(variable, 8, 8)]\n# d_mu_j_k[, k := substr(variable, 10, 10)]\n\n# Manually calculate intervals for independent model\nd_mu_j_k &lt;- rbind(\n  # d_mu_j_k,\n  d_1[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_2[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_3[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)]\n  )\n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(k, j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j_k[, .(q5 = quantile(value, prob =0.05),\n               q95 = quantile(value, prob = 0.95)), keyby = .(k,j)], \n  by = c(\"j\",\"k\")\n)\n\nd_mu_j_k &lt;- rbind(d_mu_j_k, d_mle, fill = T)\n\n# Observed\nd_mu_j_k &lt;- rbind(\n  d_mu_j_k, \n  d[, .(desc = \"observed\", mean = qlogis(mean(y))), keyby = .(k, j)],\n  fill = T)\n\n\nd_mu_j_k[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n# \nd_mu_obs &lt;- d[, .(mu = qlogis(mean(y)))]\nd_mu_mod &lt;- data.table(f3$summary(variables = c(\n    \"mu\"\n    )))[, .(model = \"no pooling\", variable, mean, q5, q95)]\n\np_fig &lt;- ggplot(d_mu_j_k, aes(x = k, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  scale_x_discrete(\"Subgroup\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2)) +\n  geom_hline(data = d_mu_j[desc == \"observed\"],\n             aes(yintercept = mean, group = desc),\n             lwd = 0.3, col = 1) +\n  geom_text(data = d[, .N, keyby = .(j, k)],\n            aes(x = k, y = min(d_mu_j_k$q5, na.rm = T) - 0.1, label = N), \n            inherit.aes = F) +\n  facet_wrap(~paste0(\"Treatment \", j)) \n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 3: Parameter estimates vs true values\n\n\n\n\n\nThe mlm partitions the variance into a between treatment variance part that characterises the variation in the treatment arms and a within treatment variance that characterises the variation due to the subgroups.\nIn Figure 4 shows the prior (red) and the posterior (black) for the variance components (actually the standard deviations). Given the differentiation between the prior and posterior, it is clear that something has been learnt about the variation in the data and the posterior is well identified, although not fully concentrated on the true value of zero. Moreover, both the between group variation (variation due to treatment) and within group variation (variation due to subgroups) are small which leads to the dynamic shrinkage as shown in the subgroup level means.\n\n\nVariance components (revision)\nd_fig &lt;- rbind(\n  cbind(desc = \"partial pool (trt)\",\n        data.table(f2$draws(variables = c(\"s_j\"), format = \"matrix\"))),\n  cbind(desc = \"partial pool (trt+subgrp)\",\n        data.table(f3$draws(variables = c(\"s\", \"s_j\"), format = \"matrix\"))  \n  ), fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = \"desc\")\nd_fig[variable == \"s\", label := \"variation b/w\"]\nd_fig[variable == \"s_j\", label := \"variation w/in\"]\n\nd_pri &lt;- CJ(\n  variable = c(\"s\", \"s_j\"),\n  desc = c(\"partial pool (trt)\", \"partial pool (trt+subgrp)\"),\n  x = seq(min(d_fig$value, na.rm = T), \n          max(d_fig$value, na.rm = T), len = 500)\n)\nd_pri[, y := fGarch::dstd(x, nu = 3, mean = 0, sd = 2)]\nd_pri[variable == \"s\", label := \"variation b/w\"]\nd_pri[variable == \"s_j\", label := \"variation w/in\"]\nd_pri[desc == \"partial pool (trt)\" & variable == \"s\", y := NA]\n# \n# d_smry &lt;- d_fig[, .(mu = mean(value)), keyby = .(label)]\n\np_fig &lt;- ggplot(d_fig, aes(x = value, group = variable)) + \n  geom_density() +\n  geom_line(\n    data = d_pri, \n    aes(x = x, y = y), col = 2, lwd = 0.2\n  ) +\n  scale_x_continuous(\"Standard deviation\") +\n  scale_y_continuous(\"Density\") +\n  facet_wrap(desc+label~., ncol = 2)\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 4: Between and within SD",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html#example---small-number-of-groups-and-exposure-levels",
    "href": "notebooks/design-notes-06.html#example---small-number-of-groups-and-exposure-levels",
    "title": "Multi-level model perspective",
    "section": "Example - small number of groups and exposure levels",
    "text": "Example - small number of groups and exposure levels\nNow repeat the same exercise with a small number of groups and exposure levels, again we simulate the data assuming no effects are present.\n\n\nCode\nset.seed(1)\npar &lt;- get_par(n_grp = 2, n_trt = 2, mu = 1, s = 0.0, s_j = 0.0)\nd &lt;- get_data(N = 3000, par)\n\n\n\n\nFit model to simulated data\n# mle - reference point\nd_lm &lt;- copy(d)\nd_lm[, `:=`(j = factor(j), k = factor(k))]\nf0 &lt;- glm(y ~ j*k, data = d_lm, family = binomial)\nX &lt;- model.matrix(f0)\n# CI\nn_sim &lt;- 1000\nd_lm_j &lt;- matrix(NA, nrow = par$n_trt, ncol = n_sim)\nd_lm_j_k &lt;- matrix(NA, nrow = par$n_trt * par$n_grp, ncol = n_sim)\nfor(i in 1:n_sim){\n  ix &lt;- sort(sample(1:nrow(d_lm), replace = T))\n  f_boot &lt;- glm(y ~ j*k, data = d_lm[ix], family = binomial)\n  d_tmp_p &lt;- cbind(\n    d_lm[ix],\n    mu = predict(f_boot)\n  )\n  d_lm_j[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = j][, mean]\n  d_lm_j_k[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = .(k, j)][, mean]\n}\n# bootstrapped intervals for means on j and within group means\nd_lm_j &lt;- data.table(d_lm_j)\nd_lm_j[, j := 1:.N]\nd_lm_j &lt;- melt(d_lm_j, id.vars = \"j\")\nd_lm_j[, j := factor(j)]\n# d_lm_j[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = j]\n\nd_lm_j_k &lt;- data.table(d_lm_j_k)\nd_lm_j_k &lt;- cbind(CJ(k = 1:par$n_grp, j = 1:par$n_trt), d_lm_j_k)\nd_lm_j_k &lt;- melt(d_lm_j_k, id.vars = c(\"j\", \"k\"))\nd_lm_j_k[, `:=`(j = factor(j), k = factor(k))]\n# d_lm_j_k[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = .(k,j)]\n\nd_lm[, eta_hat := predict(f0)]\n\n# bayes\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-01.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-02.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-03.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y, \n  J = length(unique(d$j)), K = length(unique(d$k)),\n  j = d$j, # intervention\n  k = d$k, # subgroup\n  P = ncol(X),\n  X = X,\n  s = 3,\n  s_j = 3, # for the indep means offsets\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 2.4 seconds.\nChain 2 finished in 2.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 2.4 seconds.\nTotal execution time: 2.6 seconds.\n\n\nFit model to simulated data\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 3.9 seconds.\nChain 2 finished in 4.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 4.3 seconds.\nTotal execution time: 4.7 seconds.\n\n\nWarning: 22 of 2000 (1.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nFit model to simulated data\nf3 &lt;- m3$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 8.5 seconds.\nChain 2 finished in 10.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 9.2 seconds.\nTotal execution time: 10.1 seconds.\n\n\nWarning: 57 of 2000 (3.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\n\n\nParameter estimates vs true values\nd_1 &lt;- data.table(t(f1$draws(variables = \"eta\", format = \"matrix\")))\nd_1 &lt;- cbind(d, d_1)\nd_1 &lt;- melt(d_1, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_2 &lt;- data.table(t(f2$draws(variables = \"eta\", format = \"matrix\")))\nd_2 &lt;- cbind(d, d_2)\nd_2 &lt;- melt(d_2, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_3 &lt;- data.table(t(f3$draws(variables = \"eta\", format = \"matrix\")))\nd_3 &lt;- cbind(d, d_3)\nd_3 &lt;- melt(d_3, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_mu_j &lt;- rbind(\n  d_1[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_2[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_3[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j]\n)\n\n  \n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j[, .(q5 = quantile(value, prob =0.05),\n           q95 = quantile(value, prob = 0.95)), keyby = j], \n  by = \"j\"\n)\n\nd_mu_j &lt;- rbind(d_mu_j, d_mle, fill = T)\n\n# Observed\n# Due to the imbalance between the subgroups, need to weight the\n# contributions to align (approx) with mle.\n# Easy here because only one other variable that we need to average\n# over.\nd_obs &lt;- merge(\n  d[, .(N_j = .N), keyby = .(j)],\n  d[, .(mu = qlogis(mean(y)), .N), keyby = .(j, k)],\n  by = \"j\"\n)\nd_mu_j &lt;- rbind(\n  d_mu_j,\n  d_obs[, .(\n    desc = \"observed\", \n    mean = sum(mu * N / N_j)), keyby = j]\n  , fill = T\n  )\n\n\nd_mu_j[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n\n\nd_mu &lt;- d[, .(mu = qlogis(mean(y)), \n         w = .N/nrow(d)), keyby = .(j, k)][\n           , .(desc = \"observed\", mean = sum(mu * w))]\n\n\np_fig &lt;- ggplot(d_mu_j, aes(x = j, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  geom_hline(data = d_mu,\n             aes(yintercept = mean, lty = desc),\n             lwd = 0.3, col = 1) +\n  scale_x_discrete(\"Treatment arm\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2))  +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_mu_j$q5, na.rm = T) - 0.1, \n                label = N), inherit.aes = F) +\n  theme(legend.position=\"bottom\", legend.box=\"vertical\", legend.margin=margin())\n\nsuppressWarnings(print(p_fig))  \n\n\n\n\n\n\n\n\nFigure 5: Parameter estimates vs true values\n\n\n\n\n\n\n\nParameter estimates vs true values\n# Manually calculate intervals for independent model\nd_mu_j_k &lt;- rbind(\n  # d_mu_j_k,\n  d_1[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_2[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_3[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)]\n  )\n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(k, j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j_k[, .(q5 = quantile(value, prob =0.05),\n               q95 = quantile(value, prob = 0.95)), keyby = .(k,j)], \n  by = c(\"j\",\"k\")\n)\n\nd_mu_j_k &lt;- rbind(d_mu_j_k, d_mle, fill = T)\n\n# Observed\nd_mu_j_k &lt;- rbind(\n  d_mu_j_k, \n  d[, .(desc = \"observed\", mean = qlogis(mean(y))), keyby = .(k, j)],\n  fill = T)\n\n\nd_mu_j_k[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n# \nd_mu_obs &lt;- d[, .(mu = qlogis(mean(y)))]\nd_mu_mod &lt;- data.table(f3$summary(variables = c(\n    \"mu\"\n    )))[, .(model = \"no pooling\", variable, mean, q5, q95)]\n\np_fig &lt;- ggplot(d_mu_j_k, aes(x = k, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  scale_x_discrete(\"Subgroup\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2)) +\n  geom_hline(data = d_mu_j[desc == \"observed\"],\n             aes(yintercept = mean, group = desc),\n             lwd = 0.3, col = 1) +\n  geom_text(data = d[, .N, keyby = .(j, k)],\n            aes(x = k, y = min(d_mu_j_k$q5, na.rm = T) - 0.1, label = N), \n            inherit.aes = F) +\n  facet_wrap(~paste0(\"Treatment \", j)) \n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 6: Parameter estimates vs true values\n\n\n\n\n\nThe posterior estimates for the variance components are now poorly informed by the data and therefore highly uncertain. Accordingly, the prior is having a much greater influence under this scenario.\n\n\nVariance components (revision)\nd_fig &lt;- rbind(\n  cbind(desc = \"partial pool (trt)\",\n        data.table(f2$draws(variables = c(\"s_j\"), format = \"matrix\"))),\n  cbind(desc = \"partial pool (trt+subgrp)\",\n        data.table(f3$draws(variables = c(\"s\", \"s_j\"), format = \"matrix\"))  \n  ), fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = \"desc\")\nd_fig[variable == \"s\", label := \"variation b/w\"]\nd_fig[variable == \"s_j\", label := \"variation w/in\"]\n\nd_pri &lt;- CJ(\n  variable = c(\"s\", \"s_j\"),\n  desc = c(\"partial pool (trt)\", \"partial pool (trt+subgrp)\"),\n  x = seq(min(d_fig$value, na.rm = T), \n          max(d_fig$value, na.rm = T), len = 500)\n)\nd_pri[, y := fGarch::dstd(x, nu = 3, mean = 0, sd = 2)]\nd_pri[variable == \"s\", label := \"variation b/w\"]\nd_pri[variable == \"s_j\", label := \"variation w/in\"]\nd_pri[desc == \"partial pool (trt)\" & variable == \"s\", y := NA]\n\np_fig &lt;- ggplot(d_fig, aes(x = value, group = variable)) + \n  geom_density() +\n  geom_line(\n    data = d_pri, \n    aes(x = x, y = y), col = 2, lwd = 0.2\n  ) +\n  scale_x_continuous(\"Standard deviation\") +\n  scale_y_continuous(\"Density\") +\n  facet_wrap(desc+label~., ncol = 2)\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 7: Between and within SD\n\n\n\n\n\nBased on the above, it is unclear whether the additional complexity of an mlm is warranted when only two groups are available since the results are basically analogous to those of simpler approaches.\nThe results are also somewhat unsatisfying when assuming non-zero effects between treatments and within subgroups as shown below.\n\n\nCode\nset.seed(2)\npar &lt;- get_par(n_grp = 2, n_trt = 2, mu = 1, s = 0.4, s_j = 0.2)\nd &lt;- get_data(N = 3000, par)\n\n\n\n\nFit model to simulated data\n# mle - reference point\nd_lm &lt;- copy(d)\nd_lm[, `:=`(j = factor(j), k = factor(k))]\nf0 &lt;- glm(y ~ j*k, data = d_lm, family = binomial)\nX &lt;- model.matrix(f0)\n# CI\nn_sim &lt;- 1000\nd_lm_j &lt;- matrix(NA, nrow = par$n_trt, ncol = n_sim)\nd_lm_j_k &lt;- matrix(NA, nrow = par$n_trt * par$n_grp, ncol = n_sim)\nfor(i in 1:n_sim){\n  ix &lt;- sort(sample(1:nrow(d_lm), replace = T))\n  f_boot &lt;- glm(y ~ j*k, data = d_lm[ix], family = binomial)\n  d_tmp_p &lt;- cbind(\n    d_lm[ix],\n    mu = predict(f_boot)\n  )\n  d_lm_j[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = j][, mean]\n  d_lm_j_k[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = .(k, j)][, mean]\n}\n# bootstrapped intervals for means on j and within group means\nd_lm_j &lt;- data.table(d_lm_j)\nd_lm_j[, j := 1:.N]\nd_lm_j &lt;- melt(d_lm_j, id.vars = \"j\")\nd_lm_j[, j := factor(j)]\n# d_lm_j[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = j]\n\nd_lm_j_k &lt;- data.table(d_lm_j_k)\nd_lm_j_k &lt;- cbind(CJ(k = 1:par$n_grp, j = 1:par$n_trt), d_lm_j_k)\nd_lm_j_k &lt;- melt(d_lm_j_k, id.vars = c(\"j\", \"k\"))\nd_lm_j_k[, `:=`(j = factor(j), k = factor(k))]\n# d_lm_j_k[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = .(k,j)]\n\nd_lm[, eta_hat := predict(f0)]\n\n# bayes\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-01.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-02.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-03.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y, \n  J = length(unique(d$j)), K = length(unique(d$k)),\n  j = d$j, # intervention\n  k = d$k, # subgroup\n  P = ncol(X),\n  X = X,\n  s = 3,\n  s_j = 3, # for the indep means offsets\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 2.3 seconds.\nChain 2 finished in 2.3 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 2.3 seconds.\nTotal execution time: 2.5 seconds.\n\n\nFit model to simulated data\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 5.3 seconds.\nChain 2 finished in 6.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 5.8 seconds.\nTotal execution time: 6.6 seconds.\n\n\nWarning: 25 of 2000 (1.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nFit model to simulated data\nf3 &lt;- m3$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 10.8 seconds.\nChain 1 finished in 12.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 11.7 seconds.\nTotal execution time: 12.6 seconds.\n\n\nWarning: 81 of 2000 (4.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nFor the treatment group means, the multi-level model produces estimates that are again basically equivalent to those of the simpler modelling approaches.\n\n\nParameter estimates vs true values\nd_1 &lt;- data.table(t(f1$draws(variables = \"eta\", format = \"matrix\")))\nd_1 &lt;- cbind(d, d_1)\nd_1 &lt;- melt(d_1, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_2 &lt;- data.table(t(f2$draws(variables = \"eta\", format = \"matrix\")))\nd_2 &lt;- cbind(d, d_2)\nd_2 &lt;- melt(d_2, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_3 &lt;- data.table(t(f3$draws(variables = \"eta\", format = \"matrix\")))\nd_3 &lt;- cbind(d, d_3)\nd_3 &lt;- melt(d_3, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_mu_j &lt;- rbind(\n  d_1[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_2[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_3[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j]\n)\n\n  \n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j[, .(q5 = quantile(value, prob =0.05),\n           q95 = quantile(value, prob = 0.95)), keyby = j], \n  by = \"j\"\n)\n\nd_mu_j &lt;- rbind(d_mu_j, d_mle, fill = T)\n\n# Observed\n# Due to the imbalance between the subgroups, need to weight the\n# contributions to align (approx) with mle.\n# Easy here because only one other variable that we need to average\n# over.\nd_obs &lt;- merge(\n  d[, .(N_j = .N), keyby = .(j)],\n  d[, .(mu = qlogis(mean(y)), .N), keyby = .(j, k)],\n  by = \"j\"\n)\nd_mu_j &lt;- rbind(\n  d_mu_j,\n  d_obs[, .(\n    desc = \"observed\", \n    mean = sum(mu * N / N_j)), keyby = j]\n  , fill = T\n  )\n\n\nd_mu_j[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \n  \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n\n\nd_mu &lt;- d[, .(mu = qlogis(mean(y)), \n         w = .N/nrow(d)), keyby = .(j, k)][\n           , .(desc = \"observed\", mean = sum(mu * w))]\n\n\np_fig &lt;- ggplot(d_mu_j, aes(x = j, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  geom_hline(data = d_mu,\n             aes(yintercept = mean, lty = desc),\n             lwd = 0.3, col = 1) +\n  scale_x_discrete(\"Treatment arm\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2))  +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_mu_j$q5, na.rm = T) - 0.1, \n                label = N), inherit.aes = F) +\n  theme(legend.position=\"bottom\", legend.box=\"vertical\", legend.margin=margin())\n\nsuppressWarnings(print(p_fig))  \n\n\n\n\n\n\n\n\nFigure 8: Parameter estimates vs true values\n\n\n\n\n\nFor the subgroups, the estimates were shrunk towards the treatment group means for the data set simulated here.\n\n\nParameter estimates vs true values\n# Manually calculate intervals for independent model\nd_mu_j_k &lt;- rbind(\n  # d_mu_j_k,\n  d_1[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_2[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_3[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)]\n  )\n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(k, j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j_k[, .(q5 = quantile(value, prob =0.05),\n               q95 = quantile(value, prob = 0.95)), keyby = .(k,j)], \n  by = c(\"j\",\"k\")\n)\n\nd_mu_j_k &lt;- rbind(d_mu_j_k, d_mle, fill = T)\n\n# Observed\nd_mu_j_k &lt;- rbind(\n  d_mu_j_k, \n  d[, .(desc = \"observed\", mean = qlogis(mean(y))), keyby = .(k, j)],\n  fill = T)\n\n\nd_mu_j_k[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \n  \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n# \nd_mu_obs &lt;- d[, .(mu = qlogis(mean(y)))]\nd_mu_mod &lt;- data.table(f3$summary(variables = c(\n    \"mu\"\n    )))[, .(model = \"no pooling\", variable, mean, q5, q95)]\n\np_fig &lt;- ggplot(d_mu_j_k, aes(x = k, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  scale_x_discrete(\"Subgroup\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2)) +\n  geom_hline(data = d_mu_j[desc == \"observed\"],\n             aes(yintercept = mean, group = desc),\n             lwd = 0.3, col = 1) +\n  geom_text(data = d[, .N, keyby = .(j, k)],\n            aes(x = k, y = min(d_mu_j_k$q5, na.rm = T) - 0.1, label = N), \n            inherit.aes = F) +\n  facet_wrap(~paste0(\"Treatment \", j)) \n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 9: Parameter estimates vs true values\n\n\n\n\n\nHowever, while the variance is indicated as being possibly small, it is poorly informed by the data and therefore our uncertainty regarding these parameters is high.\n\n\nVariance components (revision)\nd_fig &lt;- rbind(\n  cbind(desc = \"partial pool (trt)\",\n        data.table(f2$draws(variables = c(\"s_j\"), format = \"matrix\"))),\n  cbind(desc = \"partial pool (trt+subgrp)\",\n        data.table(f3$draws(variables = c(\"s\", \"s_j\"), format = \"matrix\"))  \n  ), fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = \"desc\")\nd_fig[variable == \"s\", label := \"variation b/w\"]\nd_fig[variable == \"s_j\", label := \"variation w/in\"]\n\nd_pri &lt;- CJ(\n  variable = c(\"s\", \"s_j\"),\n  desc = c(\"partial pool (trt)\", \"partial pool (trt+subgrp)\"),\n  x = seq(min(d_fig$value, na.rm = T), \n          max(d_fig$value, na.rm = T), len = 500)\n)\nd_pri[, y := fGarch::dstd(x, nu = 3, mean = 0, sd = 2)]\nd_pri[variable == \"s\", label := \"variation b/w\"]\nd_pri[variable == \"s_j\", label := \"variation w/in\"]\nd_pri[desc == \"partial pool (trt)\" & variable == \"s\", y := NA]\n# \n# d_smry &lt;- d_fig[, .(mu = mean(value)), keyby = .(label)]\n\np_fig &lt;- ggplot(d_fig, aes(x = value, group = variable)) + \n  geom_density() +\n  geom_line(\n    data = d_pri, \n    aes(x = x, y = y), col = 2, lwd = 0.2\n  ) +\n  scale_x_continuous(\"Standard deviation\") +\n  scale_y_continuous(\"Density\") +\n  facet_wrap(desc+label~., ncol = 2)\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 10: Between and within SD\n\n\n\n\n\nWe could certainly use a multi-level approach for ROADMAP, but given the small number of groups available, a fixed regularising prior might be more defensible and conceptually reasonable than a dynamic prior. The challenge would be to specify hyper-parameters such that are sufficiently informative to moderate extreme parameter estimates.",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/design-notes-04.html",
    "href": "notebooks/design-notes-04.html",
    "title": "Estimands, ITT and PP",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\n\n\nThe ICH E9(R1) addendum on estimands and sensitivity analysis in clinical trials (estimand framework) provides an alternative to the traditional approach of specifying treatment effects. A more explicit definition of the causal effect of interest is advocated, the goal being to measure how the outcome of an intervention compares to the outcome that would have happened to the same units under a different intervention. As we never see the unit level outcomes under all interventions, clinical trials employ randomisation as the structural mechanism to enable these effects to be identified. The causal aspects are therefore linked with randomised assignment rather than received treatment. It is, however, assumed that units will follow the assigned treatment and therefore, in the ideal case, the causal relationship can be extended to the actual taking of treatment. Intercurrent event (unit level events that occur after randomisation that alter the interpretation or existence of the outcome) can compromise the causal effects and thus need to be considered in the estimand definitions. The specification of the treatment regimen is critical in understanding what constitutes an IE.\nThe components of an estimand are: treatment condition, population, outcome, intercurrent event handling and summary measure. In English, these correspond to\n\ntreatment condition \\(:=\\) “what is the trial comparing?”\npopulation \\(:=\\) “what people/condition are we trying to help?”\noutcome \\(:=\\) “what is being measured?”\nie handling \\(:=\\) “how do we intend to handle treatment related events that disrupt the existence or interpretation of the outcome?” and\nsummary measure \\(:=\\) “what statistical measure is going to be used?”\n\nEven though the estimand framework never refers to it directly, it has causal inference very much in mind and therefore the notation used by the potential outcomes framework is a natural way to define the causal effects that are being targeted by the estimands.\nAs a way to give some insight into the concepts and notation implicit in the specification of an estimand, consider a simple two-arm randomised trial. The trial has units \\(i = 1 \\dots n\\) where each can be assigned to either control \\(a=0\\) or test \\(a = 1\\). Take \\(Y_i\\) to denote an observable binary response variable of interest and \\(M_i\\) to denote a binary IE such as discontinuation due to availability of treatment (\\(m=1\\) being discontinued, \\(m = 0\\) completed). We expect that the IE to encode characteristics \\(U_i\\) of the unit \\(i\\) as well as the treatment.\nLet \\(M_i(a)\\) denote the potential outcome for the IE and let \\(Y_i(a,m)\\) be the potential outcome for the response for unit \\(i\\) assigned to \\(a\\) and \\(m\\). Each unit has potential outcomes for the outcome:\n\n\\(Y(0,0)\\) the outcome under control without discontinuation\n\\(Y(0,1)\\) the outcome under control with discontinuation\n\\(Y(1,0)\\) the outcome under test without discontinuation\n\\(Y(1,1)\\) the outcome under test with discontinuation\n\nAdditionally:\n\n\\(M_i(a=1)\\) is the potential outcome for the IE when unit \\(i\\) is assigned to the test group\n\\(Y_i(a, m = 0)\\) is the potential outcome for the response when intervening intervening with \\(a\\) and \\(m=0\\) (assuming that intervening on \\(m\\) is somehow possible, i.e. it is a hypothetical world)\n\\(Y_i(a,M_i(a))\\) is the potential outcome for the response when the assigned treatment is \\(a\\) and the natural state that IE has when the assigned treatment is \\(a\\)\n\\(Y_i(a=1,M_i(a=1)=0) \\equiv Y_i(1,M_i(1)=0)\\) is the potential outcome for the response when under \\(a=1\\) for those who do not have the IE\n\nFor any given unit we can only observe one set of potential outcomes, that is if \\(i\\) is assigned to test \\(a = 1\\) then what becomes observable are \\(M_i(a=1)\\) and \\(Y_i(a=1,M(a=1)) \\equiv Y_i(a=1)\\), where the abbreviation follows from the composition assumption.\nA graphical representation of the study is shown below.\n\n\n\n\n\nflowchart LR\n  U --&gt; Y\n  U((\"U\")) --&gt; M\n  A((\"A\" )) --&gt; M((\"M\")) --&gt; Y((\"Y\"))\n  A --&gt; Y\n  \n  style U stroke-dasharray: 5 5\n\n\n\n\n\n\nThe ITT principle involves what units to include and what data to include on each unit. If IEs are thought of as mediators of treatment, then the ITT effect aligns with the total effect of assigned treatment, i.e. the effect of treatment through all paths. One way to implement ITT is to include all randomised units and all their outcomes ignoring post-randomisation changes in treatment, protocol violations, non-adherence etc. The implied treatment regimen is therefore the offer of the assigned treatment with potential for discontinuation of that treatment and/or the use of any other treatment at any time without restriction. Under this formulation, IEs may break the link between assignment and received treatment and this can make the results less relevant for some applications. In the estimand framework, treatment policy is aligned with ITT and under randomised treatment is identified (converted from a causal quantity to a statistical quantity) via:\n\\[\n\\begin{aligned}\n\\Delta_{ITT} &= \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)] \\\\\n   &= \\mathbb{E}[Y(1)|A = 1] - \\mathbb{E}[Y(0) | A = 0] \\\\\n   &= \\mathbb{E}[Y|A = 1] - \\mathbb{E}[Y | A = 0] \\\\\n\\end{aligned}\n\\]\nA per-protocol analysis aims at offering a specific perspective on the trial results; the implicit goal is usually that of evaluating the effect of treatment in those that adhere to the protocol. However, a traditional per-protocol analysis simply subsets the trial data to those units that have adhered and performs the primary analysis (unchanged) on that part of the data. This is insufficient to define a causal effect.\nFirst we need to identify the relevant IEs and we need to determine how these (discontinuation, treatment switching (non-compliance), rescue medication, toxicity, AEs etc) might impact the existence or interpretation of the outcome. We should also think about how likely each of these events are and document that. Then, let’s say we are interested in the effect of received treatment when used as intended with no need for variation or additional medication or intervention. We might be able to use the hypothetical strategy here. This approach imagines an idealised world where the IE does not occur, assuming that such a counterfactual reality is possible and applicable, which isn’t always the case. For example, if the outcome were just treatment success (i.e. imagine we were not using a composite outcome) then trying to use a hypothetical strategy to address the IE of death would not make sense as it would effectively disregard the most serious consequence of the interventions. However, it may well be reasonable to use the hypothetical strategy to address an IE of extended use of some therapy beyond what is defined in the protocol.\nFor the hypothetical strategy, if we let \\(m = 0\\) represent the absence the IE, then the estimand could be specified as:\n\\[\n\\begin{aligned}\n\\Delta_{HYP} &= \\mathbb{E}[Y(1,m=0)] - \\mathbb{E}[Y(0,m=0)]\n\\end{aligned}\n\\]\nwhich is the difference in the expectations of the potential outcomes under test and control where in the hypothetical setting where no IE occurs. If we attempt to estimate this effect by subsetting the data to the cohort that did not have the IE then what we are implicitly conditioning on \\(M\\) in the above DAG and because \\(M\\) is a collider, this opens a backdoor path through \\(U\\). This means that the potential outcome \\(Y(a,m)\\) is dependent on \\(M(a)\\):\n\\[\n\\begin{aligned}\n\\Delta_{HYP} &= \\mathbb{E}[Y(1,m=0)] - \\mathbb{E}[Y(0,m=0)]  \\ne \\mathbb{E}[Y|A=1,M=0] - \\mathbb{E}[Y|A=0,M=0]\n\\end{aligned}\n\\]\nIn other words, the estimand is no longer identified and cannot be converted into a statistical quantity using such an approach, which is why the traditional per-protocol analysis does not produce a causal effect.\nThe intuition is simple - say we had placebo vs test and the IE is toxicity leading to discontinuation and this is more likely in units with severe illness. If we condition on those that did not have the IE, then we will be comparing the placebo group that has a mix of illness severities with the test group that only contains units with lower severity of disease. In other words, the groups are no longer directly comparable.\nHowever, if we do have access to \\(U\\) or some proxy for \\(U\\) then we might be able to assume conditional independence within levels of \\(U\\), i.e. \\(Y(a,m) \\perp M(a) | U\\). This gives us a way to estimate the direct effect of treatment, which is effect solely due to the intervention. With \\(U\\) we can identify the estimand:\n\\[\n\\begin{aligned}\n\\Delta_{HYP} &= \\mathbb{E}[Y(1,m=0)] - \\mathbb{E}[Y(0,m=0)]  \\\\\n   &= \\sum_\\mathcal{U} \\mathbb{E}[Y | U = u, M = 0, A = 1]Pr(U = u) - \\sum_\\mathcal{U} \\mathbb{E}[Y | U = u, M = 0, A = 0]Pr(U = u)\n\\end{aligned}\n\\]\nand so we can produce an estimate of the causal effect of the hypothetical situation where the IE does not occur. Of course, this still comes at the cost of assumptions that we cannot entirely verify and we therefore need to be cautious in the reporting. There are also other ways that we might approach this.\nBelow is a simple simulation to show the difference between the ITT, the naive per protocol approach and the hypothetical estimand obtained from standardisation over the distribution of \\(U\\). It assumes the following setup\n\\[\n\\begin{aligned}\nU_i &\\sim \\text{Bernoulli}(0.35) \\\\\nA_i &\\sim \\text{Bernoulli}(0.5) \\\\\n\\pi_{m(i)} &= 0.05 + 0.15 A + 0.3 AU \\\\\nM_i &\\sim \\text{Bernoulli}(\\pi_{m(i)}) \\\\\n\\pi_{y(i)} &= 0.5 + 0*a - 0.35*u  \\\\\nY_i &\\sim \\text{Bernoulli}(\\pi_{y(i)}) \\\\\n\\end{aligned}\n\\]\nwhere the probability of the risk factor \\(U\\) is 35% in the population, the interventions are randomised 1:1, the occurrence of the IE is a function of \\(A\\) and \\(U\\) and the probability of \\(Y\\) is a function of \\(A\\), \\(U\\). The direct effect of \\(A\\) is fixed at zero.\nThe ITT and hypothetical strategy effects are consistent whereas the naive per-protocol approach inflates the effect estimate.\n\n\nCode\n# number of simulations\nN_sim &lt;- 1e3\n# sample size of each study\nN &lt;- 1e3\n# probability of factor that is external determinant of ice \np_u &lt;- 0.35\n# rand to ctl vs test\np_a &lt;- 0.5\n\nm_rd &lt;- do.call(rbind, mclapply(1:N_sim, FUN = function(i){\n  \n  rd &lt;- rep(NA, 3)\n  \n  u &lt;- rbinom(N, 1, p_u)\n  a &lt;- rbinom(N, 1, p_a)\n  d &lt;- data.table(u, a)\n  \n  # chance of ice increases when in the test group and where u is present\n  # probability that m occurs.\n  d[, m := rbinom(N, 1, 0.05 + 0.15*a + 0.3*a*u)]\n  \n  # say occurrence of y is desirable\n  # occurrence of y dependent on a, m and u \n  # a has no effect on outcome\n  # u decreases prob of y e.g. effect of risk factor\n  # m only influences y through a\n  d[, p_y := 0.5 + 0*a - 0.35*u]  \n  \n  d[, y := rbinom(N, 1, p_y)]\n  \n  # if we ignore the occurrence of the ice then we are aligned with an itt \n  # perspective and there should be negligible difference between the groups \n  # on the risk of the outcome\n  m_p_y &lt;- c(d[a == 0, mean(y)], d[a == 1, mean(y)])\n  rd[1] &lt;- diff(m_p_y)\n  # however if we restrict attention to the subset for whom the ice did not occur\n  # e.g. the subset that adhered to the protocol then we note an increase in the\n  # risk of the outcome in the treatment group.\n  \n  # this arises due to the backdoor path from m through to y\n  m_p_y &lt;- c(d[a == 0 & m == 0, mean(y)], d[a == 1 & m == 0, mean(y)])\n  rd[2] &lt;- diff(m_p_y)\n  \n  # observed marginal distribution of u\n  p_u_obs &lt;- d[, mean(u)]\n  p_a_0 &lt;- sum( d[m == 0 & a == 0 & u == 1, .(mu_y = mean(y)),]*p_u_obs + \n                  d[m == 0 & a == 0 & u == 0, .(mu_y = mean(y)),]*(1-p_u_obs))\n  p_a_1 &lt;- sum( d[m == 0 & a == 1 & u == 1, .(mu_y = mean(y)),]*p_u_obs + \n                  d[m == 0 & a == 1 & u == 0, .(mu_y = mean(y)),]*(1-p_u_obs))\n  \n  m_p_y &lt;- c(p_a_0, p_a_1)\n  rd[3] &lt;- diff(m_p_y)\n  \n  rd\n  \n}, mc.cores = 10))\n  \ncolnames(m_rd) &lt;- c(\"ITT\", \"Per protocol\", \"Hypothetical\") \n\nd_rd &lt;- data.table(m_rd)\nd_rd &lt;- melt(d_rd, measure.vars  = names(d_rd))\nd_rd[, variable := factor(variable, levels = c(\"ITT\", \"Per protocol\", \"Hypothetical\"))]\n\n\n\n\nCode\nggplot(d_rd, aes(x = value, group = variable)) + \n  geom_histogram(fill = \"white\", col = \"black\", bins = 15) +\n  geom_vline(xintercept = 0, col = 2, lwd = 1) +\n  geom_vline(data = d_rd[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu), lty = 2) + \n  scale_x_continuous(\"Risk difference (Test vs Ctl)\") +\n  scale_y_continuous(\"Frequency\") +\n  facet_grid(variable ~.)\n\n\n\n\n\n\n\n\nFigure 1: Distribution of estimates of effect estimates under different estimand strategies\n\n\n\n\n\nSo far, only a single IE has been discussed, which isn’t realistic, but it is just intended to give some intuition into what is already a well known characteristic of a naive per-protocol analyses. In practice, we (1) need to think through the implications of the multiple IEs that exist in the study and (2) need multiple variables to account for the IE.\nAs noted above, in some settings a hypothetical estimand might be appropriate but in another it might not. For example, in roadmap (thinking about the surgical domain in isolation, forgetting the other domains for now) we might have \\(U\\) corresponding to a loose joint and as such treatment switching could be inevitable and it would be difficult to conceive of a world where this did not happen given the loose joint. The hypothetical strategy would possible not be suitable here but an effect that focuses on the strata of the population might be and this might direct us towards a principal stratum strategy. This approach attemtps to target causal effects in specific strata. For example, if a patient with an intact joint (not loose) was particularly frail then the surgeon might decide that assignment to revision was not warranted, whereas a loose joint would perhaps always lead to revision irrespective of the randomised treatment.\nTo give some insight into the principal stratum approach, let \\(M\\) denote the treatment actually received with \\(M=0\\) representing that control was received and \\(M=1\\) representing that test was received. We can then define a strata as \\(S_i = (M_i(0), M_i(1))\\) where \\(M_i(0)\\) and \\(M_i(1)\\) are the received treatment when assigned to control and test respectively. This gives us four combinations: \\(S_i \\in \\{ (0,0), (0,1), (1,0), (1,1)\\}\\) and these are usually described as never takers, compliers, defiers and always takers. For example, in the \\(S_i = (0, 0)\\) strata, the members take control when assigned to that arm and when assigned to the test arm, i.e. they never take the treatment. For a principal stratum strategy we are interested in the causal effect within one (or a combination) of these strata, usually the compliers and so the estimand could be specified as\n\\[\n\\begin{aligned}\n\\Delta_{PS} &= \\mathbb{E}[Y(a=1,m)|M(a = 1)=1] - \\mathbb{E}[Y(a=0,m)|M(a = 0)=0]  \n\\end{aligned}\n\\]\ni.e. the average treatment effect in those units that would have received their assigned treatment had they been assigned to either the control or test group, which is not the same as the subset of units who were observed to have adhered to the treatment they were assigned to.\nThe problem is that for a unit \\(i\\) we only ever observe one of the components in the above definition and what we do observe represents membership in a mixture of strata rather than a single strata. For example, a unit who is assigned to control and is observed to receive control could belong to the compliers strata or the never takes test strata etc.\nTo overcome these, the common assumptions are:\n\nfor the never takers and always takers, the potential outcomes are the same irrespective of the treatment they are assigned to\nthere are no defiers\nthere is a non-zero probability for membership in the compliers strata\n\nhowever, there are actually a lot of different perspectives and approaches. Anyway, the point is that after making various assumptions, some principal strata are, in principle, identifiable.",
    "crumbs": [
      "Design notes",
      "Estimands, ITT and PP"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html",
    "href": "notebooks/design-notes-02.html",
    "title": "Design discussion (part 1)",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nThis provides some technical background with the goal of aiding insight into the limitations and challenges associated with the present design.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#complete-design",
    "href": "notebooks/design-notes-02.html#complete-design",
    "title": "Design discussion (part 1)",
    "section": "Complete design",
    "text": "Complete design\nConceptually, roadmap is somewhat nested within an approximation of a complete design, see below. We have ignored the choice domain since it’s not relevant to the discussion here, neither are variations in participation and deviations from assignment. The boxes denote nodes where assignment is under statistical control, the circles are self selected.\nThe complete design as presented still has its quirks. There are multiple version of treatment under revision and these are self selected rather than randomised. Similarly with dair, we expect 12 weeks duration will be the recommended norm, but duration is ultimately self-selected for this group. Aspirationally, we posit 12 and 6 weeks duration following dair per the revision units.\nWhile the duration has been specified as a unified intervention. The figure decomposes the duration domain into duration of antibiotic following the first and second stage operations as this aligns more closely with the interventional procedures. The dashed lines indicate paths which are not available in the current design.\n\n\n\n\n\nflowchart TD\n  Z[Surgery] --&gt; T(Revision type selected) --&gt; W[1st stage duration] --&gt; X[2nd stage duration]\n  A1[DAIR] --&gt; A5((DAIR))\n  A5 --&gt; B0((12w))\n  A5 -.-&gt; B1((6w))\n\n  A2[Revision] --&gt; A3((One-stage))\n  A2 --&gt; A4((Two-stage))\n\n  A3 --&gt; B2[12w]\n  A3 --&gt; B3[6w]\n  A4 --&gt; B4[12w]\n  A4 -.-&gt; B5[6w]\n\n  B2 --- STOP[ ]\n  B2 --- STOP2[ ]\n  B4 --&gt; C1[12w]\n  B4 --&gt; C2[7d]\n  B5 -.-&gt; C3[12w]\n  B5 -.-&gt; C4[7d]\n\n  linkStyle 5 stroke: red;\n  linkStyle 11 stroke: red;\n  linkStyle 16 stroke: red;\n  linkStyle 17 stroke: red;\n  linkStyle 12 fill:#FFFFFF00, stroke: #FFFFFF00\n  linkStyle 13 fill:#FFFFFF00, stroke: #FFFFFF00\n  style STOP  fill:#FFFFFF00, stroke:#FFFFFF00;\n  style STOP2  fill:#FFFFFF00, stroke:#FFFFFF00;\n\n\n\n\n\n\nNeither nested, nor fractional properly characterise the nature of the roadmap design since some cells are self-selected and others fall outsize the specified set of factor levels. For want of a better descriptor, I will just say that roadmap approximately sits within the complete design.\n\n\n\n\n\nflowchart TD\n  Z[Surgery] --&gt; T(Revision type selected) --&gt; W[1st stage duration] --&gt; X[2nd stage duration]\n  A1[DAIR] --&gt; B1((DAIR))\n  B1 --&gt; C1((Usual care))\n\n  A2[Revision] --&gt; B2((One-stage))\n  A2 --&gt; B3((Two-stage))\n\n  B2 --&gt; C2[12w]\n  B2 --&gt; C3[6w]\n  B3 --&gt; C4((Usual care))\n  C4 --&gt; D1[12w]\n  C4 --&gt; D2[7d]\n\n  C2 --- STOP[ ]\n  C3 --- STOP2[ ]\n\n  linkStyle 12 fill:#FFFFFF00, stroke: #FFFFFF00\n  linkStyle 13 fill:#FFFFFF00, stroke: #FFFFFF00\n  style STOP  fill:#FFFFFF00, stroke:#FFFFFF00;\n  style STOP2  fill:#FFFFFF00, stroke:#FFFFFF00;\n\n\n\n\n\n\nIn all cases in the above Usual care following the first operation equates to 12 weeks but that there is some flexibility in this and additionally, a duration of 12 weeks may be precluded by logistical considerations. For example, if the second stage of a two-stage unit occurs within 12 weeks of the first operation then it is not logically possible to assign 12 weeks worth of antibiotic.\nNevertheless, tentatively, we might fill in usual care with 12 weeks to achieve the following structure.\n\n\n\n\n\nflowchart TD\n  Z[Surgery] --&gt; T(Revision type selected) --&gt; W[1st stage duration] --&gt; X[2nd stage duration]\n  A1[DAIR] --&gt; B1((DAIR))\n  B1 --&gt; C1((12w))\n\n  A2[Revision] --&gt; B2((One-stage))\n  A2 --&gt; B3((Two-stage))\n\n  B2 --&gt; C2[12w]\n  B2 --&gt; C3[6w]\n  B3 --&gt; C4((12w))\n  C4 --&gt; D1[12w]\n  C4 --&gt; D2[7d]\n\n  C2 --- STOP[ ]\n  C3 --- STOP2[ ]\n\n  linkStyle 12 fill:#FFFFFF00, stroke: #FFFFFF00\n  linkStyle 13 fill:#FFFFFF00, stroke: #FFFFFF00\n  style STOP  fill:#FFFFFF00, stroke:#FFFFFF00;\n  style STOP2  fill:#FFFFFF00, stroke:#FFFFFF00;\n\n\n\n\n\n\nNow, under the full design model, there would be 8 treatment cells of interest.\n\nDAIR with 12 weeks\nDAIR with 6 weeks\nRevision, one-stage with 12 weeks\nRevision, one-stage with 6 weeks\nRevision, two-stage with 12 weeks following 1st, 12 weeks following 2nd\nRevision, two-stage with 12 weeks following 1st, 7 days following 2nd\nRevision, two-stage with 6 weeks following 1st, 12 weeks following 2nd\nRevision, two-stage with 6 weeks following 1st, 7 days following 2nd\n\nBut in the current roadmap setup we are reduced to 5 treatment:\n\nDAIR with 12 weeks\nRevision, one-stage with 12 weeks\nRevision, one-stage with 6 weeks\nRevision, two-stage with 12 weeks following 1st, 12 weeks following 2nd\nRevision, two-stage with 12 weeks following 1st, 7 days following 2nd\n\nHowever, for 1, 4 and 5, 12 weeks following the first surgery might not be an entirely reasonable assumption. For now, we will put that thought on hold.\nFrom the current design, although there are 5 cells, there are 3 comparisons which are of interest:\n\nDAIR with 12 weeks vs. revision with 12 weeks following 1st and X (could be 12w, 7d, or a mixture) days following 2nd if two-stage\nRevision, one stage with 12 weeks vs. with 6 weeks\nRevision, two stage with 12 weeks after 1st and 2nd vs. 7 days after 2nd.\n\nIf 1 is what is meant by “Revision vs DAIR” then it is not entirely clear who would find this useful in practice since there is potential for substantial variation in the effect dependent on which components are included.\nA saturated model for the full design might be\n\\[\n\\begin{aligned}\n\\eta = &\\beta_0 + \\beta_1r_{\\text{one-stage}} + \\beta_2 r_{\\text{two-stage}} + \\beta_3 d_{\\text{1, 6 weeks}} \\\\\n&+ \\beta_4 r_{\\text{one-stage}}d_{\\text{1, 6 weeks}} + \\beta_5 r_{\\text{two-stage}}d_{\\text{1, 6 weeks}} \\\\\n&+ \\beta_6 r_{\\text{two-stage}} d_{2,\\text{7 days}} + \\beta_7 r_{\\text{two-stage}}d_{\\text{1, 6 weeks}} d_{2,\\text{7 days}}\n\\end{aligned}\n\\]\nwhere the reference group is “DAIR with 12 weeks” and variations in participation are ignored, ditto with respect to the consideration of any level of interactions.\nUnder the current roadmap design, only a reduced model can be considered. A saturated model for the reduced design could be:\n\\[\n\\eta = \\alpha_0 + \\alpha_1r_{\\text{one-stage}} + \\alpha_2 r_{\\text{two-stage}} + \\alpha_3 r_{\\text{one-stage}} d_{\\text{1, 6 weeks}} + \\beta_4 r_{\\text{two-stage}} d_{2,\\text{7 days}}\n\\]\nwhere the reference group is “DAIR with 12 weeks”.\nA reduced model could also be considered under the full design. For example, if we assumed that the effect of first-stage duration was constant across surgery types (which it seems we don’t), and assume that second stage duration is constant across first-stage duration types, then the model would be\n\\[\n\\eta = \\beta_0 + \\beta_1r_{\\text{one-stage}} + \\beta_2 r_{\\text{two-stage}} + \\beta_3 d_{\\text{1, 6 weeks}} + \\beta_6 r_{\\text{two-stage}} d_{2,\\text{7 days}}\n\\]\ni.e. assuming that \\(\\beta_4 = \\beta_5 = \\beta_7\\) from the earlier model are all set to zero.\nThis is basically equivalent to the reduced design model. The exception being that the reduced design is estimating \\(\\alpha_3\\), the effect of duration following one-stage revision specifically. The full design would by default estimate the effect of duration using data from all surgery types, \\(\\beta_3\\), assuming that the effect is constant across types, or additionally could target surgery specific interactions.\nWhy do we only consider the reduced design? Presumably, this is because of the results from other studies that DAIR with 6 weeks is inferior to DAIR with 12 weeks and that in two-stage revision, 6 weeks is considered inferior to 12 weeks. We are investigating 6w vs 12w for one-stage under the assumption that there is effect heterogenity of duration conditional on surgery type. So, inferiority of 6w amongst DAIR/two-stage is insufficient evidence to assume inferiority of 6w in one-stage.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#associational-effects",
    "href": "notebooks/design-notes-02.html#associational-effects",
    "title": "Design discussion (part 1)",
    "section": "Associational effects",
    "text": "Associational effects\nOne of the questions that has been raised relates to how it is that the surgical and duration domain are effectively coupled by design thereby necessitating a perspective on combined interventional strategies. To understand this it is worth stepping back for a moment and thinking about the structure and implications of the models we are using and how they are used to characterise measures of association.\nStart by thinking about the representation of a linear regression versus a logistic regression and what they are aiming to achieve. This is easiest way to do so via an example so assume we have two independent factors that are predictive of independent continuous and binary outcomes. Assume that we are interested in the effect of A but B is still predictive of the outcome. In other words, assume something analogous to a randomised clinical trial setup where A corresponds to our randomised intervention set (here just control vs test) and B is some prognostic baseline characteristic (age, sex etc). For a continuous outcome, adopt a linear model of the form \\(\\mathbb{E}[Y | A,B] = \\mu = \\alpha_0 + \\alpha_1 A + \\alpha_2 B\\) with \\(Y\\) normally distributed. This model encapsulates our assumptions (unknowable in real life) for the data generating process. For the binary outcome adopt a logistic model of the form \\(g(\\mathbb{E}[W | A,B]) = \\eta = \\beta_0 + \\beta_1 A + \\beta_2 B\\) with \\(W\\) is bernoulli \\(\\eta\\) being log-odds of response and \\(g\\) being the logit link function such that the conditional mean of the response is now given by applying the inverse link \\(\\mathbb{E}[W | A,B] = g^{-1}(\\beta_0 + \\beta_1 A + \\beta_2 B)\\) with \\(g^{-1}(z) = \\frac{1}{1+\\exp(-z)} = \\frac{\\exp(z)}{1 + \\exp(z)} = \\text{expit}(z)\\). This latter representation does make sense for the dichotomous response since what we are interested in is the probability of the event and that happens to equate to the expectation, e.g. the conditional expectation of \\(W\\), given \\(X = x\\):\n\\[\n\\begin{aligned}\n\\mathbb{E}(W | X = x) &= \\sum_{w \\in \\mathcal{W} } w Pr(W=w | X = x) \\\\\n  &= 0 Pr(W = 0 | X = x) + 1 Pr(W = 1 | X = x) \\\\\n  &= Pr(W = 1 | X = x)\n\\end{aligned}\n\\]\nIn other words, the conditional mean equates to the conditional probability; \\(\\mathbb{E}[W | A, B] = g^{-1}(\\beta_0 + \\beta_1 A + \\beta_2 B) = Pr(W = 1 | A, B)\\).\nNow, instead of B mapping in the logistic regression relating to the presence/absence of a baseline characteristic, think of it as a second set of interventions so that we are now describing a factorial setup (conveniently ignoring the possibility of interactions). Both A and B remain independent dichotomous random variables. In a complete factorial experiment we would randomise units to all combinations of A and B and usually take parameter estimates as the effects (e.g. log-odds-ratios or odds ratios) of interest. The exponentiated \\(\\beta_1\\) is the multiplicative change in the odds of response associated with moving from the control to the intervention group, with the important caveat that we are holding all other terms constant.\nIn case you need to see how this works out -\nRecall that the logistic regression gives us the probability of the outcome via the inverse logit transformation: \\(Pr(W = 1 | A, B) = g^{-1}(\\beta_0 + \\beta_1 A + \\beta_2 B)\\). The odds ratio for a unit change in A (i.e. a shift from control to test) is defined as:\n\\[\n\\begin{aligned}\nOR(a + 1, a | b) &= \\frac{\\frac{g^{-1}(\\beta_0 + \\beta_1 (a+1) + \\beta_2 b)}{1-g^{-1}(\\beta_0 + \\beta_1 (a+1) + \\beta_2 b)}}{\\frac{g^{-1}(\\beta_0 + \\beta_1 a + \\beta_2 b)}{1-g^{-1}(\\beta_0 + \\beta_1 a + \\beta_2 b)}} \\\\\n&= \\frac{\\exp(\\beta_0 + \\beta_1 (a+1) + \\beta_2 b)}{\\exp(\\beta_0 + \\beta_1 a + \\beta_2 b)} \\\\\n&= \\exp(\\beta_1)\n\\end{aligned}\n\\]\nThe \\(\\beta_2 b\\) term cancels out so long as whatever b was, was the same for both groups, which is what the holding all other terms constant part relates to.\nAnother way to get to this is to take the difference between the two logged values. We know that when we take the difference between two logged values (e.g. the log-odds of response in the treatment vs control group) this equates to the log of their ratio, hence \\(\\beta_1\\) being referred to as the log-odds-ratio.\n\\[\n\\begin{aligned}\nlog(\\phi) - \\log(\\psi) = \\log(\\frac{\\phi}{\\psi})\n\\end{aligned}\n\\]\nAll of the above should be comfortably familiar, but the point was to be explicit for how things are in the context of a conditional logistic regression model and a complete factorial experiment where we have the full set of parameters irrespective of what combination of interventions we are considering.\nNow imagine a situation where we remove the secondary intervention factor (B) for one level of the primary intervention factor (A). This is analogous to a simplified version of the current roadmap design where A is representing the surgical domain and B the duration domain. Here we are only thinking about dair vs one-stage revision for the surgical interventions and 12 vs 6 weeks duration following surgery, but only for those having the one-stage procedure.\nGiven the above setup, we might choose to model the groups independently as we do not intervene on antibiotic duration for the dair group and therefore the system has a distinct data generation processes for each group.\nFor dair we could model and estimate the log-odds of response in isolation, say \\(\\theta\\) estimated from the cohort that receive dair. We take it for granted that the dair intervention is well defined in all its supportive components, which may include some flexibility in the duration of antibiotics received but it isn’t something we have control over via randomisation. Based on the literature it seems like there might be variation in the response under dair conditional on duration but again we are putting that thought on hold for now.\nFor the one-stage group, we might model\n\\[\n\\begin{aligned}\n\\zeta = \\gamma_0 + \\gamma_1 B\n\\end{aligned}\n\\]\nwhere the first term is the log-odds of response for those receiving one-stage revision and the second term relates to how the duration of antibiotics impacts that response. Based on the earlier details for how to derive the log-odds-ratio, we take the difference between the two groups:\n\\[\n\\begin{aligned}\n\\log(OR) = (\\gamma_0 + \\gamma_1 B) - \\theta\n\\end{aligned}\n\\]\nClearly, we are left with the situation where we need to make some decision on what to do with B since it hasn’t dropped out of the calculations as it did under the complete design setup discussed previously. Specifically, if we set B = 0 then we get one answer for the effect of one-stage vs dair, namely \\(\\gamma_0 - \\theta\\) and if we set B = 1 then we get another answer \\(\\gamma_0+\\gamma_1 - \\theta\\). Furthermore, it doesn’t matter whether we use independent models or one large joint model, you still have to make a decision or an assumption about how to handle B. We haven’t got a single parameter to represent the odds-ratio and if such a parameter existed it would probably have a fairly unusual interpretation.\nOne response to the question of what to do with B is to average over B and to adopt a marginal view of the measure of association. This necessitates some assumption regarding the distribution of B. In a complete factorial 2x2 design where A and B are randomised 1:1, the distribution of B is known. However, this probably doesn’t reflect the distribution of B in the population.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#consequences-of-adjustment",
    "href": "notebooks/design-notes-02.html#consequences-of-adjustment",
    "title": "Design discussion (part 1)",
    "section": "Consequences of adjustment",
    "text": "Consequences of adjustment\nAnother thing to be aware of is the concept of collapsibility. Formally, measures of association are said to be collapsible if the marginal view equates to a weighted average of the strata specific effects. In a factorial design, for the comparison of treatments in factor A, units can be grouped in stratum based on the assignment of factor B. Odds-ratios are generally not collapsible and so this should probably be a consideration when using odds-ratios as the population-level summary measure for an estimand.\nAs an example, and with reference to the earlier model, assume that the OR for the treatment group in A relative to the control is 0.5 and for B the effect is 0.1. Additionally, assume that the probability of response in the strata that receive the reference level for both A and B is 0.5. The following simulates a large sample to simply demonstrate the occurrence of differing views of association dependent on the model that is adopted and thus the need to be clear in what we are trying to target in terms of the causal estimand of interest.\n\nlibrary(data.table)\n# Large sample size\nN &lt;- 1e6\n\n# 1:1 Randomisation of A and B\na &lt;- rbinom(N, 1, 0.5)\nb &lt;- rbinom(N, 1, 0.5)\n\n# No interaction by design\neta &lt;- 0 + log(0.5)*a + log(0.1)*b\ny &lt;- rbinom(N, 1, plogis(eta))\n\nd &lt;- data.table(a, b, eta, y)\n\n# Multivariable logistic regression\nl1 &lt;- glm(y ~ a + b, data = d, family = binomial)\n\n# Conditional probabilities for each treatment group\nd_pred &lt;- CJ(a=0:1,b=0:1)\nd_pred[, p := predict(l1, type = \"response\", newdata = d_pred)]\n\n# Observed distribution of b (should be 0.5)\np_b_obs &lt;- mean(b)\n\n# Standardisation to the marginal distribution of b\nd_pred[b == 1, p_b := p_b_obs]\nd_pred[b == 0, p_b := 1-p_b_obs]\np_a_0 &lt;- d_pred[a == 0, sum(p * p_b)]\np_a_1 &lt;- d_pred[a == 1, sum(p * p_b)]\n\n# Univariate logistic regression\nl2 &lt;- glm(y ~ a, data = d, family = binomial)\n\n# Measure of association (all odds-ratios)\n\n# Conditional measures\na_cond &lt;- unname(exp(coef(l1)[2]))\n# Marginal odds ratio computed from standardisation \na_marg_std &lt;- p_a_1/(1-p_a_1) / (p_a_0/(1-p_a_0))\n# Marginal odds ratio computed from univariate regression\na_marg_reg &lt;- unname(exp(coef(l2)[2]))\n\nc(a_cond = a_cond, a_marg_std = a_marg_std, a_marg_reg = a_marg_reg)\n\n    a_cond a_marg_std a_marg_reg \n 0.5000815  0.5608424  0.5605329 \n\n\nThe conditional esitmates give the strata level odds-ratios that we anticipate, however, the marginal odds-ratios are a reflection the observed distribution of B. Clearly, this has implications for the interpretation and generalisability of the results.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#causal-ambiguity",
    "href": "notebooks/design-notes-02.html#causal-ambiguity",
    "title": "Design discussion (part 1)",
    "section": "Causal ambiguity",
    "text": "Causal ambiguity\nNone of the above has considered the causal overlay, which is perhaps the primary motivation for running a randomised clinical trial - we want to be able to say that a change in the response was caused by an intervention rather than simply being associated with it. Some background on a popular causal framework follows.\nThe Neyman-Rubin (causal) model introudces potential outcomes as a means to specify the causal effects. For a treatment with two levels (e.g. control = 0 vs active = 1), the outcome has two possible (potential) values \\(Y_i(0)\\) and \\(Y_i(1)\\) for each experimental unit, \\(i\\). That is, a hypothetical world is posed where the outcomes under both the control and active treatment are available to us. Two assumptions are implicit in the definition of potential outcomes:\n\nno interference - the potential outcome for unit \\(i\\) does not depend on any other units’ treatment\nconsistency1 - if the treatment is \\(T\\) then the observed outcome is equal to the potential outcome under \\(T\\)\n\nUsing this notation we can define a unit level effect as say the difference between the potential outcomes \\(\\tau_i = Y_i(1) - Y_i(0)\\). The problem is that we can never observe both the response to both treatment levels on a single unit. We therefore resort to group level effects for a collection of units by defining an average treatment effect \\(\\tau = \\mathbb{E}(Y_i(1) - Y_i(0))\\). Unlike the unit level effect, the average treatment effect can be identified under certain conditions and then estimated from the observed data.\nOne statistical solution2 to the identification problem above (identification is the technical term for being able to produce a statistical estimand for a given causal estimand) is to randomly assign treatments to the experimental units so that the probability of assignment does not depend on anything other than the flip of a coin. This implies that the potential outcomes will be independent of the treatment which then means that the expected value of a potential outcome is equal to the expected value of the potential outcome conditioned on the treatment status, e.g. \\(\\mathbb{E}(Y(0)) = \\mathbb{E}(Y(0) | T = 0)\\). Formally, this is referred to as the exchaneability assumption and if the consistency assumption also holds then we can resolve the causal quantity into something we can observe and estimate, e.g. \\(\\mathbb{E}(Y(0) | T = 0) = \\mathbb{E}(Y | T = 0)\\). Of course, given that the conditional expection is defined as \\(\\mathbb{E}(Y | T = 0) = \\sum_{y\\in \\mathcal{Y}} y Pr(Y | T = 0) = \\sum_{y\\in \\mathcal{Y}} y \\frac{Pr(Y , T = 0)}{Pr(T = 0)}\\), there needs to be a non-zero probability of assigning \\(T\\), otherwise the quantities that we require will not be defined mathematically. Models will work around this, but we are taking a leap of faith (sometimes an unjustifiable one) in order to believe what they are telling us. This final assumption is known as positivity - we need to have a non-zero probability of treatment assignment for all treatments.\nSo, if our trial has a single domain A which is simply looking at dair (0) vs revision (1) and the outcome were binary then we might posit the causal effect of interest (causal estimand) as the ATE. For a binary outcome amounts to a risk difference, but we are not restricted to this estimand specification, it is just convenient and simple for the purposes of the discussion. Assuming that our modelling approach remains logistic regression we would have\n\\[\n\\begin{aligned}\n\\tau &= \\mathbb{E}(Y(1)) -  \\mathbb{E}(Y(0)) \\\\\n     &= \\mathbb{E}(Y(1)|A = 1) -  \\mathbb{E}(Y(0)|A = 0) \\\\\n     &= \\mathbb{E}(Y|A = 1) -  \\mathbb{E}(Y|A = 0) \\\\\n     &= g^{-1}(\\beta_0 + \\beta_1) - g^{-1}(\\beta_0)\n\\end{aligned}\n\\]\nwhich we can work with so long as the above identification assumptions are met. This would mean that what we get from our model can be given a causal interpretation.\nIf we have two interventional factors, e.g. surgical (A) and duration (B) then we have a larger number of causal estimands to consider under a complete 2x2 factorial design. The potential outcome for a given unit is now usually specified as \\(Y_i(a_i, b_i)\\) where \\(a_i\\) and \\(b_i\\) constitute specific levels of a treatment combination for unit \\(i\\). For concreteness, take the levels for A to be dair and one-stage and the levels for B to be 12wks and 6wks so that \\(Y(1,0)\\) would denote the potential outcome under dair and 12wks. A consequence of this setup is that we can no longer meaningfully discuss \\(Y(A)\\) in isolation as it omits a component of the treatment and is therefore inconsistent in the sense that \\(Y(1)\\) might refer to either \\(Y(1,0)\\) or \\(Y(1,1)\\).\nFor the factorial design, the exchangeability/unconfoundedness assumption required for identification needs to consider both factors, i.e. we need \\((Y(a,b))_{a\\in\\mathcal{A},b\\perp\\mathcal{B}} \\perp (A,B)\\) which can (again) be achieved via randomisation. The final assumption of positivity is also extended so that we require a non-zero probability of assignment for all treatment combinations \\(Pr(A = a, B = b) &gt; 0\\) for all \\(a \\in \\mathcal{A}\\) and \\(b \\in \\mathcal{B}\\). If you are going to adhere strictly to the framework, then I think this final point rules out the use of fractional factorial designs.\nAs mentioned above, with the factorial design we can consider a variety of causal estimands. In our case, these might hypothetically include:\n\nthe effect of one-stage vs dair under 12wks duration\nthe effect of one-stage vs dair under 6wks duration\nthe effect of one-stage vs dair under usual practice for duration\nthe effect of one-stage + 12wks vs dair + 6wks\n\nFor the sake of argument, pick (1) and use an analogous approach to earlier to identify the effect:\n\\[\n\\begin{aligned}\n\\tau &= \\mathbb{E}(Y(1,0)) -  \\mathbb{E}(Y(0,0)) \\\\\n     &= \\mathbb{E}(Y(1,0)|A = 1,B=0) -  \\mathbb{E}(Y(0,0)|A = 0,B=0) \\\\\n     &= \\mathbb{E}(Y|A = 1,B=0) -  \\mathbb{E}(Y|A = 0,B=0) \\\\\n     &= g^{-1}(\\beta_0 + \\beta_1) - g^{-1}(\\beta_0)\n\\end{aligned}\n\\]\nusing the same model specification (\\(\\mathbb{E}[W | A,B] = g^{-1}(\\beta_0 + \\beta_1 A + \\beta_2 B)\\)) as was used earlier and where \\(\\tau\\) now represents a combination effect. However, while \\(Y(A)\\) is ill-defined in the factorial setting, we can still address effects within a single factor through marginalisation:\n\\[\n\\begin{aligned}\n\\psi &= \\mathbb{E}_B[\\mathbb{E}[(Y(1,B) - Y(0,B)]]\n\\end{aligned}\n\\]\nwhere \\(\\psi\\) is the marginal effect for the selected levels of \\(A\\) although this still clearly depends on the distribution of B and therefore might not generalise well to the super population if the measure of association is non-collapsible (see earlier). The central point that I am trying to get across here is that under a complete factorial design we can provide a clear specification of the causal estimands, we can identify the associated statistical estimands and this allows us to estimate effects of interest.\nI do not believe that we have this level of clarity or unification within roadmap. Returning to the current simplified roadmap setup where we have dair vs one-stage and for one-stage we have 12 vs 6 wks, we have\n\ndair + 12 wks: \\(Y(0,0)\\)\none + 12 wks: \\(Y(1,0)\\)\none + 6 wks: \\(Y(1,1)\\)\n\n\\(Y(0,1)\\) is an impossibility by design even though it exists in principle. This looks somewhat like a violation in the positivity assumption but arguably we can work around it. Additionally, \\(Y(0,0)\\) is actually never formally assigned to any unit. What we have is \\(Y(0,U)\\) where \\(U\\) denotes whatever usual practice is, or perhaps a recommendation of usual practice. While we expect (and might assume) that \\(Y(0,U) := Y(0,0)\\) but that does not appear to be guaranteed. Again, we can potentially make assumptions that might help us with all of the above within the context of a model but I am currently uncertain as to whether the causal interpretation can truly be resolved under the present specification.\nThe above simplification is obviously (and purposefully a bit inaccurate) as we currently specify that the surgical domain randomises dair vs revision where the revision intervention is then selected to be either one-stage or two-stage by a clinician based on unobserved variables.\nConsidering a design where only the surgical domain was included, this would also seem to violate the consistency assumption. Recall that consistency connects the potential outcome with the observed data. It is defined as \\(Y_i = Y_i(x)\\) if \\(x = x_i\\); in words - the observed outcome for a unit equals the potential outcome for that unit with the intervention level set to the exposure that the unit received. However, given that what we observe under revision is consequence of either a one-stage or two-stage procedure, then there are two distinct values that singular \\(Y_i(1)\\) could take on, either \\(Y_{one}\\), the observed outcome under a one-stage revision or \\(Y_{two}\\), the observed outcome under a two-stage revision. The argument against this would be that the meaning of revision simply maps to a one or two-stage procedure and the distinction does not matter.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#summary",
    "href": "notebooks/design-notes-02.html#summary",
    "title": "Design discussion (part 1)",
    "section": "Summary",
    "text": "Summary\nThese notes are an attempt to provide some background and clarifications as well as formalise some of the thinking. Hopefully they can provide something of a common understanding in relation to some of the unusual aspects of the design.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#footnotes",
    "href": "notebooks/design-notes-02.html#footnotes",
    "title": "Design discussion (part 1)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHas no relation with statistical consistency.↩︎\nHolland (1986) talks about others.↩︎",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/about.html",
    "href": "notebooks/about.html",
    "title": "About",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "notebooks/about.html#repository-status",
    "href": "notebooks/about.html#repository-status",
    "title": "About",
    "section": "Repository status",
    "text": "Repository status\nDetails on GitHub repository files, tags, commits follow:\n\n\nCode\nrepo &lt;- git2r::repository(path = \".\")\nsummary(repo)\n\n\nLocal:    main /Users/mark/Documents/project/roadmap/src/roadmap-sim\nRemote:   main @ origin (https://github.com/maj-biostat/roadmap-sim.git)\nHead:     [b13dcc0] 2025-06-08: Sim08 cfg\n\nBranches:          3\nTags:              0\nCommits:         323\nContributors:      2\nStashes:           0\nIgnored files:    82\nUntracked files:  35\nUnstaged files:   15\nStaged files:      0\n\nLatest commits:\n[b13dcc0] 2025-06-08: Sim08 cfg\n[b122b45] 2025-06-08: Update to sim07-04\n[9242aff] 2025-06-08: Update to sim07-04\n[7869e8e] 2025-06-07: Fix sim07 ex ref\n[a1e5162] 2025-06-07: Update for sim07-03",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Introduction to site",
    "section": "",
    "text": "This site contains notes, data summaries and simulation results for the ROADMAP study.\nAll the code can be found on github, just use the icon to the top right. The functionality herein has a dependency on the roadmap.data R package, which can also be found via the above link (see the readme for this repo).",
    "crumbs": [
      "Introduction to site"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html",
    "href": "notebooks/design-notes-01.html",
    "title": "Identification of effects",
    "section": "",
    "text": "Setup\nsource(\"./R/init.R\")\n\n\nWarning: package 'cmdstanr' was built under R version 4.4.3\n\n\nSetup\nlog_info(\"Called design-notes notebook\")\nStart by saying we were doing a trial in just the late acute patients. We are interested in surgery (DAIR/revision) and antibiotic duration (long/short), but we are limited in that, for whatever reason, we can not ethically randomise the type of revision surgery, only revision surgery itself.\nChoice of antibiotic duration is conditional on the type of revision surgery used, so surgery type needs to be considered in any joint analysis (alternatively, analyse separately).\nI just want to work through from a basic scenario to more involved ones to check understanding of potential issues. The following will ignore much of the complexity, but just want to get some basics down as a reference.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#surgery",
    "href": "notebooks/design-notes-01.html#surgery",
    "title": "Identification of effects",
    "section": "Surgery",
    "text": "Surgery\nAs a starting point, consider the following:\n\nR: randomised surgery - 0: DAIR, 1: revision\nS: preferred revision - 0: one-stage, 1: two-stage\nA: allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\nY: treatment success - 0: no, 1: yes\n\nPatients are randomised to a surgery type, \\(R\\): DAIR or revision. For every patient, if they were to have been allocated to revision, there is some preference/plan for one/two stage, \\(S\\). The value of \\(S\\) is determined by the surgeon/patient and I’m considering it here as just an attribute of the patient.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe above determination is actually dependent on the surgeon’s position as well as patient characteristics. In fact, one may dominate the other. For example, would a surgeon choose two-stage for all their patients simply because they have more experience or sucess with that approach, whereas another might choose one-stage for all theirs?\nNote to self - in practice, I actually think that what matters is that we know what selection is rather than what process occurs to decide. Additionally, later we see that this consideration becomes redundant.\n\n\n\nThe actual allocated treatment is a deterministic function of \\(R\\) and \\(S\\), i.e. \\(A = R \\times (S + 1)\\). Note that I’m assuming that \\(S\\) is known for every patient before \\(R\\) is revealed to the surgeon, irrespective of whether they are eventually assigned to DAIR or revision (if that it isn’t the case then perhaps some issues might arise, but I don’t think that it matters too much for what’s being considered here given randomisation).\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A \n  S --&gt; Y\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 1: Scenario 1, the \\(U\\) denote independent exogenous variables\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nThere are no back-door paths for the above, hence no open back-door paths\n\\(Y\\) is caused by/depends on some function of \\(R\\) and \\(S\\): \\(Y = f(R,S)\\)\nAssuming \\(S\\) causes \\(Y\\) a weaker/safer assumption than excluding that link.\nMaybe there should be some shared \\(U\\) that influences both \\(S\\) and \\(Y\\) rather than assuming \\(S\\) causes \\(Y\\)?\nThe graph implies:\n\n\\(S\\) and \\(R\\) are independent; \\(S \\mathrel{\\unicode{x2AEB}} R\\)\n\\(Y\\) is conditionally independent of \\(R\\) given \\(A\\) and \\(S\\); \\(Y \\mathrel{\\unicode{x2AEB}} R | A, S\\)\n\nWe can estimate the total effect of \\(R\\) on \\(Y\\) where \\(R = 1\\) is loosely defined as revision with expert selection of one-stage or two-stage procedure (or something along those lines)\nThink planned/intended procedure should be recorded prior to any elements of randomisation being revealed.\nNo adjustment is required to estimate the total effect of \\(R\\) on \\(Y\\)\n\n\n\n\nOur intervention is on \\(R\\), everything down stream from that (revision type, antibiotic use, physiotherapy, complications) is a consequence of the intervention. It’s the overall effect of allocation to \\(R=0\\) or \\(R=1\\) that we are trying to (the only thing we can, not necessarily want to) compare.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nIsn’t revision-type independent of intervention? I don’t think I understand why it is downstream.\nNot really sure what is meant by the statement the only thing we can, not necessarily want to compare\n\n\n\n\nIf \\(Y(a)\\) is the potential outcome of a patient under surgery of type \\(a\\) (dair, one-stage, two-stage), then:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y(a)] &= \\mathbb{E}[Y(a)|R=0] \\\\\n&= \\mathbb{E}[Y(a) | R=1] \\\\\n&= \\mathbb{E}[Y(a) | A = 0] \\\\\n&= \\mathbb{E}[Y(a) | A \\in \\{1,2\\}] \\\\\n&\\ne \\mathbb{E}[Y(a) | A = j], \\quad j\\in\\{1,2\\} \\\\\n\\end{aligned}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nAbove we establish exchangeability assumptions, which are a partial requirement for identifying causal effects, i.e. it gets you to \\(\\mathbb{E}[Y(1)] = \\mathbb{E}[Y|A=1]\\) and \\(\\mathbb{E}[Y(0)] = \\mathbb{E}[Y|A=0]\\) whereby you are learning about the potential outcomes from the observed data.\nAll come about due to randomisation of \\(R\\).\nWhere independence holds (as above for the majority of the cases) knowing the conditioning variable tells you nothing about \\(Y(a)\\) (the term on the LHS of the conditioning).\nFor example \\(\\mathbb{E}[Y(a)] = \\mathbb{E}[Y(a)|R=0]\\) tells us that the potential outcomes of \\(Y(a)\\) in those receive dair have the same distribution as those that do not.\nFor \\(\\mathbb{E}[Y(a)] \\ne \\mathbb{E}[Y(a) | A = 1]\\) and \\(\\mathbb{E}[Y(a)] \\ne \\mathbb{E}[Y(a) | A = 2]\\) we are saying that the distribution of potential outcomes in those for whom one-stage is planned do not share the same distribtion as for those for whom one-stage is not planned. And this is by virtue of the fact that revision type is selected rather than randomised.\n\n\n\n\nThe only randomised comparison we can make is \\(R=1\\) vs \\(R=0\\), but, given we want to eventually condition on which revision type is selected, we want to include terms for preferred revision type in the model. Assume logistic regression is the true model and specify\n\\[\n\\begin{align}\n\\mathbb{E}[Y | R] &= Pr(Y = 1 | R) = \\text{expit}(\\alpha_0 + \\alpha_1R) \\\\\n\\end{align}\n\\tag{1}\\]\n\\[\n\\begin{align}\n\\mathbb{E}[Y | A] &= Pr(Y = 1 | A) = \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(A=1) + \\beta_2\\mathbb{I}(A=2)) \\\\\n\\end{align}\n\\tag{2}\\]\nEquivalently, state in terms of \\(R\\) and \\(S\\).\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS) \\\\\n\\tag{3}\\]\nEquation 1 targets the thing we actually want to compare, the log-odds ratio of revision versus DAIR. Equation 3 splits this out into one and two stage which we would need to combine to get the overall revision effect. In Equation 3, the \\(\\beta_1\\) gives the effect of revision under a one-stage procedure and the \\(\\beta_2\\) gives the increment on that term when a two-stage procedure is undertaken. Some weighted combination of these terms will give us a view of the aggregated effect of revision.\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhat isn’t directly stated above is that the (primary?) reason we need to split \\(R\\) into one-stage and two-stage effects is so that we can incorporate the duration domain within a single model. The randomised interventions for duration are 12 weeks vs 6 weeks antibiotics for those receiving one-stage surgery and 12 weeks vs 7 days for those receiving two-stage surgery. If a patient received one-stage, the duration intervention parameters associated with two-stage are mostly irrelevant to estimating the log-odds of treatment success for this patient. Moreover, the response for the one-stage patient does not inform the two-stage duration intervention effects. To accommodate this, the one-stage and two-stage duration parameters enter the model independently, e.g.\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1 \\mathbb{I}(R = \\text{one-stage} \\land D = short) + \\beta_2 \\mathbb{I}(R = \\text{two-stage} \\land D = short)) \\\\\n\\]\nHowever, this means that the duration domain reference group for the one-stage and two-stage duration effects have the same log-odds of treatment success and this is very unlikely to be the case. Thus, by splitting \\(R\\) into one-stage and two-stage effects we allow the reference groups for the one-stage and two-stage duration effects to vary.\n\n\n\nThese models could also adjust for \\(S\\), i.e. in addition to any actual effect of one/two stage revision, the patients for whom a two-stage would be preferred may differ from those for who a one-stage is the preference. Interpretation of model parameters then changes of course.\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3S) \\\\\n\\tag{4}\\]\nWe don’t really care about the difference due to \\(S\\), as the revision type effects may still be confounded by other factors anyway. Due to the randomisation, I think that both the version with and without \\(S\\) are targeting the same estimand for revision vs. DAIR (the distribution of \\(S\\) is the same (in expectation) amongst DAIR and revision patients, so is not a confounder, but obviously, \\(S\\) is known exactly to be \\(A-1\\) when \\(R=1\\)).\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think what you are proposing for the \\(\\beta_3\\) term (the effect of \\(S\\)) boils down to the following:\n\nthe effect of \\(S\\), clinical selection of one-stage vs two-stage may be confounded and we can probably do very little about that\nhowever, the estimate we obtain for \\(\\beta_3\\) would be the same in the group that received revision as the group that did not due to the fact that dair vs revision was randomised\n\nProbably incorrectly, I think the selection effect is meaningless in the sense that receiving dair contradicts the possibility of a selection. It is analogous to a model for number of children whereby you make an adjustment for (randomised) marriage and (self-selected) age of marriage. The main effect of age of marriage is excluded, on the basis that it has no counterpart in reality and therefore no way to inform the effect.\nWhat is the counter-argument? Perhaps something along the lines of:\nTo justify the inclusion of \\(\\beta_3\\) we argue that the married and the non-married groups are balanced across age (and all other characteristics). Therefore, the married and unmarried groups are similar and the effect for age of married in the group is portable to the group that were not randomised to marriage, in the counterfactual world where they had been.\nOk, think I have convinced myself (if perhaps no-one else) that it makes sense.\n\n\n\nFor the second model above, in terms of \\(R\\) and \\(S\\), without adjustment for \\(S\\)\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | R] &= \\mathbb{E}[\\mathbb{E}[Y | S, R] | R] \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs)\\mathbb{P}(S = s | R) \\\\\n\\mathbb{E}[Y|R =0] &= \\text{expit}(\\beta_0) \\\\\n\\mathbb{E}[Y|R = 1] &=  \\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(S=0|R=1) \\\\\n& \\quad \\ + \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2)\\mathbb{P}(S=1|R=1)\n\\end{aligned}\n\\]\nso the log-odds ratio for the marginal success probability for revision vs. DAIR is\n\\[\n\\begin{aligned}\n\\ln\\frac{\\text{odds}(Y|R=1)}{\\text{odds}(Y|R=0)} &= \\text{logit}[\\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(S=0|R=1) + \\\\  \n& \\quad \\quad \\ \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2)\\mathbb{P}(S=1|R=1)] -  \\beta_0\n\\end{aligned}\n\\tag{5}\\]\nWe don’t know \\(\\mathbb{P}(S=s|R)\\) so estimate it from the sample. Due to randomisation \\(\\mathbb{P}(S=s|R) = \\mathbb{P}(S=s)\\).\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhich is just creating a standardised probability of treatment success under revision based on a weighted version of the probability of treatment success for each of the selection groups (one-stage and two-stage) where the weights are formed from the (unknown) distribution of \\(S\\) (estimated from the sample). The standardised probability of treatment success under revision is then converted to the log odds of treatment success and the reference group (DAIR) log-odds of treatment success is subtracted to come up with the log-OR.\nThe final line in the above derivation is just saying that we can assume that the probability distribution of \\(S\\) is independent to treatment group membership and so can be estimated from the full sample rather than condition on \\(R\\). Note that \\(\\mathbb{P}(S=s)\\) is not necessarily indicative of the probability distribution of \\(S\\) in the population because of our convenience sample, but this is true for all inference here and in the majority of trials.\n\n\n\nAn alternative to the above is to consider the “average” conditional log-odds ratio rather than the odds ratio of the marginal probabilities.\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S)}{\\text{odds}(Y|R=0,S)}\\right] = \\mathbb{E}[\\beta_1 + \\beta_2S] = \\beta_1 + \\beta_2\\mathbb{E}[S]\n\\tag{6}\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe expectation of \\(S\\) above is across the sample, but below the weighting is taken from the revision group. Would it not be preferable to use the mean derived from the full sample or am I thinking about it incorrectly?\n\n\n\nIf the model also adjusts for \\(S\\), then\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | R] &= \\mathbb{E}[\\mathbb{E}[Y | S, R] | R] \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs + \\beta_3s)\\mathbb{P}(S = s | R) \\\\\n\\mathbb{E}[Y|R = 0] &= \\text{expit}(\\beta_0)\\mathbb{P}(S = 0 | R=0) + \\text{expit}(\\beta_0 + \\beta_3)\\mathbb{P}(S=1|R=0)\\\\\n\\mathbb{E}[Y|R = 1] &= \\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(S = 0 | R = 1) + \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3)\\mathbb{P}(S=1 | R = 1) \\\\\n\\ln\\frac{\\text{odds}(Y|R=1)}{\\text{odds}(Y|R=0)} &= \\text{logit}(\\mathbb{E}[Y|R = 1]) - \\text{logit}(\\mathbb{E}[Y|R = 0])\n\\end{aligned}\n\\]\nWith the introduction of a main effect for \\(S\\) we can still report on the average conditional log-odds ratio in the same form as previously:\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S)}{\\text{odds}(Y|R=0,S)}\\right] = \\mathbb{E}[\\beta_1 + \\beta_2S] = \\beta_1 + \\beta_2\\mathbb{E}[S]\n\\]\ni.e. with the same terms as without adjustment for \\(S\\). However, the treatment effect parameter estimates produced from the model that includes the main effect for \\(S\\) (and the interaction term) and the model that only has the interaction term, are likely be different.\n\nExample\nHerein I am just assuming \\(n\\approx \\infty\\), i.e. checking consistency.\n\n\n\n\n\n\nNote\n\n\n\n\n\nConsistency is simply about whether the estimator produces an estimate that gets closer towards the true value as the sample size gets bigger; a consistent estimator does not negate the possibility of bias. For example, \\(\\frac{1}{N-1}\\sum_i (x_i)\\) is a consistent but biased estimator of the mean for a random vector, \\(x\\).\nThe default parameterisation for the data generating mechanism is to adopt the functional form from Equation 4, which includes terms for \\(R\\), \\(S\\) and an interaction between \\(R\\) and \\(S\\).\n\n\n\n\n\nGenerate data scenario 1\n# Assume ~ infinite population as just checking consistency\n# Precision will of course vary by approach at small sample sizes\ngenerate_data_1 &lt;- function(\n    n = 1000000,\n    f = function(r, s, x){-1 + s + 0.25 * r + 0.25 * r * s}) {\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  x &lt;- rbinom(n, 1, 0.25)\n  a &lt;- r * (s + 1)\n  y0 &lt;- rbinom(n, 1, plogis(f(0, s, x)))\n  y1 &lt;- rbinom(n, 1, plogis(f(1, s, x)))\n  y &lt;- (1 - r) * y0 + r * y1\n  w &lt;- mean(s) # Selection probability\n  D &lt;- data.table(r = r, x = x, s = s, a = a, y0 = y0, y1 = y1, y = y)[\n    ,\n    `:=`(\n      r_fac = factor(r),\n      a_fac = factor(a),\n      s_fac = factor(s),\n      a_cen = r * (a - 1 - mean(a[r == 1] - 1)),\n      s_cen = s - mean(s)\n    )\n  ]\n}\n\n\n\n\nSimulate null effect\nset.seed(123)\nD &lt;- generate_data_1(f = function(r, s, x){-1 + s})\n\n# Eqn 1\nfit1 &lt;- glm(y ~ r, data = D, family = binomial())\n\n# Eqn 3\nfit2 &lt;- glm(y ~ r + r:s, data = D, family = binomial())\n\n# Eqn 6?\nfit1s &lt;- glm(y ~ r + s, data = D, family = binomial())\n\n# Eqn 4\nfit2s &lt;- glm(y ~ r + r:s + s, data = D, family = binomial())\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nIn the use of “true” below, what is meant is the empirical log-odds ratios in the population (approximated by a very large sample) that we observe. We estimate the effects directly from the data by calculating the difference in the log-odds of treatment success in the strata of interest for those in the treated vs control groups.\nThe table just tries to line up the quantities, like with like as there were some minor differences in the naming.\n\n\n\n\n\nNull effect quantities\nw &lt;- mean(D$a == 2) / mean(D$a %in% c(1, 2))\nw_s1 &lt;- mean(D[r == 0]$s == 1)\nw_s2 &lt;- mean(D[r == 1]$s == 1)\n\nb1 &lt;- unname(coef(fit1))\nb2 &lt;- unname(coef(fit2))\nb1s &lt;- unname(coef(fit1s))\nb2s &lt;- unname(coef(fit2s))\n\nEY_R0_2 &lt;- expit(b2[1])\nEY_R1_2 &lt;- (1 - w) * expit(b2[1] + b2[2]) + w * expit(b2[1] + b2[2] + b2[3])\n\nEY_R0_1_S0 &lt;- expit(b1s[1])\nEY_R0_1_S1 &lt;- expit(b1s[1] + b1s[3])\nEY_R1_1_S0 &lt;- expit(b1s[1] + b1s[2])\nEY_R1_1_S1 &lt;- expit(b1s[1] + b1s[2] + b1s[3])\nEY_R0_1 &lt;- (1 - w_s1) * EY_R0_1_S0 + w_s1 * EY_R0_1_S1\nEY_R1_1 &lt;- (1 - w_s2) * EY_R1_1_S0 + w_s2 * EY_R1_1_S1\n\nEY_R0_2s_S0 &lt;- expit(b2s[1])\nEY_R0_2s_S1 &lt;- expit(b2s[1] + b2s[3])\nEY_R1_2s_S0 &lt;- expit(b2s[1] + b2s[2]) # Pr(A = 2 | S = 0) = 0\nEY_R1_2s_S1 &lt;- expit(b2s[1] + b2s[2] + b2s[3] + b2s[4]) # Pr(A = 2 | S = 1) = 1\nEY_R0_2s &lt;- (1 - w_s1) * EY_R0_2s_S0 + w_s1 * EY_R0_2s_S1\nEY_R1_2s &lt;- (1 - w_s2) * EY_R1_2s_S0 + w_s2 * EY_R1_2s_S1\n\nrbind(\n  \"True conditional (S = 0) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n  \"True conditional (S = 1) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n  \"True marginal log-odds ratio\" = qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  \"True weighted log-odds ratio\" =\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n  \"True average weighted log-odds ratio\" =\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y))),\n  \"fit1 marginal log-odds ratio\" = b1[2],\n  \"fit2 marginal log-odds ratio\" = qlogis(EY_R1_2) - qlogis(EY_R0_2),\n  \"fit2 conditional (weighted) log-odds ratio\" = b2[2] + w * b2[3],\n  \"fit1s conditional log-odds ratio\" = b1s[2], # Don't know what this targets\n  \"fit1s marginal log-odds ratio\" = qlogis(EY_R1_1) - qlogis(EY_R0_1),\n  \"fit2s conditional (S = 0) log-odds ratio\" = qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0),\n  \"fit2s conditional (S = 1) log-odds ratio\" = qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1),\n  \"fit2s marginal log-odds ratio\" = qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n  \"fit2s average (weighted) log-odds ratio\" = b2s[2] + w * b2s[4]\n)\n\n\n                                                   [,1]\nTrue conditional (S = 0) log-odds ratio    -0.003882742\nTrue conditional (S = 1) log-odds ratio     0.003222299\nTrue marginal log-odds ratio                0.002568068\nTrue weighted log-odds ratio               -0.018727631\nTrue average weighted log-odds ratio        0.001097800\nfit1 marginal log-odds ratio                0.002568068\nfit2 marginal log-odds ratio                0.002568068\nfit2 conditional (weighted) log-odds ratio -0.018727631\nfit1s conditional log-odds ratio            0.001436139\nfit1s marginal log-odds ratio               0.002568068\nfit2s conditional (S = 0) log-odds ratio   -0.003882742\nfit2s conditional (S = 1) log-odds ratio    0.003222299\nfit2s marginal log-odds ratio               0.002568068\nfit2s average (weighted) log-odds ratio     0.001097800\n\n\nNull effect quantities\nd_out &lt;- data.table(\n  desc = c(\n    \"conditional (S = 0) log-OR\",\n    \"conditional (S = 1) log-OR\",\n    \"conditional log-OR (?)\",\n    \"conditional (weighted) log-OR\",\n    \"marginal log-OR\",\n    \"weighted log-OR\",\n    \"average (weighted) log-OR\"\n  ),\n  true = c(\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n    NA,  \n    NA,\n    qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)))\n  ),\n  fit_1 = c(\n    NA, \n    NA,  \n    NA,\n    NA, \n    b1[2], \n    NA, \n    NA\n  ),\n  fit_2 = c(\n    NA, \n    NA,\n    NA, \n    b2[2] + w * b2[3], \n    qlogis(EY_R1_2) - qlogis(EY_R0_2), \n    NA,\n    NA\n  ),\n  fit_1s = c(\n    NA, \n    NA, \n    b1s[2],\n    NA,\n    qlogis(EY_R1_1) - qlogis(EY_R0_1), \n    NA,\n    NA\n  ),\n  fit_2s = c(\n    qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0), \n    qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1), \n    NA, \n    NA,\n    qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n    NA,\n    b2s[2] + w * b2s[4]\n  )\n)\n\n\n\n\nTabulate effect quantities\ngt_tbl &lt;- d_out |&gt; \n  gt(rowname_col = c(\"desc\")) |&gt; \n  cols_align(align = \"right\", columns = 2:6) |&gt;  \n  fmt_number(columns = everything(), decimals = 3) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") |&gt;\n  tab_options(table.font.size = \"80%\") |&gt;\n  tab_footnote(\n    footnote = \"y ~ r\",\n    locations = cells_column_labels(columns = fit_1)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s\",\n    locations = cells_column_labels(columns = fit_2)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + s\",\n    locations = cells_column_labels(columns = fit_1s)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + s\",\n    locations = cells_column_labels(columns = fit_2s)\n    ) |&gt;\n  tab_footnote(\n    footnote = md(\"Should be labelled *conditional (weighted) log-OR*?\"),\n    locations = cells_stub(rows = c(\n      \"weighted log-OR\"\n    ))\n  ) |&gt;\n  tab_footnote(\n    footnote = md(\"log-OR for R term in model, but interpretation unclear\"),\n    locations = cells_stub(rows = c(\n      \"conditional log-OR (?)\"))\n  )\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrue\nfit_11\nfit_22\nfit_1s3\nfit_2s4\n\n\n\n\nconditional (S = 0) log-OR\n−0.004\n\n\n\n\n\n\n−0.004\n\n\nconditional (S = 1) log-OR\n0.003\n\n\n\n\n\n\n0.003\n\n\nconditional log-OR (?)5\n\n\n\n\n\n\n0.001\n\n\n\n\nconditional (weighted) log-OR\n\n\n\n\n−0.019\n\n\n\n\n\n\nmarginal log-OR\n0.003\n0.003\n0.003\n0.003\n0.003\n\n\nweighted log-OR6\n−0.019\n\n\n\n\n\n\n\n\n\n\naverage (weighted) log-OR\n0.001\n\n\n\n\n\n\n0.001\n\n\n\n1 y ~ r\n\n\n2 y ~ r + r:s\n\n\n3 y ~ r + s\n\n\n4 y ~ r + r:s + s\n\n\n5 log-OR for R term in model, but interpretation unclear\n\n\n6 Should be labelled conditional (weighted) log-OR?\n\n\n\n\n\n\n\n\n\nTable 1: Null effects\n\n\n\n\n\n\nSimulate effect\nset.seed(123)\nD &lt;- generate_data_1()\nfit1 &lt;- glm(y ~ r, data = D, family = binomial())\nfit2 &lt;- glm(y ~ r + r:s, data = D, family = binomial())\nfit1s &lt;- glm(y ~ r + s, data = D, family = binomial())\nfit2s &lt;- glm(y ~ r + r:s + s, data = D, family = binomial())\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nSimulate from Equation 4 with a baseline probability of treatment success equal to 0.27 together with \\(\\beta_1 = 0.25\\), \\(\\beta_2 = 0.25\\) and \\(\\beta_3 = 1\\) for the log-ORs associated with treatment, the interaction between treatment and selection and selection, respectively.\n\n\n\n\n\nEffect quantities\nw &lt;- mean(D$a == 2) / mean(D$a %in% c(1, 2))\nw_s1 &lt;- mean(D[r == 0]$s == 1)\nw_s2 &lt;- mean(D[r == 1]$s == 1)\n\nb1 &lt;- unname(coef(fit1))\nb2 &lt;- unname(coef(fit2))\nb1s &lt;- unname(coef(fit1s))\nb2s &lt;- unname(coef(fit2s))\n\nEY_R0_2 &lt;- expit(b2[1])\nEY_R1_2 &lt;- (1 - w) * expit(b2[1] + b2[2]) + w * expit(b2[1] + b2[2] + b2[3])\n\nEY_R0_1_S0 &lt;- expit(b1s[1])\nEY_R0_1_S1 &lt;- expit(b1s[1] + b1s[3])\nEY_R1_1_S0 &lt;- expit(b1s[1] + b1s[2])\nEY_R1_1_S1 &lt;- expit(b1s[1] + b1s[2] + b1s[3])\nEY_R0_1 &lt;- (1 - w_s1) * EY_R0_1_S0 + w_s1 * EY_R0_1_S1\nEY_R1_1 &lt;- (1 - w_s2) * EY_R1_1_S0 + w_s2 * EY_R1_1_S1\n\nEY_R0_2s_S0 &lt;- expit(b2s[1])\nEY_R0_2s_S1 &lt;- expit(b2s[1] + b2s[3])\nEY_R1_2s_S0 &lt;- expit(b2s[1] + b2s[2]) # Pr(A = 2 | S = 0) = 0\nEY_R1_2s_S1 &lt;- expit(b2s[1] + b2s[2] + b2s[3] + b2s[4]) # Pr(A = 2 | S = 1) = 1\nEY_R0_2s &lt;- (1 - w_s1) * EY_R0_2s_S0 + w_s1 * EY_R0_2s_S1\nEY_R1_2s &lt;- (1 - w_s2) * EY_R1_2s_S0 + w_s2 * EY_R1_2s_S1\n\nrbind(\n  \"True conditional (S = 0) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n  \"True conditional (S = 1) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n  \"True marginal log-odds ratio\" = qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  \"True weighted log-odds ratio\" =\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n  \"True average (weighted) log-odds ratio\" =\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y))),\n  \"fit1 marginal log-odds ratio\" = b1[2],\n  \"fit2 marginal log-odds ratio\" = qlogis(EY_R1_2) - qlogis(EY_R0_2),\n  \"fit2 conditional (weighted) log-odds ratio\" = b2[2] + w * b2[3],\n  \"fit1s conditional log-odds ratio\" = b1s[2], # Don't know what this targets\n  \"fit1s marginal log-odds ratio\" = qlogis(EY_R1_1) - qlogis(EY_R0_1),\n  \"fit2s conditional (S = 0) log-odds ratio\" = qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0),\n  \"fit2s conditional (S = 1) log-odds ratio\" = qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1),\n  \"fit2s marginal log-odds ratio\" = qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n  \"fit2s average (weighted) log-odds ratio\" = b2s[2] + w * b2s[4]\n)\n\n\n                                                [,1]\nTrue conditional (S = 0) log-odds ratio    0.2462550\nTrue conditional (S = 1) log-odds ratio    0.4944007\nTrue marginal log-odds ratio               0.4038167\nTrue weighted log-odds ratio               0.4003765\nTrue average (weighted) log-odds ratio     0.4202020\nfit1 marginal log-odds ratio               0.4038167\nfit2 marginal log-odds ratio               0.4038167\nfit2 conditional (weighted) log-odds ratio 0.4003765\nfit1s conditional log-odds ratio           0.4285063\nfit1s marginal log-odds ratio              0.4038167\nfit2s conditional (S = 0) log-odds ratio   0.2462550\nfit2s conditional (S = 1) log-odds ratio   0.4944007\nfit2s marginal log-odds ratio              0.4038167\nfit2s average (weighted) log-odds ratio    0.4202020\n\n\nEffect quantities\nd_out &lt;- data.table(\n  desc = c(\n    \"conditional (S = 0) log-OR\",\n    \"conditional (S = 1) log-OR\",\n    \"conditional log-OR (?)\",\n    \"conditional (weighted) log-OR\",\n    \"marginal log-OR\",\n    \"weighted log-OR\",\n    \"average (weighted) log-OR\"\n  ),\n  true = c(\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n    NA,  \n    NA,\n    qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)))\n  ),\n  fit_1 = c(\n    NA, \n    NA,   \n    NA,\n    NA, \n    b1[2], \n    NA, \n    NA\n  ),\n  fit_2 = c(\n    NA, \n    NA, \n    NA, \n    b2[2] + w * b2[3], \n    qlogis(EY_R1_2) - qlogis(EY_R0_2), \n    NA,\n    NA\n  ),\n  fit_1s = c(\n    NA, \n    NA, \n    b1s[2],\n    NA,\n    qlogis(EY_R1_1) - qlogis(EY_R0_1), \n    NA,\n    NA\n  ),\n  fit_2s = c(\n    qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0), \n    qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1),  \n    NA, \n    NA,\n    qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n    NA,\n    b2s[2] + w * b2s[4]\n  )\n)\n\n\n\n\nTabulate effect quantities\ngt_tbl &lt;- d_out |&gt; \n  gt(rowname_col = c(\"desc\")) |&gt; \n  cols_align(align = \"right\", columns = 2:6) |&gt;  \n  fmt_number(columns = everything(), decimals = 3) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") |&gt;\n  tab_options(table.font.size = \"80%\") |&gt;\n  tab_footnote(\n    footnote = \"y ~ r\",\n    locations = cells_column_labels(columns = fit_1)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s\",\n    locations = cells_column_labels(columns = fit_2)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + s\",\n    locations = cells_column_labels(columns = fit_1s)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + s\",\n    locations = cells_column_labels(columns = fit_2s)\n    ) |&gt;\n  tab_footnote(\n    footnote = md(\"Should be labelled *conditional (weighted) log-OR*?\"),\n    locations = cells_stub(rows = c(\n      \"weighted log-OR\"))) |&gt;\n  tab_footnote(\n    footnote = md(\"log-OR for R term in model, but interpretation unclear\"),\n    locations = cells_stub(rows = c(\n      \"conditional log-OR (?)\"))\n  )\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrue\nfit_11\nfit_22\nfit_1s3\nfit_2s4\n\n\n\n\nconditional (S = 0) log-OR\n0.246\n\n\n\n\n\n\n0.246\n\n\nconditional (S = 1) log-OR\n0.494\n\n\n\n\n\n\n0.494\n\n\nconditional log-OR (?)5\n\n\n\n\n\n\n0.429\n\n\n\n\nconditional (weighted) log-OR\n\n\n\n\n0.400\n\n\n\n\n\n\nmarginal log-OR\n0.404\n0.404\n0.404\n0.404\n0.404\n\n\nweighted log-OR6\n0.400\n\n\n\n\n\n\n\n\n\n\naverage (weighted) log-OR\n0.420\n\n\n\n\n\n\n0.420\n\n\n\n1 y ~ r\n\n\n2 y ~ r + r:s\n\n\n3 y ~ r + s\n\n\n4 y ~ r + r:s + s\n\n\n5 log-OR for R term in model, but interpretation unclear\n\n\n6 Should be labelled conditional (weighted) log-OR?\n\n\n\n\n\n\n\n\n\nTable 2: Effects\n\n\n\n\nSo in the basic case, as \\(n\\to\\infty\\), these models are all in a sense equivalent, in that they are consistent for the treatment effects of interest.\nMore generally, can just use g-computation rather than analytic expressions\n\n\nCode\nm &lt;- rbind(\n  \"G-comp marginal mean\" =\n    c(avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\")$estimate, NA_real_),\n  \"G-comp marginal mean (adjust s)\" =\n    c(avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")$estimate, NA_real_),\n  \"G-comp average log-odds\" =\n    c(avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\")$estimate, NA_real_),\n  \"G-comp average log-odds (adjust s)\" = \n    c(avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\")$estimate, NA_real_),\n  \"G-comp conditional (S) average log-odds\" =\n    avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\", by = \"s\")$estimate,\n  \"G-comp conditional (S) average log-odds (adjust s)\" =\n    avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\", by = \"s\")$estimate\n)\ncolnames(m) &lt;- c(\"S = 0\", \"S = 1\")\nm\n\n\n                                                        S = 0     S = 1\nG-comp marginal mean                                0.4030520        NA\nG-comp marginal mean (adjust s)                     0.4024538        NA\nG-comp average log-odds                             0.4030520        NA\nG-comp average log-odds (adjust s)                  0.4024538        NA\nG-comp conditional (S) average log-odds            -0.4764725 0.7744050\nG-comp conditional (S) average log-odds (adjust s)  0.2462550 0.4944007\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think that the above are basically making predictions for the comparison of interest at each of the rows in the data set and then averaging to give a marginalised view.\nThe definitional differences between lnoravg and lnor amount to:\nlnor   \\(hi, lo) log((hi/(1 - hi))/(lo/(1 - lo)))\nvs.\nlnoravg    \\(hi, lo) log((mean(hi)/(1 - mean(hi)))/(mean(lo)/(1 - mean(lo)))\nso (I think but need to confirm) one is doing the calculation on every row and then averaging whereas the other averages first.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#covariate",
    "href": "notebooks/design-notes-01.html#covariate",
    "title": "Identification of effects",
    "section": "Covariate",
    "text": "Covariate\nSuppose we introduce a covariate \\(X\\) because it’s predictive of the outcome, e.g. sex. Our model, which does not adjust for \\(S\\), is\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R,S,X] &= \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3X) \\\\\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|R,S,X]|R,X] \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs + \\beta_3X)\\mathbb{P}(S=s|R,X) \\\\\n\\mathbb{E}[Y|R=0,X] &= \\text{expit}(\\beta_0 + \\beta_3X) \\\\\n\\mathbb{E}[Y|R=1,X] &= \\text{expit}(\\beta_0 + \\beta_1 + \\beta_3X)\\mathbb{P}(S=0|R=1,X)  \\\\\n&\\quad \\ + \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3X)\\mathbb{P}(S=1|R=1,X)\n\\end{aligned}\n\\]\nThe conditional (on \\(X\\)) log-odds ratio of marginal success probability for revision versus DAIR depends on the value of \\(X\\) (i.e. is not the same effect for every \\(X=x\\)) and cannot be simplified. It is\n\\[\n\\text{logit}(\\mathbb{E}[Y|R=1,X]) - (\\beta_0 + \\beta_3X).\n\\]\nBy marginalising over type of revision type (which is necessary for the comparison we want), we lose our one number summary. No way to avoid that other than perhaps considering fitting separate models for surgery and duration.\nTo maintain a one-number-summary, again an alternative is to consider the average conditional log-odds\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1|S,X)}{\\text{odds}(Y|R=0|S,X)}\\right] = \\beta_1 + \\beta_2\\mathbb{E}[S].\n\\]\nIf \\(S\\) has an effect, say in truth,\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|S,R,X] &= \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3S + \\beta_4X) \\\\\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|S,R,X]|R,X] \\\\\n&= \\sum_{s=0}^1 \\mathbb{E}[Y|S=s,R,X]\\mathbb{P}(S=s|R,X)\n\\end{aligned}\n\\]\nThen if our model does condition on \\(S\\),\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|R,X,S]|R,X] \\\\\n&= \\sum_{s=0}^1\n\\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs + \\beta_3s+\\beta_4X)\n\\mathbb{P}(S=s|R,X) \\\\\n\\mathbb{E}[Y|R=0,X] &= \\text{expit}(\\beta_0 + \\beta_4X)\\mathbb{P}(S=0|R=0,X) +\n\\text{expit}(\\beta_0 + \\beta_3 + \\beta_4X)\\mathbb{P}(S=1|R=0,X) \\\\\n\\mathbb{E}[Y|R=1,X] &= \\text{expit}(\\beta_0 + \\beta_1 + \\beta_4X)\\mathbb{P}(S=0|R=0,X) +\n\\text{expit}(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3 + \\beta_4X)\\mathbb{P}(S=1|R=0,X) \\\\\n\\ln\\frac{\\text{odds}(Y|R=1,X)}{\\text{odds}(Y|R=0,X)} &= \\text{logit}(\\mathbb{E}[Y|R=1,X]) - \\text{logit}(\\mathbb{E}[Y|R=0,X])\n\\end{aligned}\n\\]\nDue to randomisation, \\(\\mathbb{P}(S=s|R,X) = \\mathbb{P}(S=s|X)\\).\nThe model without adjustment for \\(S\\) assumes\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R,S,X] &= \\text{expit}(\\alpha_0 + \\alpha_1R + \\alpha_2RS + \\alpha_3X) \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3X + \\beta_4s)\\mathbb{P}(S=s|R,X)\n\\end{aligned}\n\\]\n\nExample\n\n\n\n\n\n\nNote\n\n\n\n\n\nBy definition, \\(x\\) has a 25% chance of occurrence in the sample data.\n\n\n\n\n\nGenerate data with covariate\nset.seed(6124)\nD &lt;- generate_data_1(\n  f = function(r, s, x){ -1 + s + x + 0.25 * r + 0.25 * r * s}\n)\nfit1 &lt;- glm(y ~ r + x, data = D, family = binomial())\nfit2 &lt;- glm(y ~ r + r:s + x, data = D, family = binomial())\nfit1s &lt;- glm(y ~ r + s + x, data = D, family = binomial())\nfit2s &lt;- glm(y ~ r + s + r:s + x, data = D, family = binomial())\n\n\nUsing G-computation to marginalise over \\(S\\) and \\(X\\).\n\n\nEffect quantities\ntt &lt;- cbind(\n  qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  NA,\n  qlogis(mean(D[r == 1 & x == 0]$y)) - qlogis(mean(D[r == 0 & x == 0]$y)),\n  qlogis(mean(D[r == 1 & x == 1]$y)) - qlogis(mean(D[r == 0 & x == 1]$y))\n)\nrownames(tt) &lt;- \"True\"\nm1 &lt;- rbind(\n  avg_comparisons(fit1, variables = \"r\", comparison = \"lnoravg\")$estimate,\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\")$estimate,\n  avg_comparisons(fit1s, variables = \"r\", comparison = \"lnoravg\")$estimate,\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")$estimate\n)\nm2 &lt;- rbind(\n  avg_comparisons(fit1, variables = \"r\", comparison = \"lnor\")$estimate,\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\")$estimate,\n  avg_comparisons(fit1s, variables = \"r\", comparison = \"lnor\")$estimate,\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\")$estimate\n)\nm3 &lt;- rbind(\n  avg_comparisons(fit1, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate,\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate,\n  avg_comparisons(fit1s, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate,\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate\n)\nm &lt;- cbind(m1, m2, m3)\ncols &lt;- c(\"Marginal log-odds ratio\", \"Average log-odds ratio\", \"Conditional (X = 0)\", \"Conditional (X = 1)\")\ncolnames(m) &lt;- cols\nrownames(m) &lt;- c(\"fit1\", \"fit2\", \"fit1s\", \"fit2s\")\nround(rbind(tt, m), 3)\n\n\n      Marginal log-odds ratio Average log-odds ratio Conditional (X = 0)\nTrue                    0.376                     NA               0.397\nfit1                    0.377                  0.377               0.391\nfit2                    0.378                  0.378               0.408\nfit1s                   0.378                  0.378               0.393\nfit2s                   0.378                  0.378               0.398\n      Conditional (X = 1)\nTrue                0.367\nfit1                0.391\nfit2                0.334\nfit1s               0.392\nfit2s               0.371\n\n\n\n\nTabulate effect quantities\nd_out &lt;- data.table(t(round(rbind(tt, m), 3)))\nd_out[, desc := cols]\nsetcolorder(d_out, \"desc\")\n\n\n\ngt_tbl &lt;- d_out |&gt; \n  gt(rowname_col = c(\"desc\")) |&gt; \n  cols_align(align = \"right\", columns = 2:6) |&gt;  \n  fmt_number(columns = everything(), decimals = 3) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") |&gt;\n  tab_options(table.font.size = \"80%\") |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + x\",\n    locations = cells_column_labels(columns = fit1)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + x\",\n    locations = cells_column_labels(columns = fit2)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + s + x\",\n    locations = cells_column_labels(columns = fit1s)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + s + x\",\n    locations = cells_column_labels(columns = fit2s)\n    ) \n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrue\nfit11\nfit22\nfit1s3\nfit2s4\n\n\n\n\nMarginal log-odds ratio\n0.376\n0.377\n0.378\n0.378\n0.378\n\n\nAverage log-odds ratio\n\n\n0.377\n0.378\n0.378\n0.378\n\n\nConditional (X = 0)\n0.397\n0.391\n0.408\n0.393\n0.398\n\n\nConditional (X = 1)\n0.367\n0.391\n0.334\n0.392\n0.371\n\n\n\n1 y ~ r + x\n\n\n2 y ~ r + r:s + x\n\n\n3 y ~ r + s + x\n\n\n4 y ~ r + r:s + s + x\n\n\n\n\n\n\n\n\n\nTable 3: G-computation estimates in presence of prognostic covariate",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#unmeasured-confounder",
    "href": "notebooks/design-notes-01.html#unmeasured-confounder",
    "title": "Identification of effects",
    "section": "Unmeasured Confounder",
    "text": "Unmeasured Confounder\nThe above hides some complexity because we assume everything is correctly specified. Suppose we introduce some unmeasured factor which influences which patients are preferred for a given revision type. Consider the following:\n\nR: randomised surgery - 0: DAIR, 1: revision\nS: preferred revision - 0: one-stage, 1: two-stage\nA: allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\nY: treatment success - 0: no, 1: yes\nZ: unmeasured factor, patient attributes/type - continuous\n\nWe assume \\(Z\\) is some immeasurable combination of factors which partly determines a patients risk of failure. We also think that this \\(Z\\) partly determines the surgeons choice of one/two stage. Say patients with higher values of \\(Z\\) are less likely to have successful treatment. However, the surgeon has some knowledge/experience/expertise/intuition which means that they are more likely to prefer a two-stage revision for patients with higher values of \\(Z\\), as they expect those types of patients will have better outcomes under two-stage. The allocated treatment and the underlying patient risk determines the patients outcome, \\(Y\\).\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A\n  Z(Z) --&gt; S & A & Y\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 2: Scenario 2, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\nGiven the randomisation, this does not really change anything, except making explicit that differences between one/two stage may just be due to confounding rather than effect of treatment. We can’t tell which without adjusting for all confounders.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#checkpoint",
    "href": "notebooks/design-notes-01.html#checkpoint",
    "title": "Identification of effects",
    "section": "Checkpoint",
    "text": "Checkpoint\nSo, perhaps the easiest quantity to consider is the average conditional log-odds, i.e.\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S,X,...)}{\\text{odds}(Y|R=0,S,X,...)}\\right] = \\beta_1 + \\beta_2\\mathbb{E}[S].\n\\]\nIs this sufficiently meaningful?\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think what you are saying is to adopt Equation 4 and then report our effect estimate for revision at the sample mean of observed selection, which is this case fully characterises the distribution anyway.\nThe terminology used for effects seems to vary a bit throughout, but my label would probably be more explicit conditional log-OR evaluated at the mean selection or something like that, whereas I think it has been previously referred to as conditional (weighted) log-OR earlier and average (weighted) log-OR earlier, probably because that is how they have been computed.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#duration",
    "href": "notebooks/design-notes-01.html#duration",
    "title": "Identification of effects",
    "section": "Duration",
    "text": "Duration\nDuration, \\(D\\), is randomised, however, the duration options depends upon assignment to revision \\(R\\), and the chosen revision type, \\(S\\). So it is random conditional on \\(R\\) and \\(S\\). Nothing else alters the distribution of \\(D\\). We expect that duration has an effect on the outcome.\nBelow we just use \\(D=0\\) for long and \\(D=1\\) for short, but note that the meaning of these is conditional on \\(R/S\\) (i.e. short for one-stage different to short for two-stage and only applies to revision)\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A & D\n  R --&gt; D\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 3: Scenario 3, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThere might be alternative representations of the above and also the potential for direct and indirect effects of \\(S\\), see below:\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A\n  S --&gt; Y\n  A --&gt; D\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; D\n  S --&gt; D\n  S --&gt; Y\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4\n\nFigure 5\nNow there are two interventions: \\(R\\) which has downstream unknown effects partly due to the unknown revision type, \\(S\\), which is selected, and \\(D\\) which is randomised.\nThe simplest approach is to analyse these separately. First, restrict the analysis to those patients who were assigned to one-stage and have an RCT for duration in embedded in that subset. Then, restrict analysis to only those assigned to two-stage and have an RCT for duration in that subset. However, we would like to have a joint model so that other effects can be shared (other domains/site/surgeon/age/whatever else). In the joint model, duration effect needs to be conditional on revision type.\nSay the true model were something like\n\\[\n\\mathbb{E}[Y|R,S,D] = \\text{expit}(\\beta_0 + \\beta_1S + \\beta_2R + \\beta_3RS + \\beta_4RD + \\beta_5RDS)\n\\tag{7}\\]\nso\n\n\\(\\beta_2\\) is the shift associated with revision and long duration (assuming long-duration is the refrence group)\n\\(\\beta_3\\) the additional shift associated with two-stage long duration,\n\\(\\beta_4\\) the relative shift for short duration given revision,\n\\(\\beta_5\\) the relative shift for short duration given two-stage.\n\nWe might choose to setup the design matrix so that it is orthonormal so that a-priori we don’t assign more uncertainty to a specific revision type. E.g.\n\\[\n\\mathbb{E}[Y|R,S] = \\text{expit}(\\beta_0 + \\beta_1(S - 0.5) + \\beta_2R + \\beta_3R(S-0.5) + \\beta_4R(D-0.5) + \\beta_5R(D-0.5)(S-0.5)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nIs the above missing a \\(D\\) from the conditioning?\n\n\n\nbut for simplicity, not doing this here.\nFrom the above, and with a focus on the surgical domain, we could compare (randomised comparison) any of:\n\nrevision long vs. DAIR\nrevision short vs. DAIR, but no other combinations of revision.\none-stage short + two-stage long vs. DAIR\ntwo-stage short + one-stage long vs. DAIR\n\nWhere (1) and (2) are the likely the most relevant comparisons of interest, but nothing precludes the comparisons stated in (3) and (4). The key point is the explicit statement of the duration type at which the comparison is made, which again is averaged over the empircal distribution of surgical procedure type (one-stage/two-stage).\nHowever, we always needs to marginalise over \\(S\\) (selection/plan):\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R=0] &= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1s)\\mathbb{P}(S=s|R=0) \\\\\n\\mathbb{E}[Y|R=1,D=0] &= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1s + \\beta_2 + \\beta_3s)\\mathbb{P}(S=s|R=1,D=0) \\\\\n\\mathbb{E}[Y|R=1,D=1] &= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1s + \\beta_2 + \\beta_3s + \\beta_4 + \\beta_5s)\\mathbb{P}(S=s|R=1,D=1)\n\\end{aligned}\n\\]\nAgain, can alternatively consider the average conditional log-odds ratio\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S,D)}{\\text{odds}(Y|R=0,S,D)}|D_0,D_1\\right] &= \\beta_2+\\beta_3\\mathbb{E}[S] + \\beta_4D_0 + \\beta_5D_1\\mathbb{E}[S]\n\\end{aligned}\n\\]\nwhere I’ve made it explicit that \\(D_0\\) (one-stage short) and \\(D_1\\) (two-stage short) may differ. However, in practice, these would likely be set to the same level.\nThe default data generating mechanism has the functional form:\n\\[\n\\mathbb{E}[Y|R,S,D] = \\text{expit}(\\beta_0 + \\beta_1X + \\beta_1S + \\beta_2R + \\beta_3RS + \\beta_4RD + \\beta_5RSD)\n\\]\nspecified with non-zero effects on all terms.\n\n\nGenerate duration data\ngenerate_data_2 &lt;- function(\n    n = 1000000,\n    f = function(x, r, s, d){ -1 + x + s + r + 0.5 * r * s - 0.5 * r * d - 0.25 * r * s * d}) {\n  x &lt;- rbinom(n, 1, 0.25)\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  a &lt;- r * (s + 1)\n  d &lt;- as.numeric((a &gt; 0) * rbinom(n, 1, 0.5))\n  y0 &lt;- rbinom(n, 1, plogis(f(x, 0, s, 0)))\n  y10 &lt;- rbinom(n, 1, plogis(f(x, 1, s, 0)))\n  y11 &lt;- rbinom(n, 1, plogis(f(x, 1, s, 1)))\n  y &lt;- (1 - r) * y0 + r * ((1 - d) * y10 + d * y11)\n  D &lt;- data.table(x = x, r = r, s = s, a = a, d = d, y0 = y0, y10 = y10, y11 = y11, y = y)[\n    ,\n    `:=`(\n      a1d1 = as.numeric(a == 1 & d == 1),\n      a2d1 = as.numeric(a == 2 & d == 1),\n      r_fac = factor(r),\n      a_fac = factor(a),\n      s_fac = factor(s),\n      a_cen = r * (a - 1 - mean(a[r == 1] - 1)),\n      s_cen = s - mean(s),\n      s_ort = s - 0.5\n    )\n  ]\n}\nset.seed(1246)\nD &lt;- generate_data_2(f = function(x, r, s, d){ -1 + s + x})\nfit2 &lt;- glm(y ~ x + r + r:s + r:d + r:s:d, data = D, family = binomial())\nfit2s &lt;- glm(y ~ x + s + r + r:s + r:d + r:s:d, data = D, family = binomial())\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nIn the following examples estimation under null effects is considered wherein the true data generation mechanism was \\(\\mathbb{E}[Y|S,X] = \\text{expit}(-1 + S + X)\\). That is, where there are no treatment effects in either the surgical or duration domains.\nThe estimates use G-computation. Specifically, all of the following average over all terms bar the comparison of interest.\n\n\n\n\n\nRevision vs. DAIR\n# Revision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")\n)\n\n\n\n Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %    97.5 %\n -0.00856    0.00410 -2.09   0.0370 4.8 -0.0166 -0.000515\n -0.00836    0.00406 -2.06   0.0396 4.7 -0.0163 -0.000400\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\nRevision (long) vs. DAIR and Revision (short) vs. DAIR\n# Revision (long) vs. DAIR and Revision (short) vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = \"d\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = \"d\", comparison = \"lnoravg\")\n)\n\n\n\n d Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %   97.5 %\n 0 -0.00864    0.00473 -1.83   0.0676 3.9 -0.0179 0.000627\n 1 -0.00832    0.00473 -1.76   0.0785 3.7 -0.0176 0.000949\n 0 -0.00863    0.00469 -1.84   0.0658 3.9 -0.0178 0.000562\n 1 -0.00755    0.00469 -1.61   0.1074 3.2 -0.0167 0.001641\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nConditional on X\n# Conditional on X\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\")\n)\n\n\n\n d x Estimate Std. Error      z Pr(&gt;|z|)    S    2.5 %    97.5 %\n 0 0  0.00267    0.00493  0.541   0.5884  0.8 -0.00700  0.012332\n 0 1 -0.04726    0.00496 -9.525   &lt;0.001 69.0 -0.05699 -0.037538\n 1 0  0.00270    0.00493  0.547   0.5842  0.8 -0.00696  0.012360\n 1 1 -0.04602    0.00496 -9.277   &lt;0.001 65.6 -0.05575 -0.036301\n 0 0 -0.00895    0.00490 -1.829   0.0675  3.9 -0.01855  0.000643\n 0 1 -0.00909    0.00494 -1.841   0.0656  3.9 -0.01878  0.000588\n 1 0 -0.00822    0.00489 -1.680   0.0930  3.4 -0.01782  0.001370\n 1 1 -0.00667    0.00494 -1.350   0.1771  2.5 -0.01635  0.003014\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, d, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nShort vs Long (one-stage) and short vs. long (two-stage)\n# Short vs Long (one-stage) and short vs. long (two-stage)\nrbind(\n  avg_comparisons(fit2, variables = \"d\", by = \"s\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"d\", by = \"s\", comparison = \"lnoravg\")\n)\n\n\n\n s Estimate Std. Error      z Pr(&gt;|z|)   S    2.5 %  97.5 %\n 0  0.00603    0.00491  1.228    0.220 2.2 -0.00359 0.01565\n 1 -0.00174    0.00330 -0.528    0.597 0.7 -0.00821 0.00472\n 0  0.00664    0.00538  1.234    0.217 2.2 -0.00390 0.01718\n 1 -0.00176    0.00333 -0.527    0.598 0.7 -0.00829 0.00478\n\nTerm: d\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, s, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nShort vs long conditional on x\n# Short vs long conditional on x\navg_comparisons(fit2, variables = \"d\", by = c(\"s\", \"x\"), comparison = \"lnoravg\")\n\n\n\n s x Estimate Std. Error      z Pr(&gt;|z|)   S    2.5 %  97.5 %\n 0 0  0.00599    0.00488  1.228    0.220 2.2 -0.00357 0.01555\n 0 1  0.00712    0.00580  1.228    0.220 2.2 -0.00425 0.01850\n 1 0 -0.00184    0.00349 -0.528    0.597 0.7 -0.00868 0.00499\n 1 1 -0.00172    0.00326 -0.528    0.597 0.7 -0.00812 0.00467\n\nTerm: d\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, s, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nAnd now consider estimation under effects for all surgery and duration.\n\n\n\n\n\nData generation assuming effects in both domains\nD &lt;- generate_data_2()\nfit2 &lt;- glm(y ~ x + r + r:s + r:d + r:s:d, data = D, family = binomial())\nfit2s &lt;- glm(y ~ x + s + r + r:s + r:d + r:s:d, data = D, family = binomial())\n\n\n\n\nRevision vs. DAIR\n# Revision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")\n)\n\n\n\n Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n     1.03    0.00427 240   &lt;0.001 Inf  1.02   1.03\n     1.03    0.00423 243   &lt;0.001 Inf  1.02   1.03\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\nRevision (long) vs. DAIR and Revision (short) vs. DAIR\n# Revision (long) vs. DAIR and Revision (short) vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = \"d\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = \"d\", comparison = \"lnoravg\")\n)\n\n\n\n d Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n 0    1.184    0.00518 228   &lt;0.001 Inf 1.174  1.194\n 1    0.607    0.00482 126   &lt;0.001 Inf 0.598  0.617\n 0    1.184    0.00515 230   &lt;0.001 Inf 1.174  1.194\n 1    0.607    0.00478 127   &lt;0.001 Inf 0.598  0.616\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nConditional on X\n# Conditional on X\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\")\n)\n\n\n\n d x Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n 0 0    1.239    0.00532 233   &lt;0.001 Inf 1.228  1.249\n 0 1    1.153    0.00554 208   &lt;0.001 Inf 1.142  1.163\n 1 0    0.645    0.00499 129   &lt;0.001 Inf 0.635  0.655\n 1 1    0.573    0.00510 112   &lt;0.001 Inf 0.563  0.583\n 0 0    1.230    0.00528 233   &lt;0.001 Inf 1.219  1.240\n 0 1    1.191    0.00554 215   &lt;0.001 Inf 1.180  1.202\n 1 0    0.635    0.00495 128   &lt;0.001 Inf 0.625  0.645\n 1 1    0.610    0.00509 120   &lt;0.001 Inf 0.600  0.620\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, d, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nShort vs Long (one-stage) and short vs. long (two-stage)\n# Short vs Long (one-stage) and short vs. long (two-stage)\nrbind(\n  avg_comparisons(fit2, variables = \"d\", by = \"s\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"d\", by = \"s\", comparison = \"lnoravg\")\n)\n\n\n\n s Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 % 97.5 %\n 0   -0.235    0.00504 -46.6   &lt;0.001 Inf -0.245 -0.225\n 1   -0.264    0.00295 -89.7   &lt;0.001 Inf -0.270 -0.258\n 0   -0.242    0.00520 -46.6   &lt;0.001 Inf -0.252 -0.232\n 1   -0.277    0.00309 -89.7   &lt;0.001 Inf -0.283 -0.271\n\nTerm: d\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, s, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nShort vs long conditional on x\n# Short vs long conditional on x\navg_comparisons(fit2, variables = \"d\", by = c(\"s\", \"x\"), comparison = \"lnoravg\")\n\n\n\n s x Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 % 97.5 %\n 0 0   -0.246    0.00527 -46.6   &lt;0.001 Inf -0.256 -0.235\n 0 1   -0.243    0.00523 -46.5   &lt;0.001 Inf -0.253 -0.233\n 1 0   -0.286    0.00319 -89.7   &lt;0.001 Inf -0.292 -0.280\n 1 1   -0.212    0.00241 -87.9   &lt;0.001 Inf -0.217 -0.207\n\nTerm: d\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, s, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#other-domains",
    "href": "notebooks/design-notes-01.html#other-domains",
    "title": "Identification of effects",
    "section": "Other Domains",
    "text": "Other Domains\nThe desire for a single model is incorporation of multiple silos and domains. Suppose we introduce the antibiotic type (rifampicin) domain, which is denoted by \\(F\\). Assume everyone were eligible. Our base model would be\n\\[\n\\mathbb{E}[Y|R,S,D,F] = \\text{expit}(\\beta_0 + \\beta_1S + \\beta_2R + \\beta_3RS + \\beta_4RD + \\beta_5RDS + \\beta_6F)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\n\\(\\beta_2\\) is now the shift for revision (under long duration irrespective of surgical type)\n\n\n\n\n\nGenerate rifampicin data\ngenerate_data_3 &lt;- function(\n    n = 1000000,\n    g = function(x, r, s, d, f){ -1 + x + s + r + 0.5 * r * s - 0.25 * r * d - 0.15 * r * s * d + 0.2 * f}) {\n  x &lt;- rbinom(n, 1, 0.25)\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  f &lt;- rbinom(n, 1, 0.5)\n  a &lt;- r * (s + 1)\n  d &lt;- as.numeric((a &gt; 0) * rbinom(n, 1, 0.5))\n  y &lt;- rbinom(n, 1, plogis(g(x, r, s, d, f)))\n  D &lt;- data.table(x = x, r = r, s = s, a = a, d = d, f = f, y = y)\n}\nset.seed(1246)\nD &lt;- generate_data_3()\nfit2 &lt;- glm(y ~ x + r + f + r:s + r:d + r:s:d, data = D, family = binomial())\nfit2s &lt;- glm(y ~ x + s + r + f + r:s + r:d + r:s:d, data = D, family = binomial())\n\n\n\n\nRevision vs. DAIR\n# Revision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")\n)\n\n\n\n Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n      1.1    0.00441 250   &lt;0.001 Inf   1.1   1.11\n      1.1    0.00437 253   &lt;0.001 Inf   1.1   1.11\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\nRevision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\")\n)\n\n\n\n Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n      1.1    0.00441 250   &lt;0.001 Inf   1.1   1.11\n      1.1    0.00437 253   &lt;0.001 Inf   1.1   1.11\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\nRevision vs. DAIR conditional\n# Revision vs. DAIR conditional\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = c(\"f\", \"x\", \"d\"), comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = c(\"f\", \"x\", \"d\"), comparison = \"lnoravg\")\n)\n\n\n\n f x d Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n 0 0 0    1.245    0.00542 230   &lt;0.001 Inf 1.234  1.256\n 0 0 1    0.945    0.00519 182   &lt;0.001 Inf 0.935  0.955\n 0 1 0    1.159    0.00561 206   &lt;0.001 Inf 1.148  1.170\n 0 1 1    0.861    0.00532 162   &lt;0.001 Inf 0.850  0.871\n 1 0 0    1.225    0.00543 226   &lt;0.001 Inf 1.215  1.236\n 1 0 1    0.926    0.00518 179   &lt;0.001 Inf 0.916  0.936\n 1 1 0    1.145    0.00567 202   &lt;0.001 Inf 1.134  1.156\n 1 1 1    0.852    0.00537 158   &lt;0.001 Inf 0.841  0.862\n 0 0 0    1.232    0.00538 229   &lt;0.001 Inf 1.222  1.243\n 0 0 1    0.931    0.00515 181   &lt;0.001 Inf 0.921  0.941\n 0 1 0    1.192    0.00560 213   &lt;0.001 Inf 1.181  1.203\n 0 1 1    0.896    0.00531 169   &lt;0.001 Inf 0.886  0.907\n 1 0 0    1.221    0.00539 227   &lt;0.001 Inf 1.210  1.231\n 1 0 1    0.922    0.00514 179   &lt;0.001 Inf 0.912  0.932\n 1 1 0    1.188    0.00569 209   &lt;0.001 Inf 1.177  1.200\n 1 1 1    0.894    0.00538 166   &lt;0.001 Inf 0.883  0.905\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, f, x, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nRevision (long) vs. DAIR and Revision (short) vs. DAIR\n# Revision (long) vs. DAIR and Revision (short) vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = \"d\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = \"d\", comparison = \"lnoravg\")\n)\n\n\n\n d Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n 0    1.182    0.00528 224   &lt;0.001 Inf 1.171  1.192\n 1    0.889    0.00502 177   &lt;0.001 Inf 0.879  0.899\n 0    1.182    0.00525 225   &lt;0.001 Inf 1.171  1.192\n 1    0.890    0.00499 178   &lt;0.001 Inf 0.880  0.899\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nRifampicin vs not\n# Rifampicin vs not\nrbind(\n  avg_comparisons(fit2, variables = \"f\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"f\", comparison = \"lnoravg\")\n)\n\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    0.168    0.00387 43.4   &lt;0.001 Inf 0.161  0.176\n    0.168    0.00382 44.0   &lt;0.001 Inf 0.160  0.175\n\nTerm: f\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\nShort vs Long (one-stage) and short vs. long (two-stage)\n# Short vs Long (one-stage) and short vs. long (two-stage)\nrbind(\n  avg_comparisons(fit2, variables = \"d\", by = \"s\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"d\", by = \"s\", comparison = \"lnoravg\")\n)\n\n\n\n s Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 % 97.5 %\n 0   -0.119    0.00505 -23.6   &lt;0.001 406.7 -0.129 -0.109\n 1   -0.121    0.00284 -42.6   &lt;0.001   Inf -0.127 -0.115\n 0   -0.120    0.00508 -23.6   &lt;0.001 407.5 -0.130 -0.110\n 1   -0.129    0.00302 -42.6   &lt;0.001   Inf -0.134 -0.123\n\nTerm: d\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, s, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\n\n\nShort vs long conditional on x\n# Short vs long conditional on x\navg_comparisons(fit2, variables = \"d\", by = c(\"s\", \"x\"), comparison = \"lnoravg\")\n\n\n\n s x Estimate Std. Error     z Pr(&gt;|z|)     S   2.5 %  97.5 %\n 0 0  -0.1250    0.00530 -23.6   &lt;0.001 406.9 -0.1354 -0.1146\n 0 1  -0.1210    0.00513 -23.6   &lt;0.001 406.4 -0.1310 -0.1109\n 1 0  -0.1309    0.00307 -42.6   &lt;0.001   Inf -0.1370 -0.1249\n 1 1  -0.0946    0.00223 -42.4   &lt;0.001   Inf -0.0989 -0.0902\n\nTerm: d\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, s, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#silos",
    "href": "notebooks/design-notes-01.html#silos",
    "title": "Identification of effects",
    "section": "Silos",
    "text": "Silos\nThe above has considered the late-acute silo in isolation. Suppose we also had a chronic silo with the same limitations: randomise to DAIR vs. revision, then revision type is determined by the surgeon/patient, duration is randomised. In the new setting, nothing really changes, we can just introduce silo-specific parameters.\nFor lack of letters, let \\(G\\) denote group (silo). Then\n\\[\n\\mathbb{E}[Y|G=g,R,S,D] = \\text{expit}(\\beta_{0,g} + \\beta_{1,g}R + \\beta_{2,g}S + \\beta_{3,g}RS + \\beta_{4,g}RD + \\beta_{5,g}RSD + \\gamma_g^\\mathsf{T}X)\n\\]\nWe might choose to assume that some of the conditional effects are equal across groups. E.g. \\(\\gamma_g=\\gamma\\) for all \\(g\\). Or \\(\\beta_{4,g} = \\beta_4\\) and \\(\\beta_{5,g}=\\beta_5\\). Depends how realistic we think these assumptions may be and whether we have sufficient data to meaningfully estimate silo-specific effects.\nPerhaps the only new issue is that now \\(\\mathbb{P}(S=s|G=1)\\ne\\mathbb{P}(S=s|G=2)\\), so need to weight things within silo.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe other thing to consider here is that in the early silo, there is no information contributed to parameters characterising the surgical intervention effects. I am not sure that the above model addresses this in that \\(\\beta_{1,g}\\) for \\(g = early\\) would not be defined.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#revision-type",
    "href": "notebooks/design-notes-01.html#revision-type",
    "title": "Identification of effects",
    "section": "Revision Type",
    "text": "Revision Type\nIn all the above I’ve been assuming that the revision type, \\(S\\), is an attribute of the patient. E.g. all surgeons would choose the same \\(S\\) for the same patient. More realistically, \\(S\\) might also partly depend on the surgeon (e.g. say a surgeon would choose \\(S=1\\) for all patients, but another would choose \\(S=0\\) for all patients, now \\(S\\) is conditional on the surgeon rather than the patient). Assume \\(S\\) is an attribute of the patient/surgeon combination rather than either alone. Do we need to change anything? How to interpret “revision effect”? An average effect over patients and surgeons?\nAlready expect that we should at least condition on the site/surgeon, but do we need anything extra to account for \\(S\\)? Distribution of \\(S\\) conditional on surgeon?",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#randomisation-reveal",
    "href": "notebooks/design-notes-01.html#randomisation-reveal",
    "title": "Identification of effects",
    "section": "Randomisation reveal",
    "text": "Randomisation reveal\nA number of simplifying assumptions have been made that result in an incomplete representation of the design. For example, at the start of the discussion on the duration domain, we assumed that duration is randomised, but depends on both \\(R\\) and \\(S\\). However, note:\n\n\\(R\\) presupposes eligibility and reveal for the surgical domain, which is not the general case, e.g. early stage infection silo.\nPatients may enter into the study without having being entered for a randomised comparison in the surgical domain (e.g. patients with early stage infection) in which case the allocated surgery (\\(R_A\\)) would have been determined entirely by clinician selection.\nPatients enter into the duration domain based on the surgical procedure that occurred. This is expected to usually align with the allocated procedure \\(R_A\\), but may deviate from that.\n\\(D\\) is random, conditional solely on \\(R_P\\) rather than both \\(R\\) and \\(S_{R_A}\\) (as stated in the duration section).\n\\(D\\) exists only for \\(R_P \\in \\{\\text{one-stage}, \\text{two-stage}\\}\\) otherwise reveal never occurs and duration allocated \\(D_A\\) is determined by clinician selection\nWhile the duration domain for one-stage and two-stage both contain long (reference) vs short levels for duration of antibiotic, the levels are distinct for each procedure.\n\nTo incorporate some of these ideas, start with the following definitions:\n\n\\(E_R\\) reveal for surgical domain - 0: no, 1: yes\n\\(E_D\\) reveal for duration domain - 0: no, 1: yes\n\\(E_F\\) reveal for choice domain - 0: no, 1: yes\n\\(R\\) randomised surgery - 0: DAIR, 1: revision\n\\(S_R\\) revision type preference (pre-randomisation) - 0: DAIR, 1: one-stage, 2: two-stage\n\\(R_A\\) allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\n\\(R_P\\) performed surgery - 0: DAIR, 1: revision\n\\(S_{R_P}\\) revision type performed (post-randomisation) - 0: one-stage, 1: two-stage\n\\(D\\) randomised duration - 0: long, 1: short\n\\(D_A\\) allocated duration - 0: long, 1: short, 2: other\n\\(S_D\\) selected duration - 0: long, 1: short, 2: other\n\\(F\\) randomised choice - 0: norif, 1: rif\n\\(F_A\\) allocated choice - 0: norif, 1: rif, 2: other\n\\(S_F\\) selected choice - 0: norif, 1: rif, 2: other\n\\(Y\\) treatment success - 0: no, 1: yes\n\nIn practice, we expect the allocated \\(R_A\\) and actual \\(R_P\\) surgical procedure performed will align, but in some cases they may not.\nContrived) example one: revision was randomised and the original surgeon only performs two-stage revision. The original surgeon becomes unavailable to do the procedure and another surgeon (who only performs one-stage revision) takes over the case. The patient enters into the duration domain for comparisons within the setting of one-stage revision.\nContrived) example two: revision was randomised and the surgeon intends to perform a two-stage revision. On the operating table, the surgeon switches to dair, for unknown reasons and the patient will no longer enter into randomised comparisons for the duration domain.\n\\(R_A\\) (allocation) is now determined by additional variables:\n\\[\nR_A = (1-E_R) S_R + E_R R S_R\n\\]\nso that when we have no revealed randomisation for the surgical domain, \\(R_A\\) aligns with the preferred procedure out of all those possible (dair, one-stage, two-stage). When randomisation revealed for the surgical domain, the first term disappears and for \\(R = 0\\), the allocation is dair, irrespective of preferred surgery, whereas when \\(R = 1\\) we get whatever one of one-stage (\\(S_R = 1\\)) or two-stage (\\(S_R = 2\\)) is preferred.\nFor duration allocated \\(D_A\\):\n\\[\nD_A = (1-E_D) S_D + E_D D\n\\]\nwhen no reveal, \\(E_D = 1\\) and \\(D_A = S_D\\) (long/short/other duration) and when revealed, \\(D_A = D\\) (long/short duration).\nFor choice allocated \\(F_A\\):\n\\[\nF_A = (1 - E_F) S_F + E_F F\n\\]\nwhen no reveal, \\(F_A = S_F\\) (norif/rif/other) and when revealed, \\(F_A = F\\) (norif/rif).\n\n\n\n\n\n\nNote\n\n\n\n\n\nAbove, I am assuming that you can randomise someone within a domain without first assessing their eligibility status or knowing anything about them other than they want to enter the platform, which I believe is the intention. Randomisation is only revealed if eligibility is confirmed and this process is independent to the randomisation process.\n\n\n\nThe edited DAG is shown below, which still has a number of simplications relative to the intended approach but is intended to represent a generalised silo and site of infection, implicitly acknowledging that the outcome will be dependent on both these factors. Patients may contribute to some or all domains, which influences the treatment regimen (combination of treatments across the domains) they receive and which suggests the various causal effects that are identifiable.\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  ER(E&lt;sub&gt;R) --&gt; RA(R&lt;sub&gt;A) \n  ER --&gt; SR(S&lt;sub&gt;R)\n  ED(E&lt;sub&gt;D) --&gt; DA(D&lt;sub&gt;A) \n  SR --&gt; RA \n  SD(S&lt;sub&gt;D) --&gt; DA \n  R --&gt; RA\n  RA --&gt; RP(R&lt;sub&gt;P) \n  SRP(S&lt;sub&gt;R&lt;sub&gt;P) --&gt; RP\n  RA --&gt; Y\n  RP --&gt; ED\n  D --&gt; DA(D&lt;sub&gt;A)\n  DA --&gt; Y\n  F --&gt; FA(F&lt;sub&gt;A)\n  EF(E&lt;sub&gt;F) --&gt; FA\n  SF(S&lt;sub&gt;F) --&gt; FA \n  FA --&gt; Y\n  UER((U&lt;sub&gt;E&lt;sub&gt;R)) -.-&gt; ER\n  UED((U&lt;sub&gt;E&lt;sub&gt;D)) -.-&gt; ED\n  UEF((U&lt;sub&gt;E&lt;sub&gt;F)) -.-&gt; EF\n  UF((U&lt;sub&gt;F)) -.-&gt; F\n  URP((U&lt;sub&gt;R&lt;sub&gt;P)) -.-&gt; SRP\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  USR((U&lt;sub&gt;S&lt;sub&gt;R)) -.-&gt; SR\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  USD((U&lt;sub&gt;S&lt;sub&gt;D)) -.-&gt; SD\n  USF((U&lt;sub&gt;S&lt;sub&gt;F)) -.-&gt; SF\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 6: Scenario 4, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThere is potentially a direct as well as the indirect effect of both \\(S_R\\) on \\(Y\\) and \\(S_{R_P}\\) on \\(Y\\) but these have been left out of the DAG for now. \\(S_R\\) is actually representing multiple ideas:\n\nwhen the surgical domain is not applicable (randomisation never revealed) e.g. for the chronic patients, then \\(S_R\\) is the selection from dair, one-stage, two-stage\nwhen surgical domain is applicable (randomisation is revealed) then \\(S_R\\) is the option between one-stage and two-stage that is most prefered.\n\nIn essence, \\(S_R\\) involves a conditional ranking of which surgical procedure is prefered.\nFor example, say the selection is: dair, two-stage, one-stage in order of preference. If randomisation is not reveal, dair is would be the selection. If randomisation is revealed, two-stage would be as it is the most prefered surgical procedure applicable to revision.\nOriginally, \\(D\\) was said to depend on some of the selection elements. However, subsequently it was decided that \\(D\\) (long/short) should be viewed like all other randomisation processes, i.e. independent of all other nodes, but is only manifest through \\(D_A\\) for certain surgery types.\n\n\n\nAgain consider intervening on surgical procedure whereby we are interested in the effect of dair vs revision on treatment success. There are no open backdoor paths apparent and therefore no adjustment is required to identify the total effect of \\(R\\) on \\(Y\\). Similarly, neither \\(D\\) nor \\(F\\) have backdoor paths.\nPostulate the following model:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|L; \\beta] &=  \\text{expit}( \\beta_0 + \\\\\n  &\\quad \\beta_1 \\mathbb{I}[G = 1] + \\beta_2 \\mathbb{I}[G = 2] + \\beta_3 J + \\\\\n  &\\quad \\beta_4 J \\mathbb{I}[G = 1] + \\beta_5 J \\mathbb{I}[G = 2] + \\\\\n  &\\quad \\beta_6 \\mathbb{I}(1-E_R) + ([\\beta_7 R + \\beta_8 R \\mathbb{I}(S_{R_P} = 2) ])\\mathbb{I}(E_R) + \\\\\n  &\\quad \\beta_9 \\mathbb{I}(1-E_D) + ([\\beta_{10} R_P D + \\beta_{11} R_P D \\mathbb{I}(S_{R_P} = 2)])\\mathbb{I}(E_D) + \\\\\n  &\\quad \\beta_{12} \\mathbb{I}(1-E_F) + \\beta_{13} F E_F )\n\\end{aligned}\n\\]\nwhere the \\(L\\) stands for the set of model variables and \\(\\beta\\) the vector of parameters. The following describe the reference/movements in the log-odds of treatment success:\n\n\\(\\beta_{0}\\) baseline log-odds of treatment success in the early silo / knee site\n\\(\\beta_{1}\\) shift for late-silo membership relative to early\n\\(\\beta_{2}\\) shift for chronic-silo membership relative to early\n\\(\\beta_{3}\\) shift for hip\n\\(\\beta_{4}\\) relative shift for late-silo membership with hip\n\\(\\beta_{5}\\) relative shift for chronic-silo membership with hip\n\\(\\beta_{6}\\) shift under non-reveal (surgery1)\n\\(\\beta_{7}\\) shift under revision that was performed with one-stage procedure for long duration and no-rif\n\\(\\beta_{8}\\) relative shift under revision that was performed with two-stage procedure for long duration and no-rif\n\\(\\beta_{9}\\) shift under non-reveal (duration) with no differentiation for surgical nor duration preference\n\\(\\beta_{10}\\) shift for short duration when one-stage was actually performed\n\\(\\beta_{11}\\) shift for short duration when two-stage was actually performed\n\\(\\beta_{12}\\) shift under non-reveal (choice) with no differentiation for choice preference\n\\(\\beta_{13}\\) shift for rif\n\nWith the complicating factor being that the surgical allocation may inform the type of surgery that the patient gets (but may deviate) and the randomisation that the patient is revealed to in the duration domain is determined by what surgical intervention the patient actually got.\nWe replace pre-randomised preference for surgical type with post-randomised surgical type performed and marginalise out this term.\n\n\n\n\n\n\nNote\n\n\n\n\n\nFull disclosure, I am not entirely sure as to whether the above addresses the full impacts of deviations between allocated and performed surgery or whether the DAG is sufficiently complete representation of the dependencies.\n\n\n\nAs previously, for the surgical domain, we are interested the effect of intervening on \\(R\\). For the duration domain, we are interested in the effect of intervening on \\(D|R_P\\). For the choice domain, we are interested in the effect of intervening on \\(F\\).\n\n\n\n\n\n\nNote\n\n\n\n\n\nNote that for the following specification, the design matrix can become singular (linear dependence between some of the variables) e.g. if surgical reveal is equivalent to silo membership. I am assuming some small amount of noise in reveal such that this isn’t a problem.\n\n\n\n\n\nGenerate complete data\ngenerate_data_4 &lt;- function(\n    n = 1e6,\n    g = function(p_a, l1, l2, j, er, ed, ef, r, rp, d, srp, f){ \n      -1 + -0.04 * l1 - 0.07 * l2 - 0.02 * j - 0.01 * l1 * j - 0.06 * l2 * j +\n        -0.1*(1-er) + (0.2*r + 0.4*r*(srp==2))*(er) +\n        -0.05*(1-ed) + (0.4*rp*d + 0.1*rp*d*(srp==2))*(ed) +\n        -0.25*(1-ef) + 0.15*f*(ef) \n      }\n    ) {\n  \n  p_a = array(\n    c(0.65, 0.55, 0.6, 0.75, 0.6, 0.65),\n    dim = c(3, 2), dimnames = list(c(\"early\", \"late\", \"chronic\"),c(\"knee\", \"hip\")))\n  \n  # silo (l) and joint (j)\n  l &lt;- sample(0:2, n, replace = T, prob = c(0.3, 0.5, 0.2)) \n  l1 = as.numeric(l == 1)\n  l2 = as.numeric(l == 2)\n  \n  p_j &lt;- array(c(0.4,0.7,0.5,0.6,0.3,0.5), dim = c(3, 2), \n               dimnames = list(c(\"early\", \"late\", \"chronic\"), c(\"knee\", \"hip\")))\n  j &lt;- rbinom(n, 1, p_j[l+1, 2])\n  # reveal for late only, with a small number who never get revealed even if they\n  # were in late. you can leave this out but the model spec will need to be updated\n  # because there will be linearly depenedent cols in the design matrix\n  er &lt;- as.numeric(l == 1)\n  er[l==1][as.logical(rbinom(er[l==1], 1, 0.05))] &lt;- 0\n  # randomise dair vs rev\n  r &lt;- rbinom(n, 1, 0.5)\n  # (approx) 70% chance of clinician choosing two-stage if pt is rand to revision \n  sr &lt;- numeric(n)\n  sr[r == 0] &lt;- sample(0:2, sum(r == 0), replace = T, prob = c(0.2, 0.2, 0.6))\n  sr[r == 1] &lt;- sample(1:2, sum(r == 1), replace = T, prob = c(0.3, 0.7))\n  # pref towards two-stage, assuming revision\n  sra &lt;- as.numeric(sr == 2)\n  # determine allocation of surgery type\n  ra &lt;- er * sr + (1-er) * r * (sr) \n  \n  # 10% of the allocated treatments may have switch to a different surg type\n  srp &lt;- ra\n  ic &lt;- rbinom(n, 1, 0.1)\n  srp[as.logical(ic)] &lt;- sample(0:2, sum(ic), replace = T, prob = c(0.2, 0.2, 0.6))\n  # was the procedure type dair or revision?\n  rp &lt;- as.numeric(srp %in% 1:2)\n  \n  # non-reveal of duration if rp is dair (0)\n  ed &lt;- as.numeric(rp == 1)\n  # rand to long (0), short (1) based on surgery received\n  d &lt;- as.numeric((rp &gt; 0) * rbinom(n, 1, 0.5))\n  # 60% reveal ab choice\n  ef &lt;- rbinom(n, 1, 0.6)\n  f &lt;- as.numeric((ef == 1) * rbinom(n, 1, 0.5))\n  \n  y &lt;- rbinom(n, 1, plogis(g(p_a, l1, l2, j, er, ed, ef, r, rp, d, srp, f)))\n  # table(y, useNA = \"always\")\n  \n  D &lt;- data.table(\n    l1, l2, j, \n    er, ed, ef,\n    erx = 1-er, edx = 1-ed, efx=1-ef,\n    r, sr, sra, ra, \n    ic, rp, srp, srp2 = as.numeric(srp == 2), d,\n    f, y\n  )\n}\nset.seed(102)\nD &lt;- generate_data_4()\n\n# early silo, should be non-reveal with no r options (default to 0)\n# D[, .N, keyby = .(l, j, er, r)]\n# those who received rev are revealed for d (ed = 0) and are 0:1 conditional on revision type (srp)\n# D[, .N, keyby = .(rp, ed, srp, d)]\n# those entering ab choice should come from all strata, infec site\n# D[ef == 0, .N, keyby = .(l, j, f)]\n# those that dont should also be dist across sample\n# D[ef == 1, .N, keyby = .(l, j, f)]\n\nfit2 &lt;- glm(y ~ l1 + l2 + j + l1:j + l2:j +\n              erx + er:r + er:r:srp2 +\n              edx + ed:rp:d + ed:d:rp:srp2 +\n              efx + ef:f, \n            data = D, family = binomial())\nsummary(fit2)\n\n\n\nCall:\nglm(formula = y ~ l1 + l2 + j + l1:j + l2:j + erx + er:r + er:r:srp2 + \n    edx + ed:rp:d + ed:d:rp:srp2 + efx + ef:f, family = binomial(), \n    data = D)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.992730   0.017361 -57.182  &lt; 2e-16 ***\nl1           -0.036997   0.016251  -2.277  0.02281 *  \nl2           -0.081398   0.009886  -8.234  &lt; 2e-16 ***\nj            -0.028103   0.008548  -3.288  0.00101 ** \nerx          -0.101703   0.015480  -6.570 5.04e-11 ***\nedx          -0.045398   0.006282  -7.227 4.94e-13 ***\nefx          -0.251435   0.005446 -46.167  &lt; 2e-16 ***\nl1:j         -0.022724   0.010840  -2.096  0.03605 *  \nl2:j         -0.052919   0.013561  -3.902 9.53e-05 ***\ner:r          0.187560   0.009727  19.283  &lt; 2e-16 ***\nef:f          0.147332   0.005624  26.198  &lt; 2e-16 ***\ner:r:srp2     0.407762   0.010375  39.302  &lt; 2e-16 ***\ned:rp:d       0.414709   0.008222  50.439  &lt; 2e-16 ***\nsrp2:ed:rp:d  0.085740   0.008749   9.800  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1216852  on 999999  degrees of freedom\nResidual deviance: 1179406  on 999986  degrees of freedom\nAIC: 1179434\n\nNumber of Fisher Scoring iterations: 4\n\n\nGenerate complete data\n# linearly_dep_cols(fit2)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nUsing g-computation to determine the marginal effects. lnor and lnoravg are used as the comparisons.\nThe first (lnor) approach (average log odds?)\n\npredicts the log-odds of treatment success for all units with the surgical approach set to revision.\npredicts the log-odds of treatment success for all units with the surgical approach set to dair.\ncomputes the difference between the response on the log odds scale and takes the mean\n\nAlso can be derived from a weigted combination of the parameters from the regression model. What is an accurate interpretation of this parameter? How would you explain it to a non-statistician?\nThe second (lnoravg) approach (marginal mean?)\n\npredicts the probability of treatment success for all units with the surgical approach set to revision and computes the mean\npredicts the probability of treatment success for all units with the surgical approach set to dair and computes the mean\nconverts the mean probability of treatment success to the log-odds scale and takes the difference\n\n\n\n\n\n\nCode\n# Revision vs. DAIR\ncmp &lt;- avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\")\n\n# avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\", by = \"er\")\n\nd_new &lt;- copy(D)\n\n# equivalent to using lnor\nd_new[, `:=`(r = 1)]\nlo1 &lt;- predict(fit2, newdata = d_new)\nd_new[, `:=`(r = 0)]\nlo0 &lt;- predict(fit2, newdata = d_new)\n\n# in this setting is equivalent to weighted combination of parameters\nb &lt;- coef(fit2)\n\nw_srp &lt;- D[er == 1, mean(srp2)]\nw_er &lt;- D[, mean(er)]\n\nrbind(\n  \"predict at r = 0/1\" = mean(lo1 - lo0),\n  \"weighting coef by er and srp (condit on reveal)\" = w_er * b[\"er:r\"] + w_er * w_srp * b[\"er:r:srp2\"] , \n  \"avg_comparisons (lnor)\" = cmp$estimate\n)\n\n\n                                                     er:r\npredict at r = 0/1                              0.2136018\nweighting coef by er and srp (condit on reveal) 0.2136018\navg_comparisons (lnor)                          0.2292898\n\n\nCode\ncmp\n\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    0.229    0.00314 73.1   &lt;0.001 Inf 0.223  0.235\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\n\n\nCode\n# using lnoravg\navg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\")\n\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    0.229    0.00314 73.1   &lt;0.001 Inf 0.223  0.235\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\nCode\nd_new[, r := 1]\np1 &lt;- predict(fit2, newdata = d_new, type = \"response\")\nd_new[, r := 0]\np0 &lt;- predict(fit2, newdata = d_new, type = \"response\")\nqlogis(mean(p1)) - qlogis(mean(p0))\n\n\n[1] 0.2292898\n\n\nAnd for duration and choice.\n\n\nCode\n# Short vs Long (one-stage) and short vs. long (two-stage)\navg_comparisons(fit2, variables = \"d\", by = \"srp2\", comparison = \"lnoravg\")\n\n\n\n srp2 Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    0    0.179    0.00361 49.8   &lt;0.001 Inf 0.172  0.187\n    1    0.486    0.00558 87.1   &lt;0.001 Inf 0.475  0.497\n\nTerm: d\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, srp2, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\nCode\n# Rifampicin vs not\navg_comparisons(fit2, variables = \"f\", comparison = \"lnoravg\")\n\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S  2.5 % 97.5 %\n   0.0894    0.00341 26.2   &lt;0.001 500.7 0.0827  0.096\n\nTerm: f\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#footnotes",
    "href": "notebooks/design-notes-01.html#footnotes",
    "title": "Identification of effects",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe parameter ignores potential differentiation for surgical type.↩︎",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-03.html",
    "href": "notebooks/design-notes-03.html",
    "title": "Design discussion (part 2)",
    "section": "",
    "text": "The DATIPO study investigated non-inferiority of 6 weeks vs 12 weeks in PJI patients. The primary outcome was persistent infection within 2 years after the completion of antibiotic therapy. Surgery type was not randomised, but most events occurred in patients who received DAIR.\nJust from a cursory read, if this were the only information I had available to me (and the only thing I cared about was “persistent infection at 2 years”), I would be wanting 12 weeks of AB duration not 6 weeks, irrespective of the type of surgery I was getting or the affected joint. Given how few events occurred in anyone who received one-stage, and assuming there is some level of homogeneity over surgery types, I wouldn’t have a different opinion for the one-stage group in particular. But this wouldn’t be a very strong belief given the small number of events in the trial overall. It would more so be a default simplification in the absence of any other information or experience, just this trial in isolation.\nIn the AB duration DSA they write:\n\nThis demonstrated that shorter course therapy was not non-inferior (I’d say that it “showed” it was inferior, not just not non-inferior) to longer course therapy. Interestingly this finding was consistent amongst patients treated with Debridement, antibiotics and implant retention (DAIR) and 2-stage revision. However, for single stage revisions, there was no meaningful difference between the 6 weeks and 12 weeks of antibiotics on the outcome of treatment success, though the study was underpowered for subgroup analyses (n=150 for one-stage revisions)… a larger trial is needed to confirm the findings in DATIPO that 6 weeks is non-inferior to 12 weeks in terms of treatment success.\n\nSo, it seems the opinion is that 6 weeks is (not non-)inferior to 12 weeks for DAIR and two-stage, but is possibly non-inferior (but perhaps not better) for one-stage. I don’t think the paper provides sufficient reason to think that the duration effect would differ by surgery type (but also not that it wouldn’t), but perhaps there are other justifications for why it might. If not willing to assume homogeneity of effect, to properly inform the duration decision in all surgery groups, you would probably want to assign 6/12 in all groups.\nBut generally, I can see where they are coming from, I see the difficulty in willingly assigning DAIR patients to 6 weeks over 12 weeks despite the uncertainties. The one-stage group is the less informed one, but if I were a patient who was to get a one-stage revision, I would want 12 weeks not 6 weeks if all I had was the information from that trial. They don’t mention any other studies, have you seen any others looking at the same kind of question?\n\n\nCode\nlibrary(dplyr)\nlibrary(marginaleffects)\n\ndat &lt;- tribble(\n  ~ type, ~ x, ~ n, ~ y,\n  \"DAIR\", 0, 76, 11,\n  \"DAIR\", 1, 75, 23,\n  \"Two\", 0, 41, 2,\n  \"Two\", 1, 40, 6,\n  \"One\", 0, 71, 2,\n  \"One\", 1, 75, 3\n)\n\nfit1 &lt;- glm(cbind(y, n - y) ~ type * x, data = dat, family = binomial())\nfit2 &lt;- glm(cbind(y, n - y) ~ type + x, data = dat, family = binomial())\n\n\n\n\nCode\nprint(avg_comparisons(fit1, variables = \"x\", by = \"type\"), digits = 1)\n\n\n\n type Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n DAIR     0.16       0.07 2.4     0.02 6.0  0.03   0.29\n One      0.01       0.03 0.4     0.69 0.5 -0.05   0.07\n Two      0.10       0.07 1.5     0.12 3.0 -0.03   0.23\n\nTerm: x\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, type, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\nCode\nprint(comparisons(fit1, variables = \"x\", by = \"type\", comparison = \"lnor\"), digits = 2)\n\n\n\n type Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n DAIR     0.96       0.41 2.34    0.019 5.7  0.16    1.8\n One      0.36       0.93 0.39    0.696 0.5 -1.46    2.2\n Two      1.24       0.85 1.45    0.146 2.8 -0.43    2.9\n\nTerm: x\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, type, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\nCode\nprint(comparisons(fit1, variables = \"x\", by = \"type\", comparison = \"lnor\", hypothesis = \"revpairwise\"), digits = 2)\n\n\n\n       Term Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n One - DAIR    -0.60       1.02 -0.59     0.56 0.8  -2.6    1.4\n Two - DAIR     0.28       0.94  0.29     0.77 0.4  -1.6    2.1\n Two - One      0.87       1.26  0.69     0.49 1.0  -1.6    3.3\n\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\nCode\nanova(fit1, fit2)\n\n\nAnalysis of Deviance Table\n\nModel 1: cbind(y, n - y) ~ type * x\nModel 2: cbind(y, n - y) ~ type + x\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1         0    0.00000                     \n2         2    0.49699 -2 -0.49699     0.78\n\n\nCode\nAIC(fit1, fit2)\n\n\n     df      AIC\nfit1  6 32.30613\nfit2  4 28.80312\n\n\nThe differences in differences of log-odds are very uncertain as expected given the small numbers available in the subgroups:\nStandard model choice metrics would prefer the model in which the effect of duration is assumed constant across surgery types, and so has 6 weeks inferior to 12 weeks irrespective of surgery type.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 2)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-03.html#notes-on-bernard-2021",
    "href": "notebooks/design-notes-03.html#notes-on-bernard-2021",
    "title": "Design discussion (part 2)",
    "section": "",
    "text": "The DATIPO study investigated non-inferiority of 6 weeks vs 12 weeks in PJI patients. The primary outcome was persistent infection within 2 years after the completion of antibiotic therapy. Surgery type was not randomised, but most events occurred in patients who received DAIR.\nJust from a cursory read, if this were the only information I had available to me (and the only thing I cared about was “persistent infection at 2 years”), I would be wanting 12 weeks of AB duration not 6 weeks, irrespective of the type of surgery I was getting or the affected joint. Given how few events occurred in anyone who received one-stage, and assuming there is some level of homogeneity over surgery types, I wouldn’t have a different opinion for the one-stage group in particular. But this wouldn’t be a very strong belief given the small number of events in the trial overall. It would more so be a default simplification in the absence of any other information or experience, just this trial in isolation.\nIn the AB duration DSA they write:\n\nThis demonstrated that shorter course therapy was not non-inferior (I’d say that it “showed” it was inferior, not just not non-inferior) to longer course therapy. Interestingly this finding was consistent amongst patients treated with Debridement, antibiotics and implant retention (DAIR) and 2-stage revision. However, for single stage revisions, there was no meaningful difference between the 6 weeks and 12 weeks of antibiotics on the outcome of treatment success, though the study was underpowered for subgroup analyses (n=150 for one-stage revisions)… a larger trial is needed to confirm the findings in DATIPO that 6 weeks is non-inferior to 12 weeks in terms of treatment success.\n\nSo, it seems the opinion is that 6 weeks is (not non-)inferior to 12 weeks for DAIR and two-stage, but is possibly non-inferior (but perhaps not better) for one-stage. I don’t think the paper provides sufficient reason to think that the duration effect would differ by surgery type (but also not that it wouldn’t), but perhaps there are other justifications for why it might. If not willing to assume homogeneity of effect, to properly inform the duration decision in all surgery groups, you would probably want to assign 6/12 in all groups.\nBut generally, I can see where they are coming from, I see the difficulty in willingly assigning DAIR patients to 6 weeks over 12 weeks despite the uncertainties. The one-stage group is the less informed one, but if I were a patient who was to get a one-stage revision, I would want 12 weeks not 6 weeks if all I had was the information from that trial. They don’t mention any other studies, have you seen any others looking at the same kind of question?\n\n\nCode\nlibrary(dplyr)\nlibrary(marginaleffects)\n\ndat &lt;- tribble(\n  ~ type, ~ x, ~ n, ~ y,\n  \"DAIR\", 0, 76, 11,\n  \"DAIR\", 1, 75, 23,\n  \"Two\", 0, 41, 2,\n  \"Two\", 1, 40, 6,\n  \"One\", 0, 71, 2,\n  \"One\", 1, 75, 3\n)\n\nfit1 &lt;- glm(cbind(y, n - y) ~ type * x, data = dat, family = binomial())\nfit2 &lt;- glm(cbind(y, n - y) ~ type + x, data = dat, family = binomial())\n\n\n\n\nCode\nprint(avg_comparisons(fit1, variables = \"x\", by = \"type\"), digits = 1)\n\n\n\n type Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n DAIR     0.16       0.07 2.4     0.02 6.0  0.03   0.29\n One      0.01       0.03 0.4     0.69 0.5 -0.05   0.07\n Two      0.10       0.07 1.5     0.12 3.0 -0.03   0.23\n\nTerm: x\nType:  response \nComparison: mean(1) - mean(0)\nColumns: term, contrast, type, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n\nCode\nprint(comparisons(fit1, variables = \"x\", by = \"type\", comparison = \"lnor\"), digits = 2)\n\n\n\n type Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n DAIR     0.96       0.41 2.34    0.019 5.7  0.16    1.8\n One      0.36       0.93 0.39    0.696 0.5 -1.46    2.2\n Two      1.24       0.85 1.45    0.146 2.8 -0.43    2.9\n\nTerm: x\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, type, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\nCode\nprint(comparisons(fit1, variables = \"x\", by = \"type\", comparison = \"lnor\", hypothesis = \"revpairwise\"), digits = 2)\n\n\n\n       Term Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n One - DAIR    -0.60       1.02 -0.59     0.56 0.8  -2.6    1.4\n Two - DAIR     0.28       0.94  0.29     0.77 0.4  -1.6    2.1\n Two - One      0.87       1.26  0.69     0.49 1.0  -1.6    3.3\n\nType:  response \nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\n\nCode\nanova(fit1, fit2)\n\n\nAnalysis of Deviance Table\n\nModel 1: cbind(y, n - y) ~ type * x\nModel 2: cbind(y, n - y) ~ type + x\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1         0    0.00000                     \n2         2    0.49699 -2 -0.49699     0.78\n\n\nCode\nAIC(fit1, fit2)\n\n\n     df      AIC\nfit1  6 32.30613\nfit2  4 28.80312\n\n\nThe differences in differences of log-odds are very uncertain as expected given the small numbers available in the subgroups:\nStandard model choice metrics would prefer the model in which the effect of duration is assumed constant across surgery types, and so has 6 weeks inferior to 12 weeks irrespective of surgery type.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 2)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-03.html#ramble",
    "href": "notebooks/design-notes-03.html#ramble",
    "title": "Design discussion (part 2)",
    "section": "Ramble",
    "text": "Ramble\nMaybe going too in depth, but I think one issue we are having is getting across the difference between what is being compared and what is being assumed in the model. Depending on the model assumptions, some of the strategies might be assumed to be equal anyway and there might only be one decision/comparison in that sense. But it’s helpful to keep separate the model assumptions from the comparisons we are trying to make. When we say “revision vs DAIR”, that only defines a comparison if we think all revisions have equal effect or we are happy to completely ignore any varying effects. But that’s not what we believe (if we did, why would we bother looking at different A/B durations following revision?). As soon as we think A/B duration has a varying effect that we want to estimate, there is no “revision vs DAIR” there is only “revision + duration vs DAIR + duration”. But we are only assigning people to “revision + duration”, for DAIR, there is just one version “DAIR” with duration unspecified (but presumably 12 weeks). So long as duration is constant across revision and DAIR (at least the first-stage of revision), they think that the effect of “revision vs DAIR” will be the same. So, for them, we only need to compare one version of revision to DAIR (the one with 12-weeks duration following first-stage of revision).\nIn terms of the model, this is how I think about it…\nIf I recall correctly, they think that ~ 70% participants will probably refuse or be ineligible for participation in the duration domain. So, just thinking about the late-acute silo, ignoring everything else: amongst those who do not (or cannot) participate in duration, we have a comparison of some version of “DAIR vs revision” which we think is DAIR + 12 weeks, or revision with first-stage followed by 12 weeks and second-stage (if two-stage) followed by some short duration. This might include ~ 70% of late acute participants. Amongst those who do participate in duration, we have a comparison of some version of “DAIR vs revision + specified duration” where again, we think DAIR is with 12 weeks A/B duration, but is technically unspecified. This might be ~ 30%.\nAt the one extreme, we could just assume duration has no effect whatsoever, then we would obtain an effect of revision in those who do and those who do not participate in the duration domain. Say we might have a model assuming things are just additive on the log-odds.\nlog-odds(y) = (b0 + b1 * r) + (a0 + a1 * r) * p, where p just denotes participation in the duration domain, and r assignment to revision.\nWe’d have an effect of “DAIR vs. revision” amongst those who participate in duration assignment, b1, and one amongst those who do not, a1. We could choose to assume (model) b1 = a1, in which case there’s really just one effect of “DAIR vs. revision” which we think applies to everyone, or we could assume the effects might be different and consider both b1 and a1 as effects of “DAIR vs revision” in two different populations. If being Bayesian we could also do something in between, where b1 - a1 ~ Normal(0, s^2) for some small s. In this case, b1 ~= a1 unless we see some extreme difference, so a decision in one group would probably imply the same decision in the other. But irrespective of whether we assume a1 = b1 or not, we are making two comparisons/decisions: one for those who participate in A/B duration and one for those who do not.\nJust in the context of this model, there are then two in-trial decisions we might want to make: is b1 &gt; 0 and is a1 &gt; 0. If b1 &gt; 0, then for those who cannot participate in duration domain, we think revision is better, and might drop DAIR for that group. If a1 &gt; 0, then for those who can participate in duration domain, we think revision is better, and might drop DAIR for that group. If we assume in the model that a1 = b1, then we would drop DAIR or revision in both groups (duration participants and non-participants) at the same time. If we think a1 ~= b1, we will probably drop DAIR or revision in both groups or neither group but unlikely to make opposite decisions in groups. If we think |a1 - b1| could be large, then we might make different decisions in each group. But generally, sounds like we probably think |a1 - b1| is small, so we would expect to make the same decision for both groups. But the only way to certainly make the same decision (in the context of the model) in both groups is if we enforce a1 = b1. Sounds to me as though they would think a1 = b1.\nWe could also think of all the above as\n(b0 + b1 * E[r1|p=0] + b2 * E[r2|p=0]) + (a0 + a1 * E[r1|p=1] + a2 * E[r2|p=1]) * p\nwhere r1 is one-stage and r2 is two-stage, but we don’t really care about any of these selection differences for the comparison we are making.\n\nThe above ignores duration altogether. Alternatively, we think duration has some effect that we want to estimate, and we don’t want to ignore it altogether. To get to the heart of it, say that everyone who is assigned to revision gets a one-stage revision. Also, suppose that we did vary duration for both DAIR and revision participants. So for those who participate in duration domain, our model might be\na0 + a1r1 + a2d1 + a3r1d1\nwhere r1 = 1 if one-stage revision, and d1 = 1 if 6 weeks duration. r1 = 0 if DAIR and d1 = 0 if 12-weeks duration. In their mind, they already “know” that a2 = a3. So, revision + 12w vs DAIR + 12w effect is a1, and equivalently, revision + 6w vs DAIR + 6w effect is also a1 (because a3 - a2 = 0). Given they “know” a2 = a3, we are not assigning anyone to DAIR + 6w duration, instead we are only assigning DAIR + 12w, one-stage + 12w, one-stage + 6w. So our model is just a0 + a1r1 + a3r1*d1. Only two comparisons are of interest: DAIR + 12w vs one-stage + 12w (a1) and one-stage + 12w vs one-stage + 6w (a3). We don’t care about DAIR + 12w vs one-stage + 6w because we think if we shortened the DAIR duration to 6w this would be equivalent to DAIR + 12w vs one-stage + 12w.\nOf course, not all revisions are one-stage, so we have to allow for varying revision types given duration depends on revision type. We need to use the more general model (amongst those who choose to participate):\n(b0 + b1 * r) + (a0 + Er1|p=1 + E[r2|p=1] * (a2 + a4 * d2) * p\nwhere, say, d1 indicates 6 weeks after one-stage and d2 indicates short duration after two-stage. The reference is assumed to be the 12 week option for both revision types. But again, it now sounds to me like we only care about one-stage + 12w, two-stage + short vs DAIR, we aren’t interested in comparing one-stage + 6w, two-stage + whatever vs DAIR, because they believe if they also shortened A/B following DAIR the effect would be the same. There is still a question of the effect in participants and non-participants. Seems like we might think that b1 ~= Er1 + E[r2] * (a2), so if make a decision for one group, would happily apply that to both groups (A/B duration participants and non-participants). But more formally, could encode that in prior.\nBig picture we are still comparing a bunch of different strategies, it’s just in their model they choose to assume they all have the same equal effect so choosing one type of “revision” as better than DAIR implies choosing all types of revision are better than DAIR in all groups. Because of this, as noted above, it sounds to me like when we are considering “revision vs DAIR” they really only care about the version of revision where “one-stage with 12 weeks A/B duration or two-stage with first-stage 12 A/B weeks and second-stage short duration (&lt;24 hours)”. So that may be the only comparison we bother to make. To them, that effect would be the same as long as A/B duration following DAIR was equal to A/B duration following first-stage.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 2)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html",
    "href": "notebooks/design-notes-05.html",
    "title": "Marginal-ish effects",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nThe following DAG includes surgical, antibiotic backbone, extended prophylactic and choice domains. Additionally, site of infection (knee/hip) and baseline clinician preferences are included where the latter are assumed to take primacy in selection of surgery type etc. The setup is intended to represent the approximate structure, not to replicate the exact data generating process.\nPreference for surgery primarily impacts those assigned to revision but would also be applicable for a patient that ends up switching treatment, for example switch from dair to revision due to a irreparable loose joint. Preference for antibiotic duration comes into play for dair and two-stage patients since these units are never randomly assigned to duration. For example, if a unit received dair, then the preference would lead to some duration of backbone antibiotic therapy. Analogously, preference for extended prophylactic applies where the unit didn’t enter the extended prophylaxis domain even though they received a two-stage revision; here prophylaxis would be determined by the clinician assessment of what is best. For antibiotic choice (rifampicin), it is conceivable that patients are eligible for the domain but the clinician is not willing to risk them being allocated to the control arm, hence the possibility of clinical selection is included for that domain as well. Only a subset of the cohort will ever enter the choice domain anyway.\nA joint-by-surgical type (dair, one, two-stage) interaction is explicitly included (denoted with \\(S_A \\times J\\)). There may be others that are of interest. My guess is that infection site will also influence the approach adopted for revision, but that is not reflected here (I don’t think it would make any difference to the statistical considerations anyway).\nPreviously, we have talked about direct paths, but these are assumed not to exist. This is because you cannot define, for example surgical procedure, as a mediator because \\(Y(a,m)\\) would need to be defined for both \\(a=0\\) and \\(a=1\\) and it is only makes sense in the context of the latter. There are therefore no direct paths within the causal structure.\nMentally I am restricting myself to the late silo and specifically to the question of the surgical intervention and hence conditioning on that silo is implicit here and not mentioned within the DAG or models.\nGiven the above, some of the following may not align with a generic perspective applicable to the other silos.\nFigure 1: Late silo units DAG (extension incorporating interactions on the DAG follows the proposal by Attia (https://doi.org/10.1093/ije/dyac126))\nThroughout, I will represent the nodes with:\nThe total effect of surgery (\\(A\\)) on outcome (\\(Y\\)) is identifiable. However, the total effect is the effect of treatment through all paths, so it amounts to a comparison of surgery plus some possible antibiotic duration and extended prophylaxis, i.e. all the open paths below.\nCode\ndo.call(cbind, paths(dag1))\n\n\n     paths                        open   \n[1,] \"a -&gt; sa -&gt; axj -&gt; y\"        \"TRUE\" \n[2,] \"a -&gt; sa -&gt; axj &lt;- j -&gt; y\"   \"FALSE\"\n[3,] \"a -&gt; sa -&gt; sd1 -&gt; y\"        \"TRUE\" \n[4,] \"a -&gt; sa -&gt; sd1 &lt;- ud1 -&gt; y\" \"FALSE\"\n[5,] \"a -&gt; sa -&gt; sd2 -&gt; y\"        \"TRUE\" \n[6,] \"a -&gt; sa -&gt; sd2 &lt;- ud2 -&gt; y\" \"FALSE\"\n[7,] \"a -&gt; sa -&gt; y\"               \"TRUE\" \n[8,] \"a -&gt; sa &lt;- ua -&gt; y\"         \"FALSE\"\nNo adjustment is necessary to obtain the total effect but under the design this obfuscates attribution due to the various interventions.",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#surgical-domain-model",
    "href": "notebooks/design-notes-05.html#surgical-domain-model",
    "title": "Marginal-ish effects",
    "section": "Surgical domain model",
    "text": "Surgical domain model\nPer the above, we could simply regress on assigned surgical treatment to obtain the total effect. However, for the surgical domain it is informative to use the following model specification:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | \\pmb{Q}; \\pmb{\\zeta}] &= \\beta_0 + \\beta_1 (S_A = 1) + \\beta_2 (S_A = 2) + \\beta_3 U_A + \\\\\n& \\beta_4 S_{D1} + \\beta_5 U_{D1} + \\\\\n& \\beta_6 S_{C} + \\beta_7 U_{C} + \\\\\n& \\beta_8 J + \\\\\n& \\beta_9 S_{D2} + \\beta_{10} U_{D2} + \\\\\n& \\gamma_1 (S_A = 1) J + \\gamma_2 (S_A = 2) J\n\\end{aligned}\n\\]\nwhere \\(\\pmb{Q}\\) and \\(\\pmb{\\zeta}\\) represent the vector of conditional elements and with the parameters for \\(D2\\) (\\(\\beta_9\\) and \\(\\beta_{10}\\)) being relevant only for the cohort receiving two-stage revision.\nTo get back to a view on dair vs revision we can use the g-formula to average over all the other terms and then compute a weighted combination of the one-stage and two-stage effects based on the distribution of these in the sample. For example, say the only conditioning element we have is \\(U_A\\) and \\(Y(a)\\) denotes the potential outcomes with respect to the randomised surgery type:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y(0)] &= \\mathbb{E}_{U_A}[  \\mathbb{E}[Y | S_A = 0, U_A = u_a] ] \\\\\n  &= \\sum_{u_A} \\mathbb{P}(U_A = u_a) \\left(\\sum_{y} y \\mathbb{P}(Y = y | S_A = 0, U_A = u_a) \\right)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y(1)] &= \\mathbb{E}_{U_A}[  \\mathbb{E}[Y | S_A \\in \\{ 1, 2\\}, U_A = u_a] ] \\\\\n  &= \\sum_{u_A} \\mathbb{P}(U_A = u_a) \\left(\\sum_{y} y \\mathbb{P}(Y = y | S_A = \\in \\{ 1, 2\\}, U_A = u_a) \\right)\n\\end{aligned}\n\\]\nThe model is implemented in stan as follows:\n\n\nLogistic regression with bootstrap in stan\ndata {\n  int N;\n  array[N] int y;\n  array[N] int n;\n  // for one an two-stage indicators \n  // these are the main effects of interest\n  int P1;\n  matrix[N, P1] X1;\n  // other terms bar interactions and ext proph related\n  int P2;\n  matrix[N, P2] X2;\n  // extra fields for extended proph\n  int P3;\n  matrix[N, P3] X3;\n  // fields for interactions\n  int P4;\n  matrix[N, P4] X4;\n  // auxiliary terms\n  // observed probability of one-stage\n  real pr_one;\n  // number preferring 1/2 stage under rev\n  int N1;\n  int N2;\n  array[N1] int ix1;\n  array[N2] int ix2;\n  // priors\n  int prior_only;\n  real sd_a0;\n  real sd_b1;\n  real sd_b2;\n  real sd_b3;\n  real sd_b4;\n}\ntransformed data {\n}\nparameters{\n  real a0;\n  // surgical effects\n  vector[P1] b1;\n  // other terms\n  vector[P2] b2;\n  // ext prophy\n  vector[P3] b3;\n  // interactions\n  vector[P4] b4;\n}\ntransformed parameters{\n  vector[N] eta;\n  for(i in 1:N){\n    // X1[i,2] should be an indicator of whether two-stage has been done\n    if(X1[i,2] == 0){\n      eta[i] = a0 + X1[i,]*b1 + X2[i,]*b2 +             X4[i, ]*b4 ;    \n    }\n    if(X1[i,2] == 1){\n      eta[i] = a0 + X1[i,]*b1 + X2[i,]*b2 + X3[i,]*b3 + X4[i, ]*b4 ;     \n    }\n  }\n}\nmodel{\n  target += normal_lpdf(a0 | 0, sd_a0);\n  target += normal_lpdf(b1 | 0, sd_b1);\n  target += normal_lpdf(b2 | 0, sd_b2);\n  target += normal_lpdf(b3 | 0, sd_b3);\n  target += normal_lpdf(b4 | 0, sd_b4);\n  if(!prior_only){\n    target += binomial_logit_lpmf(y | n, eta);  \n  }\n}\ngenerated quantities{\n  vector[N] p;    \n  real marg_p0;                                               \n  real marg_p1;       \n  real rd;                                                    \n                                                              \n  vector[N] cond_p0;                                          \n  vector[N] cond_p1;                                               \n                                                              \n  // to get to pate rather than sate                          \n  // Bayesian bootstrap (weights)                             \n  vector[N] w = dirichlet_rng(to_vector(n)); \n                                                              \n  p = inv_logit(eta);\n  \n  // drop out the terms relating to sa == 1 and sa == 2\n  // drop out last two terms that are only applicable for sa == 2\n  // dair - no X4 since sa = 0 hence zero contribution.\n  cond_p0 = inv_logit(a0 +         X2*b2); \n  // one\n  cond_p1[ix1] = inv_logit(a0 + b1[1] + X2[ix1,]*b2 +         X4[ix1,]*b4); \n  // two\n  cond_p1[ix2] = inv_logit(a0 + b1[2] + X2[ix2,]*b2 + X3[ix2,]*b3 + X4[ix2,]*b4);                          \n                                                              \n  // taking average over bayesian bootstrap weights           \n  marg_p0 = w' * cond_p0;                                  \n  marg_p1 = w' * cond_p1;    \n\n  rd = marg_p1 - marg_p0;\n}\n\n\nwhere the bootstrap functionality is used as a standardisation procedure and which could be extended to estimate strata level effects such as those relating to site of infection (knee/hip).\nBelow are scenarios with different combinations of effects that aims to illustrate the main limitation of the design. The assumed effect sizes are purely illustrative.",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#example-1---null-case",
    "href": "notebooks/design-notes-05.html#example-1---null-case",
    "title": "Marginal-ish effects",
    "section": "Example 1 - null case",
    "text": "Example 1 - null case\n\n\nGeneric data generation function\nn = 200\nget_data &lt;- function(\n    n = 200,\n    ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n      # provide a sensible linear predictor.\n      p &lt;- rep(0.5, length(a))\n      p\n      \n      })\n{\n  # joint\n  j &lt;- rbinom(n, 1, 0.5)\n  \n  # choice\n  c &lt;- rbinom(n, 1, 0.5)\n  # The clinical perspective overlay encapsulate entry into the domain.\n  # Entry implies the unit meets the conditions for rand to rif\n  uc &lt;- rbinom(n, 1, 0.6)\n  # Type received \n  sc &lt;- rep(NA, n)\n  sc[uc == 0] &lt;- c[uc == 0]\n  # those that do not enter do not get rif\n  sc[uc == 1] &lt;- 0\n  \n  # assigned surgery - just assume that all enter into this domain\n  a &lt;- rbinom(n, 1, 0.5)\n  # under receipt of rev, most clinicians would prefer to use two-stage\n  ua &lt;- rbinom(n, 1, 0.75)\n  \n  # dair = 0, one = 1, two = 2\n  sa &lt;- rep(NA, n)\n  # assume full adherence in dair group\n  sa[a == 0] &lt;- 0\n  # assigned to rev:  gets either one or two stage\n  ix &lt;- which(a == 1); \n  sa[ix] &lt;- ua[ix] + 1\n  \n  \n  # random assignment of duration 6vs12\n  d1 &lt;- sample(c(6,12), n, T)\n  # pref for duration of therapy after first op is towards longer durn\n  ud1 &lt;- sample(seq(4, 12, by = 2), n, T, 1:5/sum(1:5))\n  \n  # random assignment of prophylaxis\n  d2 &lt;- rbinom(n, 1, 0.5)\n  # most prefer to use prophylaxis\n  ud2 &lt;- rbinom(n, 1, 0.7)\n  \n  \n  # duration of antibiotic following first procedure\n  sd1 &lt;- rep(NA, n)\n  # for those getting dair, duration after first opn is exactly per pref\n  sd1[sa == 0] &lt;- ud1[sa == 0]\n  # assume full adherence in one-stage group\n  # 6 wk vs 12 wk\n  sd1[sa == 1] &lt;- d1[sa == 1]\n  # for those getting two-stage, duration after first opn is per pref\n  sd1[sa == 2] &lt;- ud1[sa == 2]\n  \n  # prophylaxis\n  sd2 &lt;- rep(NA, n)\n  # for those getting two-stage it is per the randomisation\n  sd2[sa == 2] &lt;- d2[sa == 2]\n  # otherwise it isn't defined but assign it to what it would be set to \n  # if the unit were to get two-stage\n  # these units will not be used in the likelihood, but they would be used \n  # in the bootstrap step.\n  sd2[sa != 2] &lt;- d2[sa != 2]\n    \n  d &lt;- data.table(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc)\n  \n  # outcome\n  d[, p_y := ff(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc)]\n  d[, y := rbinom(.N, 1, prob = p_y)]\n\n  d\n}\n\n\nHere all domain treatment effects are set to zero, however, the some baseline variables have been assumed to create heterogeneity in the response. Rather than repeat simulation, the model is fit to a large simulated dataset to get a sense of consistency.\n\n\nData simulation and parameter estimation\nset.seed(987654321)\ng_pars &lt;- c(paste0(\"b1[\",1:2,\"]\"),\n          paste0(\"b2[\",1:6,\"]\"),\n          paste0(\"b3[\",1:2,\"]\"),\n          paste0(\"b4[\",1:2,\"]\")\n          )\nnames(g_pars) &lt;- c(\n  \"b1 (sa1)\", \"b2 (sa2)\", \"b3 (ua)\", \n  \"b4 (sd1)\", \"b5 (ud1)\",\n  \"b6 (sc)\", \"b7 (uc)\",\n  \"b8 (j)\",\n  \"b9 (sd2)\", \"b10 (ud2)\",\n  \"g1 (sa1 x j)\", \"g2 (sa2 x j)\"\n)\n\n\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-03.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-02.stan\")\n  \nd &lt;- get_data(\n  n = 1e5,\n  ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n  \n    p &lt;- rep(NA, length(a))\n    \n    # dair\n    ix &lt;- which(sa == 0)\n    # e.g.\n    # ua: pref for two-stage suggests less sev pt\n    # sa: one-stage does nothing\n    # sa: two-stage does nothing\n    # ud1: pref for longer duration suggests more sev pt\n    # d1: duration does nothing\n    # d2: is irrelevant for dair cohort\n    # uc: does nothing\n    # c: does nothing\n    \n    p[ix] &lt;- 0.6 + \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n      \n    # one-stage\n    ix &lt;- which(sa == 1)\n    p[ix] &lt;- 0.6 + \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n    \n    # two-stage\n    ix &lt;- which(sa == 2)\n    p[ix] &lt;- 0.6 +  \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2)  + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      # last two parameters not included for dair and one-stage\n      0.0*sd2[ix] + 0*ud2[ix] +\n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n      \n    p\n  })\n\n# d[, .(.N, mean(y)), keyby = a]\n\nd[, `:=`(sa1 = as.numeric(d$sa == 1), sa2 = as.numeric(d$sa == 2))]\nd_s &lt;- d[, .(y = sum(y), n = .N, p_y = unique(p_y)), keyby = .(\n  sa1, sa2, ua, sd1, ud1, sc, uc, j, sd2, ud2, j \n)]\n\n# Model treats X[, 2] as being indicator of two-stage\nX1 &lt;- cbind(d_s$sa1, d_s$sa2)\n# all others bar interactions\nX2 &lt;- cbind(d_s$ua, d_s$sd1, d_s$ud1, d_s$sc, d_s$uc, d_s$j)\n# extended prophylaxis terms - only applies to two-stage pt\nX3 &lt;- cbind(d_s$sd2, d_s$ud2)\n# interactions\nX4 &lt;- cbind(d_s$j*d_s$sa1, d_s$j*d_s$sa2)\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X1 = X1, X2 = X2, X3 = X3, X4 = X4,\n  P1 = ncol(X1), P2 = ncol(X2), P3 = ncol(X3), P4 = ncol(X4),\n  # number of recs preference for 1/2 under revision\n  N1 = d_s[ua == 0, .N], N2 = d_s[ua == 1, .N],\n  # idx for pref for 1/2\n  ix1 = d_s[ua == 0, which = T],\n  ix2 = d_s[ua == 1, which = T],\n  pr_one = d[, mean(ua == 0)],\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b1 = 3, sd_b2 = 3, sd_b3 = 3, sd_b4 = 3\n)   \n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 19.3 seconds.\nChain 2 finished in 20.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 19.9 seconds.\nTotal execution time: 20.6 seconds.\n\n\nData simulation and parameter estimation\n# snk &lt;- capture.output(\n#       f1 &lt;- m1$pathfinder(ld, num_paths=20, single_path_draws=200,\n#                              history_size=50, max_lbfgs_iters=100,\n#                              refresh = 0, draws = 2000)\n#     )\n# f_mode &lt;- m1$optimize(data = ld, jacobian = TRUE, refresh =0)\n# f1 &lt;- m1$laplace(data = ld, mode = f_mode, refresh = 0)\n\nd_s &lt;- d[, .(y = sum(y), n = .N), keyby = .(\n  a\n)]\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X = matrix(d_s$a),\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b = 3\n)   \n\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\n\nThe parameter estimates obviously do not align with the parameters used in the linear predictor as these are estimated on the log odds scale. But the magnitudes of the effects should be in line with the parameters on the risk scale. The parameters that had non-null effects in the data generation process have been shaded red.\n\n\nPosterior distributions for model parameters\nd_post &lt;- data.table(f1$draws(variables = c(\"a0\",\"b1\",\"b2\",\"b3\",\"b4\"), format = \"matrix\"))\nnames(d_post) &lt;- c(\"a0\", names(g_pars))\n\n# parameters\ncols &lt;- c(\"a0\", names(g_pars))\nd_fig &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig[variable == \"a0\", value := plogis(value)]\nd_fig[variable != \"a0\", value := exp(value)]\n\nd_col &lt;- unique(d_fig[, .(variable)])\nd_col[, fill := factor(c(\n  1, 1, 1, 2,\n  1, 2,\n  1, 1,\n  2,\n  1, 1,\n  1, 1\n))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_rect(data = d_col, aes(fill = fill),\n            xmin = -Inf,xmax = Inf,\n            ymin = -Inf,ymax = Inf, alpha = 0.1,\n            inherit.aes = F) +\n  scale_fill_manual(\"\", values = c(\"white\", \"red\")) +\n  geom_density() +\n  geom_vline(data = d_fig[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  scale_x_continuous(\n    labels = label_number(accuracy = 0.01)\n  ) +\n  facet_wrap(~variable, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 2: Posterior distributions for model parameters (coefficients all exponentiated, intercept on risk scale)\n\n\n\n\n\nBelow are the recovered marginal probabilities of \\(Y\\) under each surgical treatment type (dair vs rev). The red overlay shows the marginal probabilities of \\(Y\\) based on using a truncated model that includes a single fixed effect for surgical intervention (dair vs rev) and no other terms.\n\n\nMarginal probability of outcome by surgical type\ncols &lt;- c(\"marg_p0\", \"marg_p1\")\nd_post &lt;- data.table(f1$draws(variables = cols, format = \"matrix\"))\nnames(d_post) &lt;- cols\n \nd_fig1 &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig2 &lt;- data.table(f2$draws(variables = cols, format = \"matrix\"))\nd_fig2 &lt;- melt(d_fig2, measure.vars = cols)\n\nggplot(d_fig1, aes(x = value, group = variable)) +\n  geom_density() +\n  geom_density(data = d_fig2, aes(x = value, group = variable), \n               col = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(\n    \"Proportion with successful outcome\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  )\n\n\n\n\n\n\n\n\nFigure 3: Marginal probability of \\(Y\\) under each surgical type (DAIR, one-stage, two-stage)\n\n\n\n\n\nRisk difference (rev - dair). The red dashed line shows the posterior distribution obtained from a reduced model that includes a single term for surgical treatment assignment (dair/rev). The result is centred around zero and aligns with what we expect.\n\n\nRisk difference (dair vs revision)\nd_fig1 &lt;- data.table(f1$draws(variables = c(\"rd\"), format = \"matrix\"))\nd_fig2 &lt;- data.table(f2$draws(variables = c(\"rd\"), format = \"matrix\"))\n\nggplot(d_fig1, aes(x = rd)) +\n  geom_density() +\n  geom_density(data = d_fig2, \n               aes(x = rd), col = 2, lty = 2) +\n  scale_x_continuous(\n    \"Risk difference\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  ) +\n  geom_vline(data = d_fig1[, .(mu = mean(rd))], \n             aes(xintercept = mu))  +\n  geom_vline(data = d_fig2[, .(mu = mean(rd))], \n             aes(xintercept = mu), col = 2) \n\n\n\n\n\n\n\n\nFigure 4: Marginal risk difference of \\(Y\\) for DAIR vs revision",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#example-2---revision-effects",
    "href": "notebooks/design-notes-05.html#example-2---revision-effects",
    "title": "Marginal-ish effects",
    "section": "Example 2 - revision effects",
    "text": "Example 2 - revision effects\nHere equal magnitude effects are used for revision for both one-stage and two-stage approach with worse outcomes for hip joints but no interactions. In the other domains, the treatment effects are set to zero.\n\n\nData simulation and parameter estimation\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-03.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-02.stan\")\n  \nd &lt;- get_data(\n  n = 1e5,\n  ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n  \n    p &lt;- rep(NA, length(a))\n    \n    # dair\n    ix &lt;- which(sa == 0)\n    p[ix] &lt;- 0.6 + \n      0.1*(sa[ix] == 1) + 0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      -0.00*j[ix]**(sa[ix] == 1) -0.00*j[ix]**(sa[ix] == 2) \n      \n    # one-stage\n    ix &lt;- which(sa == 1)\n    p[ix] &lt;- 0.6 + \n      0.1*(sa[ix] == 1) + 0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] +  \n      -0.00*j[ix]**(sa[ix] == 1) -0.00*j[ix]**(sa[ix] == 2)\n    \n    # two-stage\n    ix &lt;- which(sa == 2)\n    p[ix] &lt;- 0.6 +  \n      0.1*(sa[ix] == 1) + 0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      # last two parameters not included for dair and one-stage\n      0.0*sd2[ix] + 0*ud2[ix] +\n      -0.00*j[ix]**(sa[ix] == 1) -0.00*j[ix]**(sa[ix] == 2)\n    \n    \n    # p[ix] &lt;- 0.6 +  \n    #   0.1*(sa[ix] == 1) + 0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n    #   0*sd1[ix] - 0.01*ud1[ix] +\n    #   0*sc[ix] + 0*uc[ix] +\n    #   -0.1*j[ix] + \n    #   # last two parameters not included for dair and one-stage\n    #   0.0*sd2[ix] + 0*ud2[ix] +\n    #   -0.03*j[ix]**(sa[ix] == 1) -0.03*j[ix]**(sa[ix] == 2)\n\n    p\n  })\n\nd[, `:=`(sa1 = as.numeric(d$sa == 1), sa2 = as.numeric(d$sa == 2))]\nd_s &lt;- d[, .(y = sum(y), n = .N, p_y = unique(p_y)), keyby = .(\n  sa1, sa2, ua, sd1, ud1, sc, uc, j, sd2, ud2, j \n)]\n\n# Model treats X[, 2] as being indicator of two-stage\nX1 &lt;- cbind(d_s$sa1, d_s$sa2)\n# all others bar interactions\nX2 &lt;- cbind(d_s$ua, d_s$sd1, d_s$ud1, d_s$sc, d_s$uc, d_s$j)\n# extended prophylaxis terms - only applies to two-stage pt\nX3 &lt;- cbind(d_s$sd2, d_s$ud2)\n# interactions\nX4 &lt;- cbind(d_s$j*d_s$sa1, d_s$j*d_s$sa2)\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X1 = X1, X2 = X2, X3 = X3, X4 = X4,\n  P1 = ncol(X1), P2 = ncol(X2), P3 = ncol(X3), P4 = ncol(X4),\n  # number of recs preference for 1/2 under revision\n  N1 = d_s[ua == 0, .N], N2 = d_s[ua == 1, .N],\n  # idx for pref for 1/2\n  ix1 = d_s[ua == 0, which = T],\n  ix2 = d_s[ua == 1, which = T],\n  pr_one = d[, mean(ua == 0)],\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b1 = 3, sd_b2 = 3, sd_b3 = 3, sd_b4 = 3\n)    \n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 18.3 seconds.\nChain 2 finished in 18.7 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 18.5 seconds.\nTotal execution time: 18.8 seconds.\n\n\nData simulation and parameter estimation\n# snk &lt;- capture.output(\n#       f1 &lt;- m1$pathfinder(ld, num_paths=20, single_path_draws=200,\n#                              history_size=50, max_lbfgs_iters=100,\n#                              refresh = 0, draws = 2000)\n#     )\n\n# f_mode &lt;- m1$optimize(data = ld, jacobian = TRUE, refresh =0)\n# f1 &lt;- m1$laplace(data = ld, mode = f_mode, refresh = 0)\n\nd_s &lt;- d[, .(y = sum(y), n = .N), keyby = .(\n  a\n)]\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X = matrix(d_s$a),\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b = 10\n)   \n\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\n\nParameters estimated on the log-odds scale, but exponentiated below (intercept reported on risk scale).\n\n\nPosterior distributions for model parameters\nd_post &lt;- data.table(f1$draws(variables = c(\"a0\",\"b1\",\"b2\",\"b3\",\"b4\"), format = \"matrix\"))\nnames(d_post) &lt;- c(\"a0\", names(g_pars))\n\n# parameters\ncols &lt;- c(\"a0\", names(g_pars))\nd_fig &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig[variable == \"a0\", value := plogis(value)]\nd_fig[variable != \"a0\", value := exp(value)]\n\nd_col &lt;- unique(d_fig[, .(variable)])\nd_col[, fill := factor(c(\n  1, 2, 2, 2,\n  1, 2,\n  1, 1,\n  2,\n  1, 1,\n  2, 2\n))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_rect(data = d_col, aes(fill = fill),\n            xmin = -Inf,xmax = Inf,\n            ymin = -Inf,ymax = Inf, alpha = 0.1,\n            inherit.aes = F) +\n  scale_fill_manual(\"\", values = c(\"white\", \"red\")) +\n  geom_density() +\n  geom_vline(data = d_fig[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  scale_x_continuous(\n    labels = label_number(accuracy = 0.01)\n  ) +\n  facet_wrap(~variable, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 5: Posterior distributions for model parameters (coefficients all exponentiated, intercept on risk scale)\n\n\n\n\n\nThe distribution of the marginal probability of \\(Y\\) under each treatment type.\n\n\nMarginal probability of outcome by surgical type\ncols &lt;- c(\"marg_p0\", \"marg_p1\")\nd_post &lt;- data.table(f1$draws(variables = cols, format = \"matrix\"))\nnames(d_post) &lt;- cols\n \nd_fig1 &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig2 &lt;- data.table(f2$draws(variables = cols, format = \"matrix\"))\nd_fig2 &lt;- melt(d_fig2, measure.vars = cols)\n\nggplot(d_fig1, aes(x = value, group = variable)) +\n  geom_density() +\n  geom_density(data = d_fig2, aes(x = value, group = variable), \n               col = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(\n    \"Proportion with successful outcome\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  )\n\n\n\n\n\n\n\n\nFigure 6: Marginal probability of \\(Y\\) under each surgical type (DAIR, one-stage, two-stage)\n\n\n\n\n\nRisk difference (rev - dair). The red dashed line shows the posterior distribution obtained from a reduced model that includes a single term for surgical treatment assignment (dair/rev). The result is suggests a positive effect of surgery as expected.\n\n\nRisk difference (dair vs revision)\nd_fig1 &lt;- data.table(f1$draws(variables = c(\"rd\"), format = \"matrix\"))\nd_fig2 &lt;- data.table(f2$draws(variables = c(\"rd\"), format = \"matrix\"))\n\nggplot(d_fig1, aes(x = rd)) +\n  geom_density() +\n  scale_x_continuous(\n    \"Risk difference\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  ) +\n  geom_density(data = d_fig2, \n               aes(x = rd), col = 2, lty = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(rd))], \n             aes(xintercept = mu))  +\n  geom_vline(data = d_fig2[, .(mu = mean(rd))], \n             aes(xintercept = mu), col = 2) \n\n\n\n\n\n\n\n\nFigure 7: Marginal risk difference of \\(Y\\) for DAIR vs revision",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#example-3---extended-prophylaxis-effects",
    "href": "notebooks/design-notes-05.html#example-3---extended-prophylaxis-effects",
    "title": "Marginal-ish effects",
    "section": "Example 3 - extended prophylaxis effects",
    "text": "Example 3 - extended prophylaxis effects\nHere revision effects are set to zero but a non-zero effect is set for the extended prophylaxis.\nThis is where things start to go awry.\nDue to the fact that extended prophylaxis is only applicable for patients receiving a two-stage revision (the revision being the important part), any extended prophylaxis effect will manifest as being an effect of revision. Thus the observed effect has nothing to do with the surgery performed but rather the intervention received in the entangled domain.\n\nIs there any way around this in the setting where we are referring to a generalised revision effect?\n\n\n\nData simulation and parameter estimation\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-03.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-02.stan\")\n\nd &lt;- get_data(\n  n = 1e5,\n  ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n  \n    p &lt;- rep(NA, length(a))\n    \n    # dair\n    ix &lt;- which(sa == 0)\n    p[ix] &lt;- 0.6 + \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n      \n    # one-stage\n    ix &lt;- which(sa == 1)\n    p[ix] &lt;- 0.6 + \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] +  \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2)\n    \n    # two-stage\n    ix &lt;- which(sa == 2)\n    p[ix] &lt;- 0.6 +  \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      # last two parameters not included for dair and one-stage\n      0.2*sd2[ix] + 0*ud2[ix] +\n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2)\n      \n    p\n  })\n\nd[, `:=`(sa1 = as.numeric(d$sa == 1), sa2 = as.numeric(d$sa == 2))]\nd_s &lt;- d[, .(y = sum(y), n = .N, p_y = unique(p_y)), keyby = .(\n  sa1, sa2, ua, sd1, ud1, sc, uc, j, sd2, ud2, j \n)]\n\n# Model treats X[, 2] as being indicator of two-stage\nX1 &lt;- cbind(d_s$sa1, d_s$sa2)\n# all others bar interactions\nX2 &lt;- cbind(d_s$ua, d_s$sd1, d_s$ud1, d_s$sc, d_s$uc, d_s$j)\n# extended prophylaxis terms - only applies to two-stage pt\nX3 &lt;- cbind(d_s$sd2, d_s$ud2)\n# interactions\nX4 &lt;- cbind(d_s$j*d_s$sa1, d_s$j*d_s$sa2)\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X1 = X1, X2 = X2, X3 = X3, X4 = X4,\n  P1 = ncol(X1), P2 = ncol(X2), P3 = ncol(X3), P4 = ncol(X4),\n  # number of recs preference for 1/2 under revision\n  N1 = d_s[ua == 0, .N], N2 = d_s[ua == 1, .N],\n  # idx for pref for 1/2\n  ix1 = d_s[ua == 0, which = T],\n  ix2 = d_s[ua == 1, which = T],\n  pr_one = d[, mean(ua == 0)],\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b1 = 3, sd_b2 = 3, sd_b3 = 3, sd_b4 = 3\n)     \n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 19.0 seconds.\nChain 1 finished in 20.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 19.7 seconds.\nTotal execution time: 20.5 seconds.\n\n\nData simulation and parameter estimation\n# snk &lt;- capture.output(\n#       f1 &lt;- m1$pathfinder(ld, num_paths=20, single_path_draws=200,\n#                              history_size=50, max_lbfgs_iters=100,\n#                              refresh = 0, draws = 2000)\n#     )\n\n# f_mode &lt;- m1$optimize(data = ld, jacobian = TRUE, refresh =0)\n# f1 &lt;- m1$laplace(data = ld, mode = f_mode, refresh = 0)\n\nd_s &lt;- d[, .(y = sum(y), n = .N), keyby = .(\n  a\n)]\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X = matrix(d_s$a),\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b = 3\n)   \n\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.2 seconds.\n\n\nParameters estimated on the log-odds scale, but exponentiated below (intercept reported on risk scale).\n\n\nPosterior distributions for model parameters\nd_post &lt;- data.table(f1$draws(variables = c(\"a0\",\"b1\",\"b2\",\"b3\",\"b4\"), format = \"matrix\"))\nnames(d_post) &lt;- c(\"a0\", names(g_pars))\n\n# parameters\ncols &lt;- c(\"a0\", names(g_pars))\nd_fig &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig[variable == \"a0\", value := plogis(value)]\nd_fig[variable != \"a0\", value := exp(value)]\n\nd_col &lt;- unique(d_fig[, .(variable)])\nd_col[, fill := factor(c(\n  1, 1, 1, 2,\n  1, 2,\n  1, 1,\n  2,\n  2, 1,\n  1, 1\n))]\n\n\n  \nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_rect(data = d_col, aes(fill = fill),\n            xmin = -Inf,xmax = Inf,\n            ymin = -Inf,ymax = Inf, alpha = 0.1,\n            inherit.aes = F) +\n  scale_fill_manual(\"\", values = c(\"white\", \"red\")) +\n  geom_density() +\n  geom_vline(data = d_fig[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  scale_x_continuous(\n    labels = label_number(accuracy = 0.01)\n  ) +\n  facet_wrap(~variable, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 8: Posterior distributions for model parameters (coefficients all exponentiated, intercept on risk scale)\n\n\n\n\n\nThe distribution of the marginal probability of \\(Y\\) under each treatment type.\n\n\nMarginal probability of outcome by surgical type\ncols &lt;- c(\"marg_p0\", \"marg_p1\")\nd_post &lt;- data.table(f1$draws(variables = cols, format = \"matrix\"))\nnames(d_post) &lt;- cols\n \nd_fig1 &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig2 &lt;- data.table(f2$draws(variables = cols, format = \"matrix\"))\nd_fig2 &lt;- melt(d_fig2, measure.vars = cols)\n\nggplot(d_fig1, aes(x = value, group = variable)) +\n  geom_density() +\n  geom_density(data = d_fig2, aes(x = value, group = variable), \n               col = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(\n    \"Proportion with successful outcome\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  )\n\n\n\n\n\n\n\n\nFigure 9: Marginal probability of \\(Y\\) under each surgical type (DAIR, one-stage, two-stage)\n\n\n\n\n\nRisk difference (rev - dair). The red dashed line shows the posterior distribution obtained from a reduced model that includes a single term for surgical treatment assignment (dair/rev). Even though there is no effect of surgery, a positive risk difference for dair vs revision manifests due to the presence of an effect in the extended prophylaxis domain.\n\n\nRisk difference (dair vs revision)\nd_fig1 &lt;- data.table(f1$draws(variables = c(\"rd\"), format = \"matrix\"))\nd_fig2 &lt;- data.table(f2$draws(variables = c(\"rd\"), format = \"matrix\"))\n\nggplot(d_fig1, aes(x = rd)) +\n  geom_density() +\n  scale_x_continuous(\n    \"Risk difference\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  ) +\n  geom_density(data = d_fig2, \n               aes(x = rd), col = 2, lty = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(rd))], \n             aes(xintercept = mu))  +\n  geom_vline(data = d_fig2[, .(mu = mean(rd))], \n             aes(xintercept = mu), col = 2) \n\n\n\n\n\n\n\n\nFigure 10: Marginal risk difference of \\(Y\\) for DAIR vs revision",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#example-4---combined-revision-and-extended-prophylaxis-effects",
    "href": "notebooks/design-notes-05.html#example-4---combined-revision-and-extended-prophylaxis-effects",
    "title": "Marginal-ish effects",
    "section": "Example 4 - combined revision and extended prophylaxis effects",
    "text": "Example 4 - combined revision and extended prophylaxis effects\nHere revision effects are set to negative values (i.e. people on revision do worse) and a positive effect is set for the extended prophylaxis.\nFor similar reasons as above, the negative effect of revision (people do worse under surgical removal and replacement of the joint) is cancelled out when evaluated at the margins due to the offsetting effect of extended prophylaxis.\n\n\nData simulation and parameter estimation\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-03.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-02.stan\")\n\nd &lt;- get_data(\n  n = 1e5,\n  ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n  \n    p &lt;- rep(NA, length(a))\n    \n    # dair\n    ix &lt;- which(sa == 0)\n    p[ix] &lt;- 0.6 + \n      -0.1*(sa[ix] == 1) + -0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n      \n    # one-stage\n    ix &lt;- which(sa == 1)\n    p[ix] &lt;- 0.6 + \n      -0.07*(sa[ix] == 1) + -0.07*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] +  \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2)\n    \n    # two-stage\n    ix &lt;- which(sa == 2)\n    p[ix] &lt;- 0.6 +  \n      -0.07*(sa[ix] == 1) + -0.07*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      # last two parameters not included for dair and one-stage\n      0.2*sd2[ix] + 0*ud2[ix] +\n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2)\n      \n    p\n  })\n\n\nd[, `:=`(sa1 = as.numeric(d$sa == 1), sa2 = as.numeric(d$sa == 2))]\nd_s &lt;- d[, .(y = sum(y), n = .N, p_y = unique(p_y)), keyby = .(\n  sa1, sa2, ua, sd1, ud1, sc, uc, j, sd2, ud2, j \n)]\n\n# Model treats X[, 2] as being indicator of two-stage\nX1 &lt;- cbind(d_s$sa1, d_s$sa2)\n# all others bar interactions\nX2 &lt;- cbind(d_s$ua, d_s$sd1, d_s$ud1, d_s$sc, d_s$uc, d_s$j)\n# extended prophylaxis terms - only applies to two-stage pt\nX3 &lt;- cbind(d_s$sd2, d_s$ud2)\n# interactions\nX4 &lt;- cbind(d_s$j*d_s$sa1, d_s$j*d_s$sa2)\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X1 = X1, X2 = X2, X3 = X3, X4 = X4,\n  P1 = ncol(X1), P2 = ncol(X2), P3 = ncol(X3), P4 = ncol(X4),\n  # number of recs preference for 1/2 under revision\n  N1 = d_s[ua == 0, .N], N2 = d_s[ua == 1, .N],\n  # idx for pref for 1/2\n  ix1 = d_s[ua == 0, which = T],\n  ix2 = d_s[ua == 1, which = T],\n  pr_one = d[, mean(ua == 0)],\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b1 = 3, sd_b2 = 3, sd_b3 = 3, sd_b4 = 3\n)         \n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 18.8 seconds.\nChain 2 finished in 19.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 19.0 seconds.\nTotal execution time: 19.3 seconds.\n\n\nData simulation and parameter estimation\n# snk &lt;- capture.output(\n#       f1 &lt;- m1$pathfinder(ld, num_paths=20, single_path_draws=200,\n#                              history_size=50, max_lbfgs_iters=100,\n#                              refresh = 0, draws = 2000)\n#     )\n\n# f_mode &lt;- m1$optimize(data = ld, jacobian = TRUE, refresh =0)\n# f1 &lt;- m1$laplace(data = ld, mode = f_mode, refresh = 0)\n\nd_s &lt;- d[, .(y = sum(y), n = .N), keyby = .(\n  a\n)]\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X = matrix(d_s$a),\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b = 3\n)   \n\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.2 seconds.\n\n\nParameters estimated on the log-odds scale, but exponentiated below (intercept reported on risk scale).\n\n\nPosterior distributions for model parameters\nd_post &lt;- data.table(f1$draws(variables = c(\"a0\",\"b1\",\"b2\",\"b3\",\"b4\"), format = \"matrix\"))\nnames(d_post) &lt;- c(\"a0\", names(g_pars))\n\n# parameters\ncols &lt;- c(\"a0\", names(g_pars))\nd_fig &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig[variable == \"a0\", value := plogis(value)]\nd_fig[variable != \"a0\", value := exp(value)]\n\nd_col &lt;- unique(d_fig[, .(variable)])\nd_col[, fill := factor(c(\n  1, 2, 2, 2,\n  1, 2,\n  1, 1,\n  2,\n  2, 1,\n  1, 1\n))]\n\n\n  \nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_rect(data = d_col, aes(fill = fill),\n            xmin = -Inf,xmax = Inf,\n            ymin = -Inf,ymax = Inf, alpha = 0.1,\n            inherit.aes = F) +\n  scale_fill_manual(\"\", values = c(\"white\", \"red\")) +\n  geom_density() +\n  geom_vline(data = d_fig[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  scale_x_continuous(\n    labels = label_number(accuracy = 0.01)\n  ) +\n  facet_wrap(~variable, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 11: Posterior distributions for model parameters (coefficients all exponentiated, intercept on risk scale)\n\n\n\n\n\nThe distribution of the marginal probability of \\(Y\\) under each treatment type.\n\n\nMarginal probability of outcome by surgical type\ncols &lt;- c(\"marg_p0\", \"marg_p1\")\nd_post &lt;- data.table(f1$draws(variables = cols, format = \"matrix\"))\nnames(d_post) &lt;- cols\n \nd_fig1 &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig2 &lt;- data.table(f2$draws(variables = cols, format = \"matrix\"))\nd_fig2 &lt;- melt(d_fig2, measure.vars = cols)\n\nggplot(d_fig1, aes(x = value, group = variable)) +\n  geom_density() +\n  geom_density(data = d_fig2, aes(x = value, group = variable), \n               col = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(\n    \"Proportion with successful outcome\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  )\n\n\n\n\n\n\n\n\nFigure 12: Marginal probability of \\(Y\\) under each surgical type (DAIR, one-stage, two-stage)\n\n\n\n\n\nRisk difference (rev - dair). The red dashed line shows the posterior distribution obtained from a reduced model that includes a single term for surgical treatment assignment (dair/rev).\n\n\nRisk difference (dair vs revision)\nd_fig1 &lt;- data.table(f1$draws(variables = c(\"rd\"), format = \"matrix\"))\nd_fig2 &lt;- data.table(f2$draws(variables = c(\"rd\"), format = \"matrix\"))\n\nggplot(d_fig1, aes(x = rd)) +\n  geom_density() +\n  scale_x_continuous(\n    \"Risk difference\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  ) +\n  geom_density(data = d_fig2, \n               aes(x = rd), col = 2, lty = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(rd))], \n             aes(xintercept = mu))  +\n  geom_vline(data = d_fig2[, .(mu = mean(rd))], \n             aes(xintercept = mu), col = 2) \n\n\n\n\n\n\n\n\nFigure 13: Marginal risk difference of \\(Y\\) for DAIR vs revision",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#discussion",
    "href": "notebooks/design-notes-05.html#discussion",
    "title": "Marginal-ish effects",
    "section": "Discussion",
    "text": "Discussion\nIn a factorial design, the main effects could be isolated and have an interpretation conditional on all other terms in the model held at a constant level. When we are talking about an effect of \\(P\\) it relates specifically to intervening on \\(P\\). However, due to the roadmap design using the marginal perspective could lead us to identify positive or negative revision effects solely as a consequence of the non-zero effects in other domains.\nThe phenomena is an artefact of the design rather than the estimation process or the specification of the statistical model.\nThe only reasonable way to address this seems to be to define the concept of revision as a strategy that involves multiple domain elements. Probably the most interpretaable approach is to have dair vs revision corresponding to dair being a strict strategy of dair plus 12 weeks backbone therapy and where revision conrresponds to one-stage revision with 12 weeks backbone antibiotic or two-stage revision with 12 weeks backbone antibiotic and no extended prophylaxis. However, given that we do not have an intervention arm that is the absence of extended prophylaxis, we would have to settle on 7 days.\nIn no way does the above fix the design, but it provides a more coherent quantity to evaluate and report on than an arbitrary mix of strategies.",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-07.html",
    "href": "notebooks/design-notes-07.html",
    "title": "Missingness considerations",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nMissingness is classed into three types:\nwhich apply to both the response data and covariate data.\nThe way that you approach the analysis where you have missingness is strongly influenced by the assumptions you can make about the missing data process. Complete case analysis is often chastised but it is sometimes quite a reasonable approach. The following attempts to clarify some of the concepts by way of a simple example.\nThe following encodes a two-arm parallel group setting where the outcome is treatment failure indicated by \\(y = 1\\). The data include a treatment group indicator (x), a baseline covariate (a) and an indicator for the presence of adverse event (ae).\nWe can configure the extent to which the outcome y is influenced by these variables and also how the occurrence of adverse events arises. For example, an adverse event may make the chances of a outcome failure more likely.\nData generation function\nget_data &lt;- function(\n    N = 2000, \n    par = NULL,\n    # outcome model\n    f_y = function(par, x, a, ae){\n      eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a + par$b_out[4]*ae\n      eta\n    },\n    # model for adverse events\n    f_ae = function(par, x, a){\n      eta = par$b_ae[1] + par$b_ae[2]*x + par$b_ae[3]*a\n      eta\n    }\n    ){\n  \n  # strata\n  d &lt;- data.table()\n  \n  # intervention - even allocation\n  d[, x := rbinom(N, 1, par$pr_x)]\n  # baseline covariate indep to x\n  d[, a := rbinom(N, 1, par$pr_a)]\n  # dep on both x and a\n  d[, eta_ae := f_ae(par, x, a)]\n  d[, ae := rbinom(.N, 1, plogis(eta_ae))]\n  # outcome model\n  d[, eta_y := f_y(par, x, a, ae)]\n  # y = 1 implies treatment failure\n  d[, y := rbinom(.N, 1, plogis(eta_y))]\n\n  d  \n}\nCode\npar &lt;- list(\n  # betas for outcome model (need to align with f_y)\n  # intervention arm is detrimental (increases the chance of failure)\n  b_out = c(0.4, 0.3, 0.2, 0.5),\n  # betas for ae model b0, b_x, b_a  (need to align with f_ae)\n  # intervention arm increases likelihood of ae, as does baseline cov\n  b_ae = c(-2, 0.5, 0.1),\n  pr_x = 0.5,\n  pr_a = 0.7\n)\n\n# sanity check/consistency\n\nset.seed(2222222)\nd &lt;- get_data(1e6, par)\n# align with the outcome model\nX &lt;- as.matrix(CJ(x = 0:1, a = 0:1, ae = 0:1))\nd_X &lt;- cbind(X, eta = as.numeric(cbind(1, X) %*% par$b_out))\n\n# total effect of exposure (x) on y through all paths \n# i.e. possibly through any adverse events as well as the direct path\nate_obs &lt;- coef(glm(y ~ x, data = d, family = binomial))[2]\nBelow is a quick sanity check to see if we can empirically validate the log-odds of the response in each covariate combination.\nCode\nkableExtra::kbl(merge(\n  d_X, \n  d[, .(eta_obs = round(qlogis(mean(y)), 2)), keyby = .(x, a, ae)], \n  by = c(\"x\", \"a\", \"ae\")), \n  col.names = c(\"Intervention (x)\", \"Covariate\", \"AE Indicator\", \n                \"log-ods response (true)\", \"log-ods response (observed)\"))\n\n\n\n\n\nIntervention (x)\nCovariate\nAE Indicator\nlog-ods response (true)\nlog-ods response (observed)\n\n\n\n\n0\n0\n0\n0.4\n0.40\n\n\n0\n0\n1\n0.9\n0.90\n\n\n0\n1\n0\n0.6\n0.60\n\n\n0\n1\n1\n1.1\n1.11\n\n\n1\n0\n0\n0.7\n0.70\n\n\n1\n0\n1\n1.2\n1.18\n\n\n1\n1\n0\n0.9\n0.89\n\n\n1\n1\n1\n1.4\n1.40",
    "crumbs": [
      "Design notes",
      "Missingness considerations"
    ]
  },
  {
    "objectID": "notebooks/design-notes-07.html#missing-completely-at-random",
    "href": "notebooks/design-notes-07.html#missing-completely-at-random",
    "title": "Missingness considerations",
    "section": "Missing completely at random",
    "text": "Missing completely at random\nFor mcar, the probability of missingness depends on neither the observed or unobserved data. In the Figure 1 (a) DAG, the indicator of missingness (\\(m\\)) arises as a function of an independent process - it has nothing to do with the observed or unobserved covariates or response and so it sits off by itself as an independent node.\nThe diagram to the right shows what we might use for the statistical model. The circles show random variables and the squares show observables and the arros show stochastic and logical depdence. The boxes encasing the variables indicate iteration over units.\nOn the left hand side of the model is the representation of the outcome process. Here y is just a function of \\(x\\) and \\(a\\). On the right is the missingness model.\n\n\n\n\n\n\n\n\n\n\n\n(a) DAG MCAR\n\n\n\n\n\n\n\n\n\n\n\n(b) Model MCAR\n\n\n\n\n\n\n\nFigure 1: MCAR\n\n\n\n\n\nCode\nd &lt;- get_data(\n  1e5, \n  par, \n  f_y = function(par, x, a, ae){\n    eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n    eta\n    })\n\n# missingness is simply stochastic\nd[, m := rbinom(.N, 1, 0.2)]\n\n\nWe can incorporate this missing data mechanism into the data simulation. We retain the full data but create an indicator m to tell us which of the rows would be missing.\nWe would not observe the outcome for those records that were missing (i.e. hose that have \\(m=1\\)). However, under MCAR, the distribution of the outcome is the same in expectation in the observed and the missing data.\n\n\nObserved mean response stratified by missingness status\nd_fig &lt;- copy(d)\nd_fig[, `:=`(x=factor(x, labels = c(\"ctl\", \"test\")), \n             a=factor(a, labels = c(\"&lt;50\", \"&gt;=50\")), \n             ae=factor(ae, labels = c(\"no-ae\", \"ae\")), \n             m = factor(m, labels = c(\"obs\", \"mis\")))]\n\nd_fig &lt;- d_fig[, .(y = sum(y), n = .N), keyby = .(x, a, m)]\nd_fig[, eta_obs := qlogis(y / n)]\n\nggplot(d_fig, \n       aes(x= x, y = eta_obs)) + \n  geom_bar(position=\"dodge\", stat = \"identity\") +\n  scale_x_discrete(\"Exposure\") +\n  scale_y_continuous(\"log-odds response\") +\n  facet_grid(a ~ m)\n\n\n\n\n\n\n\n\nFigure 2: Observed mean response\n\n\n\n\n\nGiven that the missingness is independent of the outcome, the complete case analysis is unbiased.\n\n\nCode\nd_m &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\nf1_ref &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_ref &lt;- summary(f1_ref)$coef\n  \n# only select the observed cases\nd_m &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\nf1_cc &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_cc &lt;- summary(f1_cc)$coef\n\nd_tbl &lt;- rbind(\n  data.table(desc = \"full data\", par = rownames(coef_f1_ref), coef_f1_ref),\n  data.table(desc = \"complete case\", par = rownames(coef_f1_cc), coef_f1_cc)\n)\nd_tbl[, mu_se := sprintf(\"%.2f (%.3f)\", Estimate, `Std. Error`)]\nd_tbl[, par := factor(par, levels = c(\"(Intercept)\", \"x\", \"a\"))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, desc ~ par, value.var = \"mu_se\")\n))\n\n\n\n\n\ndesc\n(Intercept)\nx\na\n\n\n\n\ncomplete case\n0.41 (0.015)\n0.29 (0.015)\n0.20 (0.016)\n\n\nfull data\n0.41 (0.014)\n0.30 (0.013)\n0.19 (0.015)\n\n\n\n\n\nWe can use multiple imputation (which assumes MAR) for both the MAR and MCAR setting (the latter being a special case of the former). The mice package will default to predicting missing columns on all other variables in the data in line with attempting to maximal uncertainty. We can see that there isn’t really any benefit to imputation if the missing data mechanism is MCAR.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/missing-ex-01.stan\")\n\nd &lt;- get_data(\n    1e5, par,  \n    f_y = function(par, x, a, ae){\n      eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n      eta\n    })\n# missingness is indep process\nd[, m := rbinom(.N, 1, 0.2)]\n\nd_bin &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# full data\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_ref &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\nCode\nd_post_ref &lt;- data.table(f1_ref$draws(variables = \"b\", format = \"matrix\"))\nd_post_ref[, desc := \"full data\"]\n# d_post_ref[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\nd_bin &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# complete case\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_cc &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_cc &lt;- data.table(f1_cc$draws(variables = \"b\", format = \"matrix\"))\nd_post_cc[, desc := \"complete case\"]\n# d_post_cc[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\n# number that are missing\n# d[, .N, keyby = m]\n\n# imputation sets\nd_imp &lt;- copy(d[, .(x, a, y, m)])\nd_imp[m == 1, y := NA]\nd_imp[, m := NULL]\nn_imp &lt;- 50\n# dumb mice needs factor if you use logreg\nd_imp[, `:=`(x = factor(x), a = factor(a), y = factor(y))]\nl_imp &lt;- mice(d_imp, m = n_imp, \n              method = \"logreg\",\n              seed = 23109, printFlag = F)\n# print(l_imp)\ni &lt;- 1\n\nd_post_imp &lt;- rbindlist(mclapply(1:n_imp, function(i){\n  \n  # pick up the imputed data set\n  d_cur &lt;- data.table(complete(l_imp, i))\n  d_cur[, `:=`(x=as.numeric(as.character(x)),\n               a=as.numeric(as.character(a)),\n               y=as.numeric(as.character(y)))]\n  \n  d_bin &lt;- d_cur[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n  # full (imputed) data\n  ld &lt;- list(\n    N_obs = nrow(d_bin),\n    y = d_bin[, y], n = d_bin[, n], P = 3,\n    X_obs = model.matrix(~ x + a, data = d_bin),\n    prior_only = 0\n  )\n\n  snk &lt;- capture.output(\n    f1_imp &lt;- m1$sample(\n      ld, iter_warmup = 1000, iter_sampling = 1000,\n      parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n      max_treedepth = 10)\n  )\n  \n  d_post &lt;- data.table(f1_imp$draws(variables = \"b\", format = \"matrix\"))\n  d_post\n}), idcol = \"id_imp\")\n\nd_post_imp[, desc := \"mi\"]\n# d_post_imp[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\n\n\n\nPosterior inference on parameters for full data, complete case and MI\nd_fig &lt;- rbind(\n  d_post_ref, d_post_cc, d_post_imp, fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = c(\"desc\", \"id_imp\"))\nd_fig[variable == \"b[1]\", variable := \"(Intercept)\"]\nd_fig[variable == \"b[2]\", variable := \"x\"]\nd_fig[variable == \"b[3]\", variable := \"a\"]\nd_fig[, variable := factor(variable, levels = c(\"(Intercept)\", \"x\", \"a\"))]\nd_fig[, desc := factor(desc, levels = c(\"full data\", \"complete case\", \"mi\"))]\n\nggplot(data = d_fig, aes(x = value, group = desc, col = desc)) +\n  geom_density() +\n  geom_vline(\n    data = d_fig[, .(mu = mean(value)), keyby = .(desc, variable)],\n    aes(xintercept = mu, group = desc, col = desc)\n  ) +\n  geom_vline(\n    data = d_fig[desc == \"full data\", .(mu = mean(value)), keyby = .(variable)],\n    aes(xintercept = mu), col = 2, lwd = 0.4\n  ) +\n  facet_wrap(desc~variable) +\n  scale_color_discrete(\"\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFigure 3: Posterior inference on parameters for full data, complete case and MI",
    "crumbs": [
      "Design notes",
      "Missingness considerations"
    ]
  },
  {
    "objectID": "notebooks/design-notes-07.html#missing-at-random",
    "href": "notebooks/design-notes-07.html#missing-at-random",
    "title": "Missingness considerations",
    "section": "Missing at random",
    "text": "Missing at random\nFor mar, the probability of missingness depends only on the observed data.\nIn the Figure 4 (a) DAG, the indicator of missingness arises as a function of the exposure (\\(x\\)). You could think of this as the possibility of more missingness in the treatment relative to that in the control arm. Again, we would not observe the outcome for those records with \\(m=1\\). From the DAG you can see that \\(y\\) and \\(m\\) are conditionally independent given \\(x\\). Given that we include \\(x\\) in the model, the estimates for the treatment effect will be unbiased.\n\n\n\n\n\n\n\n\n\n\n\n(a) DAG MAR\n\n\n\n\n\n\n\n\n\n\n\n(b) Model MAR\n\n\n\n\n\n\n\nFigure 4: MAR\n\n\n\n\n\nCode\nd &lt;- get_data(\n  1e5, \n  par, \n  f_y = function(par, x, a, ae){\n    eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n    eta\n    })\n\n# missingness is a function of observed covariates\nf_mar &lt;- function(par, x, a){\n  eta = -1 + 2*x\n  eta\n}\n\nd[, eta_m := f_mar(par, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\n\nIn the simulated data, cross tabulating \\(y\\) and \\(m\\) (the observed data and the indicator of missingness) indicates they are dependent.\n\n\nCode\nd_tbl &lt;- table(d[, .(y, m)])\nX &lt;- chisq.test(d_tbl)\nX\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  d_tbl\nX-squared = 115.95, df = 1, p-value &lt; 2.2e-16\n\n\nBut when stratified by the exposure and baseline covariates, we cannot conclude any dependence.\n\n\nCode\nd_tbl &lt;- table(d[x == 1, .(y, m)])\nX &lt;- chisq.test(d_tbl)\nX\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  d_tbl\nX-squared = 0.16968, df = 1, p-value = 0.6804\n\n\nConditional on the covariates, the probability of missingness is the same for all levels of the outcome across all strata.\n\n\nCode\nd_tbl &lt;- CJ(x = 0:1, a = 0:1, y = 0:1)\nd_tbl[, p_mis := plogis(f_mar(par, x, a))]\n# d_tbl &lt;- unique(d_tbl[, .(x, y, p_mis)])\n\nknitr::kable(rbind(\n  dcast(d_tbl, x + a ~ y, value.var = \"p_mis\")\n), col.names = c(\"x\", \"a\",\"trt.success\", \"trt.failure\"), digits = 2)\n\n\n\n\n\nx\na\ntrt.success\ntrt.failure\n\n\n\n\n0\n0\n0.27\n0.27\n\n\n0\n1\n0.27\n0.27\n\n\n1\n0\n0.73\n0.73\n\n\n1\n1\n0.73\n0.73\n\n\n\n\n\nWhich means that the distribution of outcome will be approximately the same in each strata; the missingness is independent of the outcome conditional on the covariates.\n\n\nObserved mean response stratified by missingness status\nd_fig &lt;- copy(d)\nd_fig[, `:=`(x=factor(x, labels = c(\"ctl\", \"test\")), \n             a=factor(a, labels = c(\"&lt;50\", \"&gt;=50\")), \n             ae=factor(ae, labels = c(\"no-ae\", \"ae\")), \n             m = factor(m, labels = c(\"obs\", \"mis\")))]\n\nd_fig &lt;- d_fig[, .(y = sum(y), n = .N), keyby = .(x, a, m)]\nd_fig[, eta_obs := qlogis(y / n)]\n\nggplot(d_fig, \n       aes(x= x, y = eta_obs)) + \n  geom_bar(position=\"dodge\", stat = \"identity\") +\n  scale_x_discrete(\"Exposure\") +\n  scale_y_continuous(\"log-odds response\") +\n  facet_grid(a ~ m)\n\n\n\n\n\n\n\n\nFigure 5: Observed mean response\n\n\n\n\n\nSo, as long as we condition on the predictor of missingness, the complete case estimates are unbiased, albeit inefficient.\n\n\nCode\nd_m &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\nf1_ref &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_ref &lt;- summary(f1_ref)$coef\n  \n# only select the observed cases\nd_m &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\nf1_cc &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_cc &lt;- summary(f1_cc)$coef\n\nd_tbl &lt;- rbind(\n  data.table(desc = \"full data\", par = rownames(coef_f1_ref), coef_f1_ref),\n  data.table(desc = \"complete case\", par = rownames(coef_f1_cc), coef_f1_cc)\n)\nd_tbl[, mu_se := sprintf(\"%.2f (%.3f)\", Estimate, `Std. Error`)]\nd_tbl[, par := factor(par, levels = c(\"(Intercept)\", \"x\", \"a\"))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, desc ~ par, value.var = \"mu_se\")\n))\n\n\n\n\n\ndesc\n(Intercept)\nx\na\n\n\n\n\ncomplete case\n0.41 (0.018)\n0.30 (0.022)\n0.19 (0.020)\n\n\nfull data\n0.39 (0.014)\n0.31 (0.013)\n0.21 (0.015)\n\n\n\n\n\nSimilarly, if the missingness arises because of some baseline covariate, then the estimate for the exposure remains unbiased so long as we adjust for the relevant covariate.\n\n\nCode\nd &lt;- get_data(\n  1e5, \n  par, \n  f_y = function(par, x, a, ae){\n    eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n    eta\n    })\n\n# missingness is a function of observed covariates\nf_mar &lt;- function(par, y, x, a){\n  eta = -1 + 2*a\n  eta\n}\n\nd[, eta_m := f_mar(par, y, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\n\n\n\nCode\nd_m &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\nf1_ref &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_ref &lt;- summary(f1_ref)$coef\n  \n# only select the observed cases\nd_m &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\nf1_cc &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_cc &lt;- summary(f1_cc)$coef\n\nd_tbl &lt;- rbind(\n  data.table(desc = \"full data\", par = rownames(coef_f1_ref), coef_f1_ref),\n  data.table(desc = \"complete case\", par = rownames(coef_f1_cc), coef_f1_cc)\n)\nd_tbl[, mu_se := sprintf(\"%.2f (%.3f)\", Estimate, `Std. Error`)]\nd_tbl[, par := factor(par, levels = c(\"(Intercept)\", \"x\", \"a\"))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, desc ~ par, value.var = \"mu_se\")\n))\n\n\n\n\n\ndesc\n(Intercept)\nx\na\n\n\n\n\ncomplete case\n0.40 (0.017)\n0.29 (0.021)\n0.21 (0.021)\n\n\nfull data\n0.39 (0.014)\n0.30 (0.013)\n0.21 (0.014)\n\n\n\n\n\nFor mcar and mar, the missing data mechanism is referred to as ignorable because we don’t need to specify a model for the missingness in order to make valid inference. We can again use multiple imputation but because we have conditioned the model correctly, there still isn’t any real benefit in the multiple imputation approach.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/missing-ex-01.stan\")\n\nd &lt;- get_data(\n    1e5, par,\n    f_y = function(par, x, a, ae){\n      eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n      eta\n    })\n# missingness is mar\n# a function of observed covariates\nf_mar &lt;- function(par, x, a){\n  eta = -1 + 2*x\n  eta\n}\nd[, eta_m := f_mar(par, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\n\nd_bin &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# full data\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_ref &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_ref &lt;- data.table(f1_ref$draws(variables = \"b\", format = \"matrix\"))\nd_post_ref[, desc := \"full data\"]\n# d_post_ref[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\nd_bin &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# complete case\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_cc &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_cc &lt;- data.table(f1_cc$draws(variables = \"b\", format = \"matrix\"))\nd_post_cc[, desc := \"complete case\"]\n# d_post_cc[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\n# number that are missing\n# d[, .N, keyby = m]\n\n# imputation sets\nd_imp &lt;- copy(d[, .(x, a, y, m)])\nd_imp[m == 1, y := NA]\nd_imp[, m := NULL]\n# dumb mice needs factor if you use logreg\nd_imp[, `:=`(x = factor(x), a = factor(a), y = factor(y))]\nn_imp &lt;- 50\nl_imp &lt;- mice(d_imp, m = n_imp, \n              method = \"logreg\",\n              seed = 23109, printFlag = F)\n# print(l_imp)\ni &lt;- 1\n\nd_post_imp &lt;- rbindlist(mclapply(1:n_imp, function(i){\n  \n  # pick up the imputed data set\n  d_cur &lt;- data.table(complete(l_imp, i))\n  d_cur[, `:=`(x=as.numeric(as.character(x)),\n               a=as.numeric(as.character(a)),\n               y=as.numeric(as.character(y)))]\n  \n  d_bin &lt;- d_cur[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n  # full (imputed) data\n  ld &lt;- list(\n    N_obs = nrow(d_bin),\n    y = d_bin[, y], n = d_bin[, n], P = 3,\n    X_obs = model.matrix(~ x + a, data = d_bin),\n    prior_only = 0\n  )\n\n  snk &lt;- capture.output(\n    f1_imp &lt;- m1$sample(\n      ld, iter_warmup = 1000, iter_sampling = 1000,\n      parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n      max_treedepth = 10)\n  )\n  \n  d_post &lt;- data.table(f1_imp$draws(variables = \"b\", format = \"matrix\"))\n  d_post\n}), idcol = \"id_imp\")\n\nd_post_imp[, desc := \"mi\"]\n# d_post_imp[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\n\n\n\nPosterior inference on parameters for full data, complete case and MI\nd_fig &lt;- rbind(\n  d_post_ref, d_post_cc, d_post_imp, fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = c(\"desc\", \"id_imp\"))\nd_fig[variable == \"b[1]\", variable := \"(Intercept)\"]\nd_fig[variable == \"b[2]\", variable := \"x\"]\nd_fig[variable == \"b[3]\", variable := \"a\"]\nd_fig[, variable := factor(variable, levels = c(\"(Intercept)\", \"x\", \"a\"))]\nd_fig[, desc := factor(desc, levels = c(\"full data\", \"complete case\", \"mi\"))]\n\nggplot(data = d_fig, aes(x = value, group = desc, col = desc)) +\n  geom_density() +\n  geom_vline(\n    data = d_fig[, .(mu = mean(value)), keyby = .(desc, variable)],\n    aes(xintercept = mu, group = desc, col = desc)\n  ) +\n  geom_vline(\n    data = d_fig[desc == \"full data\", .(mu = mean(value)), keyby = .(variable)],\n    aes(xintercept = mu), col = 2, lwd = 0.4\n  ) +\n  facet_wrap(desc~variable) +\n  scale_color_discrete(\"\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFigure 6: Posterior inference on parameters for full data, complete case and MI",
    "crumbs": [
      "Design notes",
      "Missingness considerations"
    ]
  },
  {
    "objectID": "notebooks/design-notes-07.html#missing-not-at-random",
    "href": "notebooks/design-notes-07.html#missing-not-at-random",
    "title": "Missingness considerations",
    "section": "Missing not at random",
    "text": "Missing not at random\nIf neither mcar or mar hold, then the data are mnar. For mnar, the missing value tells us something about what the value might have been; missingness here is informative, e.g. a salary reporting - people who get paid more tend not to disclose their salary.\n\n\n\n\n\n\n\n\n\n\n\n(a) DAG MNAR\n\n\n\n\n\n\n\n\n\n\n\n(b) Model MNAR\n\n\n\n\n\n\n\nFigure 7: MNAR\n\n\n\n\n\nCode\nd &lt;- get_data(\n  1e5, \n  par, \n  f_y = function(par, x, a, ae){\n    eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n    eta\n    })\n\n# missingness is a function of observed covariates and outcome\nf_mnar &lt;- function(par, y, x, a){\n  eta = -1 + 0.5*x + 0.5*y\n  eta\n}\n\nd[, eta_m := f_mnar(par, y, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\n\nThe probability of the outcome being missing is now conditional on what would have been observed in the outcome as well as the exposure level with a higher likelihood of missingness in people who would have treatment failure (\\(y = 1\\) here).\n\n\nCode\nd_tbl &lt;- CJ(y = 0:1, x = 0:1, a = 0:1)\nd_tbl[, p_mis := plogis(f_mnar(par, y, x, a))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, x + a ~ y, value.var = \"p_mis\")\n), col.names = c(\"x\", \"a\", \"trt.success\", \"trt.failure\"), digits = 2)\n\n\n\n\n\nx\na\ntrt.success\ntrt.failure\n\n\n\n\n0\n0\n0.27\n0.38\n\n\n0\n1\n0.27\n0.38\n\n\n1\n0\n0.38\n0.50\n\n\n1\n1\n0.38\n0.50\n\n\n\n\n\nAs a consequence, the distribution of the outcome is no longer same in the observed and the missing data.\n\n\nObserved mean response stratified by missingness status\nd_fig &lt;- copy(d)\nd_fig[, `:=`(x=factor(x, labels = c(\"ctl\", \"test\")), \n             a=factor(a, labels = c(\"&lt;50\", \"&gt;=50\")), \n             ae=factor(ae, labels = c(\"no-ae\", \"ae\")), \n             m = factor(m, labels = c(\"obs\", \"mis\")))]\n\nd_fig &lt;- d_fig[, .(y = sum(y), n = .N), keyby = .(x, a, m)]\nd_fig[, eta_obs := qlogis(y / n)]\n\nggplot(d_fig, \n       aes(x= x, y = eta_obs)) + \n  geom_bar(position=\"dodge\", stat = \"identity\") +\n  scale_x_discrete(\"Exposure\") +\n  scale_y_continuous(\"log-odds response\") +\n  facet_grid(a ~ m)\n\n\n\n\n\n\n\n\nFigure 8: Observed mean response\n\n\n\n\n\nNow, even after we have conditioned on \\(x\\) a dependency exists between \\(y\\) and \\(m\\). For example, people who have early signs of treatment failure (or success) might choose to leave the study. Under this setting, the treatment effect will generally be biased.\n\n\nCode\nd_m &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\nf1_ref &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_ref &lt;- summary(f1_ref)$coef\n  \n# only select the observed cases\nd_m &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\nf1_cc &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_cc &lt;- summary(f1_cc)$coef\n\nd_tbl &lt;- rbind(\n  data.table(desc = \"full data\", par = rownames(coef_f1_ref), coef_f1_ref),\n  data.table(desc = \"complete case\", par = rownames(coef_f1_cc), coef_f1_cc)\n)\nd_tbl[, mu_se := sprintf(\"%.2f (%.3f)\", Estimate, `Std. Error`)]\nd_tbl[, par := factor(par, levels = c(\"(Intercept)\", \"x\", \"a\"))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, desc ~ par, value.var = \"mu_se\")\n))\n\n\n\n\n\ndesc\n(Intercept)\nx\na\n\n\n\n\ncomplete case\n0.24 (0.017)\n0.24 (0.017)\n0.17 (0.018)\n\n\nfull data\n0.40 (0.014)\n0.32 (0.013)\n0.18 (0.014)\n\n\n\n\n\nAgain, we can try multiple imputation but because MI assumes MAR, things go wrong without some additional assumptions.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/missing-ex-01.stan\")\n\nd &lt;- get_data(\n    1e5, par,\n    f_y = function(par, x, a, ae){\n      eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n      eta\n    })\n# missingness is a function of observed covariates and outcome\nf_mnar &lt;- function(par, y, x, a){\n  eta = -1 + 0.5*x + 0.5*y\n  eta\n}\n\nd[, eta_m := f_mnar(par, y, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\nd_bin &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# full data\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_ref &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_ref &lt;- data.table(f1_ref$draws(variables = \"b\", format = \"matrix\"))\nd_post_ref[, desc := \"full data\"]\n\nd_bin &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# complete case\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_cc &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_cc &lt;- data.table(f1_cc$draws(variables = \"b\", format = \"matrix\"))\nd_post_cc[, desc := \"complete case\"]\n\n# number that are missing\n# d[, .N, keyby = m]\n\n# imputation sets\nd_imp &lt;- copy(d[, .(x, a, y, m)])\nd_imp[m == 1, y := NA]\nd_imp[, m := NULL]\nn_imp &lt;- 50\n# dumb mice needs factor if you use logreg\nd_imp[, `:=`(x = factor(x), a = factor(a), y = factor(y))]\nl_imp &lt;- mice(d_imp, m = n_imp, \n              method = \"logreg\",\n              seed = 23109, printFlag = F)\n# print(l_imp)\ni &lt;- 1\n\nd_post_imp &lt;- rbindlist(mclapply(1:n_imp, function(i){\n  \n  # pick up the imputed data set\n  d_cur &lt;- data.table(complete(l_imp, i))\n  d_cur[, `:=`(x=as.numeric(as.character(x)),\n               a=as.numeric(as.character(a)),\n               y=as.numeric(as.character(y)))]\n  \n  d_bin &lt;- d_cur[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n  # full (imputed) data\n  ld &lt;- list(\n    N_obs = nrow(d_bin),\n    y = d_bin[, y], n = d_bin[, n], P = 3,\n    X_obs = model.matrix(~ x + a, data = d_bin),\n    prior_only = 0\n  )\n\n  snk &lt;- capture.output(\n    f1_imp &lt;- m1$sample(\n      ld, iter_warmup = 1000, iter_sampling = 1000,\n      parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n      max_treedepth = 10)\n  )\n  \n  d_post &lt;- data.table(f1_imp$draws(variables = \"b\", format = \"matrix\"))\n  d_post\n}), idcol = \"id_imp\")\n\nd_post_imp[, desc := \"mi\"]\n\n\n\n\nPosterior inference on parameters for full data, complete case and MI\nd_fig &lt;- rbind(\n  d_post_ref, d_post_cc, d_post_imp, fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = c(\"desc\", \"id_imp\"))\nd_fig[variable == \"b[1]\", variable := \"(Intercept)\"]\nd_fig[variable == \"b[2]\", variable := \"x\"]\nd_fig[variable == \"b[3]\", variable := \"a\"]\nd_fig[, variable := factor(variable, levels = c(\"(Intercept)\", \"x\", \"a\"))]\nd_fig[, desc := factor(desc, levels = c(\"full data\", \"complete case\", \"mi\"))]\n\nggplot(data = d_fig, aes(x = value, group = desc, col = desc)) +\n  geom_density() +\n  geom_vline(\n    data = d_fig[, .(mu = mean(value)), keyby = .(desc, variable)],\n    aes(xintercept = mu, group = desc, col = desc)\n  ) +\n  geom_vline(\n    data = d_fig[desc == \"full data\", .(mu = mean(value)), keyby = .(variable)],\n    aes(xintercept = mu), col = 2, lwd = 0.4\n  ) +\n  facet_wrap(desc~variable) +\n  scale_color_discrete(\"\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFigure 9: Posterior inference on parameters for full data, complete case and MI\n\n\n\n\n\nA complete case analysis will be unbiased for the treatment effect of interest when the missingness is not depenendent on that term. However, the parameter estimates for the baseline log-odds (intercept) and any term on which the missingness is dependent will be biased.\nThese results are specific to logistic regression (or more accurately odds ratios, which are a relative measure) and are in contrast to linear regression where the treatment effect will be biased if the missingness is dependent on the outcome regardless of whether adjustment is made. In linear regression the treatment effect from a complete case analysis will be biased if the missingness is due to (1) the outcome alone (2) the outcome and treatment exposure (3) the outcome and baseline factors and is only unbiased under MCAR and when the missingness depends only on the exposure.",
    "crumbs": [
      "Design notes",
      "Missingness considerations"
    ]
  },
  {
    "objectID": "notebooks/design-notes-09.html",
    "href": "notebooks/design-notes-09.html",
    "title": "Orthonormal contrasts",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nConsider the standard one factor factorial setup where we have a grand mean (as in the mean of the factor level means) and deviations for main effects:\n\\[\n\\begin{aligned}\n\\eta = 1^\\top \\mu + X_a \\alpha + X_b \\alpha + X_c \\gamma\n\\end{aligned}\n\\]\nwhere \\(X_a\\) is the design matrix.\nIt might be tempting setup a design matrix with a column for every parameter, but the OLS solution involves inverting \\(X^\\top X\\) which you cannot do as the rank of \\(X\\) is less than the number of columns in \\(X\\):\nX &lt;- cbind(1, diag(3))\n# in ols, the estimator involves inverting the design matrix\ntryCatch(\n  {\n    solve(t(X)%*%X)\n  } ,\n  error = function(z){\n    message(z, \"\\n\")\n  }\n  \n)\n\nError in solve.default(t(X) %*% X): system is computationally singular: reciprocal condition number = 1.38778e-17\nhowever, if we use the intercept as the reference group (or introduce a sum to zero constraint) then we are fine\nX &lt;- cbind(1, diag(3)[,2:3])\n# in ols, the estimator involves inverting the design matrix\nsolve(t(X)%*%X)\n\n     [,1] [,2] [,3]\n[1,]    1   -1   -1\n[2,]   -1    2    1\n[3,]   -1    1    2\nContrasts define a specific linear combination of parameters and affect their interpretation. When treatment contrasts are adopted with a design matrix that includes main and interaction effects for \\(a\\) with 3 levels and \\(b\\) with 2 levels we have\na &lt;- factor(1:3)\nb &lt;- factor(1:2)\nd &lt;- CJ(a, b)\nX &lt;- model.matrix(~a * b, data = d)\nX\n\n  (Intercept) a2 a3 b2 a2:b2 a3:b2\n1           1  0  0  0     0     0\n2           1  0  0  1     0     0\n3           1  1  0  0     0     0\n4           1  1  0  1     1     0\n5           1  0  1  0     0     0\n6           1  0  1  1     0     1\nattr(,\"assign\")\n[1] 0 1 1 2 3 3\nattr(,\"contrasts\")\nattr(,\"contrasts\")$a\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$b\n[1] \"contr.treatment\"\nand for deviation (sum to zero) contrasts, which is what would be used for the anova setup, it would look like\na &lt;- factor(1:3)\nb &lt;- factor(1:2)\nd &lt;- CJ(a, b)\ncontrasts(d$a) &lt;- contr.sum(3)\ncontrasts(d$b) &lt;- contr.sum(2)\nX &lt;- model.matrix(~a * b, data = d)\nX\n\n  (Intercept) a1 a2 b1 a1:b1 a2:b1\n1           1  1  0  1     1     0\n2           1  1  0 -1    -1     0\n3           1  0  1  1     0     1\n4           1  0  1 -1     0    -1\n5           1 -1 -1  1    -1    -1\n6           1 -1 -1 -1     1     1\nattr(,\"assign\")\n[1] 0 1 1 2 3 3\nattr(,\"contrasts\")\nattr(,\"contrasts\")$a\n  [,1] [,2]\n1    1    0\n2    0    1\n3   -1   -1\n\nattr(,\"contrasts\")$b\n  [,1]\n1    1\n2   -1\nFor treatment contrasts, the intercept represents the mean of the reference group, taken to be when \\(a\\) and \\(b\\) are both at their first level. For deviation contrasts the intercept becomes the grand mean, equating to the mean of the group means, not the mean value of the outcome in the dataset.\nWith classic ANOVA, a sum to zero constraint allows us to overcome the rank deficient nature of the design matrix.\nWhen using the treatment contrasts, the second and third levels of \\(a\\) are explicit in the design matrix whereas for the deviation contrasts, the first and second levels appear. For example, with a single factor model:\nK_a &lt;- 4\n# means at levels of a\nb_a &lt;- c(-1, 3, 2, 1)\nN &lt;- 1e6\na &lt;- sample(1:K_a, size = N, replace = T, prob = c(0.3, 0.2, 0.4, 0.1))\nd &lt;- data.table(a = factor(a))\nd[, mu := b_a[a]]\nd[, y := rnorm(.N, mu, 1)]\n\n# sum to zero/deviation contrasts as used for anova\ncontrasts(d$a) &lt;- contr.sum(K_a)\nf1 &lt;- lm(y ~ a, data = d)\nThe coefficients include an intercept and deviations for the first three levels of \\(a\\)\ncoef(f1)\n\n(Intercept)          a1          a2          a3 \n  1.2501884  -2.2485356   1.7492881   0.7522786\nFor the deviation contrasts, the mean for the first level of \\(a\\) is computed as the grand mean, plus the first parameter estimate and similarly for the second and third. The mean for the last level of \\(a\\) is implied as the grand mean minus the sum of the first three terms, hence sum to zero.\nd_new &lt;- CJ(a = factor(1:K_a))\ncontrasts(d_new$a) &lt;-  contr.sum(K_a)\nX &lt;- model.matrix(~a, data = d_new)\nX\n\n  (Intercept) a1 a2 a3\n1           1  1  0  0\n2           1  0  1  0\n3           1  0  0  1\n4           1 -1 -1 -1\nattr(,\"assign\")\n[1] 0 1 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$a\n  [,1] [,2] [,3]\n1    1    0    0\n2    0    1    0\n3    0    0    1\n4   -1   -1   -1\nand \\(\\sum_{i=1}^{K_a} \\alpha_i = 0\\) which we can derive empirically by calculating the all K_a group means, subtracting the grand mean from each and taking the sum:\n(mu_a_hat &lt;- t(model.matrix(~a, data = d_new) %*% coef(f1)))\n\n              1        2        3         4\n[1,] -0.9983472 2.999476 2.002467 0.9971573\n\nrbind(\n  tru = b_a,\n  estimate = as.numeric(round(mu_a_hat, 3))\n)\n\n           [,1]  [,2]  [,3]  [,4]\ntru      -1.000 3.000 2.000 1.000\nestimate -0.998 2.999 2.002 0.997\nwhich sum to zero:\nCode\nround(sum(mu_a_hat - coef(f1)[1]), 3)  \n\n\n[1] 0\nThe above creates an inconvenience for the Bayesian who would like to (i) play frequentist in their insistence with differentiating fixed from random effects and (ii) place equal prior weights to each group of parameters. We could (and often do) respond to this by fixing the reference parameter at zero to overcome the identification issue, but that also puts a different prior weight on this reference parameter in relation to the other parameters within the group. An alternative to arbitrarily fixing one of the factor level parameters to zero is to project the \\(K_a\\) dimension parameter space associated with the first factor into a \\(K_a - 1\\) dimensional space in a way that will enforce the same marginal prior on all \\(K_a\\) terms.\nThe way that the sum-to-zero constraint is achieved is by placing a prior that has a negative correlation across the effects:\n\\[\n\\begin{aligned}\n\\Sigma_a = \\mathbb{I}_a - J_a / K_a\n\\end{aligned}\n\\]\nwhere \\(J_a\\) is a matrix of ones of dimension \\(K_a \\times K_a\\), leading to, for example, a covariance matrix such as the following:\n# group levels\nK_a &lt;- 3\nJ &lt;- matrix(1, K_a, K_a)\nS_a &lt;- diag(K_a) - J / K_a\n# cov2cor(S_a)\nS_a\n\n           [,1]       [,2]       [,3]\n[1,]  0.6666667 -0.3333333 -0.3333333\n[2,] -0.3333333  0.6666667 -0.3333333\n[3,] -0.3333333 -0.3333333  0.6666667\nwhere again we are just considering a single factor at the moment. As a test, we can generate draws from a multivariate normal distribution using this covariance matrix and observe that they will sum to zero:\nu &lt;- mvtnorm::rmvnorm(3, rep(0, K_a), S_a)\n# final column is the sum of the draws:\nround(cbind(u, rowSums(u)), 3)\n\n      [,1]   [,2]  [,3] [,4]\n[1,] 0.455 -1.234 0.779    0\n[2,] 0.783 -1.304 0.521    0\n[3,] 0.657 -0.945 0.287    0\n\\(\\Sigma_a\\) is not full rank, but it can be decomposed using its set of the eigenvectors. Since \\(\\Sigma_a\\) is rank \\(K_a - 1 = 2\\), there will only be two non-zero eigenvalues. Both of the eigenvalues are equal to 1. Below, we construct \\(\\Sigma_a\\) as the product of \\(Q_a\\) and \\(\\Lambda\\) where \\(Q_a\\) is a matrix formed from \\(K_a - 1\\) eigenvectors that correspond to the non-zero eigenvalues of \\(\\Sigma_a\\). In this setting, \\(\\Lambda = \\mathbb{I}_{K_a - 1}\\).\n# for symmetric matrices, svd equiv to eigen\n# eigen values are sorted in decreasing order so we drop the last one\nsvd_S_a &lt;- svd(S_a)\n# eigenvectors\nQ_a &lt;- svd_S_a$v\nQ_a &lt;- Q_a[, 1:(K_a - 1)]\n# original setup for S_a\nQ_a %*% diag(K_a - 1) %*% t(Q_a)\n\n           [,1]       [,2]       [,3]\n[1,]  0.6666667 -0.3333333 -0.3333333\n[2,] -0.3333333  0.6666667 -0.3333333\n[3,] -0.3333333 -0.3333333  0.6666667\nThis allows us to define a new vector of \\(K_a - 1\\) parameters \\(\\alpha^*\\):\n\\[\n\\begin{aligned}\n\\alpha^* = Q_a^\\top \\alpha\n\\end{aligned}\n\\]\nthat sum to zero due to \\(Q_a\\):\nround(t(Q_a), 3)\n\n       [,1]   [,2]  [,3]\n[1,] -0.816  0.408 0.408\n[2,]  0.000 -0.707 0.707\nThe \\(Q_a\\) defines the contrasts that are orthonormal and allow us to identify the \\(K_a - 1\\) parameters.\nArmed with the above, we can now take our original tempting setup for the design matrix (i.e. with a column for every parameter) and convert it to a new design matrix that maps \\(\\alpha^*\\) into the observations:\n(X &lt;- diag(K_a) )\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n\n(X_star &lt;- cbind(X %*% Q_a))\n\n           [,1]          [,2]\n[1,] -0.8164966  4.108230e-17\n[2,]  0.4082483 -7.071068e-01\n[3,]  0.4082483  7.071068e-01\nTo go from the parameters in their original space to the parameters in the reduced dimensional space and back again:\nCode\n# original parameters constrained to sum to zero\nb_a &lt;- c(-1, 0.75, 0.25)\n# representation in lower dimensional space\nb_a_star &lt;- t(Q_a) %*% b_a\n\n# transformed back to b_a\nX_star %*% b_a_star \n\n\n      [,1]\n[1,] -1.00\n[2,]  0.75\n[3,]  0.25\nAn implementation for the single factor case follows:\nget_data &lt;- function(\n    N = 100,\n    K_a = 3,\n    mu = 1,\n    b_a = c(-1, 0.25, 0.75)\n    ){\n  \n  a = sample(1:K_a, size = N, replace = T)\n  d &lt;- data.table(a)\n  d[, eta := mu + b_a[a]]\n  d[, y := rbinom(N, 1, plogis(eta))]\n  \n  # saturated design matrix\n  X_a &lt;- diag(K_a)\n  \n  # correlation matrix to enforce sum to zero\n  J &lt;- matrix(1, K_a, K_a)\n  S_a &lt;- diag(K_a) - J / K_a \n  \n  # decomposition\n  # eigen vectors\n  Q_a &lt;- eigen(S_a)$vector[, 1:(K_a - 1)]\n\n  # full rank design\n  X_a_s &lt;- X_a %*% Q_a\n  \n  list(\n    d = d, K_a = K_a, \n    mu = mu, b_a = b_a,\n    X_a = X_a, X_a_s = X_a_s,\n    S_a = S_a, Q_a = Q_a\n  )\n}\nLogistic regression\n// Model for:\n// independent estimates of treatment arm by subgroup means\ndata {\n  int N;\n  array[N] int y;\n  // arm index\n  array[N] int x1trt;\n  // dimension of design matrix\n  int ncX1des;\n  int nrX1des;\n  matrix[nrX1des, ncX1des] X1des;\n  vector[ncX1des] sx1;\n  int prior_only;\n}\ntransformed data {\n  // build full design matrices\n  matrix[N, ncX1des] X1 = X1des[x1trt];\n}\nparameters{\n  real mu;\n  vector[ncX1des] bx1;\n}\ntransformed parameters{ \n  vector[N] eta = mu + X1*bx1;\n}\nmodel{\n  target += logistic_lpdf(mu | 0, 1);\n  target += normal_lpdf(bx1 | 0, sx1);\n  \n  if(!prior_only){\n    target += bernoulli_logit_lpmf(y | eta);  \n  }\n}\ngenerated quantities{\n}\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/note-09-logistic.stan\")\n\nl1 &lt;- get_data(\n  N = 1e4, K_a = 5, mu = 0.5, \n  b_a = c(-2, -1, 0, 1, 2)\n  )\n\n# would be more efficient to transform into a binomial likelihood\n# but keeping bernoulli for now since it allows me to think about\n# unit level data (not sure if that will be necessary though)\nld &lt;- list(\n  N = length(l1$d$y),\n  y = l1$d$y,\n  # \n  x1trt = l1$d$a,\n  nrX1des = nrow(l1$X_a_s), ncX1des = ncol(l1$X_a_s),\n  X1des = l1$X_a_s,\n  sx1 = rep(1, ncol(l1$X_a_s)),\n  prior_only = 1\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 12.4 seconds.\nChain 2 finished in 12.7 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 12.5 seconds.\nTotal execution time: 12.8 seconds.\n\n\nCode\nf1$summary(variables = c(\"mu\", \"bx1\"))\n\n\n# A tibble: 5 × 10\n  variable     mean    median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 mu        0.00709  0.0122   1.80   1.63 -2.90  2.96  1.00    6692.    3529.\n2 bx1[1]    0.00696 -0.0139   1.00   1.01 -1.61  1.65  1.00    6903.    4816.\n3 bx1[2]    0.0114   0.00891  0.995  1.00 -1.64  1.64  1.00    7779.    4594.\n4 bx1[3]   -0.00632 -0.00891  1.00   1.01 -1.63  1.63  1.00    7469.    4093.\n5 bx1[4]   -0.00951 -0.000821 1.01   1.03 -1.68  1.65  1.00    7889.    4745.\nTo transform the parameter estimates back to the group means that we are interested in, we need to compute the product of the parameters and the unique entries from the design matrix.\nIn theory, these should all have the same prior weight, which appears to be the case as shown below, Figure 1:\nPriors on group offsets\nm_post_s &lt;- f1$draws(variables = c(\"bx1\"), format = \"matrix\")\npost_mu &lt;- m_post_s %*% t(cbind(l1$X_a_s))\n\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a)))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  facet_wrap(~variable, ncol = 1) \n\n\n\n\n\n\n\n\nFigure 1: Priors on group means\nRun the model to see if we get close to the known (true) parameters although they won’t be immediately apparent from the summary:\nCode\nld$prior_only &lt;- 0\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 13.0 seconds.\nChain 2 finished in 13.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 13.1 seconds.\nTotal execution time: 13.3 seconds.\n\n\nCode\n# these are the parameters in the reduced dimensional space\nf1$summary(variables = c(\"mu\", \"bx1\"))\n\n\n# A tibble: 5 × 10\n  variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 mu        0.474  0.474 0.0262 0.0265  0.432  0.517  1.00    3786.    3336.\n2 bx1[1]   -0.894 -0.894 0.0455 0.0446 -0.970 -0.821  1.00    4262.    3145.\n3 bx1[2]    1.28   1.27  0.0747 0.0752  1.16   1.40   1.00    3844.    2996.\n4 bx1[3]   -2.19  -2.19  0.0577 0.0550 -2.28  -2.09   1.00    4204.    2862.\n5 bx1[4]   -1.59  -1.59  0.0550 0.0536 -1.68  -1.50   1.00    3828.    2703.\nObviously, the results won’t align exactly with the true values, but they should be somewhere close, see Figure 2:\nParameter posterior density\nm_post_s &lt;- f1$draws(variables = c(\"mu\", \"bx1\"), format = \"matrix\")\npost_mu &lt;- m_post_s %*% t(cbind(1, l1$X_a_s))\n\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a)))]\n\nd_tru &lt;- data.table(\n  a = 1:l1$K_a\n)\nd_tru[, eta := l1$mu + l1$b_a[a]]\nd_tru[, variable := factor(paste0(\"V\", a))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru, \n              aes(xintercept = eta), col = 2,\n              lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(breaks = seq(-3, 3, by = 0.5))\n\n\n\n\n\n\n\n\nFigure 2: Parameter estimates for group level means\nParameter posterior density\nm_post_s &lt;- f1$draws(variables = c(\"bx1\"), format = \"matrix\")\npost_mu &lt;- m_post_s %*% t(cbind(l1$X_a_s))\n\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a)))]\n\nd_tru &lt;- data.table(\n  a = 1:l1$K_a\n)\nd_tru[, eta := l1$b_a[a]]\nd_tru[, variable := factor(paste0(\"V\", a))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru, \n              aes(xintercept = eta), col = 2,\n              lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(breaks = seq(-3, 3, by = 0.5))\n\n\n\n\n\n\n\n\nFigure 3: Parameter estimates for group level offsets",
    "crumbs": [
      "Design notes",
      "Orthonormal contrasts"
    ]
  },
  {
    "objectID": "notebooks/design-notes-09.html#two-factor-setup",
    "href": "notebooks/design-notes-09.html#two-factor-setup",
    "title": "Orthonormal contrasts",
    "section": "Two-factor setup",
    "text": "Two-factor setup\nHere we have two main effects and their associated interactions.\nI have kept this first implementation as a record of my initial mistake on columnwise vs rowwise specification of the interaction parameters.\nIf you look at the argument for b_ab you will see that the original values were -0.05, 0.05, 0.15, ... but now they have been revised to -0.05, 0.15, -0.1, ... with the original being rowwise and the corrected approach being columnwise.\nSo, the implementation in the final section (see get_data_alt right at the end of this note), which uses kronecker rather than construct_C_ab is the correct/preferred way to do this.\n\n\nRevised data generation function\nN = 100\nK_a = 3\nK_b = 2\nb0 = 1\n# effects are sum to zero\nb_a = c(0, -1, 1)\nb_b = c(-0.6, 0.6)\nb_ab = c(-0.05, 0.15, -0.1, 0.05, -0.15,  0.1)\n# b_ab = c(-0.05, 0.05, 0.15, -0.15,  0.1, -0.1)\n\nget_data &lt;- function(\n    N = 100,\n    K_a = 3,\n    K_b = 2,\n    b0 = 1,\n    # effects are sum to zero\n    b_a = c(0, -1, 1),\n    b_b = c(-0.6, 0.6),\n    b_ab = c(-0.05, 0.15, -0.1, 0.05, -0.15,  0.1)\n    # b_ab = c(-0.05, 0.05, 0.15, -0.15,  0.1, -0.1)\n    ){\n  \n  stopifnot(all.equal(0, sum(b_a), \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(0, sum(b_b), \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(0, sum(b_ab), \n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  # cols and rows should sum to zero otherwise following will not work\n  b_ab_matrix &lt;- matrix(b_ab, nrow = K_a, ncol = K_b)\n  stopifnot(all.equal(colSums(b_ab_matrix), rep(0, K_b),\n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(rowSums(b_ab_matrix), rep(0, K_a),\n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  # we could go down this avenue but the original parameters would never be \n  # recovered.\n  # b_ab_centered &lt;- b_ab_matrix -\n  #   rowMeans(b_ab_matrix) -\n  #   rep(colMeans(b_ab_matrix), each = K_a) +\n  #   mean(b_ab_matrix)\n  # b_ab_centered &lt;- as.vector(b_ab_centered)\n  \n  a = sample(1:K_a, size = N, replace = T)\n  b = sample(1:K_b, size = N, replace = T)\n  d &lt;- data.table(a, b)\n  \n  d[, b0 := b0]\n  d[, b_a := b_a[a]]\n  d[, b_b := b_b[b]]\n  d[, ix_b_ab := a + (K_a * (b - 1))]\n  d[, b_ab := b_ab[ix_b_ab]]\n  d[, eta := b0 + b_a + b_b + b_ab]\n\n  # e.g.  \n#   &gt; unique(d[order(b, a)])\n#        a     b    b0   b_a   b_b  b_ab   eta\n#    &lt;int&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n# 1:     1     1     1     0  -0.6  -0.2   0.2\n# 2:     2     1     1    -1  -0.6   0.0  -0.6\n# 3:     3     1     1     1  -0.6   0.6   2.0\n# 4:     1     2     1     0   0.4  -0.4   1.0\n# 5:     2     2     1    -1   0.4   0.2   0.6\n# 6:     3     2     1     1   0.4  -0.2   2.2\n  \n  cols_a &lt;- paste0(\"a\", 1:K_a)\n  cols_b &lt;- paste0(\"a\", 1:K_b)\n  cols_c &lt;- unique(d[order(b, a), paste0(\"a\",a,\"b\",b)])\n  \n  d[, y := rbinom(N, 1, plogis(eta))]\n  \n  # saturated design matrix\n  X_a &lt;- diag(K_a)\n  colnames(X_a) &lt;- cols_a\n  X_b &lt;- diag(K_b)\n  colnames(X_b) &lt;- cols_b\n  X_ab &lt;- diag(K_a * K_b)\n  colnames(X_ab) &lt;- cols_c\n\n  # correlation matrix to enforce sum to zero\n  S_a &lt;- diag(K_a) - (1 / K_a )\n  S_b &lt;- diag(K_b) - (1 / K_b )\n  S_ab &lt;- kronecker(S_a, S_b)\n  # should be rank 2 for a 1:3, b 1:2\n  # pracma::Rank(S_ab)\n  \n  # decomposition eigen vectors\n  Q_a &lt;- eigen(S_a)$vector[, 1:(K_a - 1)]\n  Q_b &lt;- eigen(S_b)$vector[, 1:(K_b - 1)]\n  # Q_ab &lt;- kronecker(Q_a, Q_b)\n  \n  # Ok, Q_ab as defined above will not allow me to recover the original\n  # paramters. Why this is I do not know. The following is a workaround.\n  \n  # All we are doing is building a matrix that will sum up the \n  # columns and the rows of the interaction parameters.\n  # We will then set that to zero and solve (i.e. compute the\n  # null space).\n  C_ab &lt;- construct_C_ab(K_a, K_b)\n\n  # Calculate the null space of C_ab\n  # Nullspace of C_ab gives the set of vectors st each vector\n  # in Q_ab results in C_ab v = 0\n  Q_ab &lt;- pracma::nullspace(C_ab)\n  \n  # transformed pars\n  b_a_s &lt;- t(Q_a) %*% b_a\n  b_b_s &lt;- t(Q_b) %*% b_b\n  b_ab_s &lt;- t(Q_ab) %*% b_ab\n\n  # full rank design\n  X_a_s &lt;- X_a %*% Q_a\n  X_b_s &lt;- X_b %*% Q_b\n  X_ab_s &lt;- X_ab %*% Q_ab\n\n  X_full_s &lt;- create_full_design(X_a_s, X_b_s, X_ab_s)\n  # round(X_full_s, 3)\n   \n  # Check\n  stopifnot(all.equal(as.numeric(X_a_s %*% b_a_s), b_a, \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(as.numeric(X_b_s %*% b_b_s), b_b, \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(as.numeric(X_ab_s %*% b_ab_s), b_ab, \n                      tolerance = sqrt(.Machine$double.eps)))\n  \n\n  list(\n    d = d, b0 = b0, \n    b_a = b_a, b_b = b_b, b_ab = b_ab, \n    b_a_s = b_a_s, b_b_s = b_b_s, b_ab_s = b_ab_s, \n    \n    K_a = K_a, K_b = K_b, \n    X_a = X_a, X_a_s = X_a_s, \n    X_b = X_b, X_b_s = X_b_s, \n    X_ab = X_ab, X_ab_s = X_ab_s, \n    X_full_s = X_full_s,\n    \n    S_a = S_a, S_b = S_b, S_ab = S_ab, \n    C_ab = C_ab, Q_a = Q_a, Q_b = Q_b, Q_ab = Q_ab \n  )\n}\n\n\nWe need some utility functions to stop this getting too messy.\n\n\nUtility functions\n# Utility function to create combinations of parameters (all columns and \n# all rows) that should sum to zero.\nconstruct_C_ab &lt;- function(K_a, K_b) {\n  # Total number of interaction parameters\n  n_params &lt;- K_a * K_b\n  \n  # Number of constraints\n  n_constraints &lt;- K_a + K_b\n  \n  # Initialize C_ab matrix\n  C_ab &lt;- matrix(0, nrow = n_constraints, ncol = n_params)\n  \n  # Constraints for factor b (columns)\n  for (j in 1:K_b) {\n    col_indices &lt;- ((j - 1) * K_a + 1):(j * K_a)\n    C_ab[j, col_indices] &lt;- 1\n  }\n\n  # Constraints for factor a (rows)\n  for (i in 1:K_a) {\n    row_indices &lt;- seq(i, n_params, by = K_a)\n    C_ab[K_b + i, row_indices] &lt;- 1\n  }\n  return(C_ab)\n}\n\n# Utility function to create full design matrix from constrained space.\ncreate_full_design &lt;- function(X_a_s, X_b_s, X_ab_s) {\n  \n  K_a &lt;- nrow(X_a_s)\n  K_b &lt;- nrow(X_b_s)\n  n_a &lt;- ncol(X_a_s)\n  n_b &lt;- ncol(X_b_s)\n  n_ab &lt;- ncol(X_ab_s)\n\n  # Create all combinations\n  design &lt;- expand.grid(a = 1:K_a, b = 1:K_b)\n  \n  # Add intercept and main effects\n  X_main &lt;- cbind(1, \n                  X_a_s[design$a, ],\n                  X_b_s[design$b, ])\n  \n  # Create interaction effects\n  X_int &lt;- X_ab_s[(design$b - 1) * K_a + design$a, , drop = FALSE]\n  \n  # it looks like we can just zero out interaction when main effect is zero\n  # so that we have a logical design matrix, i.e. if some of the main factors \n  # are set to zero then the interaction should also be.\n  # for (i in 1:n_a) {\n  #   for (j in 1:n_b) {\n  #     int_col &lt;- (i - 1) * n_b + j\n  #     X_int[X_main[, 1 + i] == 0 | X_main[, 1 + n_a + j] == 0, int_col] &lt;- 0\n  #   }\n  # }\n  \n  # Combine all effects\n  X_full &lt;- cbind(X_main, X_int)\n  \n  return(X_full)\n}\n\n# Utility to create random parameter values that sum to zero\ncreate_sum_zero_matrix &lt;- function(n_rows, n_cols, sd = 1, seed = 1) {\n  \n  set.seed(seed)\n  # Step 1: Generate random values\n  mat &lt;- matrix(rnorm(n_rows * n_cols, sd = sd), nrow = n_rows, ncol = n_cols)\n  \n  # Step 2: Center columns\n  mat &lt;- scale(mat, center = TRUE, scale = FALSE)\n  \n  # Step 3: Center rows\n  mat &lt;- t(scale(t(mat), center = TRUE, scale = FALSE))\n  \n  # Step 4: Final adjustment to ensure exact zero sums\n  col_adj &lt;- colSums(mat) / n_rows\n  row_adj &lt;- rowSums(mat) / n_cols\n  \n  for (i in 1:n_rows) {\n    for (j in 1:n_cols) {\n      mat[i,j] &lt;- mat[i,j] - col_adj[j] - row_adj[i] + mean(col_adj)\n    }\n  }\n  \n  return(mat)\n}\n\n\n# Utility to create random parameter values that sum to zero\ncreate_sum_zero_vec &lt;- function(n = 3, sd = 1, seed = 1) {\n  \n  set.seed(seed)\n  \n  v &lt;- scale(rnorm(n, 0, sd), center = TRUE, scale = FALSE)\n  \n  return(as.numeric(v))\n}\n\n\nDo some tests to see if the data generation process makes sense.\nNot sure that these matrices are logical in terms of the products of the various factors…\n\n\n2x2 constrained design matrix\nK_a = 2\nK_b = 2\nb0 = 1\nb_a = create_sum_zero_vec(n = K_a, seed = 1)\nb_b = create_sum_zero_vec(n = K_b, seed = 2)\nb_ab = as.numeric(create_sum_zero_matrix(K_a, K_b, seed = 3))\n\nl1 &lt;- get_data(\n  N = 100, K_a = K_a, K_b = K_b, \n  b0 = b0, b_a = b_a, b_b = b_b, b_ab = b_ab\n)\n# 2 x 2\nround(l1$X_full_s, 2)\n\n\n     [,1]  [,2]  [,3] [,4]\n[1,]    1 -0.71 -0.71  0.5\n[2,]    1  0.71 -0.71 -0.5\n[3,]    1 -0.71  0.71 -0.5\n[4,]    1  0.71  0.71  0.5\n\n\n\n\n4x2 constrained design matrix\nK_a = 4\nK_b = 2\nb0 = 1\nb_a = create_sum_zero_vec(n = K_a, seed = 4)\nb_b = create_sum_zero_vec(n = K_b, seed = 5)\nb_ab = as.numeric(create_sum_zero_matrix(K_a, K_b, seed = 6))\n\nl1 &lt;- get_data(\n  N = 100, K_a = K_a, K_b = K_b, \n  b0 = b0, b_a = b_a, b_b = b_b, b_ab = b_ab\n)\n# 4 x 2\nround(l1$X_full_s, 2)\n\n\n     [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]\n[1,]    1  0.00  0.00  0.87 -0.71  0.17  0.51  0.29\n[2,]    1 -0.58 -0.58 -0.29 -0.71 -0.61  0.00 -0.07\n[3,]    1 -0.21  0.79 -0.29 -0.71  0.17 -0.49  0.32\n[4,]    1  0.79 -0.21 -0.29 -0.71  0.27 -0.02 -0.55\n[5,]    1  0.00  0.00  0.87  0.71 -0.17 -0.51 -0.29\n[6,]    1 -0.58 -0.58 -0.29  0.71  0.61  0.00  0.07\n[7,]    1 -0.21  0.79 -0.29  0.71 -0.17  0.49 -0.32\n[8,]    1  0.79 -0.21 -0.29  0.71 -0.27  0.02  0.55\n\n\n\n\n3x5 constrained design matrix\nK_a = 3\nK_b = 4\nb0 = 1\nb_a = create_sum_zero_vec(n = K_a, seed = 6)\nb_b = create_sum_zero_vec(n = K_b, seed = 7)\nb_ab = as.numeric(create_sum_zero_matrix(K_a, K_b, seed = 8))\n\nl1 &lt;- get_data(\n  N = 100, K_a = K_a, K_b = K_b, \n  b0 = b0, b_a = b_a, b_b = b_b, b_ab = b_ab\n)\n# 4 x 2\nround(l1$X_full_s, 2)\n\n\n      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11] [,12]\n [1,]    1  0.00  0.82  0.00  0.00  0.87 -0.10  0.45  0.30 -0.21  0.34  0.19\n [2,]    1 -0.71 -0.41  0.00  0.00  0.87  0.47 -0.17  0.20  0.24 -0.39 -0.03\n [3,]    1  0.71 -0.41  0.00  0.00  0.87 -0.37 -0.29 -0.50 -0.03  0.05 -0.16\n [4,]    1  0.00  0.82 -0.58 -0.58 -0.29 -0.07 -0.12  0.03 -0.41 -0.46 -0.31\n [5,]    1 -0.71 -0.41 -0.58 -0.58 -0.29 -0.33 -0.25  0.07  0.12  0.21  0.52\n [6,]    1  0.71 -0.41 -0.58 -0.58 -0.29  0.40  0.37 -0.10  0.29  0.26 -0.21\n [7,]    1  0.00  0.82 -0.21  0.79 -0.29  0.42 -0.33 -0.33 -0.02  0.23  0.23\n [8,]    1 -0.71 -0.41 -0.21  0.79 -0.29 -0.23  0.54 -0.30 -0.01 -0.24 -0.08\n [9,]    1  0.71 -0.41 -0.21  0.79 -0.29 -0.18 -0.21  0.63  0.04  0.01 -0.15\n[10,]    1  0.00  0.82  0.79 -0.21 -0.29 -0.25  0.00  0.00  0.64 -0.11 -0.11\n[11,]    1 -0.71 -0.41  0.79 -0.21 -0.29  0.10 -0.13  0.03 -0.35  0.43 -0.41\n[12,]    1  0.71 -0.41  0.79 -0.21 -0.29  0.15  0.13 -0.03 -0.30 -0.32  0.52\n\n\nThe model now splits up the design into three separate matrices so that we can look to recover each grouping of parameters. Also, I convert to a binomial likelihood to speed things up.\n\n\nLogistic regression\n// Model for:\n// independent estimates of treatment arm by subgroup means\ndata {\n  int N;\n  array[N] int y;\n  array[N] int n;\n  // arm index\n  array[N, 3] int trt;\n  // factor 1 design matrix\n  int ncXades;\n  int nrXades;\n  matrix[nrXades, ncXades] Xades;\n  vector[ncXades] sa;\n  // factor 2 design matrix\n  int ncXbdes;\n  int nrXbdes;\n  matrix[nrXbdes, ncXbdes] Xbdes;\n  vector[ncXbdes] sb;\n  // factor 1/2 interaction design matrix\n  int ncXabdes;\n  int nrXabdes;\n  matrix[nrXabdes, ncXabdes] Xabdes;\n  vector[ncXabdes] sab;\n  \n  int prior_only;\n}\ntransformed data {\n  // build full design matrices\n  matrix[N, ncXades] Xa = Xades[trt[,1]];\n  matrix[N, ncXbdes] Xb = Xbdes[trt[,2]];\n  // indexes the relevant col in the design matrix\n  matrix[N, ncXabdes] Xab = Xabdes[trt[,3]];\n}\nparameters{\n  real mu;\n  vector[ncXades] ba;  \n  vector[ncXbdes] bb;\n  vector[ncXabdes] bab;\n}\ntransformed parameters{ \n  vector[N] eta = mu + Xa*ba + Xb*bb + Xab*bab;\n}\nmodel{\n  target += logistic_lpdf(mu | 0, 1);\n  target += normal_lpdf(ba | 0, sa);\n  target += normal_lpdf(bb | 0, sb);\n  target += normal_lpdf(bab | 0, sab);\n  \n  if(!prior_only){\n    // target += bernoulli_logit_lpmf(y | eta);  \n    target += binomial_logit_lpmf(y | n, eta);  \n  }\n}\ngenerated quantities{\n}\n\n\n\nTwo-factor (3 x 2)\nFit the model without the likelihood involved to examine the implied priors.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/note-09-logistic-2.stan\")\n\nl1 &lt;- get_data(\n  N = 1e6, K_a = 3, K_b = 2, \n  b0 = 1,   b_a = c(0, -1, 1), b_b = c(-0.4, 0.4),\n  # has to have all rows, all cols sum to zero if you \n  # want to target recovering parameters.\n  b_ab = c(-0.05, 0.15, -0.1, 0.05, -0.15,  0.1)\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 1\n)\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\nCode\nf1$summary(variables = c(\"mu\", \"ba\", \"bb\", \"bab\"))\n\n\n# A tibble: 6 × 10\n  variable     mean   median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 mu       -0.00680  0.00949 1.83  1.59  -3.07  3.06  1.00    8006.    4149.\n2 ba[1]    -0.0157  -0.0173  1.00  0.998 -1.65  1.62  1.00    8398.    4477.\n3 ba[2]    -0.00834 -0.0232  0.976 0.977 -1.62  1.63  1.00    8236.    4753.\n4 bb[1]    -0.00215  0.0134  1.00  1.01  -1.66  1.66  1.00    8462.    4937.\n5 bab[1]   -0.0149  -0.0111  1.01  1.00  -1.66  1.68  1.00    9257.    4619.\n6 bab[2]    0.00843  0.0218  1.03  1.02  -1.71  1.67  1.00    7462.    4568.\n\n\n\n\nPriors on group means\nm_post_s &lt;- f1$draws(variables = c(\"mu\", \"ba\", \"bb\", \"bab\"), format = \"matrix\")\n\n\nX_s &lt;- cbind(l1$X_a_s[rep(1:l1$K_a, each = 2),], \n             l1$X_b_s[rep(1:l1$K_b, len = l1$K_a * l1$K_b),], \n             l1$X_ab_s)\npost_mu &lt;- m_post_s %*% t(cbind(1, X_s))\n\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a * l1$K_b)))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  facet_wrap(~variable, ncol = 1) \n\n\n\n\n\n\n\n\nFigure 4: Priors on group means for all cells\n\n\n\n\n\nAnd now look at the parameter estimates.\n\n\nCode\nld$prior_only &lt;- 0\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\n\n\nCode\nf1$summary(variables = c(\"mu\", \"ba\", \"bb\", \"bab\"))\n\n\n# A tibble: 6 × 10\n  variable     mean   median      sd     mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 mu        1.00     1.00    0.00251 0.00255  0.996    1.00     1.00    4747.\n2 ba[1]     1.42     1.42    0.00451 0.00446  1.41     1.42     1.00    3642.\n3 ba[2]    -0.00149 -0.00150 0.00433 0.00435 -0.00865  0.00560  1.00    4175.\n4 bb[1]     0.559    0.559   0.00358 0.00363  0.553    0.565    1.00    4302.\n5 bab[1]   -0.260   -0.260   0.00548 0.00548 -0.269   -0.251    1.00    4082.\n6 bab[2]    0.0598   0.0599  0.00684 0.00688  0.0484   0.0709   1.00    3558.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nChecking the recovery of the original parameters, it looks like we got somewhere near to the original values we used.\n\n\nParameter posterior density for first factor\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_mu &lt;- m_post_s %*% t(l1$X_a_s)\n\n# colMeans(post_mu)\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:l1$K_a))]\n\nd_tru &lt;- data.table(b_a = l1$b_a)\nd_tru[, variable := paste0(\"V\", 1:l1$K_a)]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru,\n             aes(xintercept = b_a), col = 2,\n             lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 5: Parameter posterior density for first factor\n\n\n\n\n\n\n\nParameter posterior density for second factor\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_mu &lt;- m_post_s %*% t(l1$X_b_s)\n\n# colMeans(post_mu)\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:l1$K_b))]\n\nd_tru &lt;- data.table(b_a = l1$b_b)\nd_tru[, variable := paste0(\"V\", 1:l1$K_b)]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru,\n             aes(xintercept = b_a), col = 2,\n             lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 6: Parameter posterior density for second factor\n\n\n\n\n\n\n\nParameter posterior density for interaction\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_mu &lt;- m_post_s %*% t(l1$X_ab_s)\n\n# colMeans(post_mu)\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a * l1$K_b)))]\n\nd_tru &lt;- data.table(b_ab = l1$b_ab)\nd_tru[, variable := paste0(\"V\", 1:(l1$K_a * l1$K_b))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru,\n             aes(xintercept = b_ab), col = 2,\n             lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 7: Parameter posterior density for interaction\n\n\n\n\n\n\n\nParameter posterior density group means\nm_post_s &lt;- f1$draws(variables = c(\"mu\", \"ba\", \"bb\", \"bab\"), format = \"matrix\") \npost_mu &lt;- m_post_s %*% t(l1$X_full_s)\n\n# colMeans(post_mu)\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a * l1$K_b)))]\n\nd_tru &lt;- unique(l1$d[order(b, a), .(a, b, eta)])\nd_tru[, variable := paste0(\"V\", 1:(l1$K_a * l1$K_b))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru,\n             aes(xintercept = eta), col = 2,\n             lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 8: Parameter posterior density group means\n\n\n\n\n\n\n\nTwo-factor (2 x 2)\n\n\nCode\nl1 &lt;- get_data(\n  N = 1e6, K_a = 2, K_b = 2, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(2, seed = 22),\n  b_b = create_sum_zero_vec(2, seed = 23),\n  b_ab = as.numeric(create_sum_zero_matrix(2, 2, seed = 24))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.2 seconds.\nChain 2 finished in 0.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 0.2 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.499\n1.499\n\n\nposterior_mean\n-1.504\n1.504\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n0.314\n-0.314\n\n\nposterior_mean\n0.314\n-0.314\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\nb_ab\n-0.521\n0.521\n0.521\n-0.521\n\n\nposterior_mean\n-0.521\n0.521\n0.521\n-0.521\n\n\n\nCompare true parameters with posterior means (interaction)\n\n\n\nTwo-factor (3 x 3)\n\n\nCode\nl1 &lt;- get_data(\n  N = 1e6, K_a = 3, K_b = 3, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(3, seed = 22),\n  b_b = create_sum_zero_vec(3, seed = 23),\n  b_ab = as.numeric(create_sum_zero_matrix(3, 3, seed = 24))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.2 seconds.\nChain 2 finished in 0.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 0.4 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.506\n1.492\n0.014\n\n\nposterior_mean\n-1.508\n1.494\n0.014\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n-0.031\n-0.659\n0.689\n\n\nposterior_mean\n-0.032\n-0.668\n0.700\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_ab\n-0.447\n0.102\n0.345\n-0.524\n0.373\n0.151\n0.971\n-0.474\n-0.496\n\n\nposterior_mean\n-0.444\n0.096\n0.347\n-0.524\n0.368\n0.156\n0.967\n-0.464\n-0.503\n\n\n\nCompare true parameters with posterior means (interaction)\n\n\n\nTwo-factor (2 x 4)\n\n\nCode\nl1 &lt;- get_data(\n  N = 1e6, K_a = 2, K_b = 4, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(2, seed = 22),\n  b_b = create_sum_zero_vec(4, seed = 23),\n  b_ab = as.numeric(create_sum_zero_matrix(2, 4, seed = 24))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.2 seconds.\nChain 2 finished in 0.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 0.4 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.499\n1.499\n\n\nposterior_mean\n-1.501\n1.501\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n-0.423\n-1.051\n0.297\n1.177\n\n\nposterior_mean\n-0.423\n-1.050\n0.296\n1.177\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_ab\n-0.718\n0.718\n0.325\n-0.325\n0.114\n-0.114\n0.279\n-0.279\n\n\nposterior_mean\n-0.717\n0.717\n0.319\n-0.319\n0.113\n-0.113\n0.285\n-0.285\n\n\n\nCompare true parameters with posterior means (interaction)\n\n\n\nTwo-factor (5 x 2)\n\n\nCode\nl1 &lt;- get_data(\n  N = 1e6, K_a = 5, K_b = 2, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(5, seed = 22),\n  b_b = create_sum_zero_vec(2, seed = 23),\n  b_ab = as.numeric(create_sum_zero_matrix(5, 2, seed = 24))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.2 seconds.\nChain 2 finished in 0.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 0.4 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.125\n1.872\n0.395\n-0.32\n-0.822\n\n\nposterior_mean\n-1.120\n1.880\n0.383\n-0.32\n-0.822\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n0.314\n-0.314\n\n\nposterior_mean\n0.313\n-0.313\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_ab\n-0.534\n-0.082\n0.315\n0.005\n0.295\n0.534\n0.082\n-0.315\n-0.005\n-0.295\n\n\nposterior_mean\n-0.532\n-0.083\n0.312\n0.004\n0.300\n0.532\n0.083\n-0.312\n-0.004\n-0.300\n\n\n\nCompare true parameters with posterior means (interaction)",
    "crumbs": [
      "Design notes",
      "Orthonormal contrasts"
    ]
  },
  {
    "objectID": "notebooks/design-notes-09.html#what-is-it-with-kroneckerq_a-q_b",
    "href": "notebooks/design-notes-09.html#what-is-it-with-kroneckerq_a-q_b",
    "title": "Orthonormal contrasts",
    "section": "What is it with kronecker(Q_a, Q_b)?",
    "text": "What is it with kronecker(Q_a, Q_b)?\nThe problem with kronecker(Q_a, Q_b) was that I was using a columnwise definition for the interaction argument passed to the data generation function. However, kronecker(Q_a, Q_b) varies b first rather than a and that is incompatible with the original specification of the interaction argument. After fixing that up, I can use kronecker as shown below. Also note that I now transform the return values from the create_sum_zero_matrix function so that the matrix will flatten with c in the correct way.\n\n\nRevised data generation function\nget_data_alt &lt;- function(\n    N = 100,\n    K_a = 3,\n    K_b = 2,\n    b0 = 1,\n    # effects are sum to zero\n    b_a = c(0, -1, 1),\n    b_b = c(-0.6, 0.6),\n    # rowwise\n    b_ab = c(-0.05, 0.05, 0.15, -0.15, -0.1, 0.1)\n    ){\n  \n  stopifnot(all.equal(0, sum(b_a), \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(0, sum(b_b), \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(0, sum(b_ab), \n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  # cols and rows should sum to zero otherwise following will not work\n  b_ab_matrix &lt;- matrix(b_ab, nrow = K_a, ncol = K_b, byrow = T)\n  stopifnot(all.equal(colSums(b_ab_matrix), rep(0, K_b),\n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(rowSums(b_ab_matrix), rep(0, K_a),\n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  a = sample(1:K_a, size = N, replace = T)\n  b = sample(1:K_b, size = N, replace = T)\n  d &lt;- data.table(a, b)\n  \n  d[, b0 := b0]\n  d[, b_a := b_a[a]]\n  d[, b_b := b_b[b]]\n  # column wise indexing into b_ab\n  # d[, ix_b_ab := a + (K_a * (b - 1))]\n  # rowwise indexing into b_ab\n  d[, ix_b_ab := ((a - 1) * K_b) + b]\n  d[, b_ab := b_ab[ix_b_ab]]\n  d[, eta := b0 + b_a + b_b + b_ab]\n\n  # e.g.  \n  unique(d[order(b, a)])\n#        a     b    b0   b_a   b_b  b_ab   eta\n#    &lt;int&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n# 1:     1     1     1     0  -0.6  -0.2   0.2\n# 2:     2     1     1    -1  -0.6   0.0  -0.6\n# 3:     3     1     1     1  -0.6   0.6   2.0\n# 4:     1     2     1     0   0.4  -0.4   1.0\n# 5:     2     2     1    -1   0.4   0.2   0.6\n# 6:     3     2     1     1   0.4  -0.2   2.2\n  \n  cols_a &lt;- paste0(\"a\", 1:K_a)\n  cols_b &lt;- paste0(\"a\", 1:K_b)\n  cols_c &lt;- unique(d[order(b, a), paste0(\"a\",a,\"b\",b)])\n  \n  d[, y := rbinom(N, 1, plogis(eta))]\n  \n  # saturated design matrix\n  X_a &lt;- diag(K_a)\n  colnames(X_a) &lt;- cols_a\n  X_b &lt;- diag(K_b)\n  colnames(X_b) &lt;- cols_b\n  X_ab &lt;- diag(K_a * K_b)\n  colnames(X_ab) &lt;- cols_c\n\n  # correlation matrix to enforce sum to zero\n  S_a &lt;- diag(K_a) - (1 / K_a )\n  S_b &lt;- diag(K_b) - (1 / K_b )\n  S_ab &lt;- kronecker(S_a, S_b)\n  # should be rank 2 for a 1:3, b 1:2\n  # pracma::Rank(S_ab)\n  \n  # decomposition eigen vectors\n  Q_a &lt;- eigen(S_a)$vector[, 1:(K_a - 1)]\n  Q_b &lt;- eigen(S_b)$vector[, 1:(K_b - 1)]\n  Q_ab &lt;- kronecker(Q_a, Q_b)\n  \n  # transformed pars\n  b_a_s &lt;- t(Q_a) %*% b_a\n  b_b_s &lt;- t(Q_b) %*% b_b\n  b_ab_s &lt;- t(Q_ab) %*% b_ab\n\n  # full rank design\n  X_a_s &lt;- X_a %*% Q_a\n  X_b_s &lt;- X_b %*% Q_b\n  X_ab_s &lt;- X_ab %*% Q_ab\n  \n \n  # Check\n  stopifnot(all.equal(as.numeric(X_a_s %*% b_a_s), b_a, \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(as.numeric(X_b_s %*% b_b_s), b_b, \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(as.numeric(X_ab_s %*% b_ab_s), b_ab, \n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  \n  \n  # build the design matrix up incrementally\n  X_full_s &lt;- cbind(\n    X_a_s[rep(1:K_a, length = K_a * K_b), ],\n    X_b_s[rep(1:K_b, each = K_a), ]\n  )\n  for(j in 1:(K_b-1)){\n    for(i in 1:(K_a-1)){\n      X_full_s &lt;- cbind(X_full_s,\n                        X_full_s[, i]  * X_full_s[, ((K_a - 1) + j)])\n    }\n  }\n  X_full_s\n  # round(X_full_s, 3)\n  \n  list(\n    d = d, b0 = b0, \n    b_a = b_a, b_b = b_b, b_ab = b_ab, \n    b_a_s = b_a_s, b_b_s = b_b_s, b_ab_s = b_ab_s, \n    \n    K_a = K_a, K_b = K_b, \n    X_a = X_a, X_a_s = X_a_s, \n    X_b = X_b, X_b_s = X_b_s, \n    X_ab = X_ab, X_ab_s = X_ab_s, \n    X_full_s = X_full_s,\n    \n    S_a = S_a, S_b = S_b, S_ab = S_ab, \n    Q_a = Q_a, Q_b = Q_b, Q_ab = Q_ab \n  )\n}\n\n\n\n\nCode\nl1 &lt;- get_data_alt(\n  N = 1e6, K_a = 3, K_b = 2, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(3, seed = 22),\n  b_b = create_sum_zero_vec(2, seed = 23),\n  b_ab = as.numeric(c(t(create_sum_zero_matrix(3, 2, seed = 24))))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  # columnwise\n  # trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  # rowwise\n  trt = cbind(d_smry$a, d_smry$b, ((d_smry$a - 1) * l1$K_b) + d_smry$b),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.2 seconds.\nChain 2 finished in 0.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 0.2 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.506\n1.492\n0.014\n\n\nposterior_mean\n-1.507\n1.486\n0.021\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n0.314\n-0.314\n\n\nposterior_mean\n0.311\n-0.311\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\nb_ab\n0.039\n-0.039\n-0.136\n0.136\n0.097\n-0.097\n\n\nposterior_mean\n0.041\n-0.041\n-0.134\n0.134\n0.093\n-0.093\n\n\n\nCompare true parameters with posterior means (interaction)",
    "crumbs": [
      "Design notes",
      "Orthonormal contrasts"
    ]
  },
  {
    "objectID": "notebooks/model-implementation.html",
    "href": "notebooks/model-implementation.html",
    "title": "Model implementation",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nThe model used for the simulations translates the binary outcome into a binomial outcome by aggregating over the unique groups. For example with the linear predictor:\n# data generation process\nformals(roadmap.data::get_trial_data)$g\n\nfunction(d, sim_spec) {\n    a0 &lt;- sim_spec$a0\n    m &lt;- sim_spec$m\n    b &lt;- sim_spec$b\n    eta &lt;- a0 + m[\"l1\"] * d$l1 + m[\"l2\"] * d$l2 + (b[\"erx\"] + \n        b[\"erx-r1\"] * d$srp1 + b[\"erx-r2\"] * d$srp2) * d$erx + \n        (b[\"r1\"] * d$srp1 + b[\"r2\"] * d$srp2) * d$r * d$er + \n        (b[\"r1d\"] * d$d * d$srp1 + b[\"r2d\"] * d$d * d$srp2) * \n            d$ed + b[\"efx\"] * d$efx + b[\"f\"] * d$f * d$ef\n    eta\n}\nI get:\n# simulate data\nset.seed(1)\nsim_spec &lt;- roadmap.data::get_sim_spec()\n\nunlist(sim_spec)\n\n         a0        m.l1        m.l2       b.erx    b.erx-r1    b.erx-r2 \n 0.61903921 -0.33718806 -0.08682239 -0.10000000 -0.05000000  0.05000000 \n       b.r1        b.r2       b.r1d       b.r2d       b.efx         b.f \n 0.20000000  0.09000000  0.30000000  0.10000000  0.25000000  0.15000000 \n\nll &lt;- roadmap.data::get_trial_data(N = 2500, sim_spec = sim_spec)\nd &lt;- copy(ll$d)\nhead(d[, .(y = sum(y), n = .N), keyby = .(l, er, ed, ef, r, srp0, srp1, srp2, d, f)])\n\nKey: &lt;l, er, ed, ef, r, srp0, srp1, srp2, d, f&gt;\n       l    er    ed    ef     r  srp0  srp1  srp2     d     f     y     n\n   &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;int&gt; &lt;int&gt;\n1:     0     0     0     0     0     1     0     0     0     0   167   247\n2:     0     0     0     1     0     1     0     0     0     0   112   193\n3:     0     0     0     1     0     1     0     0     0     1   116   197\n4:     0     0     1     0     0     0     1     0     0     0    12    15\n5:     0     0     1     0     0     0     1     0     1     0    11    12\n6:     0     0     1     1     0     0     1     0     0     0     5     7\nThe columns correspond to:\nDuration domain depends on what surgery was received, NOT what was originally planned/assigned. For one-stage 12-weeks is reference group (indicated by 0) vs 6 weeks. For two-stage 7 days is reference group (indicated by 0) vs 12 weeks (1).\nWithin early, late and chronic stage infection, the percentage (by silo, l) receiving each surgery type (srp) as a randomised or non-randomised treatment (er) are:\nPercent receiving each surgery type within silo\nll &lt;- roadmap.data::get_trial_data(N = 1e6, sim_spec = sim_spec)\nd_tbl &lt;- ll$d[, .(n = .N), keyby = .(l, er, srp)]\nd_tbl[, N_l := sum(n), keyby = l]\nd_tbl[, pct := 100 * n / N_l]\nd_tbl[, N_l := NULL]\nd_tbl\n\n\nKey: &lt;l&gt;\n        l    er   srp      n        pct\n    &lt;int&gt; &lt;num&gt; &lt;num&gt;  &lt;int&gt;      &lt;num&gt;\n 1:     0     0     0 270730 90.0593121\n 2:     0     0     1  29883  9.9406879\n 3:     1     0     0   2028  0.4059987\n 4:     1     0     1   2332  0.4668585\n 5:     1     0     2   5717  1.1445239\n 6:     1     1     0 244552 48.9584772\n 7:     1     1     1  73803 14.7751092\n 8:     1     1     2 171077 34.2490325\n 9:     2     0     0  39954 19.9891934\n10:     2     0     1  40146 20.0852520\n11:     2     0     2 119778 59.9255546",
    "crumbs": [
      "Assumptions and setup",
      "Model implementation"
    ]
  },
  {
    "objectID": "notebooks/model-implementation.html#stan-implementation",
    "href": "notebooks/model-implementation.html#stan-implementation",
    "title": "Model implementation",
    "section": "Stan implementation",
    "text": "Stan implementation\nThe model spec can be translated into stan, albeit using a different likelihood spec:\n\n\n\n\ndata {\n  int N;\n  array[N] int y;\n  array[N] int n;\n  // variation due to silo/joint\n  vector[N] l1;\n  vector[N] l2;\n  // reveal\n  vector[N] er;\n  vector[N] ed;\n  vector[N] ef;\n  // surgery\n  vector[N] r;\n  // duration\n  vector[N] d;\n  // vector[N] rp; // revision was recvd\n  vector[N] srp0; // dair recvd\n  vector[N] srp1; // one-stage revision recvd\n  vector[N] srp2; // two-stage revision recvd\n  // choice\n  vector[N] f;\n  \n  vector[2] pri_m_sd;\n  vector[9] pri_b_sd;\n  int prior_only;\n}\ntransformed data{\n  vector[N] erx;\n  vector[N] erx_srp1;\n  vector[N] erx_srp2;\n  vector[N] er_r;\n  vector[N] er_r_srp1;\n  vector[N] er_r_srp2;\n  vector[N] ed_d_srp1;\n  vector[N] ed_d_srp2;\n  vector[N] ef_f;\n  \n  erx = (1-er) ;\n  erx_srp1 = (1-er) .* srp1;\n  erx_srp2 = (1-er) .* srp2;\n  \n  er_r = er .* r;\n  \n  er_r_srp1 = er_r .* srp1;\n  er_r_srp2 = er_r .* srp2;\n\n// you can remove rp srp1 indicates one-stage happened, srp2 indicates two stage\n// the rp becomes redundant.\n  ed_d_srp1 = ed .* d .* srp1;\n  ed_d_srp2 = ed .* d .* srp2;\n\n  ef_f = ef .* f;\n}\nparameters {\n  real a0;\n  vector[2] m;\n  vector[9] b;\n}\ntransformed parameters{\n  vector[N] eta;\n \n  eta = a0 + \n      m[1]*l1 + m[2]*l2 +  \n      (b[1]*erx + b[2]*erx_srp1 + b[3]*erx_srp2)  +\n      (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n      // b[6] * (1 - ed) + \n      (b[6]*ed_d_srp1 + b[7]*ed_d_srp2)  + \n      b[8] * (1 - ef) + (b[9]*ef_f);\n      \n}\nmodel{\n  target += logistic_lpdf(a0 | 0, 1);\n  target += normal_lpdf(m | 0, pri_m_sd);\n  target += normal_lpdf(b | 0, pri_b_sd);\n  \n  // likelihood chunks pertaining to each silo\n  if(!prior_only){\n    target += binomial_logit_lpmf(y | n, eta) ;      \n  }\n  \n  \n}\ngenerated quantities{\n\n  // vector[N] eta_r_0;\n  // vector[N] eta_r_1;\n  // vector[N] eta_d_0;\n  // vector[N] eta_d_1;\n  // vector[N] eta_f_0;\n  // vector[N] eta_f_1;\n  // \n  // {\n  // \n  //   // predictions on log-odds scale setting all participants to the level\n  //   // of interest, e.g. assume all have r = 0\n  //   eta_r_0   =  a0 +\n  //     m[1]*l1   + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     // b[6] * (1 - ed  ) + \n  //     (b[6]*ed_d_srp1   + b[7]*ed_d_srp2)   +\n  //     b[8] * (1 - ef  ) + (b[9]*ef_f)  ;\n  //   // r = 1\n  //   // (only those revealed to surgery domain contribute due to the er term)\n  //   eta_r_1   =  a0 +\n  //     m[1]*l1   + m[2]*l2 +\n  //     // note the use of er here and not er_r, i.e. the r is set to 1 for\n  //     // everyone\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er .* srp1 + b[5]*er .* srp2) +\n  //     // b[6] * (1 - ed  ) + \n  //     (b[6]*ed_d_srp1   + b[7]*ed_d_srp2)   +\n  //     b[8] * (1 - ef  ) + (b[9]*ef_f);\n  // \n  //   // duration, d = 0\n  //   eta_d_0   =  a0 +\n  //     m[1]*l1 + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n  //     // b[6] * (1 - ed) +\n  //     b[8] * (1 - ef) + (b[9]*ef_f);\n  //   // d = 1\n  //   eta_d_1   =  a0 +\n  //     m[1]*l1 + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n  //     // note the use of ed and rp here and not ed_rp_d_srp1, i.e. the d is\n  //     // set to 1 for everyone\n  //     // b[6] * (1 - ed) + \n  //     (b[6]*ed .* srp1 + b[7]*ed .* srp2)  +\n  //     b[8] * (1 - ef) + (b[9]*ef_f);\n  // \n  //   // choice, f = 0\n  //   eta_f_0   =  a0 +\n  //     m[1]*l1 + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n  //     // b[6] * (1 - ed) + \n  //     (b[6]*ed_d_srp1 + b[7]*ed_d_srp2)  +\n  //     b[8] * (1 - ef)  ;\n  //   // f = 1\n  //   eta_f_1   =  a0 +\n  //     m[1]*l1 + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n  //     // b[6] * (1 - ed) + \n  //     (b[6]*ed_d_srp1 + b[7]*ed_d_srp2)  +\n  //     // note the use of ef here and not ef_f\n  //     b[8] * (1 - ef) + (b[9]*ef);\n  // \n  // }\n\n}\n\n\nThe model is fitted to a large dataset and the posterior summarised to determine if the parameter estimates approximate the known values.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThere are some terms in the model that under ‘ideal’ situation, i.e. where all patients are revealed as initially intended, that may cause estimation problems. These issues can manifest as sluggish MCMC or weird NA terms appearing in the regression results. In general an NA in the regression results from lm means that the coefficient is not estimable. This can happen due to exact collinearity, e.g. when Q3 = a Q1 + b Q2 + c for some a, b and c, but, it can also happen due to not having enough observations to estimate the relevant parameters (e.g. if p &gt;&gt; n). If you predictors are categorical and you’re adding interaction terms, an NA can also mean that there are no observations with that combination of levels of the factors.\n\n\n\n\n\nCode\nm4 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-04.stan\")\n\nset.seed(1)\n\nsim_spec &lt;- roadmap.data::get_sim_spec()\nsim_spec$a0  &lt;- qlogis(0.65)\nsim_spec$m[\"l1\"] &lt;- 0.57\nsim_spec$m[\"l2\"] &lt;- 0.64\nsim_spec$b[\"erx\"] &lt;- -0.1\nsim_spec$b[\"erx-r1\"] &lt;- -0.05\nsim_spec$b[\"erx-r2\"] &lt;- 0.05\nsim_spec$b[\"r1\"] &lt;- -0.6931472\nsim_spec$b[\"r2\"] &lt;- -0.6931472\n# sim_spec$b[\"edx\"] &lt;- -0.07\nsim_spec$b[\"r1d\"] &lt;- -0.6931472\nsim_spec$b[\"r2d\"] &lt;- -0.6931472\nsim_spec$b[\"efx\"] &lt;- -0.2\nsim_spec$b[\"f\"] &lt;- -0.6931472\n\n\nll &lt;- roadmap.data::get_trial_data(N = 2e6, sim_spec = sim_spec)\nlsd &lt;- roadmap.data::get_stan_data(ll$d)\n\nd &lt;- copy(ll$d)\nd_s &lt;- copy(lsd$d_s)\nld &lt;- lsd$ld\n\n\n# ld$pri_m_sd &lt;- rep(1, 2)\n# ld$pri_b_sd &lt;- rep(1, 9)\n\nf1 &lt;- m4$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 2.4 seconds.\nChain 2 finished in 2.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 2.5 seconds.\nTotal execution time: 2.7 seconds.\n\n\nCode\n# See note above. edx is dropped from the model as it is collinear with\n# srp1 and srp2 and leads to an estimation issue.\n\nf2 &lt;- glm(y ~ l1 + l2 +\n            erx + erx:srp1 + erx:srp2 +\n            er:r:srp1 + er:r:srp2 +\n            # edx +\n            ed:d:srp1 + ed:d:srp2 +\n            efx + ef:f,  \n          data = d, family = binomial())\n\n# summary(f2)\n\n# dtmp &lt;- data.table(model.matrix(f2)) \n# dtmp &lt;- cbind(model.matrix(f2), tot = 0)\n# pracma::rref(dtmp)\n# d_s\n\n# dtmp &lt;- data.table(model.matrix(f2))\n# \n# rref(dtmp)\n# dtmp.mean &lt;- apply(dtmp, 2, mean)\n# dtmp &lt;- sweep(dtmp, 2, dtmp.mean)\n# \n# f3 &lt;- prcomp(dtmp)\n# print(f3)\n# \n# # Fairly unsafe - checking for full rank on removal of each var\n# linearly_dep_cols(f2)\n\n\nThe parameter estimates align reasonably well to the simulation parameters used in the linear predictor:\n\n\nCode\npost1 &lt;- data.table(f1$draws(variables = c(c(\"a0\", \"m\", \"b\")), format = \"matrix\"))\ncf &lt;- coef(f2)\n\nround(rbind(\n  \"Simulation parameters\" = c(sim_spec$a0, sim_spec$m, sim_spec$b),\n  \"Posterior means\" = colMeans(post1),\n  \"Max likelihood\" = c(\n    cf[1:3], \n    cf[\"erx\"], cf[\"erx:srp1\"], cf[\"erx:srp2\"], \n    cf[\"srp1:er:r\"], cf[\"srp2:er:r\"] , \n    # cf[\"edx\"],\n    cf[\"srp1:ed:d\"], cf[\"srp2:ed:d\"],\n    cf[\"efx\"], cf[\"ef:f\"]\n  )\n), 4)\n\n\n                                 l1     l2     erx  erx-r1 erx-r2      r1\nSimulation parameters 0.6190 0.5700 0.6400 -0.1000 -0.0500 0.0500 -0.6931\nPosterior means       0.6201 0.5651 0.6365 -0.1042 -0.0585 0.0664 -0.6996\nMax likelihood        0.6203 0.5649 0.6365 -0.1045 -0.0585 0.0664 -0.6995\n                           r2     r1d     r2d    efx       f\nSimulation parameters -0.6931 -0.6931 -0.6931 -0.200 -0.6931\nPosterior means       -0.6927 -0.6844 -0.7004 -0.197 -0.6918\nMax likelihood        -0.6927 -0.6845 -0.7004 -0.197 -0.6918",
    "crumbs": [
      "Assumptions and setup",
      "Model implementation"
    ]
  },
  {
    "objectID": "notebooks/model-implementation.html#estimation---g-computation",
    "href": "notebooks/model-implementation.html#estimation---g-computation",
    "title": "Model implementation",
    "section": "Estimation - G-computation",
    "text": "Estimation - G-computation\nThis section is now incomplete due to the revised model specification.\n\n\n\n\n\n\nNote\n\n\n\n\n\nCalculations based on Bayesian model are complicated by virtue of use of binomial instead of bernoulli likelihood. To deal with this, we weight the log-odds contributions by the number of trials associated with each unique combination.\n\n\n\nPredictions on log-odds scale:\n\neta_r_0 &lt;- f1$draws(variables = c(\"eta_r_0\"), format = \"matrix\")\neta_r_1 &lt;- f1$draws(variables = c(\"eta_r_1\"), format = \"matrix\")\neta_d_0 &lt;- f1$draws(variables = c(\"eta_d_0\"), format = \"matrix\")\neta_d_1 &lt;- f1$draws(variables = c(\"eta_d_1\"), format = \"matrix\")\neta_f_0 &lt;- f1$draws(variables = c(\"eta_f_0\"), format = \"matrix\")\neta_f_1 &lt;- f1$draws(variables = c(\"eta_f_1\"), format = \"matrix\")\n\nThe G-formula allows you to go from a conditional estimate to a marginal one via standardisation or other means.\n\n# g-comp - calculations are complicated by virtue of use of binomial\n# instead of bernoulli model. Approach is to weight the log-odds contributions\n# by the number of trials associated with each unique combination.\n\nmax_rows &lt;- 1000\n\n# Compute the effect of revision\nb_r &lt;- do.call(rbind, mclapply(1:(min(nrow(eta_r_0), max_rows)), function(ii){\n  \n  # columns in eta_r_0 correspond to the covariate groups, i.e. the rows in d_s\n  \n  # The repitition gives the right contribution (weight) for each covariate \n  # combination i.e. each column (covariate combination) is replicated by \n  # the number of pts with this covariate combination. \n  \n  # This first one is averaged across both non-reveal and revealed. It is not\n  # what we want\n  lo_0 &lt;- eta_r_0[ii, rep(1:nrow(d_s), times = ld$n)]\n  lo_1 &lt;- eta_r_1[ii, rep(1:nrow(d_s), times = ld$n)]\n  mu_r = mean(lo_1 - lo_0)\n  \n  # Should be no effect of rev in those that were not rand to surg\n  # idx &lt;- d_s[er == 0 , which = T]\n  # lo_0_erx &lt;- eta_r_0[ii, rep(idx, times = ld$n[idx])]\n  # lo_1_erx &lt;- eta_r_1[ii, rep(idx, times = ld$n[idx])]\n  # mu_r_erx &lt;- sum(lo_1_erx - lo_0_erx) / sum(ld$n[idx])\n  \n  # Finally, these give the effect in those revealed to surgery domain. This\n  # is what we want.\n  idx &lt;- d_s[er == 1 , which = T]\n  lo_0_erx &lt;- eta_r_0[ii, rep(idx, times = ld$n[idx])]\n  lo_1_erx &lt;- eta_r_1[ii, rep(idx, times = ld$n[idx])]\n  mu_r_er &lt;- sum(lo_1_erx - lo_0_erx) / sum(ld$n[idx])\n  \n  # avg effect then effect in non-reveal and reveal\n  c(\"mu_r\" = mu_r, \n    # \"mu_r_erx\" = mu_r_erx, \n    \"mu_r_er\" = mu_r_er)\n}, mc.cores = 10))\n\n\n# Compute the effect of duration for the pt that received one-stage\n# and for those that received two-stage surgery.\nb_d &lt;- do.call(rbind, mclapply(1:(min(nrow(eta_d_0), max_rows)), function(ii){\n  \n  lo_0 &lt;- eta_d_0[ii, rep(1:nrow(d_s), times = ld$n)]\n  lo_1 &lt;- eta_d_1[ii, rep(1:nrow(d_s), times = ld$n)]\n\n  # stratification, silo/revision type that actually took place\n  # idx &lt;- d_s[ed == 0 & srp2 == 0, which = T]\n  # lo_0_edx_srp1 &lt;- eta_d_0[ii, rep(idx, times = ld$n[idx])]\n  # lo_1_edx_srp1 &lt;- eta_d_1[ii, rep(idx, times = ld$n[idx])]\n  # mu_d_edx_srp1 &lt;- sum(lo_1_edx_srp1 - lo_0_edx_srp1) / sum(ld$n[idx])\n  # \n  # idx &lt;- d_s[ed == 0 & srp2 == 1, which = T]\n  # lo_0_edx_srp2 &lt;- eta_d_0[ii, rep(idx, times = ld$n[idx])]\n  # lo_1_edx_srp2 &lt;- eta_d_1[ii, rep(idx, times = ld$n[idx])]\n  # mu_d_edx_srp2 &lt;- sum(lo_1_edx_srp2 - lo_0_edx_srp2) / sum(ld$n[idx])\n\n  idx &lt;- d_s[ed == 1 & srp2 == 0, which = T]\n  lo_0_ed_srp1 &lt;- eta_d_0[ii, rep(idx, times = ld$n[idx])]\n  lo_1_ed_srp1 &lt;- eta_d_1[ii, rep(idx, times = ld$n[idx])]\n  mu_d_ed_srp1 &lt;- sum(lo_1_ed_srp1 - lo_0_ed_srp1) / sum(ld$n[idx])\n\n  idx &lt;- d_s[ed == 1 & srp2 == 1, which = T]\n  lo_0_ed_srp2 &lt;- eta_d_0[ii, rep(idx, times = ld$n[idx])]\n  lo_1_ed_srp2 &lt;- eta_d_1[ii, rep(idx, times = ld$n[idx])]\n  mu_d_ed_srp2 &lt;- sum(lo_1_ed_srp2 - lo_0_ed_srp2) / sum(ld$n[idx])\n\n  c(\"mu_d\" = mean(lo_1 - lo_0), \n    # you need to base the mean on the n that were used in the strata\n    # \"mu_d_edx_srp1\" = mu_d_edx_srp1,  \"mu_d_edx_srp2\" = mu_d_edx_srp2,\n    \"mu_d_ed_srp1\" = mu_d_ed_srp1, \"mu_d_ed_srp2\" = mu_d_ed_srp2\n    )\n  \n}, mc.cores = 10))\n\n# Compute the effect of AB choice.\nb_f &lt;- do.call(rbind, mclapply(1:(min(nrow(eta_f_0), max_rows)), function(ii){\n  \n  # Avg effect of rif - what is the effect of rif in the sample population\n  # Might be wrong, but don't believe this is a meaningful/useful quantity.\n  lo_0 &lt;- eta_f_0[ii, rep(1:nrow(d_s), times = ld$n)]\n  lo_1 &lt;- eta_f_1[ii, rep(1:nrow(d_s), times = ld$n)]\n  mu_f &lt;- mean(lo_1 - lo_0)\n  \n  # Should be no effect of rif in those that were not rand to choice\n  # idx &lt;- d_s[ef == 0 , which = T]\n  # lo_0_efx &lt;- eta_f_0[ii, rep(idx, times = ld$n[idx])]\n  # lo_1_efx &lt;- eta_f_1[ii, rep(idx, times = ld$n[idx])]\n  # mu_f_efx &lt;- sum(lo_1_efx - lo_0_efx) / sum(ld$n[idx])\n\n  # Effect of rif in those rand to choice domain\n  idx &lt;- d_s[ef == 1 , which = T]\n  lo_0_ef &lt;- eta_f_0[ii, rep(idx, times = ld$n[idx])]\n  lo_1_ef &lt;- eta_f_1[ii, rep(idx, times = ld$n[idx])]\n  mu_f_ef &lt;- sum(lo_1_ef - lo_0_ef) / sum(ld$n[idx])\n  \n  c(\"mu_f\" = mu_f, \n    # \"mu_f_efx\" = mu_f_efx, \n    \"mu_f_ef\" = mu_f_ef)\n}, mc.cores = 10))\n\nThe following provides the results and also comparisons to combinations of parameters used in data simulation.\nFor the surgery domain, the comparison of interest is dair (ref) vs revision, which can be obtained by averaging over the distribution of surgery type that took place. The revision effects are silo-specific in that only the late silo is randomised which we obtain by producing a conditional treatment effect by stratifying on the reveal status (er).\n\n\n\n\n\n\nWarning\n\n\n\n\n\nI don’t believe that we currently need to worry about differential selection (\\(\\mathbb{P}(S=s|G=1)\\ne\\mathbb{P}(S=s|G=2)\\)) because only one silo is contributing to the randomised comparison and I think we are restricting to that silo by virtue of conditiong on er.\n\n\n\n\n# dair (ref)  vs revision (of any form)\navg_comparisons(f2, variables = \"r\", comparison = \"lnor\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 % 97.5 %\n   -0.167    0.00118 -141   &lt;0.001 Inf -0.169 -0.165\n\nTerm: r\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n# The above call to avg_comparisons is equivalent to:\n# w_eta_r0 &lt;- sweep(eta_r0, 1, ld$n, \"*\")\nd_new &lt;- copy(d)\nlo &lt;- copy(d_new[, r := 0])\nd_new &lt;- copy(d)\nhi &lt;- copy(d_new[, r := 1])\ny_lo &lt;- predict(f2, newdata = lo)\ny_hi &lt;- predict(f2, newdata = hi)\nmean(y_hi - y_lo)\n\n[1] -0.1701395\n\n# But we are only interested in the effect of r in the group that were revealed.\n# The following, in avg_comparisons, does not make sense to me. Need to revisit.\n# cmp &lt;- avg_comparisons(f2, newdata = d[er == 1 & r == 1], variables = \"r\", comparison = \"lnor\")\n# print(cmp, digits = 6)\n\n# The randomised comparison should approx map to a weighted combination of the pars.\n# The reason that the weights are computed conditional on r == 1 is so that we are\n# weight by the proportion within the revision group that receive each revision type \n# (approx 30% one-stage, 70% two-stage) and not the proportion receiving each revision \n# type over all those that received randomised surgery (approx 50% dair, 15% one, 35% two).\nmean(d[er == 1 & r == 1, mean(srp1)] * post1$`b[4]` + d[er == 1 & r == 1, mean(srp2)] * post1$`b[5]`) \n\n[1] -0.6947469\n\n\nThe above series of outputs suggest somewhat that we are able to recover the required parameters using various approaches.\nFor the choice domain, the comparison of interest is no-rf (ref) vs rif, which can be obtained directly from the parameter estimate that characterised the effects of the randomised comparisons. Choice domain effects reflect an average over the silos since all silos can enter this domain.\n\n# no-rif (ref)  vs rif (of any form)\n# NO - avg_comparisons(f2, variables = \"f\", comparison = \"lnor\")\n# We are only interested in the effect of choice for those revealed to choice\n# cmp &lt;- avg_comparisons(f2, newdata = d[ef == 1], variables = \"f\", comparison = \"lnor\")\n# print(cmp, digits = 6)\n\n# colMeans(b_f)\n# And this should just be the same as the coefficient from the model\nmean(post1$`b[9]`)\n\n[1] -0.6918082\n\n\nFor the duration domain, the comparison of interest can be obtained directly from the parameter estimates that characterised the effects of the randomised comparisons. Duration domain effects are also currently reflecting an average over the silos.\n\n# long (ref) vs short (specific to the type of surg recvd - one or two stage)\n\ncmp &lt;- avg_comparisons(f2, newdata = d[ed == 1 ], variables = \"d\", comparison = \"lnor\", by = \"d\")\nprint(cmp, digits = 6)\n\n\n  Estimate Std. Error        z Pr(&gt;|z|)   S     2.5 %    97.5 %\n -0.664385 0.00422153 -157.380  &lt; 0.001 Inf -0.672659 -0.656111\n -0.664248 0.00422073 -157.377  &lt; 0.001 Inf -0.672521 -0.655976\n\nTerm: d\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \n\ncmp &lt;- avg_comparisons(f2, newdata = d[ed == 1 & srp2 == 1], variables = \"d\", comparison = \"lnor\")\nprint(cmp, digits = 6)\n\n\n  Estimate Std. Error        z Pr(&gt;|z|)   S     2.5 %    97.5 %\n -0.667456  0.0051575 -129.415  &lt; 0.001 Inf -0.677565 -0.657348\n\nTerm: d\nType:  response \nComparison: ln(odds(1) / odds(0))\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \n\n# colMeans(b_d)\n\n# The randomised comparison should approx map directly to the surg type \n# specific pars \nmean(post1$`b[6]`) \n\n[1] -0.6843975\n\nmean(post1$`b[7]` ) \n\n[1] -0.7003817\n\n\nBased on the above, we seem to be in the right ballpark.",
    "crumbs": [
      "Assumptions and setup",
      "Model implementation"
    ]
  },
  {
    "objectID": "notebooks/overview.html",
    "href": "notebooks/overview.html",
    "title": "Study overview and assumptions",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3",
    "crumbs": [
      "Assumptions and setup",
      "Study overview and assumptions"
    ]
  },
  {
    "objectID": "notebooks/overview.html#population-structure",
    "href": "notebooks/overview.html#population-structure",
    "title": "Study overview and assumptions",
    "section": "Population structure",
    "text": "Population structure\nThe proportion of the population by silo membership is shown in Table 1.\n\n\n\n\n\n\n\n\n\n\n\nSilo\nProportion\n\n\n\n\nearly\n0.3\n\n\nlate\n0.5\n\n\nchronic\n0.2\n\n\n\n\n\n\n\n\nTable 1: Population membership by silo\n\n\n\n\nEach silo comprises patients with either a knee or hip infection. The assumed proportion of infections for each joint and for each silo are shown in Table 2.\n\n\n\n\n\n\n\n\n\n\n\nSilo\nJoint\nProportion\n\n\n\n\nearly\nknee\n0.4\n\n\nearly\nhip\n0.6\n\n\nlate\nknee\n0.7\n\n\nlate\nhip\n0.3\n\n\nchronic\nknee\n0.5\n\n\nchronic\nhip\n0.5\n\n\n\n\n\n\n\n\nTable 2: Population membership by silo and infection site",
    "crumbs": [
      "Assumptions and setup",
      "Study overview and assumptions"
    ]
  },
  {
    "objectID": "notebooks/overview.html#study-structure",
    "href": "notebooks/overview.html#study-structure",
    "title": "Study overview and assumptions",
    "section": "Study structure",
    "text": "Study structure\n\nPrimary outcome\nThe primary outcome is ‘treatment success’ at 12 months post platform entry, defined as all of:\n\nAlive\nClinical cure (no clinical or microbiological evidence of infection)\nNo ongoing use of antibiotics for the index joint; and\nProsthesis from the initial management strategy (destination prosthesis) is still in place\n\n\n\nDomains\n\nSurgical\nEarly stage patients do not receive randomisation and are assumed to mostly receive DAIR, although they may have any form of surgery. We assume the proportion of dair, one and two-stage surgery to be 85%, 10% and 5%.\nLate stage patients enter for randomised surgery and are allocated 1:1 to DAIR/revision. The clinician selects the specific type of revision (one-stage or two-stage) to be performed. For late stage infection patients that are randomised to dair, we assume that the preferences for dair, one and two-stage are 20%, 24% and 56%. For late stage infection patients that are randomised to revision, we assume that the preferences for one and two-stage are 30% and 70%.\nChronic stage patients do not receive randomisation and are assumed to receive DAIR, one-stage and two-stage based on clinician assessment. For chronic stage infection patients, we assume that the preferences for dair, one and two-stage are 20%, 20% and 60%.\n\n\nAntibiotic backbone duration\nEntry into antibiotic backbone duration domain is dependent on the surgery that was received. Specifically, this domain only applies for patients receiving one-stage revision.\nWithin the antibiotic backbone duration domain, allocation is to 12 weeks vs 6 weeks duration.\nPatients receiving DAIR and two-stage revision are expected to have 12 wk duration (not randomised) for the antibiotic backbone.\n\n\nExtended prophylaxis\nEntry into extended prophylaxis domain is dependent on the surgery that was received. Specifically, this domain only applies for patients receiving two-stage revision.\nWithin the extended prophylaxis domain, allocation is to 12 weeks duration vs none following the second stage of the revision.\nPatients receiving DAIR and one-stage revision are assumed to not receive any extended prophylaxis.\n\n\nAntibiotic choice\nEntry into antibiotic choice is primarily indicated by microbiology. For simplicity, the data generating process assumes that 60% of the total sample enter into this domain at random, unrelated to risk factors, irrespective of surgery type, silo and site of infection.",
    "crumbs": [
      "Assumptions and setup",
      "Study overview and assumptions"
    ]
  },
  {
    "objectID": "notebooks/overview.html#research-questions",
    "href": "notebooks/overview.html#research-questions",
    "title": "Study overview and assumptions",
    "section": "Research questions",
    "text": "Research questions\n\nSurgical\nFor the surgical domain we evaluate whether revision is superior to dair and also evaluate futility of reaching a superiority decision. This applies only to the late silo cohort.\n\n\nAntibiotic backbone duration\nFor the backbone duration domain, we evaluate whether short duration (6 wk) is non-inferior to long duration (12 wk) antibiotic treatment. This is applicable only to participants that receive one-stage revision. We also evaluate whether the non-inferiority decision is futile in the sense that it appears unlikely that non-inferiority will ever be established.\n\n\nExtended prophylaxis\nFor ethe extended prophylaxis domain, we evaluate whether a 12 wk duration is superior to no extended prophylaxis. This is applicable only to participants that receive two-stage revision (the extended prophylaxis is given following the completion of the second operation/stage). We also evaluate whether the superiority decision is futile in the sense that it appears unlikely that superiority will ever be established.\n\n\nAntibiotic choice\nFor the choice domain we evaluate whether rifampicin is superior to no rifampicin. This is applicable to the participants that are enter into the choice domain. We also evaluate whether the superiority decision is futile in the sense that it appears unlikely that superiority will ever be established.",
    "crumbs": [
      "Assumptions and setup",
      "Study overview and assumptions"
    ]
  },
  {
    "objectID": "notebooks/overview.html#response-rates",
    "href": "notebooks/overview.html#response-rates",
    "title": "Study overview and assumptions",
    "section": "Response rates",
    "text": "Response rates\nThe baseline probability/log-odds of treatment success is assumed to vary by silo and site of infection as detailed in Table 3.\n\n\n\n\n\n\n\n\n\n\n\nSilo\nJoint\nPr(trt success)\nlog-odds sucess\n\n\n\n\nearly\nknee\n0.65\n0.62\n\n\nearly\nhip\n0.75\n1.10\n\n\nlate\nknee\n0.55\n0.20\n\n\nlate\nhip\n0.60\n0.41\n\n\nchronic\nknee\n0.60\n0.41\n\n\nchronic\nhip\n0.65\n0.62\n\n\n\n\n\n\n\n\nTable 3: Baseline probability of treatment success by silo and site of infection",
    "crumbs": [
      "Assumptions and setup",
      "Study overview and assumptions"
    ]
  },
  {
    "objectID": "notebooks/overview.html#enrolment",
    "href": "notebooks/overview.html#enrolment",
    "title": "Study overview and assumptions",
    "section": "Enrolment",
    "text": "Enrolment\nFor the purposes of simulating the study cohort, accrual is assumed to follow a non-homogeneous Poisson process that ramps up over the first 12 months of enrolment and then has a steady state of around 1.5 per new entrants per day.\n\n\nCode\n# events per day\nlambda = 1.52\n# ramp up over 12 months \nrho = function(t) pmin(t/360, 1)\n\nd_fig &lt;- data.table(\n  t = 0:(5 * 365),\n  # expected number enrolled\n  n = c(0, nhpp.mean(lambda, rho, t1 = 5 * 365, num.points = 5 * 365))\n)\n\ndf1 &lt;- data.table(x1 = 365/365, \n                 x2 = 730/365, \n                 y1 = d_fig[t == 365, n], \n                 y2 = d_fig[t == 365, n]\n                 )\ndf2 &lt;- data.table(x1 = 730/365, \n                 x2 = 730/365, \n                 y1 = d_fig[t == 365, n], \n                 y2 = d_fig[t == 730, n]\n                 )\n\nn_p_y &lt;- d_fig[t == 730, n] - d_fig[t == 365, n]\n\nggplot(d_fig, aes(x = t/365, y = n)) +\n  geom_line() +\n  geom_segment(aes(x = x1,\n                   y = y1,\n                   xend = x2,\n                   yend = y2),\n               lty = 1, lwd = 0.2, \n               arrow = arrow(length = unit(0.2, \"inches\")),\n               data = df1) +\n  geom_segment(aes(x = x1,\n                   y = y1,\n                   xend = x2,\n                   yend = y2),\n               lty = 1, lwd = 0.2, \n               arrow = arrow(length = unit(0.2, \"inches\")),\n               data = df2) +\n  annotate(\"text\", \n           x = 2.68, \n           y = 500, \n           label = sprintf(\"~ %.0f increment\", n_p_y)) +\n  scale_x_continuous(\"Year\") +\n  scale_y_continuous(\"E[accrual]\", breaks = seq(0, 2500, by = 500))\n\n\n\n\n\n\n\n\nFigure 1: Expected accrual",
    "crumbs": [
      "Assumptions and setup",
      "Study overview and assumptions"
    ]
  },
  {
    "objectID": "notebooks/overview.html#analyses",
    "href": "notebooks/overview.html#analyses",
    "title": "Study overview and assumptions",
    "section": "Analyses",
    "text": "Analyses\n\nCohort data informing analyses\nDifferent cohorts inform different parts of the experimental results.\n\nEarly infection\nPatients with early stage infection are not revealed to the surgical domain. The surgical intervention will usually be dair for which 12 weeks of backbone antibiotics are recommended. There are, however, instances where early stage infection patients will receive either one-stage or two-stage revision. Some of these patients will be able to enter the randomised backbone duration domain (those that receive one-stage) and the extended prophylaxis domain (those that receive two-stage). Early silo patients will also enter the choice domain if they have the relevant microbiological state that means that they will be eligible to do so.\n\n\nLate infection\nPatients with late infection can enter all domains with some restrictions. They are randomised to dair vs revision in the surgical domain. Patients allocated to revision will receive a one or two-stage procedure based on self-selection. Both the planned surgery (one-stage/two-stage) and the surgery actually performed should be captured – the former should be recorded at the time of randomisation. Patients receiving one-stage will also receive randomised backbone antibiotic duration. Patients receiving two-stage will not receive randomised backbone antibiotic duration, but will receive randomised extended prophylaxis. Late silo patients will also enter the choice domain if they are eligible to do so.\n\n\nChronic infection\nPatients with chronic stage infection are not randomised into the surgical domain. Like the early silo cohort, they can enter into the antibiotic backbone domain and the extended prophylaxis domain based on the type of surgery they receive. Chronic silo patients will also enter the choice domain if they are eligible to do so.\n\n\n\nMissingness\nMissingness is not currently implemented within the simulations.\n\n\nNon-differential follow-up\nTo avoid artifacts associated with non-differential follow-up (e.g. early vs late deaths), participants will be included in the analyses only when they reach the primary endpoints (12 months) irrespective of whether they experienced treatment failure before that time.\n\n\nModel specification\nFor each silo \\(l\\) and site of infection \\(j\\) we therefore simulate the probability of treatment success as:\n\\[\n\\begin{aligned}\n\\text{logit}(\\pi) &=  \\mu + \\lambda_s + \\rho_j + \\phi_{l} + \\sum_{d=1}^{D} x_d^\\top \\vec{\\beta_d} + \\zeta_{r,v} + \\tau_t + z^\\top \\vec{\\omega}\n\\end{aligned}\n\\tag{1}\\]\n\n\\(\\mu\\) grand mean log-odds of treatment success; it serves as a reference from which all other effects deviate\n\\(\\lambda_s\\) change associated with membership silo \\(s\\)\n\\(\\rho_j\\) change associated with site of infection (joint) \\(j\\)\n\\(\\phi_{l}\\) preference for surgical approach under revision type \\(l\\) with elements for non-randomised treatment, one-stage and two-stage\n\\(\\vec{\\beta_d}\\) change associated treatment allocation with domain \\(d\\)\n\\(\\zeta_{r,v}\\) change associated with site \\(v\\) nested within region \\(r\\)\n\\(\\tau_t\\) change associated with randomisation period \\(t\\)\n\\(\\omega\\) parameters associated with baseline factors\n\nThe trial data will be modelled as above with decisions made on the basis of the joint posterior, but an additional analysis model run with treatment by site of infection (hip/knee) interactions to characterise and report treatment heterogeneity.",
    "crumbs": [
      "Assumptions and setup",
      "Study overview and assumptions"
    ]
  },
  {
    "objectID": "notebooks/overview.html#decision-rules",
    "href": "notebooks/overview.html#decision-rules",
    "title": "Study overview and assumptions",
    "section": "Decision rules",
    "text": "Decision rules\nIn the following, all treatment effect parameters relate back to the model specification provided earlier.\n\nSurgical domain\nThe surgical domain considers the effect of revision relative to dair in the late-stage infection silo.\nFollowing the earlier model specification, let \\(\\Delta_R = \\beta_4 \\mathbb{E}[\\mathbb{I}(S_{R_P} == 1 \\land R == 1)] + \\beta_5 \\mathbb{E}[\\mathbb{I}(S_{R_P} == 2 \\land R == 1)]\\) correspond to the average conditional log-odds ratio associated with revision. The probability that revision is superior to dair is defined as:\n\\[\\begin{aligned}\nP_{\\text{surgical (sup)}} = Pr(\\Delta_R &gt; 0)\n\\end{aligned}\\]\nand enrolment is stopped for superiority if \\(P_{\\text{surgical (sup)}} &gt; 0.99\\).\nThe probability of futility for revision being superior to dair is defined as:\n\\[\\begin{aligned}\nP_{\\text{surgical (fut)}} = Pr(\\Delta_R &gt; \\log(1.2))\n\\end{aligned}\\]\nand enrolment is stopped for futility if \\(P_{\\text{surgical (fut)}} &lt; 0.05\\).\n\n\nDuration domain\nThe duration domain considers the effect of short relative to long duration therapy depending on the type of revision received.\nIf, in the surgical domain, revision is found to be inferior to DAIR, then randomisation in the surgical domain will cease and DAIR will be recommended for all late acute who meet the domain eligibility criteria. But the duration domain will continue, because people in other silos will continue to have revision surgery (occasionally in Early and routinely in Chronic).\n\nDAIR\nNo duration effects are applicable for DAIR.\n\n\nOne-stage revision\nLet \\(\\beta_6\\) correspond to the conditional log-odds ratio associated with 6 weeks (short) duration antibiotics relative to 12 weeks (long) when one-stage revision is received. The probability that short is non-inferior to long is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-1 (ni)}} = Pr(\\beta_6 &gt; \\log(1/1.2))\n\\end{aligned}\\]\nand enrolment is stopped for non-inferiority if \\(P_{\\text{duration-1 (ni)}} &gt; 0.99\\).\nThe probability of futility for revision being superior to dair is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-1 (fut)}} = Pr(\\beta_6 &gt; \\log(1))\n\\end{aligned}\\]\nand enrolment is stopped for futility (with respect to being able to establish non-inferiority) if \\(P_{\\text{duration-1 (fut)}} &lt; 0.05\\).\n\n\nTwo-stage revision\nLet \\(\\beta_7\\) correspond to the conditional log-odds ratio associated with 12 weeks (long) duration antibiotics relative to 7 days (short) when two-stage revision is received. The probability that long duration is superior to short is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-2 (sup)}} = Pr(\\beta_7 &gt; 0)\n\\end{aligned}\\]\nand enrolment is stopped for superiority if \\(P_{\\text{duration-2 (sup)}} &gt; 0.99\\).\nThe probability of futility for long duration being superior to short is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-2 (fut)}} = Pr(\\beta_7 &gt; \\log(1.2))\n\\end{aligned}\\]\nand enrolment is stopped for futility if \\(P_{\\text{duration-2 (fut)}} &lt; 0.05\\).\n\n\n\nChoice domain\nThe choice domain considers the effect of rifampacin relative to no-rifampacin.\nLet \\(\\beta_{9}\\) correspond to the conditional log-odds ratio associated with rifampacin relative to no-rifampacin The probability that rifampacin is superior to no-rifampacin is defined as:\n\\[\\begin{aligned}\nP_{\\text{choice (sup)}} = Pr(\\beta_{9} &gt; 0)\n\\end{aligned}\\]\nand enrolment is stopped for superiority if \\(P_{\\text{choice (sup)}} &gt; 0.99\\).\nThe probability of futility for rifampacin being superior to no-rifampacin is defined as:\n\\[\\begin{aligned}\nP_{\\text{choice (fut)}} = Pr(\\beta_{9} &gt; \\log(1.2))\n\\end{aligned}\\]\nand enrolment is stopped for futility if \\(P_{\\text{choice (fut)}} &lt; 0.05\\).",
    "crumbs": [
      "Assumptions and setup",
      "Study overview and assumptions"
    ]
  },
  {
    "objectID": "notebooks/setup.html",
    "href": "notebooks/setup.html",
    "title": "Overview",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3"
  },
  {
    "objectID": "notebooks/setup.html#population-structure",
    "href": "notebooks/setup.html#population-structure",
    "title": "Overview",
    "section": "Population structure",
    "text": "Population structure\nThe proportion of the population by silo membership is shown in Table 1.\n\n\n\n\n\n\n\n\n\n\n\nSilo\nProportion\n\n\n\n\nearly\n0.3\n\n\nlate\n0.5\n\n\nchronic\n0.2\n\n\n\n\n\n\n\n\nTable 1: Population membership by silo\n\n\n\n\nEach silo comprises patients with either a knee or hip infection. The assumed proportion of infections for each joint and for each silo are shown below.\n\n\n\n\n\n\n\n\n\n\n\nSilo\nJoint\nProportion\n\n\n\n\nearly\nknee\n0.4\n\n\nearly\nhip\n0.6\n\n\nlate\nknee\n0.7\n\n\nlate\nhip\n0.3\n\n\nchronic\nknee\n0.5\n\n\nchronic\nhip\n0.5\n\n\n\n\n\n\n\n\nTable 2: Population membership by silo and infection site"
  },
  {
    "objectID": "notebooks/setup.html#study-structure",
    "href": "notebooks/setup.html#study-structure",
    "title": "Overview",
    "section": "Study structure",
    "text": "Study structure\n\nPrimary outcome\nThe primary outcome is treatment success at 12 months post platform entry, defined as all of:\n\nAlive\nClinical cure (no clinical or microbiological evidence of infection)\nNo ongoing use of antibiotics for the index joint; and\nThe prosthesis present after the initial management strategy is complete (destination prosthesis) still in place\n\nreferred to as ‘treatment success’.\n\n\nDomains\n\nSurgical\nEarly stage patients do not receive randomisation and are assumed to mostly receive DAIR, although they may have any form of surgery. We assume the proportion of dair, one and two-stage surgery to be 85%, 10% and 5%.\nLate stage patients enter for randomised surgery and are allocated 1:1 to DAIR/revision. The clinician selects the specific type of revision (one-stage or two-stage) to be performed. For late stage infection patients that are randomised to dair, we assume that the preferences for dair, one and two-stage are 20%, 24% and 56%. For late stage infection patients that are randomised to revision, we assume that the preferences for one and two-stage are 30% and 70%.\nChronic stage patients do not receive randomisation and are assumed to receive DAIR, one-stage and two-stage based on clinician assessment. For chronic stage infection patients, we assume that the preferences for dair, one and two-stage are 20%, 20% and 60%.\n\n\nAntibiotic backbone duration\nEntry into antibiotic backbone duration domain is dependent on the surgery that was received. Specifically, this domain only applies for patients receiving one-stage revision.\nWithin the antibiotic backbone duration domain, allocation is to 12 weeks vs 6 weeks duration.\nPatients receiving DAIR and two-stage revision are assumed to have 12 wk duration (not randomised).\n\n\nExtended prophylaxis\nEntry into extended prophylaxis domain is dependent on the surgery that was received. Specifically, this domain only applies for patients receiving two-stage revision.\nWithin the extended prophylaxis domain, allocation is to 12 weeks duration vs none following the second stage of the revision.\nPatients receiving DAIR and one-stage revision are assumed to not receive any extended prophylaxis.\n\n\nAntibiotic choice\nEntry into antibiotic choice is primarily indicated by microbiology. For simplicity, the data generating process assumes that 60% of the total sample enter into this domain at random, unrelated to risk factors, irrespective of surgery type, silo and site of infection."
  },
  {
    "objectID": "notebooks/setup.html#research-questions",
    "href": "notebooks/setup.html#research-questions",
    "title": "Overview",
    "section": "Research questions",
    "text": "Research questions\nThe questions of interest are as follows:\n\nSurgical\nFor the surgical domain we evaluate whether revision is superior to dair and futility for superiority. This applies only to the late silo cohort.\n\n\nAntibiotic backbone duration\nFor the backbone duration domain, we evaluate whether short duration (6 wk) is non-inferior to long duration (12 wk) antibiotic treatment. This is applicable only to participants that receive one-stage revision. We also evaluate whether the non-inferiority decision is futile in the sense that it appears unlikely that non-inferiority will ever be established.\n\n\nExtended prophylaxis\nFor ethe extended prophylaxis domain, we evaluate whether a 12 wk duration is superior to no extended prophylaxis. This is applicable only to participants that receive two-stage revision (the extended prophylaxis follows the second operation). We also evaluate whether the superiority decision is futile in the sense that it appears unlikely that superiority will ever be established.\n\n\nAntibiotic choice\nFor the choice domain we evaluate whether rifampicin is superior to no rifampicin. This is applicable to the participants that are enter into the choice domain. We also evaluate whether the superiority decision is futile in the sense that it appears unlikely that superiority will ever be established."
  },
  {
    "objectID": "notebooks/setup.html#response-rates",
    "href": "notebooks/setup.html#response-rates",
    "title": "Overview",
    "section": "Response rates",
    "text": "Response rates\nThe baseline probability/log-odds of treatment success is assumed to vary by silo and site of infection as detailed below.\n\n\n\n\n\n\n\n\n\n\n\nSilo\nJoint\nPr(trt success)\nlog-odds sucess\n\n\n\n\nearly\nknee\n0.65\n0.62\n\n\nearly\nhip\n0.75\n1.10\n\n\nlate\nknee\n0.55\n0.20\n\n\nlate\nhip\n0.60\n0.41\n\n\nchronic\nknee\n0.60\n0.41\n\n\nchronic\nhip\n0.65\n0.62\n\n\n\n\n\n\n\n\nTable 3: Baseline probability of treatment success by silo and site of infection"
  },
  {
    "objectID": "notebooks/setup.html#expected-accrual",
    "href": "notebooks/setup.html#expected-accrual",
    "title": "Overview",
    "section": "Expected accrual",
    "text": "Expected accrual\nFor the purposes of simulating the study cohort, accrual is assumed to follow a non-homogeneous Poisson process that ramps up over the first 12 months of enrolment and then has a steady state of around 1.5 per new entrants per day.\n\n\nCode\n# events per day\nlambda = 1.52\n# ramp up over 12 months \nrho = function(t) pmin(t/360, 1)\n\nd_fig &lt;- data.table(\n  t = 0:(5 * 365),\n  # expected number enrolled\n  n = c(0, nhpp.mean(lambda, rho, t1 = 5 * 365, num.points = 5 * 365))\n)\n\ndf1 &lt;- data.table(x1 = 365/365, \n                 x2 = 730/365, \n                 y1 = d_fig[t == 365, n], \n                 y2 = d_fig[t == 365, n]\n                 )\ndf2 &lt;- data.table(x1 = 730/365, \n                 x2 = 730/365, \n                 y1 = d_fig[t == 365, n], \n                 y2 = d_fig[t == 730, n]\n                 )\n\nn_p_y &lt;- d_fig[t == 730, n] - d_fig[t == 365, n]\n\nggplot(d_fig, aes(x = t/365, y = n)) +\n  geom_line() +\n  geom_segment(aes(x = x1,\n                   y = y1,\n                   xend = x2,\n                   yend = y2),\n               lty = 1, lwd = 0.2, \n               arrow = arrow(length = unit(0.2, \"inches\")),\n               data = df1) +\n  geom_segment(aes(x = x1,\n                   y = y1,\n                   xend = x2,\n                   yend = y2),\n               lty = 1, lwd = 0.2, \n               arrow = arrow(length = unit(0.2, \"inches\")),\n               data = df2) +\n  annotate(\"text\", \n           x = 2.6, \n           y = 500, \n           label = sprintf(\"~ %.0f increment\", n_p_y)) +\n  scale_x_continuous(\"Year\") +\n  scale_y_continuous(\"E[accrual]\", breaks = seq(0, 2500, by = 500))\n\n\n\n\n\n\n\n\nFigure 1: Expected accrual"
  },
  {
    "objectID": "notebooks/setup.html#analyses",
    "href": "notebooks/setup.html#analyses",
    "title": "Overview",
    "section": "Analyses",
    "text": "Analyses\n\nCohort data informing analyses\nDifferent cohorts enter inform different parts of the experiment.\n\nEarly infection\nPatients with early stage infection are not revealed to the surgical domain. The surgical intervention will usually be dair for which 12 weeks of backbone antibiotics are recommended. There are, however, instances where early stage infection patients will receive either one-stage or two-stage revision. These patients will be able to enter the randomised backbone duration domain (one-stage, but not two-stage) and the extended prophylaxis domain (two-stage, but not one-stage). Early silo patients will also enter the choice domain if they are eligible to do so.\n\n\nLate infection\nPatients with late infection can enter all domains with some restrictions. They are randomised to dair vs revision in the surgical domain. Patients allocated to revision will receive a one or two-stage procedure based on self-selection. Both the planned surgery (one-stage/two-stage) and the surgery actually performed should be captured – the former should be recorded at the time of randomisation. Patients receiving one-stage receive randomised backbone antibiotics. Patients receiving two-stage receive randomised extended prophylaxis. Late silo patients will also enter the choice domain if they are eligible to do so.\n\n\nChronic infection\nPatients with chronic stage infection are not randomised into the surgical domain. Like the early silo cohort, they can enter into the antibiotic backbone domain and the extended prophylaxis domain based on the type of surgery they receive. Chronic silo patients will also enter the choice domain if they are eligible to do so.\n\n\n\nMissingness\nMissingness is not currently implemented within the simulations.\n\n\nNon-differential follow-up\nTo avoid artifacts associated with non-differential follow-up (e.g. early vs late deaths), participants will be included in the analyses only when they reach the primary endpoints (12 months) irrespective of whether they experienced treatment failure before that time.\n\n\nModel specification\nFor each silo \\(l\\) and site of infection \\(j\\) we therefore simulate the probability of treatment success as:\n\\[\n\\begin{aligned}\n\\text{logit}(\\pi) &=  \\mu + \\lambda_s + \\rho_j + \\phi_{l} + \\sum_{d=1}^{D} x_d^\\top \\vec{\\beta_d} + \\zeta_{r,v} + \\tau_t + z^\\top \\vec{\\omega}\n\\end{aligned}\n\\tag{1}\\]\n\n\\(\\mu\\) grand mean log-odds of treatment success; it serves as a reference from which all other effects deviate\n\\(\\lambda_s\\) change associated with membership silo \\(s\\)\n\\(\\rho_j\\) change associated with site of infection (joint) \\(j\\)\n\\(\\phi_{l}\\) preference for surgical approach under revision type \\(l\\) with elements for non-randomised treatment, one-stage and two-stage\n\\(\\vec{\\beta_d}\\) change associated treatment allocation with domain \\(d\\)\n\\(\\zeta_{r,v}\\) change associated with site \\(v\\) nested within region \\(r\\)\n\\(\\tau_t\\) change associated with randomisation period \\(t\\)\n\\(\\omega\\) parameters associated with baseline factors\n\nThe trial data will be modelled as above with decisions made on the basis of the joint posterior, but an additional analysis model run with treatment by site of infection (hip/knee) interactions to characterise and report treatment heterogeneity."
  },
  {
    "objectID": "notebooks/setup.html#decision-rules",
    "href": "notebooks/setup.html#decision-rules",
    "title": "Overview",
    "section": "Decision rules",
    "text": "Decision rules\nIn the following, all treatment effect parameters relate back to the model specification provided earlier.\n\nSurgical domain\nThe surgical domain considers the effect of revision relative to dair in the late-stage infection silo.\nFollowing the earlier model specification, let \\(\\Delta_R = \\beta_4 \\mathbb{E}[\\mathbb{I}(S_{R_P} == 1 \\land R == 1)] + \\beta_5 \\mathbb{E}[\\mathbb{I}(S_{R_P} == 2 \\land R == 1)]\\) correspond to the average conditional log-odds ratio associated with revision. The probability that revision is superior to dair is defined as:\n\\[\\begin{aligned}\nP_{\\text{surgical (sup)}} = Pr(\\Delta_R &gt; 0)\n\\end{aligned}\\]\nand enrolment is stopped for superiority if \\(P_{\\text{surgical (sup)}} &gt; 0.99\\).\nThe probability of futility for revision being superior to dair is defined as:\n\\[\\begin{aligned}\nP_{\\text{surgical (fut)}} = Pr(\\Delta_R &gt; \\log(1.2))\n\\end{aligned}\\]\nand enrolment is stopped for futility if \\(P_{\\text{surgical (fut)}} &lt; 0.05\\).\n\n\nDuration domain\nThe duration domain considers the effect of short relative to long duration therapy depending on the type of revision received.\nIf, in the surgical domain, revision is found to be inferior to DAIR, then randomisation in the surgical domain will cease and DAIR will be recommended for all late acute who meet the domain eligibility criteria. But the duration domain will continue, because people in other silos will continue to have revision surgery (occasionally in Early and routinely in Chronic).\n\nDAIR\nNo duration effects are applicable for DAIR.\n\n\nOne-stage revision\nLet \\(\\beta_6\\) correspond to the conditional log-odds ratio associated with 6 weeks (short) duration antibiotics relative to 12 weeks (long) when one-stage revision is received. The probability that short is non-inferior to long is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-1 (ni)}} = Pr(\\beta_6 &gt; \\log(1/1.2))\n\\end{aligned}\\]\nand enrolment is stopped for non-inferiority if \\(P_{\\text{duration-1 (ni)}} &gt; 0.99\\).\nThe probability of futility for revision being superior to dair is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-1 (fut)}} = Pr(\\beta_6 &gt; \\log(1))\n\\end{aligned}\\]\nand enrolment is stopped for futility (with respect to being able to establish non-inferiority) if \\(P_{\\text{duration-1 (fut)}} &lt; 0.05\\).\n\n\nTwo-stage revision\nLet \\(\\beta_7\\) correspond to the conditional log-odds ratio associated with 12 weeks (long) duration antibiotics relative to 7 days (short) when two-stage revision is received. The probability that long duration is superior to short is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-2 (sup)}} = Pr(\\beta_7 &gt; 0)\n\\end{aligned}\\]\nand enrolment is stopped for superiority if \\(P_{\\text{duration-2 (sup)}} &gt; 0.99\\).\nThe probability of futility for long duration being superior to short is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-2 (fut)}} = Pr(\\beta_7 &gt; \\log(1.2))\n\\end{aligned}\\]\nand enrolment is stopped for futility if \\(P_{\\text{duration-2 (fut)}} &lt; 0.05\\).\n\n\n\nChoice domain\nThe choice domain considers the effect of rifampacin relative to no-rifampacin.\nLet \\(\\beta_{9}\\) correspond to the conditional log-odds ratio associated with rifampacin relative to no-rifampacin The probability that rifampacin is superior to no-rifampacin is defined as:\n\\[\\begin{aligned}\nP_{\\text{choice (sup)}} = Pr(\\beta_{9} &gt; 0)\n\\end{aligned}\\]\nand enrolment is stopped for superiority if \\(P_{\\text{choice (sup)}} &gt; 0.99\\).\nThe probability of futility for rifampacin being superior to no-rifampacin is defined as:\n\\[\\begin{aligned}\nP_{\\text{choice (fut)}} = Pr(\\beta_{9} &gt; \\log(1.2))\n\\end{aligned}\\]\nand enrolment is stopped for futility if \\(P_{\\text{choice (fut)}} &lt; 0.05\\)."
  },
  {
    "objectID": "notebooks/sim-design3-results.html",
    "href": "notebooks/sim-design3-results.html",
    "title": "Simulation results 3",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\n\n\nSimulation 3 is a sequential trial with decision criteria for superiority, and non-inferiority and also for futility with respect to both superiority and non-inferiority.\n\nFor the surgical domain we evaluate whether revision is superior to dair and futility for superiority.\nFor the duration domain (one-stage) we evaluate whether short duration is non-inferior to long duration antibiotic treatment. We also evaluate whether the non-inferiority decision is futile.\nFor the duration domain (two-stage) we evaluate whether long duration is superior to short duration antibiotic treatment (equivalently whether short duration is inferior to long). We also evaluate whether the superiority decision is futile.\nFor the choice domain we evaluate whether rif is superior to no-rif. We also evaluate whether the superiority decision is futile.\n\nEnrolment stops for the respective domain/cells when any of the above are triggered based the decision rules described earlier.\nWe provide summaries of each simulation scenario and the results that were obtained.\n\n\nLoad simulation results\n# files of interest\nflist &lt;- list.files(\"data\", pattern = \"sim03-sc01\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n\n\n\nConfiguration used for each simulated scenario\n# cfg used in each scenario\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\n# conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  N_pt = as.numeric(N_pt),\n  b_r1 = as.numeric(b_r1),\n  b_r2 = as.numeric(b_r2),\n  w_srp2 = as.numeric(w_srp2),\n  b_r1d = as.numeric(b_r1d),\n  b_r2d = as.numeric(b_r2d),\n  b_f = as.numeric(b_f),\n  d_sup = as.numeric(thresh_sup),\n  d_ni = as.numeric(thresh_non_inf),\n  d_fut_sup = as.numeric(thresh_fut_sup),\n  d_fut_ni = as.numeric(thresh_fut_ni)\n  )]\n\n# derive the 'true' effect for surgery based on weight combination\n# d_cfg[, b_r := b_r1 + w_srp2 * b_r2]\n# d_cfg[, `:=`(b_r1 = NULL, b_r2 = NULL, w_srp2 = NULL)]\n\nd_cfg[, `:=`(w_srp2 = NULL)]\n\n# d_tru &lt;- melt(d_cfg[\n#   , .SD, .SDcols = c(\"sc\", \"v\", \"analys\", \n#                      \"b_r\", \"b_r1d\", \"b_r2d\", \"b_f\")], \n#   id.vars = c(\"sc\", \"v\", \"analys\"), value.name = \"lor_tru\")\n\n\n\n\nProcess simulation results for variables of interest\n# Decisions\ni &lt;- 1\nd_dec &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  # l[[i]]$d_decision\n\n  d_decision &lt;- copy(l[[i]]$d_decision)\n  m &lt;- melt(d_decision, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"parname\")\n  \n  # Should be right, but just in case...\n  if(any(is.na(m$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    m[is.na(value), value := FALSE]\n  }\n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  m[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, parname)]\n  # summarise by analysis, decision type and parameter\n  m &lt;- m[, .(pr_val = mean(value)), keyby = .(analys, quant, parname)]\n  # put into wide format\n  m &lt;- dcast(m, parname + analys ~ quant, value.var = \"pr_val\")\n\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n# Posterior summaries on effects of interest\nd_post_smry_2 &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- l[[i]]$d_post_smry_2\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n# Participant data from trial (grouped)\nd_all &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- l[[i]]$d_grp\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n\nTable 1 summarises the configurations used in each simulated scenario. Each treatment effect parameter is set to have the same magnitude of effect. The effects range from \\(\\log(1/2)\\) in scenario 1 to \\(\\log(2)\\) in scenario 7. Decision rules and thresholds remain constant over the entire enrolment period. The decision processes are documented in the Decision rules page.\nRevision effects are computed as a weighted combination of the log-odds ratios for the one-stage and two-stage revision effects. The weights are the sample proportion receiving one-stage and two-stage surgery in those patients receiving randomised surgical treatment and randomised to revision.\n\n\nCode\nd_tbl &lt;- d_cfg[, .(v, N_pt, b_r1, b_r2, b_r1d, b_r2d, b_f, \n                   delta_sup = delta_sup,\n                   delta_sup_fut = delta_sup_fut,\n                   delta_ni = 1/delta_ni,\n                   thresh_sup, thresh_non_inf, thresh_fut_sup, thresh_fut_ni)]\n\ng_tbl &lt;- d_tbl |&gt; gt() |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = c(b_r1, b_r2, b_r1d, b_r2d, b_f,\n                delta_ni\n                ),\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_r1, b_r2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_r1d, b_r2d)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_f)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision setup\"),\n    columns = c(delta_sup, thresh_sup, \n                delta_sup_fut, thresh_fut_sup, \n                delta_ni, thresh_non_inf, thresh_fut_ni)\n  ) |&gt;\n  cols_label(\n    v = html(\"Configuration\"),\n    b_r1 = html(\"rev&lt;br&gt;(one-stage)\"),\n    b_r2 = html(\"rev&lt;br&gt;(two-stage)\"),\n    b_r1d = html(\"short&lt;br&gt;(one-stage)\"),\n    b_r2d = html(\"short&lt;br&gt;(two-stage)\"),\n    b_f = html(\"rif\"),\n    delta_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    thresh_sup = html(\"p&lt;sub&gt;sup&lt;/sub&gt;\"),\n    delta_sup_fut = html(\"delta&lt;sub&gt;fut-sup&lt;/sub&gt;\"),\n    thresh_fut_sup = html(\"p&lt;sub&gt;fut-sup&lt;/sub&gt;\"),\n    delta_ni = html(\"delta&lt;sub&gt;ni&lt;/sub&gt;\"),\n    thresh_non_inf = html(\"p&lt;sub&gt;ni&lt;/sub&gt;\"),\n    thresh_fut_ni = html(\"p&lt;sub&gt;fut-ni&lt;/sub&gt;\")\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"bottom\"), color = \"black\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = N_pt == 2500\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Surgical effects only applies to late silo, effect is relative to response under DAIR.\",\n    locations = cells_column_labels(columns = c(b_r1, b_r2))\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under long duration.\",\n    locations = cells_column_labels(columns = b_r1d)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under short duration.\",\n    locations = cells_column_labels(columns = b_r2d)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under no-rifampicin\",\n    locations = cells_column_labels(columns = b_f)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating superiority\",\n    locations = cells_column_labels(columns = delta_sup)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Probability threshold above which superiority is concluded\",\n    locations = cells_column_labels(columns = thresh_sup)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating futility wrt the superiority decision\",\n    locations = cells_column_labels(columns = delta_sup_fut)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold below which futility is concluded\",\n    locations = cells_column_labels(columns = thresh_fut_sup)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating non-inferiority\",\n    locations = cells_column_labels(columns = delta_ni)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold above which non-inferiority is concluded\",\n    locations = cells_column_labels(columns = thresh_non_inf)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold below which non-inferiority decision is deemed futile\",\n    locations = cells_column_labels(columns = thresh_fut_ni)\n  )   \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration\nN_pt\n\nSurgical (Da)\n\n\nDuration (Db)\n\n\nType (Dc)\n\n\nDecision setup\n\n\n\nrev\n(one-stage)1\nrev\n(two-stage)1\nshort\n(one-stage)2\nshort\n(two-stage)3\nrif4\ndeltasup5\npsup6\ndeltafut-sup7\npfut-sup8\ndeltani9\npni10\npfut-ni11\n\n\n\n\nv01\n500\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv01\n1000\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv01\n1500\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv01\n2000\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv01\n2500\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n500\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n1000\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n1500\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n2000\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n2500\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n1000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n1500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n2000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n500\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n1000\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n1500\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n2000\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n500\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n1000\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n1500\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n2000\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n500\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n1000\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n1500\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n2000\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n2500\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n500\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n1000\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n1500\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n2000\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\n\n1 Surgical effects only applies to late silo, effect is relative to response under DAIR.\n\n\n2 Applies to all silos, effect is relative to response under long duration.\n\n\n3 Applies to all silos, effect is relative to response under short duration.\n\n\n4 Applies to all silos, effect is relative to response under no-rifampicin\n\n\n5 Reference OR for evaluating superiority\n\n\n6 Probability threshold above which superiority is concluded\n\n\n7 Reference OR for evaluating futility wrt the superiority decision\n\n\n8 Probability threshold below which futility is concluded\n\n\n9 Reference OR for evaluating non-inferiority\n\n\n10 Probability threshold above which non-inferiority is concluded\n\n\n11 Probability threshold below which non-inferiority decision is deemed futile\n\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 shows the cumulative probability of each decision quantity. Once answered, the questions are no longer evaluated.\n\nThe first row details the cumulative probability of decisions within the surgical domain, which currently applies only to the late silo. Superiority (sup in legend) and futility (fut_sup) are the relevant quantities of interest.\nThe second row details the cumulative probability of decisions within the duration domain under one-stage revision. Non-inferiority (ni) and inferiority (fut_ni) are the relevant quantities of interest.\nThe third row details the cumulative probability of decisions within the duration domain under two-stage revision. Superiority (sup) and futility (fut_sup) are the relevant quantities of interest.\nThe fourth row details the cumulative probability of decisions within the choice domain. Superiority (sup) and futility (fut_sup) are the relevant quantities of interest.\n\n\n\nCode\n# put power by scenario, variant and analysis in long format\nd_fig_0_01 &lt;- melt(d_dec, id.vars = c(\"sc\", \"v\", \"analys\", \"parname\"), variable.name = \"quant\")\nd_fig_0_01[, quant := factor(quant, \n                        levels = c(\"sup\", \"fut_sup\", \"trt_ni_ref\", \"fut_trt_ni_ref\"))]\n# add in the number of pts having reached 12 months post rand by analysis num\nd_fig_0_01 &lt;- merge(d_fig_0_01, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig_0_01 &lt;- rbind(\n  d_fig_0_01[parname == \"b_r\" & quant %in% c(\"sup\", \"fut_sup\"), ],\n  d_fig_0_01[parname == \"b_r1d\" & quant %in% c(\"trt_ni_ref\", \"fut_trt_ni_ref\"), ],\n  d_fig_0_01[parname == \"b_r2d\" & quant %in% c(\"sup\", \"fut_sup\"), ],\n  d_fig_0_01[parname == \"b_f\" & quant %in% c(\"sup\", \"fut_sup\"), ]\n)\n\nd_fig_0_01[, or_tru := g_or_lab[v]]\nd_fig_0_01[, or_tru := factor(\n  or_tru, labels = g_or_lab, levels = g_or_lab)]\n\nfx &lt;- g_fx\nnames(fx) &lt;- c(\"rev vs dair\", \"6-wk vs 12-wk (one)\", \"12-wk vs 7-day (two)\", \"rif vs no-rif\")\nd_fig_0_01[, parname_lab := factor(\n  names(fx[parname]), levels = c(\"rev vs dair\", \"6-wk vs 12-wk (one)\", \"12-wk vs 7-day (two)\", \"rif vs no-rif\")\n  ) ]\n\nd_text &lt;- unique(d_fig_0_01[, .(parname_lab, or_tru, quant)])\nd_text[parname_lab == \"rev vs dair\" & or_tru %in% c(\"OR 1/2\"),\n       `:=`(label = c(\"rev fut (sup)\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"rev vs dair\" & or_tru %in% c(\"OR 2\"),\n       `:=`(label = c(\"rev sup \\nto dair\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"6-wk vs 12-wk (one)\" & or_tru %in% c(\"OR 1/2\"),\n       `:=`(label = c(\"short fut (ni)\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"6-wk vs 12-wk (one)\" & or_tru %in% c(\"OR 2\"),\n       `:=`(label = c(\"short ni \\nto long\"), x = 500, y = 0.2)]\n\n\nd_text[parname_lab == \"12-wk vs 7-day (two)\" & or_tru %in% c(\"OR 1/2\"),\n       `:=`(label = c(\"long fut (sup)\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"12-wk vs 7-day (two)\" & or_tru %in% c(\"OR 2\"),\n       `:=`(label = c(\"long sup \\nto short\"), x = 500, y = 0.2)]\n\nd_text[parname_lab == \"rif vs no-rif\" & or_tru %in% c(\"OR 1/2\"),\n       `:=`(label = c(\"rif fut (sup)\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"rif vs no-rif\" & or_tru %in% c(\"OR 2\"),\n       `:=`(label = c(\"rif sup \\nto no-rif\"), x = 500, y = 0.2)]\n\n\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility (sup)\", \"fut_sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"NI (trt ni ref)\", \"trt_ni_inf\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility (NI)\", \"fut_trt_ni_ref\", names(d_tbl))\n\nd_fig_0_01$quant &lt;- factor(\n  d_fig_0_01$quant, \n  levels = c(\"sup\", \"fut_sup\", \"trt_ni_ref\", \"fut_trt_ni_ref\"),\n  labels = c(\"sup\", \"fut_sup\", \"ni\", \"fut_ni\"))\n\np &lt;- ggplot(d_fig_0_01, aes(x = N_pt, y = value, group = quant, col = quant)) +\n  geom_point(size = 0.5) +\n  geom_line(lwd = 0.4) +\n  geom_hline(yintercept = 0.05, lwd = 0.2) +\n  ggthemes::scale_colour_tableau(\n    \"\", palette = \"Tableau 10\",\n  type = \"regular\",\n  direction = 1) +\n  geom_text(\n    data = d_text,\n    aes(x = x, y = y, label = label),\n    hjust   = 0,\n    vjust   = 0, col = 1, size = 3) +\n  scale_linetype_discrete(\"\") +\n  scale_x_continuous(\"N (12-months post rand)\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Cumulative probability\", breaks = seq(0, 1, by = 0.1)) +\n  facet_grid(parname_lab ~ or_tru)\n\nsuppressWarnings(print(p))\n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\nTable 2 provides the same detail as the above figure, but makes it easier to see what the magnitudes of the cumulate probabilities are.\n\n\nCode\n# Widen data so that power is shown by col with each col corresponding to an\n# analysis\nd_tbl &lt;- d_fig_0_01[quant %in% c(\"sup\", \"fut_sup\", \"ni\", \"fut_ni\")]\nd_tbl &lt;- dcast(d_tbl, parname + or_tru ~ quant + analys, value.var = \"value\")\nd_tbl &lt;- d_tbl[order(or_tru, parname)]\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"parname\") |&gt;\n  fmt_number(\n    columns = everything(),\n    decimals = 2,\n    use_seps = FALSE\n  ) |&gt; \n  tab_spanner(\n    label = html(\"Superiority\"),\n    columns = paste0(\"sup_\", 1:5)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility (sup)\"),\n    columns = c(paste0(\"fut_sup_\", 1:5))\n  ) |&gt;\n  tab_spanner(\n    label = html(\"NI (trt ni ref)\"),\n    columns = paste0(\"ni_\", 1:5)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility (ni)\"),\n    columns = c(paste0(\"fut_ni_\", 1:5))\n  ) |&gt;\n  cols_label(\n    or_tru = html(\"OR (true)\"),\n    sup_1 = html(\"500\"),\n    sup_2 = html(\"1000\"),\n    sup_3 = html(\"1500\"),\n    sup_4 = html(\"2000\"),\n    sup_5 = html(\"2500\"),\n    fut_sup_1 = html(\"500\"),\n    fut_sup_2 = html(\"1000\"),\n    fut_sup_3 = html(\"1500\"),\n    fut_sup_4 = html(\"2000\"),\n    fut_sup_5 = html(\"2500\"),\n    ni_1 = html(\"500\"),\n    ni_2 = html(\"1000\"),\n    ni_3 = html(\"1500\"),\n    ni_4 = html(\"2000\"),\n    ni_5 = html(\"2500\"),\n    fut_ni_1 = html(\"500\"),\n    fut_ni_2 = html(\"1000\"),\n    fut_ni_3 = html(\"1500\"),\n    fut_ni_4 = html(\"2000\"),\n    fut_ni_5 = html(\"2500\")\n  ) |&gt;\n  tab_style(\n    style = cell_borders(\n      sides = c(\"left\"),\n      weight = px(1)),\n    locations = cells_body(\n      # columns = c(sup_1, fut_sup_1, inf_1, fut_inf_1, ni_1, fut_ni_1)\n      columns = c(sup_1, fut_sup_1, ni_1, fut_ni_1)\n      )\n    ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or_tru == \"OR 1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR (true)\n\nSuperiority\n\n\nFutility (sup)\n\n\nNI (trt ni ref)\n\n\nFutility (ni)\n\n\n\n500\n1000\n1500\n2000\n2500\n500\n1000\n1500\n2000\n2500\n500\n1000\n1500\n2000\n2500\n500\n1000\n1500\n2000\n2500\n\n\n\n\nb_r\n\n\nOR 1/2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.93\n1.00\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.5\n0.00\n0.00\n0.00\n0.00\n0.00\n0.68\n0.93\n0.99\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.35\n0.63\n0.80\n0.90\n0.95\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1\n0.01\n0.01\n0.02\n0.02\n0.03\n0.15\n0.28\n0.39\n0.48\n0.56\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.2\n0.04\n0.09\n0.14\n0.19\n0.25\n0.04\n0.07\n0.09\n0.11\n0.12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.5\n0.15\n0.38\n0.59\n0.76\n0.86\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 2\n0.45\n0.86\n0.98\n1.00\n1.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_r1d\n\n\nOR 1/2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.00\n0.00\n0.00\n0.00\n0.00\n0.40\n0.75\n0.90\n0.96\n0.99\n\n\nOR 1/1.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.00\n0.00\n0.00\n0.00\n0.00\n0.19\n0.40\n0.57\n0.69\n0.78\n\n\nOR 1/1.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.00\n0.01\n0.01\n0.02\n0.02\n0.07\n0.16\n0.23\n0.30\n0.35\n\n\nOR 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.02\n0.04\n0.06\n0.10\n0.12\n0.03\n0.06\n0.08\n0.10\n0.11\n\n\nOR 1.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.04\n0.12\n0.20\n0.28\n0.36\n0.01\n0.01\n0.02\n0.02\n0.02\n\n\nOR 1.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.12\n0.29\n0.47\n0.63\n0.76\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\nOR 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.22\n0.60\n0.84\n0.95\n0.98\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\nb_r2d\n\n\nOR 1/2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.83\n0.99\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.5\n0.00\n0.00\n0.00\n0.00\n0.00\n0.57\n0.88\n0.97\n0.99\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.30\n0.56\n0.72\n0.83\n0.90\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1\n0.01\n0.02\n0.02\n0.03\n0.03\n0.13\n0.24\n0.33\n0.42\n0.49\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.2\n0.03\n0.07\n0.12\n0.16\n0.20\n0.04\n0.07\n0.09\n0.11\n0.12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.5\n0.10\n0.28\n0.47\n0.62\n0.75\n0.01\n0.01\n0.01\n0.01\n0.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 2\n0.28\n0.69\n0.92\n0.98\n1.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_f\n\n\nOR 1/2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.98\n1.00\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.5\n0.00\n0.00\n0.00\n0.00\n0.00\n0.80\n0.97\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.46\n0.75\n0.89\n0.95\n0.98\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1\n0.01\n0.02\n0.02\n0.03\n0.03\n0.18\n0.33\n0.45\n0.55\n0.63\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.2\n0.06\n0.13\n0.21\n0.28\n0.35\n0.04\n0.07\n0.09\n0.10\n0.11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.5\n0.25\n0.52\n0.73\n0.85\n0.93\n0.00\n0.01\n0.01\n0.01\n0.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 2\n0.62\n0.93\n0.99\n1.00\n1.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2: Cumulative probability of decision\n\n\n\n\nFigure 2 shows the distribution of estimated posterior means by simulated effect size, parameter and sample size.\n\n\n\n\n\n\n\n\nFigure 2: Distribution of posterior means (true log OR shown in red).",
    "crumbs": [
      "Simulations",
      "Simulation results 3"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-ex02.html",
    "href": "notebooks/sim-design5-ex02.html",
    "title": "Simulation 5 - example 2",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\n\nsim_lab &lt;- \"sim05-15\"\n# files of interest\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim05\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\nix_scenario &lt;- 4\nix_trial = 871",
    "crumbs": [
      "Simulations",
      "Simulation 5 - example 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-ex02.html#results-from-example-trial",
    "href": "notebooks/sim-design5-ex02.html#results-from-example-trial",
    "title": "Simulation 5 - example 2",
    "section": "Results from example trial",
    "text": "Results from example trial\n\n\nCumulative probability of each decision type for example trial\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(analys, N, quant, domain)]\n  \n  \n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected number of enrolments\n# Similar to above but focus on expected number of enrolments\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 1\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix that contains the stopping decision by \n  # quantity (superiority, ni, futility, etc) for each domain by analysis\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  # long version of decision, e.g.\n  #      sim analys  quant domain  value\n  #    &lt;int&gt;  &lt;int&gt; &lt;char&gt; &lt;fctr&gt; &lt;lgcl&gt;\n  # 1:     1      1    sup     d1  FALSE\n  # 2:     1      2    sup     d1  FALSE\n  # 3:     1      3    sup     d1  FALSE\n  # 4:     1      4    sup     d1  FALSE\n  # 5:     1      5    sup     d1  FALSE\n  # 6:     2      1    sup     d1  FALSE\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case we had a sim fall over, fill in value\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # Extract the first instance of any decision occurring by sim and domain.\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise the \n# posterior means, they would thus be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# what we estimate is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 2\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  d_pars &lt;- dcast(d_pars, sim + id_analys + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  setnames(d_pars, \"id_analys\", \"analys\")\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"analys\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(analys, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nCumulative probability of each decision type\n# &gt; names(l[[ix_scenario]])\n#  [1] \"cfg\"           \"d_pr_sup\"      \"d_pr_ni\"       \"d_pr_sup_fut\"  \"d_pr_ni_fut\"   \"d_decision\"   \n#  [7] \"d_post_smry_1\" \"d_all\"         \"d_n_units\"     \"d_n_assign\" \n\n# extract the decision matrix - sim, analysis, quantity, domain level decision\n\n\nd_N &lt;- data.table(\n  analys = 0:5,\n  N = seq(0, 2500, by = 500)\n)\n\n# Extract example trial specific data\nl_cfg &lt;- copy(l[[ix_scenario]]$cfg)\nd_dat &lt;- copy(l[[ix_scenario]]$d_all[sim == ix_trial])\n# Parameter summaries from analysis\nd_mod &lt;- copy(l[[ix_scenario]]$d_post_smry_1[sim == ix_trial])\n# Decision matrix for this trial\nd_dec &lt;- copy(l[[ix_scenario]]$d_decision[sim == ix_trial])\n# Probability level reached by domain and analysis\nd_pr_sup &lt;- copy(l[[ix_scenario]]$d_pr_sup[sim == ix_trial])\nd_pr_sup_fut &lt;- copy(l[[ix_scenario]]$d_pr_sup_fut[sim == ix_trial])\nd_pr_ni &lt;- copy(l[[ix_scenario]]$d_pr_ni[sim == ix_trial])\nd_pr_ni_fut &lt;- copy(l[[ix_scenario]]$d_pr_ni_fut[sim == ix_trial])\n\n# observed data\nsetnames(d_dat, \"id_analys\", \"analys\")\nsetnames(d_mod, \"id_analys\", \"analys\")\n\nd_mod &lt;- merge(d_mod, d_N, by = \"analys\")\n\nd_pr_sup &lt;- merge(d_pr_sup, d_N, by = \"analys\")\nd_pr_sup &lt;- melt(d_pr_sup[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup[, quant := \"sup\"]\n\nd_pr_sup_fut &lt;- merge(d_pr_sup_fut, d_N, by = \"analys\")\nd_pr_sup_fut &lt;- melt(d_pr_sup_fut[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup_fut[, quant := \"sup_fut\"]\n\nd_pr_ni &lt;- merge(d_pr_ni, d_N, by = \"analys\")\nd_pr_ni &lt;- melt(d_pr_ni[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni[, quant := \"ni\"]\n\nd_pr_ni_fut &lt;- merge(d_pr_ni_fut, d_N, by = \"analys\")\nd_pr_ni_fut &lt;- melt(d_pr_ni_fut[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni_fut[, quant := \"ni_fut\"]\n\nd_pr_dec &lt;- rbind(d_pr_sup, d_pr_sup_fut, d_pr_ni, d_pr_ni_fut  )\nd_pr_dec[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_pr_dec[domain %in% c(2), question := \"Non-inferiority\"]\n\n# domain 1 relates only to the late acute silo\nd_dat_d1 &lt;- d_dat[\n  silo == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d1)]\nd_dat_d1[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d1)]\nd_dat_d1[, p_obs := cy/cn]\nd_dat_d1[, d1 := factor(d1, labels = c(\"DAIR\", \"One-stage\", \"Two-stage\"))]\n\n# domain 2 relates only to the group that receive one-stage\nd_dat_d2 &lt;- d_dat[\n  d1 == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d2)]\nd_dat_d2[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d2)]\nd_dat_d2[, p_obs := cy/cn]\nd_dat_d2[, d2 := factor(d2, labels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\n# domain 3 relates only to the group that receive two-stage\nd_dat_d3 &lt;- d_dat[\n  d1 == 3, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d3)]\nd_dat_d3[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d3)]\nd_dat_d3[, p_obs := cy/cn]\nd_dat_d3[, d3 := factor(d3, labels = c(\"Selected\", \"none\", \"12wk\"))]\n\n# domain 4 relates only to the group that receive two-stage\nd_dat_d4 &lt;- d_dat[\n  , .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d4)]\nd_dat_d4[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d4)]\nd_dat_d4[, p_obs := cy/cn]\nd_dat_d4[, d4 := factor(d4, labels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\nd_dec &lt;- melt(d_dec, measure.vars = paste0(\"d\", 1:4), variable.name = \"domain\")\nd_dec[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n# Subset to the decisions that are evaluated by domain\nd_dec &lt;- rbind(\n  d_dec[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n  d_dec[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n)\n\n\nd_dec_thres &lt;- data.table(\n  quant = rep(c(\"sup\", \"sup_fut\", \"ni\", \"ni_fut\"), each = 4),\n  domain = rep(1:4, len = 16)\n  )\nd_dec_thres[, threshold := c(\n    l_cfg$dec_probs$thresh_sup,\n    l_cfg$dec_probs$thresh_fut_sup,\n    l_cfg$dec_probs$thresh_ni,\n    l_cfg$dec_probs$thresh_fut_ni\n  )]\n\n\n## State transition through the different states of knowledge based on decisions\n\nd_dec_timeline &lt;- merge(\n  CJ(domain = 1:4, analys = 0:5),\n  d_N, by = \"analys\", all.y = T\n)\nsetorder(d_dec_timeline, domain, analys)\nd_dec_timeline[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_dec_timeline[domain %in% c(2), question := \"Non-inferiority\"]\nd_dec_timeline[N == 0, decision := \"Indeterminate\"]\n\n\ni &lt;- j &lt;- 1\n# For i across domains\nfor(i in 1:4){\n  # For j across analyses\n  for(j in 1:5){\n    \n    if(i %in% c(1, 3, 4)){\n      \n      if(d_dec[domain == i & analys == j & quant == \"sup\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"Superior\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_sup\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (sup)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    } else {\n      \n      if(d_dec[domain == i & analys == j & quant == \"ni\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"NI\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_ni\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (NI)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    }\n    \n  }\n  \n}\n\nd_dec_timeline[, decision := factor(decision, levels = c(\n  \"Indeterminate\", \"Superior\", \"Futile (sup)\", \"NI\", \"Futile (NI)\"\n))]\n\n\n# Dealing with those for which a decision was not reached.\nd_decision &lt;- data.table(\n  domain = 1:4,\n  N = 2500\n)\nif(any(d_dec_timeline$decision != \"Indeterminate\")){\n  d_decision &lt;- d_dec_timeline[\n    decision != \"Indeterminate\", .(N = min(N)), keyby = .(domain, decision)]\n}\n\nd_decision &lt;- merge(\n  d_decision, \n  data.table(domain = 1:4),\n  by = \"domain\", all.y = T\n)\nd_decision[is.na(decision), `:=`(\n  decision = \"Intermediate\", N = 2500  \n)]\n\n\nd_dec_timeline &lt;- d_dec_timeline[N &lt;= max(d_decision$N)]\n\n\nTable 1 shows the decisions made for each domain (or indeterminate if no decisions were made).\n\n\nCode\ng_tbl &lt;- d_decision |&gt; \n  gt() |&gt; \n  cols_align(\n    columns = 1:2,\n    align = \"center\"\n  )  |&gt; \n  cols_align(\n    columns = 3,\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    decision = \"Decision\",\n    N = \"Enrolment\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nDomain\nDecision\nEnrolment\n\n\n\n\n1\nFutile (sup)\n500\n\n\n2\nIntermediate\n2,500\n\n\n3\nFutile (sup)\n500\n\n\n4\nFutile (sup)\n500\n\n\n\n\n\n\n\n\nTable 1: Trial decisions by domain\n\n\n\n\nFigure 1 shows the knowledge transitions based on the decisions made for each domain by sample size up to the point where the trial was stopped either due to running out of resources or having addressed all the questions.\nInitially, all domains start in an indeterminate state in that neither treatment arm is preferred. As the data accrues and analyses progresses, the knowledge state for each domain may transition to, superiority, non-inferiority or futility.\n\n\nCode\np1 &lt;- ggplot(d_dec_timeline, aes(x = N, y = decision)) +\n  geom_point() +\n  scale_y_discrete(\"\", drop=FALSE) +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 1: Decision timeline\n\n\n\n\n\nFigure 2 through to Figure 5 show sample size for each domains.\n\nDomain 1: Sample sizeDomain 2: Sample sizeDomain 3: Sample sizeDomain 4: Sample size\n\n\nAny decision rule only applies to the late acute silo (silo 2).\n\n\nCode\nd_fig &lt;- copy(d_dat_d1)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d1 = c(\"DAIR\", \"One-stage\", \"Two-stage\")),\n  by = c(\"silo\", \"analys\", \"d1\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d1)]\n\np_d1 &lt;- ggplot(d_fig, aes(x = d1, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\", breaks = seq(0, 800, by = 200)) +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(print(p_d1))\n\n\n\n\n\n\n\n\nFigure 2: Domain 1: Surgical sample size\n\n\n\n\n\n\n\nOf those receiving one-stage (see figure for domain 1) and irrespective of silo membership, approximately 70% are assumed to enter the AB duration domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d2)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"silo\", \"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_a &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d2)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d2)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_b &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d2_a, p_d2_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\nOf those receiving two-stage (see figure for domain 1) and irrespective of silo membership, approximately 90% are assumed to enter the AB ext-proph domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d3)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"silo\", \"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_a &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d3)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d3)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_b &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d3_a, p_d3_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 4: Domain 3: AB Expt-proph sample size\n\n\n\n\n\n\n\nAcross the entire trial sample, approximately 60% are assumed to enter the AB choice domain.\nHere, we know there is an effect of AB choice and would hope that a decision for superiority is made such that new participants are directed to receive rifampacin.\n\n\nCode\nd_fig &lt;- copy(d_dat_d4)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"silo\", \"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\np_d4_a &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6))\n\nd_fig &lt;- copy(d_dat_d4)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d4)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\np_d4_b &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d4_a, p_d4_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 5: AB Choice sample size\n\n\n\n\n\n\n\n\nFigure 6 and Figure 7 show the parameter estimates.\nNote:\nParameter estimates will only be reported up until the simulated trial was stopped due to all questions having been answered.\n\nPosterior odds-ratio summaryPosterior risk-difference summary\n\n\nFigure 6 shows the posterior odds-ratios for the randomised comparisons by domain and enrolment progression.\n\n\nCode\n# late acute, surgical effects\nd_d1_n &lt;- d_dat[silo == 2, \n                .(n = sum(N), domain = 1), keyby = .(analys, d1)]\nsetnames(d_d1_n, \"d1\", \"trt\")\n# those receiving one-stage and randomised treatment in domain 2\nd_d2_n &lt;- d_dat[d1 == 2 & d2 %in% 2:3, \n                .(n = sum(N), domain = 2), keyby = .(analys, d2)]\nsetnames(d_d2_n, \"d2\", \"trt\")\n# those receiving two-stage and randomised treatment in domain 3\nd_d3_n &lt;- d_dat[d1 == 3 & d3 %in% 2:3, \n                .(n = sum(N), domain = 3), keyby = .(analys, d3)]\nsetnames(d_d3_n, \"d3\", \"trt\")\n# those receiving randomised treatment in domain 4\nd_d4_n &lt;- d_dat[d4 %in% 2:3, \n                .(n = sum(N), domain = 4), keyby = .(analys, d4)]\nsetnames(d_d4_n, \"d4\", \"trt\")\n\nd_n_trt &lt;- rbind(\n  d_d1_n, d_d2_n, d_d3_n, d_d4_n\n)\nd_n_trt &lt;- merge(\n  d_n_trt,\n  d_N[analys != 0],\n  by = \"analys\"\n)\n\nd_n_trt &lt;- d_n_trt[, .(n = sum(n)), keyby = .(N, domain)]\nd_n_trt[, n := cumsum(n), keyby = domain]\n\np1 &lt;- ggplot(d_mod[par == \"lor\"], aes(x = N, y = exp(med))) +\n  geom_point() +\n  geom_linerange(aes(ymin = exp(q_025), ymax = exp(q_975)), lwd = 0.25) +\n  geom_text(\n    data = d_n_trt, \n    aes(x = N, y = -0.5, label = n), col = 2, size = 2\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 6: Posterior summary measures\n\n\n\n\n\n\n\nFigure 7 shows the posterior risk differences for the randomised comparisons by domain and enrolment progression.\n\n\nCode\np1 &lt;- ggplot(d_mod[par == \"rd\"], aes(x = N, y = med)) +\n  geom_point() +\n  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 7: Posterior summary measures\n\n\n\n\n\n\n\n\nFigure 8 shows the probability associated with each decision type for the randomised comparisons by domain and enrolment progression.\nFor example, for domain 1 in analysis 1, the probability of revision being superior to DAIR (per the definition of superiority, which is a measure that is relative to nominated reference level for superiority) is approxiamtely 0.35. To make a superiority decision, this probability needs to exceed 0.920.\nSimilarly, for domain 1 in analysis 1, the probability of the superiority decision being futile (per the relevant definition) is approximately 0.14. To make a futility decision (related to superiority) this probability has to fall below 0.300.\nNote:\n\nThe futility probabilities are based on being below a given threshold (rather than above).\n\n\n\nCode\np1 &lt;- ggplot(d_fig_1, aes(x = N, y = value)) +\n  geom_point(aes(col=quant), position = position_dodge2(width = 100), size = 0.6) + \n  geom_linerange(aes(ymin = 0, ymax = value, col=quant), \n                 position = position_dodge2(width = 100), lwd = 0.25)+\n  geom_hline(\n    data = d_fig_2,\n    aes(yintercept = threshold, col=quant), lwd = 0.25\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Decision probability\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 8: Probability decision summaries\n\n\n\n\n\n\n\n\n\n\n\nReveal scenario\n\n\n\n\n\nThe results are from a simulated trial picked from scenario 4: Moderate (OR 1.75) surgical revision effect (two-stage).\n\n\nCode\nl_cfg\n\n\n$cov\n$cov$silo\n$cov$silo[[1]]\n[1] 0\n\n$cov$silo[[2]]\n[1] -0.3\n\n$cov$silo[[3]]\n[1] -0.2\n\n\n$cov$jnt\n$cov$jnt[[1]]\n[1] 0\n\n$cov$jnt[[2]]\n[1] 0.4\n\n\n$cov$pref\n$cov$pref[[1]]\n[1] 0\n\n$cov$pref[[2]]\n[1] -0.2\n\n\n$cov$mu\n[1] 0.7\n\n\n$d1\n$d1[[1]]\n[1] 0\n\n$d1[[2]]\n[1] 0\n\n$d1[[3]]\n[1] 0.5596\n\n$d1[[4]]\n[1] 0\n\n$d1[[5]]\n[1] 0.5596\n\n$d1[[6]]\n[1] 0\n\n$d1[[7]]\n[1] 0\n\n$d1[[8]]\n[1] 0\n\n$d1[[9]]\n[1] 0.5596\n\n\n$pri\n$pri$mu\n[1] 0.7 0.7\n\n$pri$b_silo\n[1] 0 1\n\n$pri$b_jnt\n[1] 0 1\n\n$pri$b_prf\n[1] 0 1\n\n$pri$b_trt\n[1] 0 1\n\n\n$dec_ref\n$dec_ref$delta_sup\n[1] 0\n\n$dec_ref$delta_sup_fut\n[1] 0.05\n\n$dec_ref$delta_ni\n[1] -0.05\n\n$dec_ref$delta_ni_fut\n[1] 0\n\n\n$dec_probs\n$dec_probs$thresh_sup\n[1] 0.920 0.950 0.950 0.995\n\n$dec_probs$thresh_ni\n[1] 0.975 0.925 0.975 0.975\n\n$dec_probs$thresh_fut_sup\n[1] 0.30 0.25 0.25 0.25\n\n$dec_probs$thresh_fut_ni\n[1] 0.25 0.10 0.25 0.25\n\n\n$desc\n[1] \"Moderate (OR 1.75) surgical revision effect (two-stage)\"\n\n$nsim\n[1] 1000\n\n$mc_cores\n[1] 40\n\n$N_pt\n[1]  500 1000 1500 2000 2500\n\n$d2\n[1] 0 0 0\n\n$d3\n[1] 0 0 0\n\n$d4\n[1] 0 0 0",
    "crumbs": [
      "Simulations",
      "Simulation 5 - example 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-results.html",
    "href": "notebooks/sim-design5-results.html",
    "title": "Simulation results 5",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\nsim_lab &lt;- \"sim05-15\"\n\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim05\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}",
    "crumbs": [
      "Simulations",
      "Simulation results 5"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-results.html#introduction",
    "href": "notebooks/sim-design5-results.html#introduction",
    "title": "Simulation results 5",
    "section": "Introduction",
    "text": "Introduction\nIn the present design, the model is used to compute unit level risk (probability) and assesses decisions based on risk difference for the intervention comparisons by domain. Log-odds scale had limited interpretability for clinical users and is inconsistent in absolute terms across strata with varying baseline rates. It is also useful to explore what an absolute perspective on effectiveness translates to in terms of operating characteristics. Simulation parameters continue to be expressed as log-odds-ratios. This makes the simulation process simpler. Results are presented on both the odds and risk scale. Aim is to give us a better intuition and transparency on the magnitude of effects we are contemplating and determine if these are reasonable assumptions.\nWe have a single multivariable logistic regression model. One of the sets of parameters accounts for clinician preference for revision type in order to achieve conditional exchangeability across groups. At each interim, we assess the posterior and if a decision threshold is met, we act. For example, if a superiority decision is reached in one of the domains for which this decision type is relevant, then we consider that domain dealt with and all subsequent participants are assigned to receive the superior intervention. We continue to update the posterior for the stopped comparisons in subsequent interim analyses until we get to the point where all questions have been answered in all domains. Once all questions have been answered, the trial recruitment will stop.\nThe priors were as follows:\n\nReference log-odds of response: logistic distribution, mean 0.7 and scale 0.7\nSilo effects: normal distribution, mean 0 and scale 1\nJoint effects: normal distribution, mean 0 and scale 1\nPreference effects: normal distribution, mean 0 and scale 1\nTreatment effects: normal distribution, mean 0 and scale 1\n\nSuperiority and non-inferiority are applicable to some domains and not others, however, we define reference and threshold values for all domains, just in case.\nFor the superiority decision, a reference value of 0 was used and the probability thresholds were:\n\n0.92 for surgical domain\n0.95 for antibiotic duration domain\n0.95 for extended prophylaxis domain\n0.995 for antibiotic choice domain\n\nFor the futility decision (in relation to superiority) a reference value of 0.05 was used and the probability thresholds were:\n\n0.3 for surgical domain\n0.25 for antibiotic duration domain\n0.25 for extended prophylaxis domain\n0.25 for antibiotic choice domain\n\nThe above means, for example, that if the probability that the risk difference is greater than 0.05 is less than 0.3 in the surgical domain comparison, then we say the superiority goal is futile.\nFor the ni decision, a reference value of -0.05 was used and the probability thresholds were:\n\n0.975 for surgical domain\n0.925 for antibiotic duration domain\n0.975 for extended prophylaxis domain\n0.975 for antibiotic choice domain\n\nThe above means, for example, that if the probability that the risk difference is greater than -0.05 is greater than 0.925, in the antibiotic duration domain, then we will say the intervention is non-inferior.\nThe futility decision (in relation to non-inferiority) has a reference value of 0 and the probability thresholds were:\n\n0.25 for surgical domain\n0.1 for antibiotic duration domain\n0.25 for extended prophylaxis domain\n0.25 for antibiotic choice domain\n\nThis means, for example, that if the probability that the risk difference is greater than 0 is less than 0.1, in the antibiotic duration domain, then we say the non-inferiority goal is futile.\nFigure 1 attempts to put the superiority rules into pictures based on possible scenarios for assessment of the posterior risk difference for an arbitrary domain where superiority is being assessed. The approach, reference values and thresholds apply to all domains where superiority is assessed.\n\n\n\n\n\n\n\n\nFigure 1: Visualisation of decision rule scenarios for superiority\n\n\n\n\n\nAnalogously, Figure 2 puts the non-inferiority rule into pictures based on possible scenarios for assessment of the posterior risk difference for an arbitrary domain where non-inferiority is being assessed. The approach, reference values and thresholds apply to all domains.\n\n\n\n\n\n\n\n\nFigure 2: Visualisation of decision rule scenarios for non-inferiority\n\n\n\n\n\nFor this set of simulations, the number of simulated trials per scenario was 1000, the simulation label is sim05-15.",
    "crumbs": [
      "Simulations",
      "Simulation results 5"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-results.html#simulation-results",
    "href": "notebooks/sim-design5-results.html#simulation-results",
    "title": "Simulation results 5",
    "section": "Simulation results",
    "text": "Simulation results\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(analys, N, quant, domain)]\n  \n  \n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected sample size\n# Expected sample size\n\n# Similar to above but focus on expected sample size\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 2\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decision\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # First instance of any decision rule being hit by sim and domain.\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  \n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n                      # all combinations of sim and domain\n                      unique(d_dec_2[, .(sim, domain)]),\n                      by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise these \n# posterior means, they would be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# our estimates is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 2\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  d_pars &lt;- dcast(d_pars, sim + id_analys + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  setnames(d_pars, \"id_analys\", \"analys\")\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"analys\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(analys, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (conditional)\n# Distribution of posterior means for parameters of interest.\n\n# By way of contrast to the above, here we summarise based on the stopping\n# rules. That is, the posterior means that are included in the summary are only\n# those that 'survived' until the relevant interim. This is simply to give you \n# a sense of how extreme the selection effects associated with stopping can be.\n\ni &lt;- 6\nd_tbl_4 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  bd1 &lt;- unlist(l_cfg$d1)\n  bd2 &lt;- unlist(l_cfg$d2)\n  bd3 &lt;- unlist(l_cfg$d3)\n  bd4 &lt;- unlist(l_cfg$d4)\n  \n  d_tru &lt;- copy(l[[i]]$d_all)\n  setnames(d_tru, \"id_analys\", \"analys\")\n  \n  d_tru &lt;- dcast(\n    d_tru[, .(N = sum(N)), keyby = .(sim, analys, pref_rev)],\n    sim + analys ~ pref_rev, value.var = \"N\"\n  )\n  colnames(d_tru) &lt;- c(\"sim\", \"analys\", \"N1\", \"N2\")\n  d_tru[, `:=`(prop_p1 = N1 / (N1 + N2), \n               prop_p2 = N2 / (N1 + N2))]\n  d_tru[, db1 := as.numeric(\n    (d_tru$prop_p1 * bd1[2] + d_tru$prop_p2 * bd1[3]) - bd1[1])]\n  d_tru[, db2 := as.numeric(bd2[3] - bd2[2])]\n  d_tru[, db3 := as.numeric(bd3[3] - bd3[2])]\n  d_tru[, db4 := as.numeric(bd4[3] - bd4[2])]\n  d_tru[, `:=`(\n    N1 = NULL, N2 = NULL, prop_p1 = NULL, prop_p2 = NULL\n  )]\n  d_tru &lt;- melt(\n    d_tru,\n    measure.vars = c(\"db1\", \"db2\", \"db3\", \"db4\"),\n    value.name = \"lor_tru\", variable.name = \"domain\"\n  )\n  d_tru[, domain := as.numeric(gsub(\"db\", \"\", domain))]\n\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decision - assessment of each quantity by sim, domain and analysis\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # First instance of any decision rule being hit by sim and domain.\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  \n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    # value being set to TRUE indicates we hit a stopping run\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any the domains where we did not stop early\n  d_dec_stop &lt;- merge(d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n                      # all combinations of sim and domain\n                      unique(d_dec_2[, .(sim, domain)]),\n                      by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  # get rid of quant\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped for any reason \n  # within each sim. Great.\n  \n  # Add in the other looks at the data so that we have a complete set\n  d_dec_stop &lt;- merge(\n    d_dec_stop,\n    unique(d_dec_2[, .(analys, sim, domain, N)]),\n    by = c(\"sim\", \"domain\"),\n    all.y = T\n  )\n  \n  # Merge in the parameter estimates (posterior means)\n  d_dec_stop &lt;- merge(\n    d_dec_stop, \n    dcast(d_pars, sim + id_analys + domain ~ par, value.var = \"mu\"),\n    by.x = c(\"analys\", \"sim\", \"domain\"),\n    by.y = c(\"id_analys\", \"sim\", \"domain\")\n  )\n  \n  # so now drop any records for which we had stopped the trial\n  d_dec_stop &lt;- d_dec_stop[!is.na(lor)]\n  \n  d_dec_stop &lt;- merge(\n    d_dec_stop,\n    d_tru,\n    by = c(\"sim\", \"analys\", \"domain\")\n  )\n  \n  # d_dec_stop[quant == \"sup\", mean(type_m_ratio), keyby = .(analys, domain, N)]\n  \n  # out of all the decision that were made, i.e. those where quant is not NA\n  # what proportion \n  \n  d_tbl_4 &lt;- rbind(\n    d_tbl_4,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_dec_stop[, .(sim, analys, domain, quant, N, lor, rd, stopped_early, N_stopped)]\n      )\n  )\n\n}\n\n\n\n\nNumber of participants for each randomised comparison over time\n# \n\ni &lt;- 1\nd_N_by_arm &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # long version of decisions\n  d_dec_2 &lt;- melt(\n    d_dec_1, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_enrolment &lt;- data.table(analys = seq_along(l_cfg$N_pt), N_enrol = l_cfg$N_pt)\n  # observed trial data sets\n  d_tru &lt;- copy(l[[i]]$d_all)\n  setnames(d_tru, \"id_analys\", \"analys\")\n  \n  # late acute, surgical arms\n  # *** silo isn't included in the keyby because we want to average across \n  # the entire trial population, not silo specific sample sizes.\n  d_1_tmp &lt;- d_tru[\n    silo == 2, .(N = sum(N), domain = 1), keyby = .(sim, analys, d1)]\n  d_1_tmp[, N := cumsum(N), keyby = .(sim, d1)]\n  setnames(d_1_tmp, old = \"d1\", \"arm\")\n  d_1_tmp &lt;- merge(\n    d_1_tmp, \n    CJ(sim = 1:max(d_tru$sim), analys = 1:5, arm = 1:3, domain = 1), \n    by = c(\"sim\", \"analys\", \"arm\", \"domain\"),\n    all.y = T)\n  d_1_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_1_tmp, sim, analys, arm)\n  \n  # one-stage revision, ab duration randomised arms\n  d_2_tmp &lt;- d_tru[\n    d1 == 2 & d2 %in% 2:3, \n    .(N = sum(N), domain = 2), keyby = .(sim, analys, d2)]\n  d_2_tmp[, N := cumsum(N), keyby = .(sim, d2)]\n  setnames(d_2_tmp, old = \"d2\", \"arm\")\n  d_2_tmp &lt;- merge(\n    d_2_tmp, \n    CJ(sim = 1:max(d_tru$sim), analys = 1:5, arm = 2:3, domain = 2), \n    by = c(\"sim\", \"analys\", \"arm\", \"domain\"),\n    all.y = T)\n  d_2_tmp[analys == 1 & is.na(N), N := 0]\n  d_2_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_2_tmp, sim, analys, arm)\n  \n  # two-stage revision, extended prophy randomised arms\n  d_3_tmp &lt;- d_tru[\n    d1 == 3 & d3 %in% 2:3, \n    .(N = sum(N), domain = 3), keyby = .(sim, analys, d3)]\n  d_3_tmp[, N := cumsum(N), keyby = .(sim, d3)]\n  setnames(d_3_tmp, old = \"d3\", \"arm\")\n  d_3_tmp &lt;- merge(\n    d_3_tmp, \n    CJ(sim = 1:max(d_tru$sim), analys = 1:5, arm = 2:3, domain = 3), \n    by = c(\"sim\", \"analys\", \"arm\", \"domain\"),\n    all.y = T)\n  d_3_tmp[analys == 1 & is.na(N), N := 0]\n  d_3_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_3_tmp, sim, analys, arm)\n  \n  # ab choice randomised arms\n  d_4_tmp &lt;- d_tru[\n    d4 %in% 2:3, .(N = sum(N), domain = 4), keyby = .(sim, analys, d4)]\n  d_4_tmp[, N := cumsum(N), keyby = .(sim, d4)]\n  setnames(d_4_tmp, old = \"d4\", \"arm\")\n  d_4_tmp &lt;- merge(\n    d_4_tmp, \n    CJ(sim = 1:max(d_tru$sim), analys = 1:5, arm = 2:3, domain = 4), \n    by = c(\"sim\", \"analys\", \"arm\", \"domain\"),\n    all.y = T)\n  d_4_tmp[analys == 1 & is.na(N), N := 0]\n  d_4_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_4_tmp, sim, analys, arm)\n  \n  d_arm_tmp &lt;- rbind(d_1_tmp, d_2_tmp, d_3_tmp, d_4_tmp)\n  \n  # d_arm_tmp\n  # d_dec_2[value == T, .SD[1], keyby = .(sim, analys, domain, quant)]\n  # dcast(\n  #   d_dec_1[\n  #     sim == 5 & quant %in% c(\"sup\", \"fut_sup\"), .(sim, analys, quant, d1)],\n  #   sim + analys ~ quant, value.var = \"d1\"\n  # )\n  \n  d_arm_tmp[, `:=`(\n    scenario = i, desc = l_cfg$desc\n  )]\n  \n  d_arm_tmp &lt;- merge(\n    d_arm_tmp,\n    d_enrolment,\n    by = \"analys\")\n  \n  d_N_by_arm &lt;- rbind(d_N_by_arm, d_arm_tmp)\n\n}\n\n\n\nProbability of triggering decision\nTable 1 shows the cumulative probability of a superiority decision across each of the scenarios simulated (the same information is shown in Figure 3). Operating characteristics are shown only for the relevant domains and the futility of a superiority decision is included in parentheses.\nIn the first eight scenarios, the surgical effects are simulated assuming equal sizes in all silos. In the second set of scenarios, silo specific heterogeneity is introduced. Under silo-specific heterogeneity there is inflation of the type-i assertion probability in the surgical domain.\n\nSuperiority decision - tabulatedSuperiority decision - visualisation\n\n\n\n\n\nCode\nd_tbl_1_cur &lt;- d_tbl_1[quant %in% c(\"sup\", \"fut_sup\") & domain %in% c(1, 3, 4), .SD]\nsetorderv(d_tbl_1_cur, cols = c(\"scenario\", \"domain\", \"analys\", \"quant\"), \n          order = c(1, 1, 1, -1))\nd_tbl_1_cur &lt;- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = \"pr_val\")\nd_tbl_1_cur &lt;- d_tbl_1_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nd_tbl_1_cur[, domain := factor(domain, \n                               levels = c(1, 3, 4), \n                               labels = c(\"Surgical\", \"AB Ext-proph\", \"AB Choice\"))]\n\ng_tbl &lt;- d_tbl_1_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_1_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_500\", \"fut_sup_500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )   |&gt; \n  cols_merge(\n    columns = c(\"sup_1000\", \"fut_sup_1000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  cols_merge(\n    columns = c(\"sup_1500\", \"fut_sup_1500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_2000\", \"fut_sup_2000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_2500\", \"fut_sup_2500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt;\n  tab_spanner(\n    label = md(\"Cumulative probability of **superiority** (futility) decision\"),\n    columns = 3:ncol(d_tbl_1_cur)\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    sup_500 = html(\"500\"),\n    sup_1000 = html(\"1000\"),\n    sup_1500 = html(\"1500\"),\n    sup_2000 = html(\"2000\"),\n    sup_2500 = html(\"2500\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain\n\nCumulative probability of superiority (futility) decision\n\n\n\n500\n1000\n1500\n2000\n2500\n\n\n\n\nNull effect in all domains\n\n\nSurgical\n0.045 (0.521)\n0.075 (0.667)\n0.099 (0.709)\n0.107 (0.737)\n0.108 (0.743)\n\n\nAB Ext-proph\n0.052 (0.437)\n0.081 (0.597)\n0.098 (0.682)\n0.108 (0.729)\n0.118 (0.756)\n\n\nAB Choice\n0.006 (0.596)\n0.011 (0.787)\n0.013 (0.868)\n0.015 (0.916)\n0.017 (0.944)\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage)\n\n\nSurgical\n0.568 (0.045)\n0.739 (0.052)\n0.794 (0.054)\n0.818 (0.055)\n0.838 (0.056)\n\n\nAB Ext-proph\n0.052 (0.506)\n0.082 (0.721)\n0.103 (0.801)\n0.11 (0.842)\n0.118 (0.863)\n\n\nAB Choice\n0.01 (0.602)\n0.016 (0.786)\n0.02 (0.878)\n0.023 (0.931)\n0.024 (0.945)\n\n\nModerate (OR 1.75) surgical revision effect (one-stage)\n\n\nSurgical\n0.203 (0.26)\n0.297 (0.336)\n0.346 (0.359)\n0.373 (0.38)\n0.393 (0.391)\n\n\nAB Ext-proph\n0.05 (0.49)\n0.087 (0.653)\n0.102 (0.734)\n0.113 (0.79)\n0.121 (0.816)\n\n\nAB Choice\n0.003 (0.612)\n0.007 (0.814)\n0.008 (0.898)\n0.01 (0.942)\n0.01 (0.962)\n\n\nModerate (OR 1.75) surgical revision effect (two-stage)\n\n\nSurgical\n0.154 (0.258)\n0.257 (0.342)\n0.303 (0.378)\n0.34 (0.403)\n0.358 (0.411)\n\n\nAB Ext-proph\n0.048 (0.479)\n0.077 (0.633)\n0.104 (0.728)\n0.115 (0.776)\n0.122 (0.806)\n\n\nAB Choice\n0.005 (0.594)\n0.009 (0.778)\n0.012 (0.868)\n0.015 (0.923)\n0.017 (0.953)\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect\n\n\nSurgical\n0.052 (0.494)\n0.087 (0.622)\n0.104 (0.667)\n0.111 (0.681)\n0.114 (0.689)\n\n\nAB Ext-proph\n0.043 (0.493)\n0.073 (0.665)\n0.086 (0.722)\n0.096 (0.761)\n0.102 (0.801)\n\n\nAB Choice\n0 (0.557)\n0.002 (0.787)\n0.006 (0.881)\n0.006 (0.921)\n0.007 (0.952)\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect\n\n\nSurgical\n0.059 (0.501)\n0.092 (0.643)\n0.107 (0.704)\n0.113 (0.721)\n0.12 (0.729)\n\n\nAB Ext-proph\n0.414 (0.056)\n0.676 (0.069)\n0.784 (0.077)\n0.844 (0.078)\n0.869 (0.08)\n\n\nAB Choice\n0.009 (0.58)\n0.011 (0.792)\n0.013 (0.871)\n0.015 (0.923)\n0.015 (0.948)\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect\n\n\nSurgical\n0.047 (0.519)\n0.078 (0.657)\n0.091 (0.718)\n0.096 (0.741)\n0.1 (0.75)\n\n\nAB Ext-proph\n0.055 (0.456)\n0.074 (0.608)\n0.086 (0.702)\n0.102 (0.747)\n0.108 (0.781)\n\n\nAB Choice\n0.337 (0.024)\n0.751 (0.028)\n0.896 (0.028)\n0.945 (0.028)\n0.966 (0.028)\n\n\nModerate (OR 1.75) effects in all domains\n\n\nSurgical\n0.649 (0.028)\n0.801 (0.037)\n0.853 (0.04)\n0.87 (0.041)\n0.881 (0.041)\n\n\nAB Ext-proph\n0.379 (0.09)\n0.669 (0.116)\n0.815 (0.12)\n0.863 (0.123)\n0.88 (0.124)\n\n\nAB Choice\n0.307 (0.044)\n0.642 (0.054)\n0.836 (0.057)\n0.904 (0.057)\n0.927 (0.058)\n\n\nNull effect in all domains +silo specific effects\n\n\nSurgical\n0.115 (0.312)\n0.197 (0.424)\n0.241 (0.471)\n0.26 (0.5)\n0.282 (0.513)\n\n\nAB Ext-proph\n0.041 (0.501)\n0.063 (0.672)\n0.078 (0.746)\n0.092 (0.797)\n0.097 (0.838)\n\n\nAB Choice\n0.005 (0.578)\n0.009 (0.76)\n0.015 (0.854)\n0.021 (0.899)\n0.026 (0.931)\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage) +silo specific effects\n\n\nSurgical\n0.616 (0.033)\n0.778 (0.04)\n0.831 (0.042)\n0.854 (0.043)\n0.872 (0.045)\n\n\nAB Ext-proph\n0.05 (0.51)\n0.076 (0.712)\n0.093 (0.802)\n0.108 (0.844)\n0.121 (0.864)\n\n\nAB Choice\n0.009 (0.543)\n0.011 (0.774)\n0.015 (0.868)\n0.017 (0.921)\n0.017 (0.954)\n\n\nModerate (OR 1.75) surgical revision effect (one-stage) +silo specific effects\n\n\nSurgical\n0.286 (0.139)\n0.428 (0.181)\n0.503 (0.199)\n0.543 (0.213)\n0.566 (0.218)\n\n\nAB Ext-proph\n0.045 (0.479)\n0.071 (0.672)\n0.083 (0.767)\n0.1 (0.819)\n0.113 (0.854)\n\n\nAB Choice\n0.005 (0.606)\n0.006 (0.799)\n0.008 (0.872)\n0.011 (0.924)\n0.012 (0.944)\n\n\nModerate (OR 1.75) surgical revision effect (two-stage) +silo specific effects\n\n\nSurgical\n0.439 (0.067)\n0.596 (0.084)\n0.655 (0.093)\n0.674 (0.095)\n0.692 (0.097)\n\n\nAB Ext-proph\n0.048 (0.478)\n0.07 (0.676)\n0.09 (0.791)\n0.1 (0.841)\n0.105 (0.864)\n\n\nAB Choice\n0.004 (0.597)\n0.006 (0.8)\n0.008 (0.895)\n0.009 (0.938)\n0.009 (0.962)\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect +silo specific effects\n\n\nSurgical\n0.17 (0.239)\n0.261 (0.328)\n0.31 (0.361)\n0.334 (0.376)\n0.351 (0.385)\n\n\nAB Ext-proph\n0.06 (0.456)\n0.087 (0.654)\n0.108 (0.737)\n0.121 (0.79)\n0.124 (0.818)\n\n\nAB Choice\n0.006 (0.592)\n0.01 (0.783)\n0.01 (0.874)\n0.011 (0.924)\n0.014 (0.955)\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect +silo specific effects\n\n\nSurgical\n0.202 (0.221)\n0.312 (0.305)\n0.364 (0.34)\n0.401 (0.36)\n0.425 (0.372)\n\n\nAB Ext-proph\n0.405 (0.066)\n0.661 (0.078)\n0.794 (0.086)\n0.847 (0.089)\n0.881 (0.091)\n\n\nAB Choice\n0.005 (0.603)\n0.01 (0.806)\n0.013 (0.904)\n0.013 (0.94)\n0.015 (0.96)\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect +silo specific effects\n\n\nSurgical\n0.148 (0.286)\n0.234 (0.366)\n0.285 (0.401)\n0.312 (0.427)\n0.337 (0.438)\n\n\nAB Ext-proph\n0.043 (0.468)\n0.076 (0.651)\n0.096 (0.754)\n0.111 (0.793)\n0.114 (0.828)\n\n\nAB Choice\n0.339 (0.034)\n0.709 (0.038)\n0.876 (0.038)\n0.943 (0.038)\n0.962 (0.038)\n\n\nModerate (OR 1.75) effects in all domains +silo specific effects\n\n\nSurgical\n0.653 (0.025)\n0.797 (0.032)\n0.839 (0.033)\n0.86 (0.035)\n0.875 (0.035)\n\n\nAB Ext-proph\n0.367 (0.114)\n0.669 (0.141)\n0.801 (0.148)\n0.836 (0.153)\n0.85 (0.158)\n\n\nAB Choice\n0.322 (0.033)\n0.673 (0.043)\n0.844 (0.045)\n0.919 (0.046)\n0.945 (0.047)\n\n\n\n\n\n\n\n\nTable 1: Cumulative probability of superiority (futility in parentheses) decision at each interim (shown by total enrolment by interim)\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_1[quant %in% c(\"sup\", \"fut_sup\") & domain %in% c(1, 3, 4), .SD]\nsetorderv(d_fig, cols = c(\"scenario\", \"domain\", \"analys\", \"quant\"), \n          order = c(1, 1, 1, -1))\n\nd_fig[, domain := factor(domain, \n                         levels = c(1, 3, 4), \n                         labels = c(\"Surgical\", \"AB Ext-proph\", \"AB Choice\"))]\n\nd_fig[, quant := factor(quant, \n                        levels = c(\"sup\", \"fut_sup\"), \n                        labels = c(\"Superiority\", \"Futility\"))]\n\nd_fig[, desc := factor(desc, \n                        levels = unique(d_fig$desc), \n                        labels = unique(d_fig$desc))]\n\n\nggplot(d_fig, aes(x = N, y = pr_val, group = quant, col = quant)) +\n  geom_line(lwd = 0.25) +\n  scale_y_continuous(\"\") +\n  scale_color_discrete(\"\") +\n  # facet_grid(desc ~ domain) + \n  # facet_grid2(desc ~ domain, render_empty = FALSE)\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 3: Cumulative probabilities for superiority assessments\n\n\n\n\n\n\n\n\nTable 2 shows the cumulative probability of a non-inferiority decision with futility shown in parentheses (the same information is shown in Figure 4). The results are only shown for the domains for which non-inferiority is evaluated.\nThe “Null effect in all domains” is actually a bit of a misnomer as the true null with regards to the NI decision would be at the NI margin, whereas the scenario refers to the setting where all effects are set to zero. Thus an inflation over the usual type-i assertion probability is to be expected.\n\nNon-inferiority - tabulatedNon-inferiority - visualisation\n\n\n\n\nCode\nd_tbl_1_cur &lt;- d_tbl_1[quant %in% c(\"ni\", \"fut_ni\") & domain %in% c(2), .SD]\nsetorderv(d_tbl_1_cur, cols = c(\"scenario\", \"domain\", \"analys\", \"quant\"), \n          order = c(1, 1, 1, -1))\nd_tbl_1_cur &lt;- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = \"pr_val\")\nd_tbl_1_cur &lt;- d_tbl_1_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nd_tbl_1_cur[, domain := factor(domain, \n                               levels = c(2), \n                               labels = c(\"AB Duration\"))]\n\ng_tbl &lt;- d_tbl_1_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_1_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_500\", \"fut_ni_500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )   |&gt; \n  cols_merge(\n    columns = c(\"ni_1000\", \"fut_ni_1000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  cols_merge(\n    columns = c(\"ni_1500\", \"fut_ni_1500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_2000\", \"fut_ni_2000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_2500\", \"fut_ni_2500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt;\n  tab_spanner(\n    label = md(\"Cumulative probability of **NI** (futility) decision\"),\n    columns = 3:ncol(d_tbl_1_cur)\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    ni_500 = html(\"500\"),\n    ni_1000 = html(\"1000\"),\n    ni_1500 = html(\"1500\"),\n    ni_2000 = html(\"2000\"),\n    ni_2500 = html(\"2500\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain\n\nCumulative probability of NI (futility) decision\n\n\n\n500\n1000\n1500\n2000\n2500\n\n\n\n\nNull effect in all domains\n\n\nAB Duration\n0.149 (0.095)\n0.248 (0.133)\n0.298 (0.161)\n0.342 (0.184)\n0.371 (0.197)\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage)\n\n\nAB Duration\n0.159 (0.098)\n0.284 (0.145)\n0.366 (0.185)\n0.44 (0.221)\n0.497 (0.235)\n\n\nModerate (OR 1.75) surgical revision effect (one-stage)\n\n\nAB Duration\n0.155 (0.097)\n0.256 (0.134)\n0.324 (0.173)\n0.387 (0.197)\n0.438 (0.213)\n\n\nModerate (OR 1.75) surgical revision effect (two-stage)\n\n\nAB Duration\n0.156 (0.084)\n0.254 (0.142)\n0.33 (0.173)\n0.389 (0.196)\n0.437 (0.215)\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect\n\n\nAB Duration\n0.451 (0.006)\n0.65 (0.007)\n0.783 (0.008)\n0.855 (0.008)\n0.896 (0.008)\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect\n\n\nAB Duration\n0.148 (0.096)\n0.226 (0.141)\n0.276 (0.178)\n0.314 (0.199)\n0.351 (0.22)\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect\n\n\nAB Duration\n0.134 (0.084)\n0.218 (0.135)\n0.279 (0.167)\n0.34 (0.183)\n0.373 (0.198)\n\n\nModerate (OR 1.75) effects in all domains\n\n\nAB Duration\n0.436 (0.012)\n0.732 (0.014)\n0.875 (0.015)\n0.928 (0.016)\n0.968 (0.016)\n\n\nNull effect in all domains +silo specific effects\n\n\nAB Duration\n0.139 (0.085)\n0.231 (0.135)\n0.314 (0.156)\n0.355 (0.18)\n0.402 (0.192)\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage) +silo specific effects\n\n\nAB Duration\n0.163 (0.075)\n0.299 (0.134)\n0.379 (0.174)\n0.454 (0.197)\n0.509 (0.216)\n\n\nModerate (OR 1.75) surgical revision effect (one-stage) +silo specific effects\n\n\nAB Duration\n0.159 (0.086)\n0.277 (0.14)\n0.356 (0.169)\n0.422 (0.19)\n0.469 (0.214)\n\n\nModerate (OR 1.75) surgical revision effect (two-stage) +silo specific effects\n\n\nAB Duration\n0.646 (0.001)\n0.898 (0.001)\n0.98 (0.001)\n0.993 (0.001)\n0.995 (0.001)\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect +silo specific effects\n\n\nAB Duration\n0.401 (0.021)\n0.668 (0.025)\n0.81 (0.027)\n0.866 (0.028)\n0.9 (0.028)\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect +silo specific effects\n\n\nAB Duration\n0.145 (0.084)\n0.243 (0.137)\n0.312 (0.171)\n0.364 (0.195)\n0.41 (0.211)\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect +silo specific effects\n\n\nAB Duration\n0.138 (0.088)\n0.232 (0.125)\n0.312 (0.167)\n0.374 (0.186)\n0.419 (0.204)\n\n\nModerate (OR 1.75) effects in all domains +silo specific effects\n\n\nAB Duration\n0.427 (0.014)\n0.713 (0.019)\n0.877 (0.02)\n0.944 (0.02)\n0.961 (0.021)\n\n\n\n\n\n\n\n\nTable 2: Cumulative probability of NI (futility in parentheses) decision at each interim (shown by total enrolment by interim)\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_1[quant %in% c(\"ni\", \"fut_ni\") & domain %in% c(2), .SD]\nsetorderv(d_fig, cols = c(\"scenario\", \"domain\", \"analys\", \"quant\"), \n          order = c(1, 1, 1, -1))\n\n# d_fig &lt;- rbind(\n#   d_fig,\n#   data.table(\n#     scenario = 1, desc = \"Null effect in all domains\",\n#     analys = 1, N = 500, quant = \"ni\", domain = 1, pr_val = NA\n#   ),\n#   data.table(\n#     scenario = 1, desc = \"Null effect in all domains\",\n#     analys = 1, N = 500, quant = \"ni\", domain = 3, pr_val = NA\n#   )\n# )\n# d_fig[, domain := factor(domain, \n#                                levels = c(1, 2, 3), \n#                                labels = c(\"1\", \"AB Duration\", \"3\"))]\n\nd_fig[, domain := factor(domain, \n                               levels = c(2), \n                               labels = c(\"AB Duration\"))]\n\nd_fig[, quant := factor(quant, \n                        levels = c(\"ni\", \"fut_ni\"), \n                        labels = c(\"NI\", \"Futility for NI\"))]\n\nd_fig[, desc := factor(desc, \n                        levels = unique(d_fig$desc), \n                        labels = unique(d_fig$desc))]\n\n\nggplot(d_fig, aes(x = N, y = pr_val, group = quant, col = quant)) +\n  geom_line(lwd = 0.25) +\n  scale_y_continuous(\"\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  # facet_grid(desc ~ domain, space = \"free\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  ggh4x::force_panelsizes(cols = unit(c(4), \"cm\"), TRUE) +\n  # facet_manual(\n  #   . ~ desc, design = matrix(1:17, ncol = 1),\n  #   widths = unit(3, \"cm\")\n  # ) +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 4: Cumulative probabilities for NI assessments\n\n\n\n\n\n\n\n\n\n\nSample size of randomised comparisons\nTable 3 shows the number of enrolments when any stopping decision is made (or for reaching the maximum 2500 sample size). This is the total number of enrolments that are expected to have occurred, not how many are contributing to the inference in a given domain.\nFigure 5 shows the number of participants entering into each of the randomised comparisons by domain and scenario.\nThe expected cumulative sample sizes are calculated by extracting the number of participants entering into each randomised comparison (i.e. restricted to the relevant strata) and taking the cumulative sum of these over time. For example, the domain 1 (surgical) expected values are based on the participants in the late acute silo that receive randomised surgical intervention. Similarly, the domain 2 (antibiotic duration) expected values are based on the participants across all silos that received one-stage revision and then receive one of the randomised treatment allocations (i.e. are not in the non-randomised treatment group for any reason).\nIf a decision was made in a domain, then subsequent enrolments would be assigned to the relevant arm and so the allocation would be expected to deviate away from 1:1. For example, if a superiority decision was made for domain 1 (and the trial was still ongoing) then all subsequent participants are assigned to the superior intervention. Finally, if a decision was made for all research questions, the trial stops early. To avoid any bias in the calculation, we use LOCF to propagate the expectations forward through to the maximum number of enrolments.\n\nEnrolments to stoppingSample size of randomised comparisons\n\n\n\n\nCode\nd_tbl_2_cur &lt;- d_tbl_2[, .(N_mu = mean(N_stopped)), keyby = .(scenario, desc, domain)]\nd_tbl_2_cur &lt;- dcast(d_tbl_2_cur, scenario + desc ~ domain, value.var = \"N_mu\")\nd_tbl_2_cur &lt;- d_tbl_2_cur[, .SD, .SDcols = !c(\"scenario\")]\n\ng_tbl &lt;- d_tbl_2_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_2_cur),\n    align = \"center\"\n  )  |&gt; \n  tab_spanner(\n    label = html(\"Expected number of total enrolments to hit stopping rule by domain\"),\n    columns = 2:ncol(d_tbl_2_cur)\n  )  |&gt;\n  cols_label(\n    `1` = \"Surgical\",\n    `2` = \"AB Duration\",\n    `3` = \"AB Ext-proph\",\n    `4` = \"AB choice\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 0, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpected number of total enrolments to hit stopping rule by domain\n\n\n\nSurgical\nAB Duration\nAB Ext-proph\nAB choice\n\n\n\n\nNull effect in all domains\n\n\n1,026\n1,695\n1,108\n894\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage)\n\n\n943\n1,553\n898\n867\n\n\nModerate (OR 1.75) surgical revision effect (one-stage)\n\n\n1,232\n1,638\n992\n853\n\n\nModerate (OR 1.75) surgical revision effect (two-stage)\n\n\n1,293\n1,638\n1,023\n898\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect\n\n\n1,104\n1,116\n1,034\n920\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect\n\n\n1,044\n1,711\n1,006\n893\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect\n\n\n1,031\n1,730\n1,090\n982\n\n\nModerate (OR 1.75) effects in all domains\n\n\n848\n986\n925\n1,052\n\n\nNull effect in all domains +silo specific effects\n\n\n1,250\n1,704\n1,008\n930\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage) +silo specific effects\n\n\n890\n1,564\n906\n921\n\n\nModerate (OR 1.75) surgical revision effect (one-stage) +silo specific effects\n\n\n1,266\n1,602\n984\n884\n\n\nModerate (OR 1.75) surgical revision effect (two-stage) +silo specific effects\n\n\n1,152\n740\n954\n872\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect +silo specific effects\n\n\n1,322\n1,077\n994\n895\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect +silo specific effects\n\n\n1,258\n1,674\n994\n853\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect +silo specific effects\n\n\n1,282\n1,690\n1,009\n996\n\n\nModerate (OR 1.75) effects in all domains +silo specific effects\n\n\n864\n984\n901\n1,040\n\n\n\n\n\n\n\n\nTable 3: Expected number of enrolments to hit any stopping rule (including reaching maximum sample size)\n\n\n\n\n\n\n\n\nCode\nd_fig_1 &lt;- d_N_by_arm[, .(mu_N = mean(N)), keyby = .(desc, domain, arm, N_enrol)]\nd_fig_1[, desc := factor(\n  desc,\n  levels = unique(d_N_by_arm$desc))]\nd_fig_1[\n  , domain := factor(\n    domain,\n    levels = 1:4,\n    labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\nd_fig_2 &lt;- d_N_by_arm[\n  domain == 1 & arm %in% 2:3, \n  .(N = sum(N), arm = 4), \n  keyby = .(analys, sim, domain, scenario, desc, N_enrol)]\nd_fig_2 &lt;- d_fig_2[, .(mu_N = mean(N)), keyby = .(desc, domain, arm, N_enrol)]\n\nd_fig_2[, desc := factor(\n  desc,\n  levels = unique(d_N_by_arm$desc))]\nd_fig_2[\n  , domain := factor(\n    domain,\n    levels = 1:4,\n    labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n  \nd_fig_1[, arm := factor(arm)]\nggplot(d_fig_1, aes(x = N_enrol, y = mu_N, col = arm)) +\n  geom_line(lwd = 0.2) +\n  geom_point(size = 0.4) +\n  geom_line(\n    data = d_fig_2, \n    aes(x = N_enrol, y = mu_N), lwd = 0.2, lty = 2, inherit.aes = F) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Expected number of participants\") +\n  scale_color_discrete(\"Treatment arm: \") +\n  ggh4x::facet_grid2(\n    desc ~ domain, \n    labeller = labeller(desc = label_wrap_gen(35)), \n    scales = \"free_y\", independent = \"y\") +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.title.y=element_text(size = 5),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 5: Expected number of participants on domain arms\n\n\n\n\n\n\n\n\n\n\nParameter estimation\nFigure 6 shows the median value and 95% quantiles from the posterior mean odds ratios obtained from the simulations by each domain and scenario. The estimates are unconditional, in that they ignore the stopping rule and propagate estimates forward with LOCF so that we are working from a random sample (albeit with static imputation) rather than a dependent sample of simulations.\nFigure 7 shows the median value and 95% quantiles for the posterior mean risk differences obtained from the simulations for each domain and scenario. The transformation to a risk difference suggests that the odds ratios amount to effects in the order of 10-20% on the risk scale, dependent on the silo, domain etc.\nThe AB duration domain has high variance in the distribution of posterior means that we anticipate to observe. That is, when there is no true effect, we might still see posterior means as large as \\(\\pm 0.2\\) on the absolute risk scale.\n\nTreatment effects - odds ratiosTreatment effects - risk difference\n\n\n\n\nCode\n# ggplot2::theme_update(text = element_text(size = 8))\n# ggplot2::theme_update(legend.position = \"bottom\")\n# # ggplot2::theme_update(legend.title = element_blank())\n# ggplot2::theme_update(axis.text.x = element_text(size = 8))\n# ggplot2::theme_update(axis.text.y = element_text(size = 8))\n\nd_fig &lt;- d_tbl_3[,\n                 .(or = median(exp(mu_lor)),\n                   q_025 = quantile(exp(mu_lor), prob = 0.025),\n                   q_975 = quantile(exp(mu_lor), prob = 0.975)), \n                 keyby = .(scenario, desc, analys, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_fig[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_fig[, domain := factor(domain, \n                         levels = 1:4, \n                         labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\n# d_tbl_3[scenario == 8, range(lor)]\n\nggplot(data = d_fig,  \n       aes(x = N, y = or)) +\n  geom_line(lwd = 0.25) +\n  geom_errorbar(aes(ymin = q_025, ymax = q_975), lwd = 0.25, width = 50) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n        strip.text.x = element_text(angle = 0, size = 5),\n        axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),\n        axis.text.y = element_text(size = 5),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1))\n\n\n\n\n\n\n\n\nFigure 6: Median value of posterior means for odds-ratio treatment effects by domain and simulation scenario\n\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_3[,\n                 .(rd = median(mu_rd),\n                   q_025 = quantile(mu_rd, prob = 0.025),\n                   q_975 = quantile(mu_rd, prob = 0.975)), \n                 keyby = .(scenario, desc, analys, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_fig[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_fig[, domain := factor(domain, \n                         levels = 1:4, \n                         labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\n# d_tbl_3[scenario == 8, range(lor)]\n\nggplot(data = d_fig,  \n       aes(x = N, y = rd)) +\n  geom_line(lwd = 0.25) +\n  geom_errorbar(aes(ymin = q_025, ymax = q_975), lwd = 0.25, width = 50) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n        strip.text.x = element_text(angle = 0, size = 5),\n        axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),\n        axis.text.y = element_text(size = 5),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1))\n\n\n\n\n\n\n\n\nFigure 7: Median value of posterior means for risk difference treatment effects by domain and simulation scenario",
    "crumbs": [
      "Simulations",
      "Simulation results 5"
    ]
  },
  {
    "objectID": "notebooks/sim-design5-results.html#fraction-of-uncertainty-resolved",
    "href": "notebooks/sim-design5-results.html#fraction-of-uncertainty-resolved",
    "title": "Simulation results 5",
    "section": "Fraction of uncertainty resolved",
    "text": "Fraction of uncertainty resolved\nFigure 8 shows the median value and 95% quantiles for the fraction of uncertainty resolved based on\n\\[\n\\begin{aligned}\n\\text{Fraction \\ Resolved} = 1 - \\frac{Var(\\beta_{post})}{Var(\\beta_{pri})}\n\\end{aligned}\n\\]\nwhere \\(Var(\\beta_{post})\\) and \\(Var(\\beta_{pri})\\) represent the variance associated with the prior and posterior belief for the relevant log-odds ratio for the treatment effects. This is basically just a way to compare the prior and posterior variance. When the posterior is based on negligible data, the variance will be similar to that of the prior and the fraction resolved will be very small. A low fraction resolved (e.g. less than 0.5) suggests that any decision that was made was done so with a substantial amount of uncertainty remaining (you didn’t move far from your prior belief) whereas values close to unity suggest that a lot of the uncertainty has been resolved.\n\nWhat is obvious from the above plots is also obvious here, the decision made in the AB duration domain are subject to a substantial amount of uncertainty.\n\n\n\nCode\nl_cfg &lt;- copy(l[[1]]$cfg)\n\n# initial uncertainty\nv0 &lt;- (l_cfg$pri$b_trt[2])^2\n\nd_fig &lt;- copy(d_tbl_3)\nd_fig[, fr_unc := 1 - (se_lor/v0)]\n\nd_fig &lt;- d_fig[,\n                 .(fr_unc = median(fr_unc),\n                   q_025 = quantile(fr_unc, prob = 0.025),\n                   q_975 = quantile(fr_unc, prob = 0.975)), \n                 keyby = .(scenario, desc, analys, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_fig[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_fig[, domain := factor(domain, \n                         levels = 1:4, \n                         labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\n# d_tbl_3[scenario == 8, range(lor)]\n\nggplot(data = d_fig,  \n       aes(x = N, y = fr_unc)) +\n  geom_line(lwd = 0.25) +\n  geom_errorbar(aes(ymin = q_025, ymax = q_975), lwd = 0.25, width = 50) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Fraction of uncertainty resolved (1-(V_post/V_pri))\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_clean() +\n  # theme_minimal() +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n        strip.text.x = element_text(angle = 0, size = 5),\n        axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),\n        axis.text.y = element_text(size = 5),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1))\n\n\n\n\n\n\n\n\nFigure 8: Median values and quantiles for fraction of uncertainty resolved",
    "crumbs": [
      "Simulations",
      "Simulation results 5"
    ]
  },
  {
    "objectID": "notebooks/sim-design6-ex02.html",
    "href": "notebooks/sim-design6-ex02.html",
    "title": "Simulation 6 - example 2",
    "section": "",
    "text": "Warning: package 'cmdstanr' was built under R version 4.4.3\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\nsim_lab &lt;- \"sim06-05\"\n# files of interest\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim06\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\nix_scenario &lt;- 1\nix_trial &lt;- 99",
    "crumbs": [
      "Simulations",
      "Simulation 6 - example 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design6-ex02.html#results-from-example-trial",
    "href": "notebooks/sim-design6-ex02.html#results-from-example-trial",
    "title": "Simulation 6 - example 2",
    "section": "Results from example trial",
    "text": "Results from example trial\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(analys, N, quant, domain)]\n  \n  \n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected number of enrolments\n# Similar to above but focus on expected number of enrolments\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 1\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix that contains the stopping decision by \n  # quantity (superiority, ni, futility, etc) for each domain by analysis\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  # long version of decision, e.g.\n  #      sim analys  quant domain  value\n  #    &lt;int&gt;  &lt;int&gt; &lt;char&gt; &lt;fctr&gt; &lt;lgcl&gt;\n  # 1:     1      1    sup     d1  FALSE\n  # 2:     1      2    sup     d1  FALSE\n  # 3:     1      3    sup     d1  FALSE\n  # 4:     1      4    sup     d1  FALSE\n  # 5:     1      5    sup     d1  FALSE\n  # 6:     2      1    sup     d1  FALSE\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case we had a sim fall over, fill in value\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # Extract the first instance of any decision occurring by sim and domain.\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise the \n# posterior means, they would thus be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# what we estimate is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 2\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  d_pars &lt;- dcast(d_pars, sim + id_analys + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  setnames(d_pars, \"id_analys\", \"analys\")\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"analys\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(analys, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nCumulative probability of each decision type for example trial\n# &gt; names(l[[ix_scenario]])\n#  [1] \"cfg\"           \"d_pr_sup\"      \"d_pr_ni\"       \"d_pr_sup_fut\"  \"d_pr_ni_fut\"   \"d_decision\"   \n#  [7] \"d_post_smry_1\" \"d_all\"         \"d_n_units\"     \"d_n_assign\" \n\n# extract the decision matrix - sim, analysis, quantity, domain level decision\n\n\nd_N &lt;- data.table(\n  analys = 0:5,\n  N = seq(0, 2500, by = 500)\n)\n\n# Extract example trial specific data\nl_cfg &lt;- copy(l[[ix_scenario]]$cfg)\nd_dat &lt;- copy(l[[ix_scenario]]$d_all[sim == ix_trial])\n# Parameter summaries from analysis\nd_mod &lt;- copy(l[[ix_scenario]]$d_post_smry_1[sim == ix_trial])\n# Decision matrix for this trial\nd_dec &lt;- copy(l[[ix_scenario]]$d_decision[sim == ix_trial])\n# Probability level reached by domain and analysis\nd_pr_sup &lt;- copy(l[[ix_scenario]]$d_pr_sup[sim == ix_trial])\nd_pr_sup_fut &lt;- copy(l[[ix_scenario]]$d_pr_sup_fut[sim == ix_trial])\nd_pr_ni &lt;- copy(l[[ix_scenario]]$d_pr_ni[sim == ix_trial])\nd_pr_ni_fut &lt;- copy(l[[ix_scenario]]$d_pr_ni_fut[sim == ix_trial])\n\n# observed data\nsetnames(d_dat, \"id_analys\", \"analys\")\nsetnames(d_mod, \"id_analys\", \"analys\")\n\nd_mod &lt;- merge(d_mod, d_N, by = \"analys\")\n\nd_pr_sup &lt;- merge(d_pr_sup, d_N, by = \"analys\")\nd_pr_sup &lt;- melt(d_pr_sup[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup[, quant := \"sup\"]\n\nd_pr_sup_fut &lt;- merge(d_pr_sup_fut, d_N, by = \"analys\")\nd_pr_sup_fut &lt;- melt(d_pr_sup_fut[, .(analys, d1, d3, d4, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_sup_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_sup_fut[, quant := \"sup_fut\"]\n\nd_pr_ni &lt;- merge(d_pr_ni, d_N, by = \"analys\")\nd_pr_ni &lt;- melt(d_pr_ni[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni[, quant := \"ni\"]\n\nd_pr_ni_fut &lt;- merge(d_pr_ni_fut, d_N, by = \"analys\")\nd_pr_ni_fut &lt;- melt(d_pr_ni_fut[, .(analys, d2, N)], \n                 id.vars = c(\"analys\", \"N\"), variable.name = \"domain\")\nd_pr_ni_fut[, domain := as.numeric(gsub(\"d\", \"\", domain))]\nd_pr_ni_fut[, quant := \"ni_fut\"]\n\nd_pr_dec &lt;- rbind(d_pr_sup, d_pr_sup_fut, d_pr_ni, d_pr_ni_fut  )\nd_pr_dec[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_pr_dec[domain %in% c(2), question := \"Non-inferiority\"]\n\n# domain 1 relates only to the late acute silo\nd_dat_d1 &lt;- d_dat[\n  silo == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d1)]\nd_dat_d1[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d1)]\nd_dat_d1[, p_obs := cy/cn]\nd_dat_d1[, d1 := factor(d1, labels = c(\"DAIR\", \"One-stage\", \"Two-stage\"))]\n\n# domain 2 relates only to the group that receive one-stage\nd_dat_d2 &lt;- d_dat[\n  d1 == 2, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d2)]\nd_dat_d2[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d2)]\nd_dat_d2[, p_obs := cy/cn]\nd_dat_d2[, d2 := factor(d2, labels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\n# domain 3 relates only to the group that receive two-stage\nd_dat_d3 &lt;- d_dat[\n  d1 == 3, .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d3)]\nd_dat_d3[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d3)]\nd_dat_d3[, p_obs := cy/cn]\nd_dat_d3[, d3 := factor(d3, labels = c(\"Selected\", \"none\", \"12wk\"))]\n\n# domain 4 relates only to the group that receive two-stage\nd_dat_d4 &lt;- d_dat[\n  , .(y = sum(y), n = sum(N)), keyby = .(silo, analys, d4)]\nd_dat_d4[, `:=`(cy = cumsum(y), cn = cumsum(n)), keyby = .(silo, d4)]\nd_dat_d4[, p_obs := cy/cn]\nd_dat_d4[, d4 := factor(d4, labels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\nd_dec &lt;- melt(d_dec, measure.vars = paste0(\"d\", 1:4), variable.name = \"domain\")\nd_dec[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n# Subset to the decisions that are evaluated by domain\nd_dec &lt;- rbind(\n  d_dec[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n  d_dec[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n)\n\n\nd_dec_thres &lt;- data.table(\n  quant = rep(c(\"sup\", \"sup_fut\", \"ni\", \"ni_fut\"), each = 4),\n  domain = rep(1:4, len = 16)\n  )\nd_dec_thres[, threshold := c(\n    l_cfg$dec_probs$thresh_sup,\n    l_cfg$dec_probs$thresh_fut_sup,\n    l_cfg$dec_probs$thresh_ni,\n    l_cfg$dec_probs$thresh_fut_ni\n  )]\n\n\n## State transition through the different states of knowledge based on decisions\n\nd_dec_timeline &lt;- merge(\n  CJ(domain = 1:4, analys = 0:5),\n  d_N, by = \"analys\", all.y = T\n)\nsetorder(d_dec_timeline, domain, analys)\nd_dec_timeline[domain %in% c(1, 3, 4), question := \"Superiority\"]\nd_dec_timeline[domain %in% c(2), question := \"Non-inferiority\"]\nd_dec_timeline[N == 0, decision := \"Indeterminate\"]\n\n\ni &lt;- j &lt;- 1\n# For i across domains\nfor(i in 1:4){\n  # For j across analyses\n  for(j in 1:5){\n    \n    if(i %in% c(1, 3, 4)){\n      \n      if(d_dec[domain == i & analys == j & quant == \"sup\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"Superior\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_sup\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (sup)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    } else {\n      \n      if(d_dec[domain == i & analys == j & quant == \"ni\", value])  {\n        d_dec_timeline[domain == i & analys == j, decision := \"NI\"] \n      } else if (d_dec[domain == i & analys == j & quant == \"fut_ni\", value]) {\n        d_dec_timeline[domain == i & analys == j, decision := \"Futile (NI)\"] \n      } else {\n        d_dec_timeline[domain == i & analys == j, decision := \"Indeterminate\"] \n      }\n      \n    }\n    \n  }\n  \n}\n\nd_dec_timeline[, decision := factor(decision, levels = c(\n  \"Indeterminate\", \"Superior\", \"Futile (sup)\", \"NI\", \"Futile (NI)\"\n))]\n\n\n# Dealing with those for which a decision was not reached.\nd_decision &lt;- data.table(\n  domain = 1:4,\n  N = 2500\n)\nif(any(d_dec_timeline$decision != \"Indeterminate\")){\n  d_decision &lt;- d_dec_timeline[\n    decision != \"Indeterminate\", .(N = min(N)), keyby = .(domain, decision)]\n}\n\nd_decision &lt;- merge(\n  d_decision, \n  data.table(domain = 1:4),\n  by = \"domain\", all.y = T\n)\nd_decision[is.na(decision), `:=`(\n  decision = \"Intermediate\", N = 2500  \n)]\n\n\nd_dec_timeline &lt;- d_dec_timeline[N &lt;= max(d_decision$N)]\n\n\nTable 1 shows the decisions made for each domain (or indeterminate if no decisions were made).\n\n\nCode\ng_tbl &lt;- d_decision |&gt; \n  gt() |&gt; \n  cols_align(\n    columns = 1:2,\n    align = \"center\"\n  )  |&gt; \n  cols_align(\n    columns = 3,\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    decision = \"Decision\",\n    N = \"Enrolment\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nDomain\nDecision\nEnrolment\n\n\n\n\n1\nFutile (sup)\n1,000\n\n\n2\nNI\n2,000\n\n\n3\nFutile (sup)\n1,000\n\n\n4\nIntermediate\n2,500\n\n\n\n\n\n\n\n\nTable 1: Trial decisions by domain\n\n\n\n\nFigure 1 shows the knowledge transitions based on the decisions made for each domain by sample size up to the point where the trial was stopped either due to running out of resources or having addressed all the questions.\nInitially, all domains start in an indeterminate state in that neither treatment arm is preferred. As the data accrues and analyses progresses, the knowledge state for each domain may transition to, superiority, non-inferiority or futility.\n\n\nCode\np1 &lt;- ggplot(d_dec_timeline, aes(x = N, y = decision)) +\n  geom_point() +\n  scale_y_discrete(\"\", drop=FALSE) +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 1: Decision timeline\n\n\n\n\n\nFigure 2 through to Figure 5 show sample size for each domains.\n\nDomain 1: Sample sizeDomain 2: Sample sizeDomain 3: Sample sizeDomain 4: Sample size\n\n\nAny decision rule only applies to the late acute silo (silo 2).\n\n\nCode\nd_fig &lt;- copy(d_dat_d1)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d1 = c(\"DAIR\", \"One-stage\", \"Two-stage\")),\n  by = c(\"silo\", \"analys\", \"d1\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d1)]\n\np_d1 &lt;- ggplot(d_fig, aes(x = d1, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\", breaks = seq(0, 800, by = 200)) +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(print(p_d1))\n\n\n\n\n\n\n\n\nFigure 2: Domain 1: Surgical sample size\n\n\n\n\n\n\n\nOf those receiving one-stage (see figure for domain 1) and irrespective of silo membership, approximately 70% are assumed to enter the AB duration domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d2)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"silo\", \"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_a &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d2)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d2)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d2 = c(\"Selected\", \"12wk\", \"6wk\")),\n  by = c(\"analys\", \"d2\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d2)]\n\nd_fig[, d2 := factor(\n  d2, levels = c(\"Selected\", \"12wk\", \"6wk\"))]\n\np_d2_b &lt;- ggplot(d_fig, aes(x = d2, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d2_a, p_d2_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\n\n\nOf those receiving two-stage (see figure for domain 1) and irrespective of silo membership, approximately 90% are assumed to enter the AB ext-proph domain.\n\n\nCode\nd_fig &lt;- copy(d_dat_d3)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"silo\", \"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_a &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\n\nd_fig &lt;- copy(d_dat_d3)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d3)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d3 = c(\"Selected\", \"none\", \"12wk\")),\n  by = c(\"analys\", \"d3\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d3)]\n\nd_fig[, d3 := factor(\n  d3, levels = c(\"Selected\", \"none\", \"12wk\"))]\n\np_d3_b &lt;- ggplot(d_fig, aes(x = d3, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d3_a, p_d3_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 4: Domain 3: AB Expt-proph sample size\n\n\n\n\n\n\n\nAcross the entire trial sample, approximately 60% are assumed to enter the AB choice domain.\nHere, we know there is an effect of AB choice and would hope that a decision for superiority is made such that new participants are directed to receive rifampacin.\n\n\nCode\nd_fig &lt;- copy(d_dat_d4)\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(silo = 1:3, analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"silo\", \"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(silo, d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\n\np_d4_a &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(silo ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6))\n\nd_fig &lt;- copy(d_dat_d4)\nd_fig &lt;- d_fig[, .(cn = sum(cn)), keyby = .(analys, d4)]\n\nd_fig &lt;- merge(\n  d_fig, \n  CJ(analys = 1:5, d4 = c(\"Selected\", \"no-rif\", \"rif\")),\n  by = c(\"analys\", \"d4\"),\n  all.y = T\n)\nd_fig[, cn := nafill(cn, type = \"locf\"), keyby = .(d4)]\n\nd_fig[, d4 := factor(\n  d4, levels = c(\"Selected\", \"no-rif\", \"rif\"))]\n\np_d4_b &lt;- ggplot(d_fig, aes(x = d4, y = cn)) +\n  geom_linerange(aes(ymin = 0, ymax = cn), lwd = 1) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"Sample size\") +\n  facet_grid(. ~ analys, labeller = label_both) +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0, size = 6),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 6),\n        axis.text.y = element_text(size = 6)) \n\nsuppressWarnings(\n  grid.arrange(p_d4_a, p_d4_b, nrow = 2, heights = c(3, 1))\n)\n\n\n\n\n\n\n\n\nFigure 5: AB Choice sample size\n\n\n\n\n\n\n\n\nFigure 6 and Figure 7 show the parameter estimates.\nNote:\nParameter estimates will only be reported up until the simulated trial was stopped due to all questions having been answered.\n\nPosterior odds-ratio summaryPosterior risk-difference summary\n\n\nFigure 6 shows the posterior odds-ratios for the randomised comparisons by domain and enrolment progression.\n\n\nCode\n# late acute, surgical effects\nd_d1_n &lt;- d_dat[silo == 2, \n                .(n = sum(N), domain = 1), keyby = .(analys, d1)]\nsetnames(d_d1_n, \"d1\", \"trt\")\n# those receiving one-stage and randomised treatment in domain 2\nd_d2_n &lt;- d_dat[d1 == 2 & d2 %in% 2:3, \n                .(n = sum(N), domain = 2), keyby = .(analys, d2)]\nsetnames(d_d2_n, \"d2\", \"trt\")\n# those receiving two-stage and randomised treatment in domain 3\nd_d3_n &lt;- d_dat[d1 == 3 & d3 %in% 2:3, \n                .(n = sum(N), domain = 3), keyby = .(analys, d3)]\nsetnames(d_d3_n, \"d3\", \"trt\")\n# those receiving randomised treatment in domain 4\nd_d4_n &lt;- d_dat[d4 %in% 2:3, \n                .(n = sum(N), domain = 4), keyby = .(analys, d4)]\nsetnames(d_d4_n, \"d4\", \"trt\")\n\nd_n_trt &lt;- rbind(\n  d_d1_n, d_d2_n, d_d3_n, d_d4_n\n)\nd_n_trt &lt;- merge(\n  d_n_trt,\n  d_N[analys != 0],\n  by = \"analys\"\n)\n\nd_n_trt &lt;- d_n_trt[, .(n = sum(n)), keyby = .(N, domain)]\nd_n_trt[, n := cumsum(n), keyby = domain]\n\np1 &lt;- ggplot(d_mod[par == \"lor\"], aes(x = N, y = exp(med))) +\n  geom_point() +\n  geom_linerange(aes(ymin = exp(q_025), ymax = exp(q_975)), lwd = 0.25) +\n  geom_text(\n    data = d_n_trt, \n    aes(x = N, y = -0.5, label = n), col = 2, size = 2\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 6: Posterior summary measures\n\n\n\n\n\n\n\nFigure 7 shows the posterior risk differences for the randomised comparisons by domain and enrolment progression.\n\n\nCode\np1 &lt;- ggplot(d_mod[par == \"rd\"], aes(x = N, y = med)) +\n  geom_point() +\n  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  facet_wrap(domain ~ ., labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 7: Posterior summary measures\n\n\n\n\n\n\n\n\nFigure 8 shows the probability associated with each decision type for the randomised comparisons by domain and enrolment progression.\nFor example, for domain 1 in analysis 1, the probability of revision being superior to DAIR (per the definition of superiority, which is a measure that is relative to nominated reference level for superiority) is approxiamtely 0.74. To make a superiority decision, this probability needs to exceed 0.920.\nSimilarly, for domain 1 in analysis 1, the probability of the superiority decision being futile (per the relevant definition) is approximately 0.50. To make a futility decision (related to superiority) this probability has to fall below 0.300.\nNote:\n\nThe futility probabilities are based on being below a given threshold (rather than above).\n\n\n\nCode\np1 &lt;- ggplot(d_fig_1, aes(x = N, y = value)) +\n  geom_point(aes(col=quant), position = position_dodge2(width = 100), size = 0.6) + \n  geom_linerange(aes(ymin = 0, ymax = value, col=quant), \n                 position = position_dodge2(width = 100), lwd = 0.25)+\n  geom_hline(\n    data = d_fig_2,\n    aes(yintercept = threshold, col=quant), lwd = 0.25\n  ) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Decision probability\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  facet_wrap(domain ~ question, labeller = label_both)\n\nsuppressWarnings(print(p1))\n\n\n\n\n\n\n\n\nFigure 8: Probability decision summaries\n\n\n\n\n\n\n\n\n\n\n\nReveal scenario\n\n\n\n\n\nThe results are from a simulated trial picked from scenario 1: Null effect in all domains +silo specific effects.\n\n\nCode\nl_cfg\n\n\n$cov\n$cov$silo\n$cov$silo[[1]]\n[1] 0\n\n$cov$silo[[2]]\n[1] -0.3\n\n$cov$silo[[3]]\n[1] -0.2\n\n\n$cov$jnt\n$cov$jnt[[1]]\n[1] 0\n\n$cov$jnt[[2]]\n[1] 0.4\n\n\n$cov$pref\n$cov$pref[[1]]\n[1] 0\n\n$cov$pref[[2]]\n[1] -0.2\n\n\n$cov$mu\n[1] 0.7\n\n\n$d1\n$d1[[1]]\n[1] 0\n\n$d1[[2]]\n[1] 0.693\n\n$d1[[3]]\n[1] 0.693\n\n$d1[[4]]\n[1] 0\n\n$d1[[5]]\n[1] 0\n\n$d1[[6]]\n[1] 0\n\n$d1[[7]]\n[1] 0.1\n\n$d1[[8]]\n[1] 0.693\n\n$d1[[9]]\n[1] 0.693\n\n\n$pri\n$pri$mu\n[1] 0.7 0.7\n\n$pri$b_silo\n[1] 0 1\n\n$pri$b_jnt\n[1] 0 1\n\n$pri$b_prf\n[1] 0 1\n\n$pri$b_trt\n[1] 0 1\n\n\n$dec_ref\n$dec_ref$delta_sup\n[1] 0\n\n$dec_ref$delta_sup_fut\n[1] 0.05\n\n$dec_ref$delta_ni\n[1] -0.05\n\n$dec_ref$delta_ni_fut\n[1] 0\n\n\n$dec_probs\n$dec_probs$thresh_sup\n[1] 0.920 0.950 0.950 0.995\n\n$dec_probs$thresh_ni\n[1] 0.975 0.925 0.975 0.975\n\n$dec_probs$thresh_fut_sup\n[1] 0.30 0.25 0.25 0.25\n\n$dec_probs$thresh_fut_ni\n[1] 0.25 0.10 0.25 0.25\n\n\n$desc\n[1] \"Null effect in all domains +silo specific effects\"\n\n$nsim\n[1] 2500\n\n$mc_cores\n[1] 40\n\n$N_pt\n[1]  500 1000 1500 2000 2500\n\n$d2\n[1] 0 0 0\n\n$d3\n[1] 0 0 0\n\n$d4\n[1] 0 0 0",
    "crumbs": [
      "Simulations",
      "Simulation 6 - example 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design6-results.html",
    "href": "notebooks/sim-design6-results.html",
    "title": "Simulation results 6",
    "section": "",
    "text": "Libraries and globals\nsource(\"./R/init.R\")\n\n\nWarning: package 'cmdstanr' was built under R version 4.4.3\n\n\nLibraries and globals\nsource(\"./R/util.R\")\nsource(\"./R/data.R\")\nlog_info(\"Called simulation-results 6 notebook\")\n\ntoks &lt;- unlist(tstrsplit(getwd(), \"/\")) \nif(toks[length(toks)] == \"roadmap-sim\"){\n  prefix_cfg &lt;- \"./etc/sim06/\"\n  prefix_stan &lt;- \"./stan\"\n  prefix_fig &lt;- \"./fig\"\n} else {\n  prefix_cfg &lt;- \"../etc/sim06/\"\n  prefix_stan &lt;- \"../stan\"\n  prefix_fig &lt;- \"../fig\"\n}\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\nsim_lab &lt;- \"sim06-06\"\n\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim06\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}",
    "crumbs": [
      "Simulations",
      "Simulation results 6"
    ]
  },
  {
    "objectID": "notebooks/sim-design6-results.html#introduction",
    "href": "notebooks/sim-design6-results.html#introduction",
    "title": "Simulation results 6",
    "section": "Introduction",
    "text": "Introduction\n\nData generation\nData is generated based on the empirical distributions obtained mostly from the PIANO study.\nWe simulate silo membership from a multinomial distribution with probabilities 0.3, 0.5 and 0.2 for early, late and chronic. Conditional on silo membership, we simulate site of infection from a multinomial distribution with probabilities 0.4, 0.6 (knee, hip | early), 0.7, 0.3 (knee, hip | late) and 0.5, 0.5 (knee, hip | chronic).\nFor the surgical domain, we simulate preference towards revision from a multinomial distribution with probabilities 0.66, 0.33 (rev(1), rev(2) | early), 0.3, 0.7 (rev(1), rev(2) | late), 0.25, 0.75 (rev(1), rev(2) | chronic).\nWe simulate surgical intervention from a multinomial distribution with probabilities 0.85, 0.15 (DAIR, revision | early), 0.5, 0.5 (DAIR, revision | late), 0.2, 0.8 (DAIR, revision | chronic). Revision is subsequently decomposed into one and two-stage via the preferences.\nA silo-specific index can be computed as \\(d_1 + (K_{d_1}  (s - 1))\\) where \\(d_1 \\in \\{1, 2, 3\\}\\) is the treatment allocation (DAIR, rev(1), rev(2)), \\(K_{d_1} = 3\\) is the number of surgical treatment types and \\(s \\in \\{1, 2, 3\\}\\) is the silo membership (early, late, chronic).\nFor the antibiotic duration domain, we fix all participants that have received DAIR or two-stage revision as having non-randomised treatment. For all those receiving one-stage, we simulate antibiotic duration intervention from a multinomial distribution with probabilities 0.3, 0.35, 0.35 (non-rand, 12 weeks, 6 weeks | rev(1)). That is, 70% of the eligible set get randomised treatment and the split between 12 weeks and 6 weeks is 1:1.\nFor the extended prophylaxis domain, we fix all participants that have received DAIR or one-stage revision as having non-randomised treatment. For all those receiving one-stage, we simulate extended prophylaxis intervention from a multinomial distribution with probabilities 0.1, 0.45, 0.45 (non-rand, 12 weeks, 6 weeks | rev(2)). That is, 90% of the eligible set get randomised treatment and the split between 12 weeks and 6 weeks is 1:1.\nFor the antibiotic choice domain, we simulate the intervention from a multinomial distribution with probabilities 0.4, 0.3, 0.3 (non-rand, no-rifampicin, rifampicin) unconditional on silo membership. That is, 60% of the eligible set get randomised treatment and the split between no-rifampicin and rifampicin is 1:1.\nAs the trial progresses, decisions may be made which would lead to some allocations being shut off.\nThe true log-odds of response by subject is calculated as the sum of their parameters indexed by the levels generated above. Treatment success is simulated as a bernoulli random variable with probability equal to the inverse logit transform of the log-odds from the linear predictor. To speed up the model, we aggregate number of successes and number of trials by covariate group which gives the analogous binomial random variable representation.\n\n\nModel\nWe adopt a revised model where we allow for silo-specific effects in the surgical domain.\nIf, for whatever reason, the early or chronic silo show variation in the surgical domain effects adjustment for silo is inadequate to account for this and we end up with a polluted version of the surgical domain parameters. Most other things in the model remain the same as the previous simulation. The model is used to compute unit level risk (probability) and assesses decisions based on risk difference for the intervention comparisons by domain.\nFor the simulations, we have a single, multivariable logistic regression model with a linear predictor that incorporates all domains and is specified as follows:\n\\[\n\\begin{aligned}\nY &\\sim \\text{Binomial}(n, p) \\\\\n\\text{logit}(p) &= \\mu + \\beta_{s} + \\beta_{j} + \\beta_{p} + \\\\\n  \\quad& \\beta_{d1[k_{d1}, s]} + \\beta_{d2[k_{d2}]} + \\beta_{d3[k_{d3}]} + \\beta_{d4[k_{d4}]}  \n\\end{aligned}\n\\]\nfor each distinct covariate grouping where:\n\n\\(\\mu\\) represents an overall reference level from which all covariates deviate\n\\(\\beta_{s}\\) represents the silo deviations, which can be thought of as a seriousness of disease adjustment. We fix the first parameter (early) in this vector to zero for identifiability and the components are for early, late and chronic silo membership.\n\\(\\beta_{j}\\) represents the joint deviations, accounting for heterogeneity in outcome due to site of infection. Again, we fix the first parameter (knee) in this vector to zero for identifiability and the components are knee and hip.\n\\(\\beta_{p}\\) represents the (pre-revealed) preference adjustment, assuming revision was allocated but included irrespective of silo and what the assignment ultimately turned out to be. This accounts for heterogeneity in outcome due to clinical preference for revision type, which can be thought of as expert elicitation on aspects of the patient state and clinicial experience. Again, we fix the first parameter (preference one-stage revision) in this vector to zero for identifiability and the components are preference for one-stage or two-stage. Assuming revision is assigned, we would expect that the original preference would ultimately align with the type of revision received, but there is nothing enforcing this. Arguably, this could be restricted to the late-acute cohort, but we would need to extend the vector of parameters to accommodate for this. The preference indicators are also used to compute the sample weights for aggregating one and two-stage revision into a single overall revision effect.\n\\(\\beta_{d1[k_{d1}, s]}\\) represents the silo-specific deviations associated with the surgery type. This accounts for heterogeneity in outcome due to surgery type and with the late-acute deviations taken as a randomised comparison of dair vs revision after the agreed weighting is applied. Again, we fix the first parameter (dair in the early cohort) in this vector to zero for identifiability and the components are dair, rev(1), rev(2) for each silo. The reason for the silo-specific context is that if revision effects exist in one silo but not another, then without this conditioning, we will end up with biased inference. For example, if (for whatever reason) there is an revision effect in the early domain but not the late-acute cohort then without this level of adjustment, we would end up reporting a revision effect when we shouldn’t be; adjustment for silo doesn’t protect us from this, even though it is perfectly collinear with a unit receiving non-randomised or randomised surgical treatment.\n\\(\\beta_{d2[k_{d2}]}\\) represents the deviations associated with backbone antibiotic duration. This accounts for heterogeneity in outcome due to the assigned backbone antibiotic duration. The first parameter (non-randomised treatment) in this vector is set to zero for identifiability and the components are non-randomised, 12 weeks and 6 weeks. The term is included in the model irrespective of what surgery type was received but only units receiving randomised and revealed one-stage are captured within the 12 week/6 week comparison. The other units contribute to the non-randomised set (which is essentially a nuissance variable that we don’t particularly care about). We are assuming that there is no silo-specific (or any other) hetereogeneity for this comparison.\n\\(\\beta_{d3[k_{d3}]}\\) represents the deviations associated with extended prophylaxis duration. This accounts for heterogeneity in outcome due to the assigned extended prophylaxis duration. The first parameter (non-randomised treatment) in this vector is set to zero for identifiability and the components are non-randomised, no ext-proph and 12 weeks. The term is included in the model irrespective of what surgery type was received but only units receiving randomised and revealed two-stage are captured within the none/12 week comparison. The other units contribute to the non-randomised set (which again is a nuissance variable that we don’t particularly care about). We are assuming that there is no silo-specific hetereogeneity for this comparison.\n\\(\\beta_{d4[k_{d4}]}\\) represents the deviations associated with antibiotic choice. This accounts for heterogeneity in outcome due to the assigned antibiotic choice. The first parameter (non-randomised treatment) in this vector is set to zero for identifiability and the components are non-randomised, no rifampicin and rifampicin. The term is included for all units for which rifampicin may be indicated. The other units contribute to the non-randomised set. We are assuming that there is no silo-specific hetereogeneity for this comparison.\n\nThe simulation model isn’t particularly complicated but the way that terms enter the model is convoluted and understanding the dependency implications and consequently interpretations is fairly challenging. For the actual trial analysis, the model will be revised to the equivalent Bernoulli likelihood on unit level data and also extended to account for site, randomisation period and prognostic covariates. Bar the surgical domain, for which ‘by silo’ deviations are implicit in the existing parameterisation, no further interactions are included. However, given that heterogeneity by site of infection (joint) is of interest (primarily in the surgical domain) the analysis plan will include specification to account for this (essentially by an additional set of surgical domain parameters for which each term could be partially pooled, if that aligns with the prior belief structure).\n\n\nDecision\nAt each interim, we assess the posterior and if a decision threshold is met, we act. For example, if a superiority decision is reached in one of the domains for which this decision type is relevant, then we consider that domain dealt with and all subsequent participants are assigned to receive the superior intervention. We can (and presently do) continue to update the posterior inference for the comparison that has stopped in subsequent interim analyses until we get to the point where all questions have been answered in all domains, at which point the trial will stop.\nSuperiority and non-inferiority are applicable to some domains and not others, however, we define reference and threshold values for all domains, just in case. Decisions are made with respect to the average within any `random-effect’ terms that might exist within the model.\nFor the superiority decision, a reference value of 0 was used and the probability thresholds were:\n\n0.92 for surgical domain\n0.95 for antibiotic duration domain\n0.95 for extended prophylaxis domain\n0.995 for antibiotic choice domain\n\nThere was no particular reason for the choice of these thresholds bar the fact that they lead to preferred operating characteristics and give nominal control of the type-i assertion probabilities.\nFor the futility decision (in relation to superiority) a reference value of 0.05 was used and the probability thresholds were:\n\n0.3 for surgical domain\n0.25 for antibiotic duration domain\n0.25 for extended prophylaxis domain\n0.25 for antibiotic choice domain\n\nThe above means, for example, that if the probability that the risk difference is greater than 0.05 is less than 0.3 in the surgical domain comparison, then we say the superiority goal is futile.\nFor the ni decision, a reference value of -0.05 was used and the probability thresholds were:\n\n0.975 for surgical domain\n0.925 for antibiotic duration domain\n0.975 for extended prophylaxis domain\n0.975 for antibiotic choice domain\n\nThe above means, for example, that if the probability that the risk difference is greater than -0.05 is greater than 0.925, in the antibiotic duration domain, then we will say the intervention is non-inferior.\nThe futility decision (in relation to non-inferiority) has a reference value of 0 and the probability thresholds were:\n\n0.25 for surgical domain\n0.1 for antibiotic duration domain\n0.25 for extended prophylaxis domain\n0.25 for antibiotic choice domain\n\nThis means, for example, that if the probability that the risk difference is greater than 0 is less than 0.1, in the antibiotic duration domain, then we say the non-inferiority goal is futile.\n\n\nPrior\nThe priors were as follows:\n\nReference log-odds of response: logistic distribution, mean 0.7 and scale 0.7\nSilo effects: normal distribution, mean 0 and scale 1\nJoint effects: normal distribution, mean 0 and scale 1\nPreference effects: normal distribution, mean 0 and scale 1\nTreatment effects: normal distribution, mean 0 and scale 1\n\nThe prior predictive distribution is consistent with a mean probability across of response over the covariate groupings that covers the entire support on the probability scale, is centred around 0.6 and has first and third quarters at 0.4 to 0.8.",
    "crumbs": [
      "Simulations",
      "Simulation results 6"
    ]
  },
  {
    "objectID": "notebooks/sim-design6-results.html#simulation-results",
    "href": "notebooks/sim-design6-results.html#simulation-results",
    "title": "Simulation results 6",
    "section": "Simulation results",
    "text": "Simulation results\nFor this set of simulations, the number of simulated trials per scenario was 1000, the simulation label is sim06-06.\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 1\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(analys, N, quant, domain)]\n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected enrolment progression\n# Expected sample size\n\n# Similar to above but focus on expected sample size\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 2\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  # long version of decision\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"analys\", \"quant\"), \n                  variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # First instance of any decision rule being hit by sim and domain.\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  \n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n                      # all combinations of sim and domain\n                      unique(d_dec_2[, .(sim, domain)]),\n                      by = c(\"sim\", \"domain\"), all.y = T)\n  \n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise these \n# posterior means, they would be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n\n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# our estimates is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 1\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)\n  \n  d_pars &lt;- dcast(d_pars, sim + id_analys + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  setnames(d_pars, \"id_analys\", \"analys\")\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"analys\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(analys, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nNumber of participants for each randomised comparison over time\n# \n\ni &lt;- 1\nd_N_by_arm &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # long version of decisions\n  d_dec_2 &lt;- melt(\n    d_dec_1, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_enrolment &lt;- data.table(analys = seq_along(l_cfg$N_pt), N_enrol = l_cfg$N_pt)\n  # observed trial data sets\n  d_tru &lt;- copy(l[[i]]$d_all)\n  setnames(d_tru, \"id_analys\", \"analys\")\n  \n  \n  # late acute, surgical arms\n  # *** silo isn't included in the keyby because we want to average across \n  # the entire trial population, not silo specific sample sizes.\n  d_1_tmp &lt;- d_tru[\n    silo == 2, .(N = sum(N), domain = 1), keyby = .(sim, analys, d1)]\n  d_1_tmp[, N := cumsum(N), keyby = .(sim, d1)]\n  setnames(d_1_tmp, old = \"d1\", \"arm\")\n  d_1_tmp &lt;- merge(\n    d_1_tmp, \n    CJ(sim = 1:max(d_tru$sim), analys = 1:5, arm = 1:3, domain = 1), \n    by = c(\"sim\", \"analys\", \"arm\", \"domain\"),\n    all.y = T)\n  d_1_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_1_tmp, sim, analys, arm)\n  \n  # one-stage revision, ab duration randomised arms\n  d_2_tmp &lt;- d_tru[\n    d1 == 2 & d2 %in% 2:3, \n    .(N = sum(N), domain = 2), keyby = .(sim, analys, d2)]\n  d_2_tmp[, N := cumsum(N), keyby = .(sim, d2)]\n  setnames(d_2_tmp, old = \"d2\", \"arm\")\n  d_2_tmp &lt;- merge(\n    d_2_tmp, \n    CJ(sim = 1:max(d_tru$sim), analys = 1:5, arm = 2:3, domain = 2), \n    by = c(\"sim\", \"analys\", \"arm\", \"domain\"),\n    all.y = T)\n  d_2_tmp[analys == 1 & is.na(N), N := 0]\n  d_2_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_2_tmp, sim, analys, arm)\n  \n  # two-stage revision, extended prophy randomised arms\n  d_3_tmp &lt;- d_tru[\n    d1 == 3 & d3 %in% 2:3, \n    .(N = sum(N), domain = 3), keyby = .(sim, analys, d3)]\n  d_3_tmp[, N := cumsum(N), keyby = .(sim, d3)]\n  setnames(d_3_tmp, old = \"d3\", \"arm\")\n  d_3_tmp &lt;- merge(\n    d_3_tmp, \n    CJ(sim = 1:max(d_tru$sim), analys = 1:5, arm = 2:3, domain = 3), \n    by = c(\"sim\", \"analys\", \"arm\", \"domain\"),\n    all.y = T)\n  d_3_tmp[analys == 1 & is.na(N), N := 0]\n  d_3_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_3_tmp, sim, analys, arm)\n  \n  # ab choice randomised arms\n  d_4_tmp &lt;- d_tru[\n    d4 %in% 2:3, .(N = sum(N), domain = 4), keyby = .(sim, analys, d4)]\n  d_4_tmp[, N := cumsum(N), keyby = .(sim, d4)]\n  setnames(d_4_tmp, old = \"d4\", \"arm\")\n  d_4_tmp &lt;- merge(\n    d_4_tmp, \n    CJ(sim = 1:max(d_tru$sim), analys = 1:5, arm = 2:3, domain = 4), \n    by = c(\"sim\", \"analys\", \"arm\", \"domain\"),\n    all.y = T)\n  d_4_tmp[analys == 1 & is.na(N), N := 0]\n  d_4_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_4_tmp, sim, analys, arm)\n  \n  d_arm_tmp &lt;- rbind(d_1_tmp, d_2_tmp, d_3_tmp, d_4_tmp)\n\n  \n  d_arm_tmp[, `:=`(\n    scenario = i, desc = l_cfg$desc\n  )]\n  \n  d_arm_tmp &lt;- merge(\n    d_arm_tmp,\n    d_enrolment,\n    by = \"analys\")\n  \n  d_N_by_arm &lt;- rbind(d_N_by_arm, d_arm_tmp)\n\n}\n\n\n\n\nSummaries of empirical probability of treatment success\ni &lt;- 1\nd_tbl_4 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_enrolment &lt;- data.table(analys = seq_along(l_cfg$N_pt), N_enrol = l_cfg$N_pt)\n  # observed data\n  d_all &lt;- copy(l[[i]]$d_all)\n  setnames(d_all, \"id_analys\", \"analys\")\n  \n  d_all &lt;- merge(d_all, d_enrolment , by = \"analys\")\n  # long version of decision\n  d_dec_2 &lt;- melt(\n    d_dec_1, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"analys\")\n  \n  # First instance of any decision rule being hit by sim and domain.\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  \n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"analys\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_domain_1 &lt;- d_all[\n    silo == 2 & d1 %in% 1:3, .(sim, analys, silo, jnt, pref_rev, arm = d1, y, N, N_enrol)]\n  d_domain_1 &lt;- merge(d_domain_1, d_dec_stop[domain == 1], by = c(\"sim\"))\n  d_domain_1 &lt;- d_domain_1[N_enrol &lt;= N_stopped, ]\n  d_domain_1 &lt;- d_domain_1[, .(domain = 1, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_1[, p_hat := y / N]\n  \n  d_domain_2 &lt;- d_all[\n    d1 == 2 & d2 %in% 2:3, .(sim, analys, silo, jnt, pref_rev, arm = d2, y, N, N_enrol)]\n  d_domain_2 &lt;- merge(d_domain_2, d_dec_stop[domain == 2], by = c(\"sim\"))\n  d_domain_2 &lt;- d_domain_2[N_enrol &lt;= N_stopped, ]\n  d_domain_2 &lt;- d_domain_2[, .(domain = 2, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_2[, p_hat := y / N]\n  \n  d_domain_3 &lt;- d_all[\n    d1 == 3 & d3 %in% 2:3, .(sim, analys, silo, jnt, pref_rev, arm = d3, y, N, N_enrol)]\n  d_domain_3 &lt;- merge(d_domain_3, d_dec_stop[domain == 3], by = c(\"sim\"))\n  d_domain_3 &lt;- d_domain_3[N_enrol &lt;= N_stopped, ]\n  d_domain_3 &lt;- d_domain_3[, .(domain = 3, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_3[, p_hat := y / N]\n  \n  d_domain_4 &lt;- d_all[\n    d4 %in% 2:3, .(sim, analys, silo, jnt, pref_rev, arm = d4, y, N, N_enrol)]\n  d_domain_4 &lt;- merge(d_domain_4, d_dec_stop[domain == 4], by = c(\"sim\"))\n  d_domain_4 &lt;- d_domain_4[N_enrol &lt;= N_stopped, ]\n  d_domain_4 &lt;- d_domain_4[, .(domain = 4, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_4[, p_hat := y / N]\n  \n  d_domain &lt;- rbind(\n    d_domain_1, d_domain_2, d_domain_3, d_domain_4\n  )\n  \n  d_tbl_4 &lt;- rbind(\n    d_tbl_4, \n    cbind(scenario = i, desc = l_cfg$desc, d_domain)\n  )\n  \n}\n\n\n\nProbability of triggering decision\nTable 1 shows the cumulative probability of a superiority decision across each of the scenarios simulated (the same information is shown in Figure 1). Operating characteristics are shown only for the relevant domains and the futility of a superiority decision is included in parentheses.\n\nSuperiority decision - tabulatedSuperiority decision - visualisation\n\n\n\n\n\nCode\nd_tbl_1_cur &lt;- d_tbl_1[quant %in% c(\"sup\", \"fut_sup\") & domain %in% c(1, 3, 4), .SD]\nsetorderv(d_tbl_1_cur, cols = c(\"scenario\", \"domain\", \"analys\", \"quant\"), \n          order = c(1, 1, 1, -1))\nd_tbl_1_cur &lt;- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = \"pr_val\")\nd_tbl_1_cur &lt;- d_tbl_1_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nd_tbl_1_cur[, domain := factor(domain, \n                               levels = c(1, 3, 4), \n                               labels = c(\"Surgical\", \"AB Ext-proph\", \"AB Choice\"))]\n\ng_tbl &lt;- d_tbl_1_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_1_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_500\", \"fut_sup_500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )   |&gt; \n  cols_merge(\n    columns = c(\"sup_1000\", \"fut_sup_1000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  cols_merge(\n    columns = c(\"sup_1500\", \"fut_sup_1500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_2000\", \"fut_sup_2000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_2500\", \"fut_sup_2500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt;\n  tab_spanner(\n    label = md(\"Cumulative probability of **superiority** (futility) decision\"),\n    columns = 3:ncol(d_tbl_1_cur)\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    sup_500 = html(\"500\"),\n    sup_1000 = html(\"1000\"),\n    sup_1500 = html(\"1500\"),\n    sup_2000 = html(\"2000\"),\n    sup_2500 = html(\"2500\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain\n\nCumulative probability of superiority (futility) decision\n\n\n\n500\n1000\n1500\n2000\n2500\n\n\n\n\nNull effect in all domains +silo specific effects\n\n\nSurgical\n0.03 (0.603)\n0.046 (0.749)\n0.06 (0.807)\n0.066 (0.839)\n0.071 (0.849)\n\n\nAB Ext-proph\n0.05 (0.5)\n0.086 (0.642)\n0.092 (0.721)\n0.103 (0.764)\n0.109 (0.812)\n\n\nAB Choice\n0.005 (0.597)\n0.012 (0.811)\n0.016 (0.892)\n0.017 (0.934)\n0.017 (0.959)\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage) +silo specific effects\n\n\nSurgical\n0.453 (0.073)\n0.646 (0.098)\n0.736 (0.11)\n0.77 (0.115)\n0.791 (0.122)\n\n\nAB Ext-proph\n0.047 (0.505)\n0.074 (0.706)\n0.098 (0.801)\n0.108 (0.84)\n0.113 (0.865)\n\n\nAB Choice\n0.003 (0.61)\n0.01 (0.813)\n0.012 (0.883)\n0.016 (0.929)\n0.018 (0.951)\n\n\nModerate (OR 1.75) surgical revision effect (one-stage) +silo specific effects\n\n\nSurgical\n0.124 (0.35)\n0.203 (0.461)\n0.232 (0.502)\n0.25 (0.532)\n0.261 (0.554)\n\n\nAB Ext-proph\n0.053 (0.475)\n0.082 (0.65)\n0.097 (0.734)\n0.108 (0.781)\n0.122 (0.819)\n\n\nAB Choice\n0.006 (0.632)\n0.007 (0.818)\n0.014 (0.903)\n0.015 (0.942)\n0.016 (0.965)\n\n\nModerate (OR 1.75) surgical revision effect (two-stage) +silo specific effects\n\n\nSurgical\n0.229 (0.219)\n0.345 (0.3)\n0.405 (0.336)\n0.446 (0.35)\n0.471 (0.357)\n\n\nAB Ext-proph\n0.041 (0.503)\n0.073 (0.674)\n0.093 (0.765)\n0.102 (0.821)\n0.108 (0.848)\n\n\nAB Choice\n0.005 (0.602)\n0.011 (0.81)\n0.013 (0.903)\n0.013 (0.939)\n0.014 (0.968)\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect +silo specific effects\n\n\nSurgical\n0.041 (0.546)\n0.063 (0.723)\n0.071 (0.789)\n0.076 (0.816)\n0.076 (0.834)\n\n\nAB Ext-proph\n0.051 (0.484)\n0.074 (0.643)\n0.089 (0.723)\n0.102 (0.769)\n0.111 (0.797)\n\n\nAB Choice\n0.002 (0.622)\n0.007 (0.816)\n0.01 (0.893)\n0.011 (0.94)\n0.012 (0.961)\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect +silo specific effects\n\n\nSurgical\n0.055 (0.547)\n0.077 (0.706)\n0.092 (0.771)\n0.097 (0.808)\n0.1 (0.819)\n\n\nAB Ext-proph\n0.396 (0.056)\n0.62 (0.075)\n0.735 (0.083)\n0.796 (0.091)\n0.842 (0.093)\n\n\nAB Choice\n0.009 (0.629)\n0.011 (0.814)\n0.011 (0.889)\n0.015 (0.942)\n0.016 (0.958)\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect +silo specific effects\n\n\nSurgical\n0.035 (0.613)\n0.049 (0.756)\n0.057 (0.808)\n0.06 (0.848)\n0.066 (0.862)\n\n\nAB Ext-proph\n0.044 (0.52)\n0.062 (0.657)\n0.082 (0.729)\n0.092 (0.777)\n0.104 (0.817)\n\n\nAB Choice\n0.317 (0.031)\n0.688 (0.036)\n0.883 (0.038)\n0.945 (0.038)\n0.957 (0.038)\n\n\nModerate (OR 1.75) effects in all domains +silo specific effects\n\n\nSurgical\n0.51 (0.072)\n0.692 (0.089)\n0.758 (0.099)\n0.777 (0.101)\n0.793 (0.102)\n\n\nAB Ext-proph\n0.339 (0.109)\n0.654 (0.129)\n0.798 (0.137)\n0.844 (0.139)\n0.858 (0.14)\n\n\nAB Choice\n0.278 (0.045)\n0.65 (0.051)\n0.836 (0.053)\n0.907 (0.056)\n0.936 (0.056)\n\n\n\n\n\n\n\n\nTable 1: Cumulative probability of superiority (futility in parentheses) decision at each interim (shown by total enrolment by interim)\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_1[quant %in% c(\"sup\", \"fut_sup\") & domain %in% c(1, 3, 4), .SD]\nsetorderv(d_fig, cols = c(\"scenario\", \"domain\", \"analys\", \"quant\"), \n          order = c(1, 1, 1, -1))\n\nd_fig[, domain := factor(domain, \n                         levels = c(1, 3, 4), \n                         labels = c(\"Surgical\", \"AB Ext-proph\", \"AB Choice\"))]\n\nd_fig[, quant := factor(quant, \n                        levels = c(\"sup\", \"fut_sup\"), \n                        labels = c(\"Superiority\", \"Futility\"))]\n\nd_fig[, desc := factor(desc, \n                        levels = unique(d_fig$desc), \n                        labels = unique(d_fig$desc))]\n\n\nggplot(d_fig, aes(x = N, y = pr_val, group = quant, col = quant)) +\n  geom_line(lwd = 0.25) +\n  scale_y_continuous(\"\") +\n  scale_color_discrete(\"\") +\n  # facet_grid(desc ~ domain) + \n  # facet_grid2(desc ~ domain, render_empty = FALSE)\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 1: Cumulative probabilities for superiority assessments\n\n\n\n\n\n\n\n\nTable 2 shows the cumulative probability of a non-inferiority decision with futility shown in parentheses (the same information is shown in Figure 2). The results are only shown for the domains for which non-inferiority is evaluated.\nThe “Null effect in all domains” is actually a bit of a misnomer as the true null with regards to the NI decision would be at the NI margin, whereas the scenario refers to the setting where all effects are set to zero. Thus an inflation over the usual type-i assertion probability is to be expected.\n\nNon-inferiority - tabulatedNon-inferiority - visualisation\n\n\n\n\nCode\nd_tbl_1_cur &lt;- d_tbl_1[quant %in% c(\"ni\", \"fut_ni\") & domain %in% c(2), .SD]\nsetorderv(d_tbl_1_cur, cols = c(\"scenario\", \"domain\", \"analys\", \"quant\"), \n          order = c(1, 1, 1, -1))\nd_tbl_1_cur &lt;- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = \"pr_val\")\nd_tbl_1_cur &lt;- d_tbl_1_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nd_tbl_1_cur[, domain := factor(domain, \n                               levels = c(2), \n                               labels = c(\"AB Duration\"))]\n\ng_tbl &lt;- d_tbl_1_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_1_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_500\", \"fut_ni_500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )   |&gt; \n  cols_merge(\n    columns = c(\"ni_1000\", \"fut_ni_1000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  cols_merge(\n    columns = c(\"ni_1500\", \"fut_ni_1500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_2000\", \"fut_ni_2000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_2500\", \"fut_ni_2500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt;\n  tab_spanner(\n    label = md(\"Cumulative probability of **NI** (futility) decision\"),\n    columns = 3:ncol(d_tbl_1_cur)\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    ni_500 = html(\"500\"),\n    ni_1000 = html(\"1000\"),\n    ni_1500 = html(\"1500\"),\n    ni_2000 = html(\"2000\"),\n    ni_2500 = html(\"2500\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain\n\nCumulative probability of NI (futility) decision\n\n\n\n500\n1000\n1500\n2000\n2500\n\n\n\n\nNull effect in all domains +silo specific effects\n\n\nAB Duration\n0.148 (0.082)\n0.236 (0.122)\n0.3 (0.159)\n0.35 (0.181)\n0.394 (0.194)\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage) +silo specific effects\n\n\nAB Duration\n0.153 (0.082)\n0.286 (0.138)\n0.386 (0.17)\n0.451 (0.199)\n0.504 (0.221)\n\n\nModerate (OR 1.75) surgical revision effect (one-stage) +silo specific effects\n\n\nAB Duration\n0.173 (0.096)\n0.283 (0.141)\n0.34 (0.17)\n0.387 (0.187)\n0.433 (0.203)\n\n\nModerate (OR 1.75) surgical revision effect (two-stage) +silo specific effects\n\n\nAB Duration\n0.151 (0.084)\n0.261 (0.127)\n0.344 (0.163)\n0.406 (0.186)\n0.458 (0.2)\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect +silo specific effects\n\n\nAB Duration\n0.445 (0.008)\n0.659 (0.01)\n0.781 (0.012)\n0.845 (0.014)\n0.889 (0.015)\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect +silo specific effects\n\n\nAB Duration\n0.155 (0.088)\n0.256 (0.14)\n0.314 (0.163)\n0.356 (0.178)\n0.402 (0.199)\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect +silo specific effects\n\n\nAB Duration\n0.157 (0.083)\n0.251 (0.135)\n0.315 (0.169)\n0.366 (0.191)\n0.412 (0.203)\n\n\nModerate (OR 1.75) effects in all domains +silo specific effects\n\n\nAB Duration\n0.432 (0.016)\n0.711 (0.016)\n0.849 (0.018)\n0.926 (0.018)\n0.947 (0.018)\n\n\n\n\n\n\n\n\nTable 2: Cumulative probability of NI (futility in parentheses) decision at each interim (shown by total enrolment by interim)\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_1[quant %in% c(\"ni\", \"fut_ni\") & domain %in% c(2), .SD]\nsetorderv(d_fig, cols = c(\"scenario\", \"domain\", \"analys\", \"quant\"), \n          order = c(1, 1, 1, -1))\n\nd_fig[, domain := factor(domain, \n                               levels = c(2), \n                               labels = c(\"AB Duration\"))]\n\nd_fig[, quant := factor(quant, \n                        levels = c(\"ni\", \"fut_ni\"), \n                        labels = c(\"NI\", \"Futility for NI\"))]\n\nd_fig[, desc := factor(desc, \n                        levels = unique(d_fig$desc), \n                        labels = unique(d_fig$desc))]\n\n\nggplot(d_fig, aes(x = N, y = pr_val, group = quant, col = quant)) +\n  geom_line(lwd = 0.25) +\n  scale_y_continuous(\"\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  # facet_grid(desc ~ domain, space = \"free\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  \n  ggh4x::force_panelsizes(cols = unit(c(4), \"cm\"), TRUE) +\n  # facet_manual(\n  #   . ~ desc, design = matrix(1:17, ncol = 1),\n  #   widths = unit(3, \"cm\")\n  # ) +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 2: Cumulative probabilities for NI assessments\n\n\n\n\n\n\n\n\n\n\nSample sizes\nTable 3 shows the number of enrolments when any stopping decision is made (or for reaching the maximum 2500 sample size). This is the total number of enrolments that are expected to have occurred, not how many are contributing to the inference in a given domain.\nFigure 3 shows the number of participants entering into each of the randomised comparisons by domain and scenario.\nThe expected cumulative sample sizes are calculated by extracting the number of participants entering into each randomised comparison (i.e. restricted to the relevant strata) and taking the cumulative sum of these over time. For example, the domain 1 (surgical) expected values are based on the participants in the late acute silo that receive randomised surgical intervention. Similarly, the domain 2 (antibiotic duration) expected values are based on the participants across all silos that received one-stage revision and then receive one of the randomised treatment allocations (i.e. are not in the non-randomised treatment group for any reason).\nIf a decision was made in a domain, then subsequent enrolments would be assigned to the relevant arm and so the allocation would be expected to deviate away from 1:1. For example, if a superiority decision was made for domain 1 (and the trial was still ongoing) then all subsequent participants are assigned to the superior intervention. Finally, if a decision was made for all research questions, the trial stops early. To avoid any bias in the calculation, we use LOCF to propagate the expectations forward through to the maximum number of enrolments.\n\nEnrolments to stoppingSample size of randomised comparisons\n\n\n\n\nCode\nd_tbl_2_cur &lt;- d_tbl_2[, .(N_mu = mean(N_stopped)), keyby = .(scenario, desc, domain)]\nd_tbl_2_cur &lt;- dcast(d_tbl_2_cur, scenario + desc ~ domain, value.var = \"N_mu\")\nd_tbl_2_cur &lt;- d_tbl_2_cur[, .SD, .SDcols = !c(\"scenario\")]\n\ng_tbl &lt;- d_tbl_2_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_2_cur),\n    align = \"center\"\n  )  |&gt; \n  tab_spanner(\n    label = html(\"Expected number of total enrolments to hit stopping rule by domain\"),\n    columns = 2:ncol(d_tbl_2_cur)\n  )  |&gt;\n  cols_label(\n    `1` = \"Surgical\",\n    `2` = \"AB Duration\",\n    `3` = \"AB Ext-proph\",\n    `4` = \"AB choice\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 0, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nExpected number of total enrolments to hit stopping rule by domain\n\n\n\nSurgical\nAB Duration\nAB Ext-proph\nAB choice\n\n\n\n\nNull effect in all domains +silo specific effects\n\n\n906\n1,711\n1,024\n859\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage) +silo specific effects\n\n\n1,004\n1,568\n912\n862\n\n\nModerate (OR 1.75) surgical revision effect (one-stage) +silo specific effects\n\n\n1,179\n1,614\n1,012\n832\n\n\nModerate (OR 1.75) surgical revision effect (two-stage) +silo specific effects\n\n\n1,198\n1,640\n971\n852\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect +silo specific effects\n\n\n938\n1,114\n1,034\n850\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect +silo specific effects\n\n\n927\n1,675\n1,076\n842\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect +silo specific effects\n\n\n888\n1,666\n1,020\n1,012\n\n\nModerate (OR 1.75) effects in all domains +silo specific effects\n\n\n954\n1,007\n938\n1,062\n\n\n\n\n\n\n\n\nTable 3: Expected number of enrolments to hit any stopping rule (including reaching maximum sample size)\n\n\n\n\n\n\n\n\nCode\nd_fig_1 &lt;- d_N_by_arm[, .(mu_N = mean(N)), keyby = .(desc, domain, arm, N_enrol)]\nd_fig_1[, desc := factor(\n  desc,\n  levels = unique(d_N_by_arm$desc))]\nd_fig_1[\n  , domain := factor(\n    domain,\n    levels = 1:4,\n    labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\nd_fig_2 &lt;- d_N_by_arm[\n  domain == 1 & arm %in% 2:3, \n  .(N = sum(N), arm = 4), \n  keyby = .(analys, sim, domain, scenario, desc, N_enrol)]\nd_fig_2 &lt;- d_fig_2[, .(mu_N = mean(N)), keyby = .(desc, domain, arm, N_enrol)]\n\nd_fig_2[, desc := factor(\n  desc,\n  levels = unique(d_N_by_arm$desc))]\nd_fig_2[\n  , domain := factor(\n    domain,\n    levels = 1:4,\n    labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n  \nd_fig_1[, arm := factor(arm)]\nggplot(d_fig_1, aes(x = N_enrol, y = mu_N, col = arm)) +\n  geom_line(lwd = 0.2) +\n  geom_point(size = 0.4) +\n  geom_line(\n    data = d_fig_2, \n    aes(x = N_enrol, y = mu_N), lwd = 0.2, lty = 2, inherit.aes = F) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Expected number of participants\") +\n  scale_color_discrete(\"Treatment arm: \") +\n  ggh4x::facet_grid2(\n    desc ~ domain, \n    labeller = labeller(desc = label_wrap_gen(35)), \n    scales = \"free_y\", independent = \"y\") +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.title.y=element_text(size = 5),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 3: Expected number of participants on domain arms\n\n\n\n\n\n\n\n\n\n\nParameter estimation\nFigure 4 shows the median value and 95% quantiles from the posterior mean odds ratios obtained from the simulations by each domain and scenario. The estimates are unconditional, in that they ignore the stopping rule and propagate estimates forward with LOCF so that we are working from a random sample (albeit with static imputation) rather than a dependent sample of simulations.\nFigure 5 shows the median value and 95% quantiles for the posterior mean risk differences obtained from the simulations for each domain and scenario. The transformation to a risk difference suggests that the odds ratios amount to effects in the order of 10-20% on the risk scale, dependent on the silo, domain etc.\nThe AB duration domain has high variance in the distribution of posterior means that we anticipate to observe. That is, when there is no true effect, we might still see posterior means as large as \\(\\pm 0.2\\) on the absolute risk scale.\n\nTreatment effects - odds ratiosTreatment effects - risk difference\n\n\n\n\nCode\n# ggplot2::theme_update(text = element_text(size = 8))\n# ggplot2::theme_update(legend.position = \"bottom\")\n# # ggplot2::theme_update(legend.title = element_blank())\n# ggplot2::theme_update(axis.text.x = element_text(size = 8))\n# ggplot2::theme_update(axis.text.y = element_text(size = 8))\n\nd_fig &lt;- d_tbl_3[,\n                 .(or = median(exp(mu_lor)),\n                   q_025 = quantile(exp(mu_lor), prob = 0.025),\n                   q_975 = quantile(exp(mu_lor), prob = 0.975)), \n                 keyby = .(scenario, desc, analys, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_fig[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_fig[, domain := factor(domain, \n                         levels = 1:4, \n                         labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\n# d_tbl_3[scenario == 8, range(lor)]\n\nggplot(data = d_fig,  \n       aes(x = N, y = or)) +\n  geom_line(lwd = 0.25) +\n  geom_errorbar(aes(ymin = q_025, ymax = q_975), lwd = 0.25, width = 50) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n        strip.text.x = element_text(angle = 0, size = 5),\n        axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),\n        axis.text.y = element_text(size = 5),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1))\n\n\n\n\n\n\n\n\nFigure 4: Median value of posterior means for odds-ratio treatment effects by domain and simulation scenario\n\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_3[,\n                 .(rd = median(mu_rd),\n                   q_025 = quantile(mu_rd, prob = 0.025),\n                   q_975 = quantile(mu_rd, prob = 0.975)), \n                 keyby = .(scenario, desc, analys, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_fig[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_fig[, domain := factor(domain, \n                         levels = 1:4, \n                         labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\n# d_tbl_3[scenario == 8, range(lor)]\n\nggplot(data = d_fig,  \n       aes(x = N, y = rd)) +\n  geom_line(lwd = 0.25) +\n  geom_errorbar(aes(ymin = q_025, ymax = q_975), lwd = 0.25, width = 50) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n        strip.text.x = element_text(angle = 0, size = 5),\n        axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),\n        axis.text.y = element_text(size = 5),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1))\n\n\n\n\n\n\n\n\nFigure 5: Median value of posterior means for risk difference treatment effects by domain and simulation scenario\n\n\n\n\n\n\n\n\n\n\nProportion with treatment success\nTable 4 shows the empirical proportion having treatment success within the randomised comparisons subsets averaged over the simulations. For example, the values for the surgical domain shows the empirical proportion having treatment success within the late acute silo by treatment arm (dair, rev(1), rev(2)).\n\n\nCode\nd_tbl_4_cur &lt;- dcast(d_tbl_4, scenario + desc + domain ~ arm, value.var = \"p_hat\")\nd_tbl_4_cur[, domain := factor(\n  domain, \n  levels = c(1, 2, 3, 4), \n  labels = c(\"Surgical\", \"AB Duration\",  \"AB Ext-proph\", \"AB Choice\"))]\nd_tbl_4_cur &lt;- d_tbl_4_cur[, .(desc, domain, `1`, `2`, `3`)]\n\ng_tbl &lt;- d_tbl_4_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_4_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_label(\n    domain = \"Domain\"\n  )  |&gt;\n  tab_spanner(\n    label = html(\"Empirical risk by domain and treatment arm\"),\n    columns = 2:ncol(d_tbl_4_cur)\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 2, drop_trailing_zeros = TRUE) |&gt;\n  sub_missing(\n    columns = everything(),\n    rows = everything(),\n    missing_text = \"-\"\n  )\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpirical risk by domain and treatment arm\n\n\n\nDomain\n1\n2\n3\n\n\n\n\nNull effect in all domains +silo specific effects\n\n\nSurgical\n0.59\n0.62\n0.58\n\n\nAB Duration\n-\n0.74\n0.74\n\n\nAB Ext-proph\n-\n0.68\n0.68\n\n\nAB Choice\n-\n0.66\n0.66\n\n\nModerate (OR 1.75) surgical revision effect (one and two-stage) +silo specific effects\n\n\nSurgical\n0.57\n0.72\n0.68\n\n\nAB Duration\n-\n0.76\n0.76\n\n\nAB Ext-proph\n-\n0.72\n0.72\n\n\nAB Choice\n-\n0.69\n0.69\n\n\nModerate (OR 1.75) surgical revision effect (one-stage) +silo specific effects\n\n\nSurgical\n0.57\n0.72\n0.56\n\n\nAB Duration\n-\n0.77\n0.77\n\n\nAB Ext-proph\n-\n0.66\n0.66\n\n\nAB Choice\n-\n0.66\n0.66\n\n\nModerate (OR 1.75) surgical revision effect (two-stage) +silo specific effects\n\n\nSurgical\n0.57\n0.6\n0.68\n\n\nAB Duration\n-\n0.7\n0.7\n\n\nAB Ext-proph\n-\n0.72\n0.72\n\n\nAB Choice\n-\n0.67\n0.67\n\n\nModerate (OR 1.75) antibiotic duration 6wk effect +silo specific effects\n\n\nSurgical\n0.59\n0.67\n0.58\n\n\nAB Duration\n-\n0.71\n0.81\n\n\nAB Ext-proph\n-\n0.68\n0.68\n\n\nAB Choice\n-\n0.67\n0.67\n\n\nModerate (OR 1.75) antibiotic ext-proph 12wk effect +silo specific effects\n\n\nSurgical\n0.59\n0.62\n0.63\n\n\nAB Duration\n-\n0.74\n0.74\n\n\nAB Ext-proph\n-\n0.66\n0.77\n\n\nAB Choice\n-\n0.67\n0.67\n\n\nModerate (OR 1.75) antibiotic choice rifampacin effect +silo specific effects\n\n\nSurgical\n0.63\n0.65\n0.61\n\n\nAB Duration\n-\n0.77\n0.77\n\n\nAB Ext-proph\n-\n0.71\n0.71\n\n\nAB Choice\n-\n0.64\n0.75\n\n\nModerate (OR 1.75) effects in all domains +silo specific effects\n\n\nSurgical\n0.6\n0.78\n0.75\n\n\nAB Duration\n-\n0.77\n0.85\n\n\nAB Ext-proph\n-\n0.72\n0.82\n\n\nAB Choice\n-\n0.69\n0.79\n\n\n\n\n\n\n\n\nTable 4: Expected number of enrolments to hit any stopping rule (including reaching maximum sample size)\n\n\n\n\n\n\nFraction of uncertainty resolved\nFigure 6 shows the median value and 95% quantiles for the fraction of uncertainty resolved based on\n\\[\n\\begin{aligned}\n\\text{Fraction \\ Resolved} = 1 - \\frac{Var(\\beta_{post})}{Var(\\beta_{pri})}\n\\end{aligned}\n\\]\nwhere \\(Var(\\beta_{post})\\) and \\(Var(\\beta_{pri})\\) represent the variance associated with the prior and posterior belief for the relevant log-odds ratio for the treatment effects. This is basically just a way to compare the prior and posterior variance. When the posterior is based on negligible data, the variance will be similar to that of the prior and the fraction resolved will be very small. A low fraction resolved (e.g. less than 0.5) suggests that any decision that was made was done so with a substantial amount of uncertainty remaining (you didn’t move far from your prior belief) whereas values close to unity suggest that a lot of the uncertainty has been resolved.\n\nWhat is obvious from the above plots is also obvious here, the decision made in the AB duration domain are subject to a substantial amount of uncertainty.\n\n\n\nCode\nl_cfg &lt;- copy(l[[1]]$cfg)\n\n# initial uncertainty\nv0 &lt;- (l_cfg$pri$b_trt[2])^2\n\nd_fig &lt;- copy(d_tbl_3)\nd_fig[, fr_unc := 1 - (se_lor/v0)]\n\nd_fig &lt;- d_fig[,\n                 .(fr_unc = median(fr_unc),\n                   q_025 = quantile(fr_unc, prob = 0.025),\n                   q_975 = quantile(fr_unc, prob = 0.975)), \n                 keyby = .(scenario, desc, analys, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_fig[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_fig[, domain := factor(domain, \n                         levels = 1:4, \n                         labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\n# d_tbl_3[scenario == 8, range(lor)]\n\nggplot(data = d_fig,  \n       aes(x = N, y = fr_unc)) +\n  geom_line(lwd = 0.25) +\n  geom_errorbar(aes(ymin = q_025, ymax = q_975), lwd = 0.25, width = 50) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Fraction of uncertainty resolved (1-(V_post/V_pri))\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_clean() +\n  # theme_minimal() +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n        strip.text.x = element_text(angle = 0, size = 5),\n        axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),\n        axis.text.y = element_text(size = 5),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1))\n\n\n\n\n\n\n\n\nFigure 6: Median values and quantiles for fraction of uncertainty resolved",
    "crumbs": [
      "Simulations",
      "Simulation results 6"
    ]
  },
  {
    "objectID": "notebooks/sim-design7-results.html",
    "href": "notebooks/sim-design7-results.html",
    "title": "Simulation results 7",
    "section": "",
    "text": "Libraries and globals\nsource(\"./R/init.R\")\n\n\nWarning: package 'cmdstanr' was built under R version 4.4.3\n\n\nLibraries and globals\nsource(\"./R/util.R\")\nsource(\"./R/data.R\")\nlog_info(\"Called simulation-results 7 notebook\")\n\ntoks &lt;- unlist(tstrsplit(getwd(), \"/\")) \nif(toks[length(toks)] == \"roadmap-sim\"){\n  prefix_cfg &lt;- \"./etc/sim07/\"\n  prefix_stan &lt;- \"./stan\"\n  prefix_fig &lt;- \"./fig\"\n} else {\n  prefix_cfg &lt;- \"../etc/sim07/\"\n  prefix_stan &lt;- \"../stan\"\n  prefix_fig &lt;- \"../fig\"\n}\nLoad simulation results\n# Each input file corresponds to the results from a single simulation\n# scenario/configuration.\n# Load all the files into a single list.\n\n# files of interest\nsim_lab &lt;- \"sim07-04\"\n\nflist &lt;- list.files(paste0(\"data/\", sim_lab), pattern = \"sim07\")\ntoks &lt;- list()\nl &lt;- list()\ni &lt;- 1\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(paste0(\"data/\", sim_lab), flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}",
    "crumbs": [
      "Simulations",
      "Simulation results 7"
    ]
  },
  {
    "objectID": "notebooks/sim-design7-results.html#introduction",
    "href": "notebooks/sim-design7-results.html#introduction",
    "title": "Simulation results 7",
    "section": "Introduction",
    "text": "Introduction\n\nData generation\nData is generated based on the empirical distributions obtained mostly from the PIANO study.\nWe simulate silo membership from a multinomial distribution with probabilities 0.3, 0.5 and 0.2 for early, late and chronic.\nConditional on silo membership, we generate domain level allocations and entry indicators that are independent of the design but parameterised to silo specific probabilities. In contrast to the previous simulations, we have simplified the model by ignoring joint level heterogeneity. Adjustment for joint will be reintroduced in the actual analysis model.\nFor the early silo, we assume:\n\nallocation to revision with probability 0.15\npreference for two-stage revision, rev(2), with probability 0.35\nentry into antibiotic duration domain with probability 0.7\nwithin antibiotic duration domain, allocation to 6 weeks with probability 0.5\nentry into extended prophylaxis domain with probability 0.9\nwithin extended prophylaxis domain, allocation to 12 weeks with probability 0.5\nentry into antibiotic choice domain with probability 0.6\nwithin antibiotic choice domain, allocation to rifampicin with probability 0.5\n\nSimilalry, for the late acute silo, we assume:\n\nallocation to revision with probability 0.5\npreference for two-stage revision, rev(2), with probability 0.7\nentry into antibiotic duration domain with probability 0.7\nwithin antibiotic duration domain, allocation to 6 weeks with probability 0.5\nentry into extended prophylaxis domain with probability 0.9\nwithin extended prophylaxis domain, allocation to 12 weeks with probability 0.5\nentry into antibiotic choice domain with probability 0.6\nwithin antibiotic choice domain, allocation to rifampicin with probability 0.5\n\nFor the chronic silo, we assume:\n\nallocation to revision with probability 0.8\npreference for two-stage revision, rev(2), with probability 0.75\nentry into antibiotic duration domain with probability 0.7\nwithin antibiotic duration domain, allocation to 6 weeks with probability 0.5\nentry into extended prophylaxis domain with probability 0.9\nwithin extended prophylaxis domain, allocation to 12 weeks with probability 0.5\nentry into antibiotic choice domain with probability 0.6\nwithin antibiotic choice domain, allocation to rifampicin with probability 0.5\n\nAfter the design independent allocations are made, we finalise the participant level domain entry and allocation based on the known design dependencies.\nAs the trial progresses, decisions may be made which would lead to some allocations being shut off. For example, if revision is deemed superiori to DAIR, then subsequent allocations within the late acute silo would direct all participants to revision with a split between one-stage and two-stage continuing to be based on the clinical preferences.\nThe true log-odds of response by subject is calculated as the sum of their parameters indexed by the levels generated above. Treatment success is simulated as a bernoulli random variable with probability equal to the inverse logit transform of the log-odds from the linear predictor. To speed up the model, we aggregate number of successes and number of trials by covariate group which gives the analogous binomial random variable representation.\n\n\nModel\nWe adopt a revised model where we allow for silo-specific effects in the surgical domain.\nIf, for whatever reason, the early or chronic silo show variation in the surgical domain effects, adjustment for silo is inadequate to account for this, and we end up with a polluted version of the surgical domain parameters. The remainder of the model is analogous to the previous versions. The model is used to compute unit level risk (probability) and assesses decisions based on risk difference for the intervention comparisons by domain.\nFor the simulations, we have a single, multivariable logistic regression model with a linear predictor that incorporates all domains and is specified as follows:\n\\[\n\\begin{aligned}\nY &\\sim \\text{Binomial}(n, p) \\\\\n\\text{logit}(p) &= \\begin{cases}\n  \\mu + \\beta_{s} + \\beta_{p} + \\beta_{d1[k_{d1}, s]} + \\beta_{d4[k_{d4}]} & \\text{(dair)} \\\\\n  \\mu + \\beta_{s} + \\beta_{d1[k_{d1}, s]} + \\beta_{d2[k_{d2}]} + \\beta_{d4[k_{d4}]} & \\text{(one-stage)} \\\\\n  \\mu + \\beta_{s} + \\beta_{p} + \\beta_{d1[k_{d1}, s]} + \\beta_{d3[k_{d3}]} + \\beta_{d4[k_{d4}]} & \\text{(two-stage)}\n         \\end{cases}\n\\end{aligned}\n\\]\nfor each distinct covariate grouping where:\n\n\\(\\mu\\) represents an overall reference level from which all covariates deviate\n\\(\\beta_{s}\\) represents the silo deviations, which can be thought of as a seriousness of disease adjustment. We fix the first parameter (early) to zero for identifiability and the components are for early, late and chronic silo membership.\n\\(\\beta_{p}\\) represents the (pre-revealed) preference adjustment, assuming revision was allocated but included irrespective of silo and what the assignment ultimately turned out to be. This accounts for heterogeneity in outcome due to clinical preference for revision type, which can be thought of as expert elicitation on aspects of the patient state and clinicial experience. We fix the first parameter (preference one-stage revision) in this vector to zero for identifiability and the components are preference for one-stage or two-stage. The preference indicators are also used to compute the sample weights for aggregating one and two-stage revision into a single overall revision effect.\n\\(\\beta_{d1[k_{d1}, s]}\\) represents the silo-specific deviations associated with the surgery type. This accounts for heterogeneity in outcome due to surgery type and with the late-acute deviations taken as a randomised comparison of dair vs revision after the agreed weighting is applied. We fix the first parameter (dair in the early cohort) in this vector to zero for identifiability and the components are dair, rev(1), rev(2) for each silo. The reason for the silo-specific context is that if revision effects exist in one silo but not another, then without this conditioning, we will end up with biased inference. For example, if (for whatever reason) there is an revision effect in the early domain but not the late-acute cohort then without this level of adjustment, we would end up reporting a revision effect when we shouldn’t be; adjustment for silo doesn’t protect us from this, even though it is perfectly collinear with a unit receiving non-randomised or randomised surgical treatment.\n\\(\\beta_{d2[k_{d2}]}\\) represents the deviations associated with backbone antibiotic duration. This accounts for heterogeneity in outcome due to the assigned backbone antibiotic duration. The first parameter (non-randomised treatment) in this vector is set to zero for identifiability and the components are non-randomised, 12 weeks and 6 weeks. The term is undefined for DAIR and rev(2) participants. Units that receive rev(1) but do not enter into d2 contribute to the non-randomised set. We are assuming that there is no silo-specific (or any other) hetereogeneity for this comparison.\n\\(\\beta_{d3[k_{d3}]}\\) represents the deviations associated with extended prophylaxis duration. This accounts for heterogeneity in outcome due to the assigned extended prophylaxis duration. The first parameter (non-randomised treatment) in this vector is set to zero for identifiability and the components are non-randomised, no ext-proph and 12 weeks. The term is undefined for DAIR and rev(1) participants. Units that receive rev(2) but do not enter into d3 contribute to the non-randomised set. We are assuming that there is no silo-specific hetereogeneity for this comparison.\n\\(\\beta_{d4[k_{d4}]}\\) represents the deviations associated with antibiotic choice. This accounts for heterogeneity in outcome due to the assigned antibiotic choice. The first parameter (non-randomised treatment) in this vector is set to zero for identifiability and the components are non-randomised, no rifampicin and rifampicin. The term is included for all units for which rifampicin may be indicated. The other units contribute to the non-randomised set. We are assuming that there is no silo-specific hetereogeneity for this comparison.\n\nThe way that terms enter the model is somewhat convoluted and understanding the dependency implications and consequently interpretations is fairly challenging. For the actual trial analysis, the model will be revised to an equivalent Bernoulli likelihood on unit level data but extended to account for joint, site, randomisation period (if required) and prognostic covariates. Bar the surgical domain, for which ‘by silo’ deviations are implicit in the existing parameterisation, no further interactions are included. Given that heterogeneity by site of infection (joint) is of interest (primarily in the surgical domain) the analysis plan will include specification to account for this.\n\n\nDecision\nAt each interim, we assess the posterior and if a decision threshold is met, we act. For example, if a superiority decision is reached in one of the domains for which this decision type is relevant, then we consider that domain dealt with and all subsequent participants are assigned to receive the superior intervention. We can (and presently do) continue to update the posterior inference for the comparison that has stopped in subsequent interim analyses until we get to the point where all questions have been answered in all domains, at which point the trial will stop.\nSuperiority and non-inferiority are applicable to some domains and not others, however, we define reference and threshold values for all domains, just in case. Decisions are made with respect to the average within any `random-effect’ terms that might exist within the model.\nFor the superiority decision, a reference value of 0 was used and the probability thresholds were:\n\n0.96 for surgical domain\n0.96 for antibiotic duration domain\n0.96 for extended prophylaxis domain\n0.99 for antibiotic choice domain\n\nThere was no particular reason for the choice of these thresholds bar the fact that they lead to preferred operating characteristics and give nominal control of the type-i assertion probabilities.\nFor the futility decision (in relation to superiority) a reference value of 0.05 was used and the probability thresholds were:\n\n0.3 for surgical domain\n0.3 for antibiotic duration domain\n0.3 for extended prophylaxis domain\n0.3 for antibiotic choice domain\n\nThe above means, for example, that if the probability that the risk difference is greater than 0.05 is less than in the surgical domain comparison, then we say the superiority goal is futile.\nFor the ni decision, a reference value of -0.05 was used and the probability thresholds were:\n\n0.975 for surgical domain\n0.925 for antibiotic duration domain\n0.975 for extended prophylaxis domain\n0.975 for antibiotic choice domain\n\nThe above means, for example, that if the probability that the risk difference is greater than -0.05 is greater than 0.925, in the antibiotic duration domain, then we will say the intervention is non-inferior.\nThe futility decision (in relation to non-inferiority) has a reference value of 0 and the probability thresholds were:\n\n0.25 for surgical domain\n0.1 for antibiotic duration domain\n0.25 for extended prophylaxis domain\n0.25 for antibiotic choice domain\n\nThis means, for example, that if the probability that the risk difference is greater than 0 is less than 0.1, in the antibiotic duration domain, then we say the non-inferiority goal is futile.\n\n\nPrior\nThe priors were as follows:\n\nReference log-odds of response: logistic distribution, mean 0.7 and scale 0.7\nSilo effects: normal distribution, mean 0 and scale 1\nPreference effects: normal distribution, mean 0 and scale 1\nTreatment effects (domain 1): normal distribution, mean 0 and scale 1\nTreatment effects (domain 2): normal distribution, mean 0 and scale 1\nTreatment effects (domain 3): normal distribution, mean 0 and scale 1\nTreatment effects (domain 4): normal distribution, mean 0 and scale 1\n\nThe prior predictive distribution is consistent with a mean probability across of response over the covariate groupings that covers the entire support on the probability scale, is centred around 0.6 and has first and third quarters at 0.4 to 0.8.",
    "crumbs": [
      "Simulations",
      "Simulation results 7"
    ]
  },
  {
    "objectID": "notebooks/sim-design7-results.html#simulation-results",
    "href": "notebooks/sim-design7-results.html#simulation-results",
    "title": "Simulation results 7",
    "section": "Simulation results",
    "text": "Simulation results\nFor this set of simulations, the number of simulated trials per scenario was 2500, the simulation label is sim07-04.\n\n\nCumulative probability of each decision type\n# Cumulative probability of decisions:\n\n# Traverse the list of simulation results and for each one summarise the \n# cumulative probability of each decision type.\n\ni &lt;- 8\nd_tbl_1 &lt;- data.table()\n\n# For each scenario that was simulated\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  \n  # number of enrolments at each interim (interim sample size sequence)\n  d_N &lt;- data.table(ia = seq_along(l_cfg$N_pt), N = cumsum(l_cfg$N_pt))\n  \n  # long version of decisions\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"ia\", \"quant\"), \n                  variable.name = \"domain\")\n\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  d_dec_2[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, domain)]\n  \n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"ia\")\n  \n  # cumulative proportion for which each decision quantity has been met by \n  # analysis and domain\n  d_dec_cumprob &lt;- d_dec_2[, .(pr_val = mean(value)), keyby = .(ia, N, quant, domain)]\n  \n  d_tbl_1 &lt;- rbind(\n    d_tbl_1,\n    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)\n  )\n\n}\n\n\n\n\nExpected enrolment progression\n# Expected sample size\n\n# Similar to above but focus on expected sample size\n\n# Traverse the list of simulation results and for each one summarise the \n# sample sizes at which stopping for a domain occurs for any reason.\n\n# All we are trying to get to is the expected sample size by domain and \n# are not really interested in what decision was made. The cumulative prob\n# of each decision type is computed previously.\n\ni &lt;- 2\nd_tbl_2 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_N &lt;- data.table(ia = seq_along(l_cfg$N_pt), N = cumsum(l_cfg$N_pt))\n  \n  # long version of decision\n  d_dec_2 &lt;- melt(d_dec_1, \n                  id.vars = c(\"sim\", \"ia\", \"quant\"), \n                  variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"ia\")\n  \n  # First instance of any decision rule being hit by sim and domain.\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  \n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  \n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(d_dec_stop[, .SD, .SDcols = !c(\"ia\")], \n                      # all combinations of sim and domain \n                      # which with leave non-stoppers with NA\n                      unique(d_dec_2[, .(sim, domain)]),\n                      by = c(\"sim\", \"domain\"), all.y = T)\n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"na\"]\n  \n  d_tbl_2 &lt;- rbind(\n    d_tbl_2,\n    cbind(\n      scenario = i, \n      desc = l_cfg$desc, \n      d_dec_stop\n      )\n  )\n\n}\n\n\n\n\nDistributions of posterior means (unconditional)\n# Distribution of posterior means for parameters of interest.\n\n# Some simulated trials will have stopped prior to the maximum sample size and\n# these will have NA for their posterior means. If you were to summarise these \n# posterior means, they would be conditional on the trial having 'survived' \n# until the relevant interim. This means that you have missing data at later \n# interims, which creates a selection bias in that your selection of sims at any\n# given interim are not a random sample, but rather a sample conditioned on the \n# stopping rules. \n\n# If you do not account for this in some way then a summary can be either \n# optimistic or pessimistic depending on how the stopping rules interact \n# with the data. Here we try to account for this missingness by imputing the \n# missing posterior means with locf within each simulation.\n# Note that this is really only a partial 'fix' to get a sense of whether \n# our estimates is representative of the parameter values we used to simulate\n# the data.\n\ni &lt;- 1\nd_tbl_3 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # params\n  d_pars &lt;- copy(l[[i]]$d_post_smry_1)\n  d_pars &lt;- d_pars[par %in% c(\"lor\", \"rd\")]\n  \n  # interim looks\n  d_N &lt;- data.table(ia = seq_along(l_cfg$N_pt), N = cumsum(l_cfg$N_pt))\n  \n  d_pars &lt;- dcast(d_pars, sim + ia + domain ~ par, value.var = c(\"mu\", \"se\"))\n  \n  # locf\n  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = \"locf\"),\n                mu_rd = nafill(mu_rd, type = \"locf\"),\n                se_lor = nafill(se_lor, type = \"locf\"),\n                se_rd = nafill(se_rd, type = \"locf\")\n                ), \n         keyby = .(sim, domain)]\n  #\n  \n  d_pars &lt;- merge(d_pars, d_N, by = \"ia\")\n  \n  d_tbl_3 &lt;- rbind(\n    d_tbl_3,\n    cbind(\n      scenario = i, desc = l_cfg$desc,\n      d_pars[, .(ia, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]\n      )\n  )\n\n}\n\n\n\n\nNumber of participants for each randomised comparison over time\n# \n\ni &lt;- 1\nd_N_by_arm &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # long version of decisions\n  d_dec_2 &lt;- melt(\n    d_dec_1, id.vars = c(\"sim\", \"ia\", \"quant\"), variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  # No other stopping rules apply and so we only evaluate the operating \n  # characteristics on these, i.e. we do not care about the results for the \n  # cumualative probability of ni for domain 1, 3 and 4 because we would never\n  # stop for this. \n  d_dec_2 &lt;- rbind(\n    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c(\"sup\", \"fut_sup\")],\n    d_dec_2[domain %in% c(2) & quant %in% c(\"ni\", \"fut_ni\")]\n  )\n  \n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_enrolment &lt;- data.table(ia = seq_along(l_cfg$N_pt), N_enrol = cumsum(l_cfg$N_pt))\n  # observed trial data sets\n  d_tru &lt;- copy(l[[i]]$d_all)\n  d_tru[, `:=`(\n    d1 = as.integer(d1),\n    d2 = as.integer(d2),\n    d3 = as.integer(d3),\n    d4 = as.integer(d4))]\n  \n  \n  # late acute, surgical arms\n  # *** silo isn't included in the keyby because we want to average across \n  # the entire trial population, not silo specific sample sizes.\n  d_1_tmp &lt;- d_tru[\n    s == 2, .(N = sum(N), domain = 1), keyby = .(sim, ia, d1)]\n  d_1_tmp[, N := cumsum(N), keyby = .(sim, d1)]\n  setnames(d_1_tmp, old = \"d1\", \"arm\")\n  d_1_tmp &lt;- merge(\n    d_1_tmp, \n    CJ(sim = 1:max(d_tru$sim), ia = 1:5, arm = 1:3, domain = 1), \n    by = c(\"sim\", \"ia\", \"arm\", \"domain\"),\n    all.y = T)\n  d_1_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_1_tmp, sim, ia, arm)\n  \n  # one-stage revision, ab duration randomised arms\n  d_2_tmp &lt;- d_tru[\n    d1 == 2 & d2 %in% 2:3, \n    .(N = sum(N), domain = 2), keyby = .(sim, ia, d2)]\n  d_2_tmp[, N := cumsum(N), keyby = .(sim, d2)]\n  setnames(d_2_tmp, old = \"d2\", \"arm\")\n  d_2_tmp &lt;- merge(\n    d_2_tmp, \n    CJ(sim = 1:max(d_tru$sim), ia = 1:5, arm = 2:3, domain = 2), \n    by = c(\"sim\", \"ia\", \"arm\", \"domain\"),\n    all.y = T)\n  d_2_tmp[ia == 1 & is.na(N), N := 0]\n  d_2_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_2_tmp, sim, ia, arm)\n  \n  # two-stage revision, extended prophy randomised arms\n  d_3_tmp &lt;- d_tru[\n    d1 == 3 & d3 %in% 2:3, \n    .(N = sum(N), domain = 3), keyby = .(sim, ia, d3)]\n  d_3_tmp[, N := cumsum(N), keyby = .(sim, d3)]\n  setnames(d_3_tmp, old = \"d3\", \"arm\")\n  d_3_tmp &lt;- merge(\n    d_3_tmp, \n    CJ(sim = 1:max(d_tru$sim), ia = 1:5, arm = 2:3, domain = 3), \n    by = c(\"sim\", \"ia\", \"arm\", \"domain\"),\n    all.y = T)\n  d_3_tmp[ia == 1 & is.na(N), N := 0]\n  d_3_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_3_tmp, sim, ia, arm)\n  \n  # ab choice randomised arms\n  d_4_tmp &lt;- d_tru[\n    d4 %in% 2:3, .(N = sum(N), domain = 4), keyby = .(sim, ia, d4)]\n  d_4_tmp[, N := cumsum(N), keyby = .(sim, d4)]\n  setnames(d_4_tmp, old = \"d4\", \"arm\")\n  d_4_tmp &lt;- merge(\n    d_4_tmp, \n    CJ(sim = 1:max(d_tru$sim), ia = 1:5, arm = 2:3, domain = 4), \n    by = c(\"sim\", \"ia\", \"arm\", \"domain\"),\n    all.y = T)\n  d_4_tmp[ia == 1 & is.na(N), N := 0]\n  d_4_tmp[, N := nafill(N, type = \"locf\"), keyby = .(sim, arm)]\n  setkey(d_4_tmp, sim, ia, arm)\n  \n  d_arm_tmp &lt;- rbind(d_1_tmp, d_2_tmp, d_3_tmp, d_4_tmp)\n\n  \n  d_arm_tmp[, `:=`(\n    scenario = i, desc = l_cfg$desc\n  )]\n  \n  d_arm_tmp &lt;- merge(\n    d_arm_tmp,\n    d_enrolment,\n    by = \"ia\")\n  \n  d_N_by_arm &lt;- rbind(d_N_by_arm, d_arm_tmp)\n\n}\n\n\n\n\nSummaries of empirical probability of treatment success\ni &lt;- 1\nd_tbl_4 &lt;- data.table()\n\nfor(i in 1:length(l)){\n  \n  # extract the decision matrix - sim, analysis, quantity, domain level decision\n  d_dec_1 &lt;- copy(l[[i]]$d_decision)\n  # config for scenario\n  l_cfg &lt;- copy(l[[i]]$cfg)\n  # interim looks\n  d_enrolment &lt;- data.table(ia = seq_along(l_cfg$N_pt), N_enrol = cumsum(l_cfg$N_pt))\n  # observed data\n  d_all &lt;- copy(l[[i]]$d_all)\n  \n  d_all &lt;- merge(d_all, d_enrolment , by = \"ia\")\n  # long version of decision\n  d_dec_2 &lt;- melt(\n    d_dec_1, id.vars = c(\"sim\", \"ia\", \"quant\"), variable.name = \"domain\")\n  # Should be right, but just in case...\n  if(any(is.na(d_dec_2$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    d_dec_2[is.na(value), value := FALSE]\n  }\n  d_dec_2[, domain := as.numeric(gsub(\"d\", \"\", domain))]\n  d_dec_2 &lt;- merge(d_dec_2, d_N, by = \"ia\")\n  \n  # First instance of any decision rule being hit by sim and domain.\n  \n  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.\n  # Domaain 2 will stop for NI or futility for NI.\n  \n  # Sometimes a decision rule will not be hit for a domain and it will continue\n  # to the max sample size. We will deal with that in a minute.\n  d_dec_stop &lt;- rbind(\n    d_dec_2[\n      domain %in% c(1, 3, 4) & value == T & quant %in% c(\"sup\", \"fut_sup\"), \n      .SD[1], keyby = .(sim, domain)],\n    d_dec_2[\n      domain %in% c(2) & value == T & quant %in% c(\"ni\", \"fut_ni\"), \n      .SD[1], keyby = .(sim, domain)]\n  )\n  setnames(d_dec_stop, \"N\", \"N_stopped\")\n  setnames(d_dec_stop, \"value\", \"stopped_early\")\n  # Add in any rows for which no early stopping happened\n  d_dec_stop &lt;- merge(\n    d_dec_stop[, .SD, .SDcols = !c(\"ia\")], \n    # all combinations of sim and domain\n    unique(d_dec_2[, .(sim, domain)]),\n    by = c(\"sim\", \"domain\"), all.y = T)\n  # If domain or trial not stopped then record as having run to the \n  # maximum sample size with no decision made.\n  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]\n  d_dec_stop[is.na(stopped_early), stopped_early := F]\n  # So now we know where every domain was stopped and the reason for stopping\n  # within each sim. Great.\n  d_dec_stop[is.na(quant), quant := \"null\"]\n  \n  d_domain_1 &lt;- d_all[\n    s == 2 & d1 %in% 1:3, .(sim, ia, s, pref, arm = d1, y, N, N_enrol)]\n  d_domain_1 &lt;- merge(d_domain_1, d_dec_stop[domain == 1], by = c(\"sim\"))\n  d_domain_1 &lt;- d_domain_1[N_enrol &lt;= N_stopped, ]\n  d_domain_1 &lt;- d_domain_1[, .(domain = 1, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_1[, p_hat := y / N]\n  \n  d_domain_2 &lt;- d_all[\n    d1 == 2 & d2 %in% 2:3, .(sim, ia, s, pref, arm = d2, y, N, N_enrol)]\n  d_domain_2 &lt;- merge(d_domain_2, d_dec_stop[domain == 2], by = c(\"sim\"))\n  d_domain_2 &lt;- d_domain_2[N_enrol &lt;= N_stopped, ]\n  d_domain_2 &lt;- d_domain_2[, .(domain = 2, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_2[, p_hat := y / N]\n  \n  d_domain_3 &lt;- d_all[\n    d1 == 3 & d3 %in% 2:3, .(sim, ia, s, pref, arm = d3, y, N, N_enrol)]\n  d_domain_3 &lt;- merge(d_domain_3, d_dec_stop[domain == 3], by = c(\"sim\"))\n  d_domain_3 &lt;- d_domain_3[N_enrol &lt;= N_stopped, ]\n  d_domain_3 &lt;- d_domain_3[, .(domain = 3, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_3[, p_hat := y / N]\n  \n  d_domain_4 &lt;- d_all[\n    d4 %in% 2:3, .(sim, ia, s, pref, arm = d4, y, N, N_enrol)]\n  d_domain_4 &lt;- merge(d_domain_4, d_dec_stop[domain == 4], by = c(\"sim\"))\n  d_domain_4 &lt;- d_domain_4[N_enrol &lt;= N_stopped, ]\n  d_domain_4 &lt;- d_domain_4[, .(domain = 4, y = sum(y), N = sum(N)), keyby = .(arm)]\n  d_domain_4[, p_hat := y / N]\n  \n  d_domain &lt;- rbind(\n    d_domain_1, d_domain_2, d_domain_3, d_domain_4\n  )\n  \n  d_tbl_4 &lt;- rbind(\n    d_tbl_4, \n    cbind(scenario = i, desc = l_cfg$desc, d_domain)\n  )\n  \n}\n\n\n\nProbability of triggering decision\nTable 1 shows the cumulative probability of a superiority decision across each of the scenarios simulated (the same information is shown in Figure 1). Operating characteristics are shown only for the relevant domains and the futility of a superiority decision is included in parentheses.\n\nSuperiority decision - tabulatedSuperiority decision - visualisation\n\n\n\n\n\nCode\nd_tbl_1_cur &lt;- d_tbl_1[quant %in% c(\"sup\", \"fut_sup\") & domain %in% c(1, 3, 4), .SD]\nsetorderv(d_tbl_1_cur, cols = c(\"scenario\", \"domain\", \"ia\", \"quant\"), \n          order = c(1, 1, 1, -1))\nd_tbl_1_cur &lt;- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = \"pr_val\")\nd_tbl_1_cur &lt;- d_tbl_1_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nd_tbl_1_cur[, domain := factor(domain, \n                               levels = c(1, 3, 4), \n                               labels = c(\"Surgical\", \"AB Ext-proph\", \"AB Choice\"))]\n\ng_tbl &lt;- d_tbl_1_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_1_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_500\", \"fut_sup_500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )   |&gt; \n  cols_merge(\n    columns = c(\"sup_1000\", \"fut_sup_1000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  cols_merge(\n    columns = c(\"sup_1500\", \"fut_sup_1500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_2000\", \"fut_sup_2000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"sup_2500\", \"fut_sup_2500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt;\n  tab_spanner(\n    label = md(\"Cumulative probability of **superiority** (futility) decision\"),\n    columns = 3:ncol(d_tbl_1_cur)\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    sup_500 = html(\"500\"),\n    sup_1000 = html(\"1000\"),\n    sup_1500 = html(\"1500\"),\n    sup_2000 = html(\"2000\"),\n    sup_2500 = html(\"2500\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain\n\nCumulative probability of superiority (futility) decision\n\n\n\n500\n1000\n1500\n2000\n2500\n\n\n\n\nRD = 0 in all domains +silo specific d1\n\n\nSurgical\n0.018 (0.515)\n0.034 (0.692)\n0.049 (0.777)\n0.059 (0.826)\n0.068 (0.857)\n\n\nAB Ext-proph\n0.039 (0.534)\n0.062 (0.67)\n0.074 (0.744)\n0.086 (0.786)\n0.092 (0.818)\n\n\nAB Choice\n0.017 (0.64)\n0.026 (0.828)\n0.03 (0.898)\n0.034 (0.936)\n0.036 (0.952)\n\n\nRD = 0.12: surgical revision (one and two-stage) +silo specific d1\n\n\nSurgical\n0.316 (0.09)\n0.555 (0.11)\n0.712 (0.121)\n0.793 (0.123)\n0.836 (0.125)\n\n\nAB Ext-proph\n0.043 (0.548)\n0.065 (0.735)\n0.081 (0.82)\n0.088 (0.865)\n0.092 (0.888)\n\n\nAB Choice\n0.01 (0.654)\n0.019 (0.832)\n0.024 (0.906)\n0.028 (0.937)\n0.03 (0.954)\n\n\nRD = 0.12: surgical revision (one-stage only) +silo specific d1\n\n\nSurgical\n0.042 (0.406)\n0.086 (0.543)\n0.122 (0.629)\n0.147 (0.684)\n0.164 (0.71)\n\n\nAB Ext-proph\n0.031 (0.535)\n0.052 (0.69)\n0.064 (0.778)\n0.075 (0.83)\n0.08 (0.854)\n\n\nAB Choice\n0.01 (0.654)\n0.016 (0.822)\n0.019 (0.897)\n0.023 (0.936)\n0.026 (0.955)\n\n\nRD = 0.12: surgical revision (two-stage only) +silo specific d1\n\n\nSurgical\n0.198 (0.134)\n0.378 (0.178)\n0.511 (0.203)\n0.606 (0.216)\n0.67 (0.22)\n\n\nAB Ext-proph\n0.044 (0.558)\n0.066 (0.727)\n0.081 (0.811)\n0.089 (0.857)\n0.094 (0.879)\n\n\nAB Choice\n0.01 (0.651)\n0.016 (0.826)\n0.02 (0.908)\n0.024 (0.943)\n0.026 (0.959)\n\n\nRD = 0.12: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0.018 (0.532)\n0.036 (0.695)\n0.054 (0.783)\n0.064 (0.83)\n0.07 (0.864)\n\n\nAB Ext-proph\n0.042 (0.548)\n0.065 (0.686)\n0.084 (0.751)\n0.093 (0.789)\n0.1 (0.816)\n\n\nAB Choice\n0.012 (0.648)\n0.018 (0.836)\n0.023 (0.905)\n0.027 (0.939)\n0.029 (0.956)\n\n\nRD = 0.12: ext-proph 12wk effect +silo specific d1\n\n\nSurgical\n0.022 (0.492)\n0.038 (0.67)\n0.047 (0.764)\n0.058 (0.815)\n0.068 (0.85)\n\n\nAB Ext-proph\n0.366 (0.088)\n0.586 (0.108)\n0.709 (0.115)\n0.769 (0.118)\n0.819 (0.121)\n\n\nAB Choice\n0.011 (0.648)\n0.019 (0.826)\n0.025 (0.904)\n0.03 (0.94)\n0.03 (0.953)\n\n\nRD = 0.12: abx choice rif effect +silo specific d1\n\n\nSurgical\n0.02 (0.558)\n0.034 (0.727)\n0.048 (0.798)\n0.06 (0.838)\n0.068 (0.866)\n\n\nAB Ext-proph\n0.044 (0.538)\n0.065 (0.691)\n0.076 (0.76)\n0.084 (0.798)\n0.09 (0.831)\n\n\nAB Choice\n0.458 (0.03)\n0.811 (0.031)\n0.932 (0.032)\n0.964 (0.032)\n0.968 (0.032)\n\n\nRD = 0.12: all domains +silo specific d1\n\n\nSurgical\n0.367 (0.05)\n0.597 (0.068)\n0.742 (0.079)\n0.817 (0.086)\n0.861 (0.087)\n\n\nAB Ext-proph\n0.424 (0.072)\n0.733 (0.088)\n0.854 (0.092)\n0.896 (0.095)\n0.905 (0.095)\n\n\nAB Choice\n0.467 (0.03)\n0.817 (0.04)\n0.921 (0.04)\n0.952 (0.04)\n0.959 (0.04)\n\n\nRD = -0.05: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0.02 (0.515)\n0.034 (0.68)\n0.051 (0.771)\n0.062 (0.821)\n0.067 (0.858)\n\n\nAB Ext-proph\n0.032 (0.541)\n0.056 (0.694)\n0.075 (0.766)\n0.081 (0.808)\n0.087 (0.84)\n\n\nAB Choice\n0.012 (0.66)\n0.018 (0.827)\n0.024 (0.899)\n0.027 (0.943)\n0.028 (0.962)\n\n\nRD = 0.12 surgical, RD = 0.08 abx choice +silo specific d1\n\n\nSurgical\n0.304 (0.065)\n0.556 (0.09)\n0.703 (0.098)\n0.794 (0.103)\n0.845 (0.106)\n\n\nAB Ext-proph\n0.035 (0.56)\n0.058 (0.74)\n0.071 (0.842)\n0.077 (0.881)\n0.08 (0.9)\n\n\nAB Choice\n0.472 (0.036)\n0.817 (0.04)\n0.928 (0.04)\n0.96 (0.04)\n0.967 (0.04)\n\n\n\n\n\n\n\n\nTable 1: Cumulative probability of superiority (futility in parentheses) decision at each interim (shown by total enrolment by interim)\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_1[quant %in% c(\"sup\", \"fut_sup\") & domain %in% c(1, 3, 4), .SD]\nsetorderv(d_fig, cols = c(\"scenario\", \"domain\", \"ia\", \"quant\"), \n          order = c(1, 1, 1, -1))\n\nd_fig[, domain := factor(domain, \n                         levels = c(1, 3, 4), \n                         labels = c(\"Surgical\", \"AB Ext-proph\", \"AB Choice\"))]\n\nd_fig[, quant := factor(quant, \n                        levels = c(\"sup\", \"fut_sup\"), \n                        labels = c(\"Superiority\", \"Futility\"))]\n\nd_fig[, desc := factor(desc, \n                        levels = unique(d_fig$desc), \n                        labels = unique(d_fig$desc))]\n\n\nggplot(d_fig, aes(x = N, y = pr_val, group = quant, col = quant)) +\n  geom_line(lwd = 0.25) +\n  scale_y_continuous(\"\") +\n  scale_color_discrete(\"\") +\n  # facet_grid(desc ~ domain) + \n  # facet_grid2(desc ~ domain, render_empty = FALSE)\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 1: Cumulative probabilities for superiority assessments\n\n\n\n\n\n\n\n\nTable 2 shows the cumulative probability of a non-inferiority decision with futility shown in parentheses (the same information is shown in Figure 2). The results are only shown for the domains for which non-inferiority is evaluated.\nThe “Null effect in all domains” is actually a bit of a misnomer as the true null with regards to the NI decision would be at the NI margin, whereas the scenario refers to the setting where all effects are set to zero. Thus an inflation over the usual type-i assertion probability is to be expected.\n\nNon-inferiority - tabulatedNon-inferiority - visualisation\n\n\n\n\nCode\nd_tbl_1_cur &lt;- d_tbl_1[quant %in% c(\"ni\", \"fut_ni\") & domain %in% c(2), .SD]\nsetorderv(d_tbl_1_cur, cols = c(\"scenario\", \"domain\", \"ia\", \"quant\"), \n          order = c(1, 1, 1, -1))\nd_tbl_1_cur &lt;- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = \"pr_val\")\nd_tbl_1_cur &lt;- d_tbl_1_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nd_tbl_1_cur[, domain := factor(domain, \n                               levels = c(2), \n                               labels = c(\"AB Duration\"))]\n\ng_tbl &lt;- d_tbl_1_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_1_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_500\", \"fut_ni_500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )   |&gt; \n  cols_merge(\n    columns = c(\"ni_1000\", \"fut_ni_1000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  cols_merge(\n    columns = c(\"ni_1500\", \"fut_ni_1500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_2000\", \"fut_ni_2000\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"ni_2500\", \"fut_ni_2500\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt;\n  tab_spanner(\n    label = md(\"Cumulative probability of **NI** (futility) decision\"),\n    columns = 3:ncol(d_tbl_1_cur)\n  )  |&gt;\n  cols_label(\n    domain = \"Domain\",\n    ni_500 = html(\"500\"),\n    ni_1000 = html(\"1000\"),\n    ni_1500 = html(\"1500\"),\n    ni_2000 = html(\"2000\"),\n    ni_2500 = html(\"2500\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDomain\n\nCumulative probability of NI (futility) decision\n\n\n\n500\n1000\n1500\n2000\n2500\n\n\n\n\nRD = 0 in all domains +silo specific d1\n\n\nAB Duration\n0.142 (0.09)\n0.226 (0.136)\n0.284 (0.175)\n0.329 (0.195)\n0.363 (0.212)\n\n\nRD = 0.12: surgical revision (one and two-stage) +silo specific d1\n\n\nAB Duration\n0.146 (0.082)\n0.261 (0.145)\n0.334 (0.19)\n0.398 (0.22)\n0.45 (0.236)\n\n\nRD = 0.12: surgical revision (one-stage only) +silo specific d1\n\n\nAB Duration\n0.143 (0.092)\n0.238 (0.142)\n0.299 (0.172)\n0.347 (0.192)\n0.386 (0.21)\n\n\nRD = 0.12: surgical revision (two-stage only) +silo specific d1\n\n\nAB Duration\n0.153 (0.094)\n0.234 (0.149)\n0.325 (0.177)\n0.392 (0.204)\n0.443 (0.224)\n\n\nRD = 0.12: abx duration 6wk effect +silo specific d1\n\n\nAB Duration\n0.444 (0.011)\n0.654 (0.014)\n0.77 (0.016)\n0.842 (0.018)\n0.889 (0.018)\n\n\nRD = 0.12: ext-proph 12wk effect +silo specific d1\n\n\nAB Duration\n0.138 (0.083)\n0.22 (0.131)\n0.285 (0.165)\n0.325 (0.188)\n0.358 (0.205)\n\n\nRD = 0.12: abx choice rif effect +silo specific d1\n\n\nAB Duration\n0.144 (0.091)\n0.226 (0.131)\n0.283 (0.164)\n0.339 (0.186)\n0.375 (0.21)\n\n\nRD = 0.12: all domains +silo specific d1\n\n\nAB Duration\n0.486 (0.012)\n0.784 (0.013)\n0.91 (0.013)\n0.954 (0.013)\n0.978 (0.013)\n\n\nRD = -0.05: abx duration 6wk effect +silo specific d1\n\n\nAB Duration\n0.078 (0.163)\n0.113 (0.248)\n0.143 (0.319)\n0.156 (0.367)\n0.171 (0.413)\n\n\nRD = 0.12 surgical, RD = 0.08 abx choice +silo specific d1\n\n\nAB Duration\n0.153 (0.094)\n0.269 (0.142)\n0.352 (0.178)\n0.412 (0.201)\n0.463 (0.22)\n\n\n\n\n\n\n\n\nTable 2: Cumulative probability of NI (futility in parentheses) decision at each interim (shown by total enrolment by interim)\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_1[quant %in% c(\"ni\", \"fut_ni\") & domain %in% c(2), .SD]\nsetorderv(d_fig, cols = c(\"scenario\", \"domain\", \"ia\", \"quant\"), \n          order = c(1, 1, 1, -1))\n\nd_fig[, domain := factor(domain, \n                               levels = c(2), \n                               labels = c(\"AB Duration\"))]\n\nd_fig[, quant := factor(quant, \n                        levels = c(\"ni\", \"fut_ni\"), \n                        labels = c(\"NI\", \"Futility for NI\"))]\n\nd_fig[, desc := factor(desc, \n                        levels = unique(d_fig$desc), \n                        labels = unique(d_fig$desc))]\n\n\nggplot(d_fig, aes(x = N, y = pr_val, group = quant, col = quant)) +\n  geom_line(lwd = 0.25) +\n  scale_y_continuous(\"\", breaks = seq(0, 1, by = 0.2)) +\n  scale_color_discrete(\"\") +\n  # facet_grid(desc ~ domain, space = \"free\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  \n  ggh4x::force_panelsizes(cols = unit(c(4), \"cm\"), TRUE) +\n  # facet_manual(\n  #   . ~ desc, design = matrix(1:17, ncol = 1),\n  #   widths = unit(3, \"cm\")\n  # ) +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 2: Cumulative probabilities for NI assessments\n\n\n\n\n\n\n\n\n\n\nSample sizes\nTable 3 shows the mean number of enrolments into the platform until a stopping rule is hit for each of the domains by scenario and stopping rule. In parentheses are the percentage of sims for each decision type and those that were not stopped early (last row) run to the maximum sample size (2500).\nFigure 3 shows the number of participants entering into each of the randomised comparisons by domain and scenario. The expected cumulative sample sizes (Figure 3) are calculated by extracting the number of participants entering into each randomised comparison (i.e. restricted to the relevant strata) and taking the cumulative sum of these over time. For example, the domain 1 (surgical) expected values are based on the participants in the late acute silo that receive randomised surgical intervention. Similarly, the domain 2 (antibiotic duration) expected values are based on the participants across all silos that received one-stage revision and then receive one of the randomised treatment allocations (i.e. are not in the non-randomised treatment group for any reason).\nIf a decision was made in a domain, then subsequent enrolments would be assigned to the remaining arms and so the allocation would be expected to deviate away from 1:1. For example, if a superiority decision was made for domain 1 (and the trial was still ongoing) then all subsequent participants are assigned to the superior intervention. Finally, if a decision was made for all research questions, the trial stops early. To avoid any bias in the calculation, we use LOCF to propagate the expectations forward through to the maximum number of enrolments.\n\nEnrolments to stoppingSample size of randomised comparisons\n\n\n\n\nCode\nd_tbl_2_cur &lt;- d_tbl_2[\n  , .(N_mu = mean(N_stopped), \n      pct_sims = sprintf(\"%.0f%%\", 100*.N/l[[1]]$cfg$nsim)), \n  keyby = .(scenario, desc, domain, quant)]\nd_tbl_2_cur &lt;- dcast(d_tbl_2_cur, scenario + desc + quant ~ domain, value.var = list(\"N_mu\", \"pct_sims\"))\n\nd_tbl_2_cur[, quant := factor(\n  quant, \n  levels = c(\"sup\", \"fut_sup\", \"ni\", \"fut_ni\", \"na\"),\n  labels = c(\"superiority\", \"futility (sup)\", \"ni\", \"futility (ni)\", \"-\"))]\n\nd_tbl_2_cur &lt;- d_tbl_2_cur[order(scenario, quant)]\nd_tbl_2_cur &lt;- d_tbl_2_cur[, .SD, .SDcols = !c(\"scenario\")]\n\nsetcolorder(d_tbl_2_cur, c(\"desc\", \"quant\",\n                           \"N_mu_1\", \"pct_sims_1\", \n                           \"N_mu_2\", \"pct_sims_2\", \n                           \"N_mu_3\", \"pct_sims_3\", \n                           \"N_mu_4\", \"pct_sims_4\"\n                           ))\n\ng_tbl &lt;- d_tbl_2_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1:2,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 3:ncol(d_tbl_2_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"N_mu_1\", \"pct_sims_1\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"N_mu_2\", \"pct_sims_2\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"N_mu_3\", \"pct_sims_3\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"N_mu_4\", \"pct_sims_4\"\n                ),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2})&gt;&gt;\"\n  ) |&gt; \n  tab_spanner(\n    label = html(\"Expected number of total enrolments to hit stopping rule by domain\"),\n    columns = 3:ncol(d_tbl_2_cur)\n  )  |&gt;\n  cols_label(\n    N_mu_1 = \"Surgical\",\n    N_mu_2 = \"AB Duration\",\n    N_mu_3 = \"AB Ext-proph\",\n    N_mu_4 = \"AB choice\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 0, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nquant\n\nExpected number of total enrolments to hit stopping rule by domain\n\n\n\nSurgical\nAB Duration\nAB Ext-proph\nAB choice\n\n\n\n\nRD = 0 in all domains +silo specific d1\n\n\nsuperiority\n1,307 (7%)\n\n1,066 (9%)\n1,006 (3%)\n\n\nfutility (sup)\n857 (85%)\n\n826 (82%)\n764 (95%)\n\n\nni\n\n1,151 (36%)\n\n\n\n\nfutility (ni)\n\n1,095 (21%)\n\n\n\n\n-\n2,500 (8%)\n2,500 (42%)\n2,500 (9%)\n2,500 (1%)\n\n\nRD = 0.12: surgical revision (one and two-stage) +silo specific d1\n\n\nsuperiority\n1,069 (83%)\n\n971 (9%)\n1,151 (3%)\n\n\nfutility (sup)\n707 (12%)\n\n825 (89%)\n755 (95%)\n\n\nni\n\n1,234 (45%)\n\n\n\n\nfutility (ni)\n\n1,152 (24%)\n\n\n\n\n-\n2,500 (5%)\n2,500 (31%)\n2,500 (2%)\n2,500 (2%)\n\n\nRD = 0.12: surgical revision (one-stage only) +silo specific d1\n\n\nsuperiority\n1,276 (16%)\n\n1,088 (8%)\n1,164 (3%)\n\n\nfutility (sup)\n900 (71%)\n\n841 (85%)\n767 (95%)\n\n\nni\n\n1,170 (39%)\n\n\n\n\nfutility (ni)\n\n1,073 (21%)\n\n\n\n\n-\n2,500 (13%)\n2,500 (40%)\n2,500 (7%)\n2,500 (2%)\n\n\nRD = 0.12: surgical revision (two-stage only) +silo specific d1\n\n\nsuperiority\n1,232 (67%)\n\n996 (9%)\n1,138 (3%)\n\n\nfutility (sup)\n836 (22%)\n\n814 (87%)\n764 (96%)\n\n\nni\n\n1,254 (44%)\n\n\n\n\nfutility (ni)\n\n1,107 (22%)\n\n\n\n\n-\n2,500 (11%)\n2,500 (33%)\n2,500 (4%)\n2,500 (2%)\n\n\nRD = 0.12: abx duration 6wk effect +silo specific d1\n\n\nsuperiority\n1,256 (7%)\n\n1,059 (10%)\n1,106 (3%)\n\n\nfutility (sup)\n854 (86%)\n\n799 (82%)\n759 (96%)\n\n\nni\n\n976 (89%)\n\n\n\n\nfutility (ni)\n\n818 (2%)\n\n\n\n\n-\n2,500 (7%)\n2,500 (9%)\n2,500 (9%)\n2,500 (2%)\n\n\nRD = 0.12: ext-proph 12wk effect +silo specific d1\n\n\nsuperiority\n1,274 (7%)\n\n1,011 (81%)\n1,093 (3%)\n\n\nfutility (sup)\n884 (85%)\n\n716 (12%)\n757 (95%)\n\n\nni\n\n1,147 (36%)\n\n\n\n\nfutility (ni)\n\n1,120 (21%)\n\n\n\n\n-\n2,500 (9%)\n2,500 (44%)\n2,500 (7%)\n2,500 (2%)\n\n\nRD = 0.12: abx choice rif effect +silo specific d1\n\n\nsuperiority\n1,296 (7%)\n\n1,011 (9%)\n863 (97%)\n\n\nfutility (sup)\n809 (86%)\n\n819 (83%)\n556 (3%)\n\n\nni\n\n1,177 (37%)\n\n\n\n\nfutility (ni)\n\n1,135 (21%)\n\n\n\n\n-\n2,500 (7%)\n2,500 (42%)\n2,500 (8%)\n2,500 (0%)\n\n\nRD = 0.12: all domains +silo specific d1\n\n\nsuperiority\n1,034 (86%)\n\n890 (90%)\n854 (96%)\n\n\nfutility (sup)\n869 (9%)\n\n671 (9%)\n630 (4%)\n\n\nni\n\n897 (98%)\n\n\n\n\nfutility (ni)\n\n547 (1%)\n\n\n\n\n-\n2,500 (5%)\n2,500 (1%)\n2,500 (0%)\n2,500 (0%)\n\n\nRD = -0.05: abx duration 6wk effect +silo specific d1\n\n\nsuperiority\n1,242 (7%)\n\n1,091 (9%)\n1,086 (3%)\n\n\nfutility (sup)\n873 (86%)\n\n824 (84%)\n767 (96%)\n\n\nni\n\n1,062 (17%)\n\n\n\n\nfutility (ni)\n\n1,173 (41%)\n\n\n\n\n-\n2,500 (8%)\n2,500 (42%)\n2,500 (8%)\n2,500 (1%)\n\n\nRD = 0.12 surgical, RD = 0.08 abx choice +silo specific d1\n\n\nsuperiority\n1,100 (84%)\n\n977 (8%)\n852 (96%)\n\n\nfutility (sup)\n816 (11%)\n\n818 (90%)\n559 (4%)\n\n\nni\n\n1,218 (46%)\n\n\n\n\nfutility (ni)\n\n1,103 (22%)\n\n\n\n\n-\n2,500 (5%)\n2,500 (32%)\n2,500 (2%)\n2,500 (0%)\n\n\n\n\n\n\n\n\nTable 3: Expected number of enrolments to hit any stopping rule (including reaching maximum sample size)\n\n\n\n\n\n\n\n\nCode\nd_fig_1 &lt;- d_N_by_arm[, .(mu_N = mean(N)), keyby = .(desc, domain, arm, N_enrol)]\nd_fig_1[, desc := factor(\n  desc,\n  levels = unique(d_N_by_arm$desc))]\nd_fig_1[\n  , domain := factor(\n    domain,\n    levels = 1:4,\n    labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\nd_fig_2 &lt;- d_N_by_arm[\n  domain == 1 & arm %in% 2:3, \n  .(N = sum(N), arm = 4), \n  keyby = .(ia, sim, domain, scenario, desc, N_enrol)]\nd_fig_2 &lt;- d_fig_2[, .(mu_N = mean(N)), keyby = .(desc, domain, arm, N_enrol)]\n\nd_fig_2[, desc := factor(\n  desc,\n  levels = unique(d_N_by_arm$desc))]\nd_fig_2[\n  , domain := factor(\n    domain,\n    levels = 1:4,\n    labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n  \nd_fig_1[, arm := factor(arm)]\nggplot(d_fig_1, aes(x = N_enrol, y = mu_N, col = arm)) +\n  geom_line(lwd = 0.2) +\n  geom_point(size = 0.4) +\n  geom_line(\n    data = d_fig_2, \n    aes(x = N_enrol, y = mu_N), lwd = 0.2, lty = 2, inherit.aes = F) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Expected number of participants\") +\n  scale_color_discrete(\"Treatment arm: \") +\n  ggh4x::facet_grid2(\n    desc ~ domain, \n    labeller = labeller(desc = label_wrap_gen(35)), \n    scales = \"free_y\", independent = \"y\") +\n  # theme_minimal() +\n  theme(\n    legend.position = \"bottom\",\n    strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n    axis.ticks = element_blank(),\n    strip.text.x.top = element_text(size = 4),\n    panel.grid.minor = element_blank(),\n    panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1),\n    axis.title.y=element_text(size = 5),\n    axis.text.y = element_text(size = 4), \n    axis.text.x = element_text(size = 4), \n    axis.title.x = element_text(size = 5),\n    legend.text = element_text(size = 4)\n  )\n\n\n\n\n\n\n\n\nFigure 3: Expected number of participants on domain arms\n\n\n\n\n\n\n\n\n\n\nParameter estimation\nFigure 4 shows the median value and 95% quantiles from the posterior mean odds ratios obtained from the simulations by each domain and scenario. The estimates are unconditional, in that they ignore the stopping rule and propagate estimates forward with LOCF so that we are working from a random sample (albeit with static imputation) rather than a dependent sample of simulations.\nFigure 5 shows the median value and 95% quantiles for the posterior mean risk differences obtained from the simulations for each domain and scenario. The transformation to a risk difference suggests that the odds ratios amount to effects in the order of 10-20% on the risk scale, dependent on the silo, domain etc.\nThe AB duration domain has high variance in the distribution of posterior means that we anticipate to observe. That is, when there is no true effect, we might still see posterior means as large as \\(\\pm 0.2\\) on the absolute risk scale.\n\nTreatment effects - odds ratiosTreatment effects - risk differenceTreatment effects - risk difference (tabulated)\n\n\n\n\nCode\n# ggplot2::theme_update(text = element_text(size = 8))\n# ggplot2::theme_update(legend.position = \"bottom\")\n# # ggplot2::theme_update(legend.title = element_blank())\n# ggplot2::theme_update(axis.text.x = element_text(size = 8))\n# ggplot2::theme_update(axis.text.y = element_text(size = 8))\n\nd_fig &lt;- d_tbl_3[,\n                 .(or = median(exp(mu_lor)),\n                   q_025 = quantile(exp(mu_lor), prob = 0.025),\n                   q_975 = quantile(exp(mu_lor), prob = 0.975)), \n                 keyby = .(scenario, desc, ia, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_fig[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_fig[, domain := factor(domain, \n                         levels = 1:4, \n                         labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\n# d_tbl_3[scenario == 8, range(lor)]\n\nggplot(data = d_fig,  \n       aes(x = N, y = or)) +\n  geom_line(lwd = 0.25) +\n  geom_errorbar(aes(ymin = q_025, ymax = q_975), lwd = 0.25, width = 50) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"OR\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n        strip.text.x = element_text(angle = 0, size = 5),\n        axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),\n        axis.text.y = element_text(size = 5),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1))\n\n\n\n\n\n\n\n\nFigure 4: Median value of posterior means for odds-ratio treatment effects by domain and simulation scenario\n\n\n\n\n\n\n\n\n\nCode\nd_fig &lt;- d_tbl_3[,\n                 .(rd = mean(mu_rd),\n                   q_025 = quantile(mu_rd, prob = 0.025),\n                   q_975 = quantile(mu_rd, prob = 0.975)), \n                 keyby = .(scenario, desc, ia, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_fig[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_fig[, domain := factor(\n  domain, \n  levels = 1:4, \n  labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\n# d_tbl_3[scenario == 8, range(lor)]\n\nggplot(data = d_fig,  \n       aes(x = N, y = rd)) +\n  geom_line(lwd = 0.25) +\n  geom_errorbar(aes(ymin = q_025, ymax = q_975), lwd = 0.25, width = 50) +\n  scale_x_continuous(\"\") +\n  scale_y_continuous(\"Risk difference\") +\n  ggh4x::facet_grid2(desc ~ domain , \n             labeller = labeller(desc = label_wrap_gen(35)), \n             scales = \"free\",\n             axes = \"y\",\n             independent = \"y\") +\n  # theme_minimal() +\n  theme(text = element_text(size = 6),\n        strip.text.y.right = element_text(angle = 0,\n                                      hjust = 0,\n                                      vjust = 0.2,\n                                      size = 4),\n        strip.text.x = element_text(angle = 0, size = 5),\n        axis.ticks = element_blank(),\n        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),\n        axis.text.y = element_text(size = 5),\n        panel.grid.minor = element_blank(),\n        panel.grid.major = element_line(color = \"grey\",\n                                  linewidth = 0.1,\n                                  linetype = 1))\n\n\n\n\n\n\n\n\nFigure 5: Expectation of posterior means for risk difference treatment effects by domain and simulation scenario\n\n\n\n\n\n\n\n\n\nCode\nd_tbl &lt;- d_tbl_3[,\n                 .(rd = mean(mu_rd),\n                   q_025 = quantile(mu_rd, prob = 0.025),\n                   q_975 = quantile(mu_rd, prob = 0.975)), \n                 keyby = .(scenario, desc, ia, domain, N)]\n# setorderv(d_fig, cols = \"scenario\", order = -1L)\nd_tbl[, desc := factor(desc, levels = unique(d_fig$desc))]\nd_tbl[, domain := factor(\n  domain, \n  levels = 1:4, \n  labels = c(\"Surgical\", \"AB Duration\", \"AB Ext-proph\", \"AB Choice\"))]\n\nd_tbl &lt;- dcast(d_tbl, desc + domain ~ N, value.var = list(\"rd\", \"q_025\", \"q_975\"))\n\nci_names &lt;- function(x = 500){\n  paste0(c(\"rd_\",\"q_025_\", \"q_975_\"), x)\n}\nsetcolorder(\n  d_tbl, \n  c(\"desc\", \"domain\", \n    ci_names(500), ci_names(1000), ci_names(1500), ci_names(2000), ci_names(2500)))\n\n\ng_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl),\n    align = \"center\"\n  )  |&gt; \n  cols_align(\n    columns = 3:ncol(d_tbl_2_cur),\n    align = \"right\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"rd_500\", \"q_025_500\", \"q_975_500\"),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2}, {3})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"rd_1000\", \"q_025_1000\", \"q_975_1000\"),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2}, {3})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"rd_1500\", \"q_025_1500\", \"q_975_1500\"),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2}, {3})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"rd_2000\", \"q_025_2000\", \"q_975_2000\"),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2}, {3})&gt;&gt;\"\n  )  |&gt; \n  cols_merge(\n    columns = c(\"rd_2500\", \"q_025_2500\", \"q_975_2500\"),\n    pattern = \"&lt;&lt;{1}&gt;&gt;&lt;&lt; ({2}, {3})&gt;&gt;\"\n  )  |&gt; \n  tab_spanner(\n    label = html(\"Risk difference (expectation of posterior means and 95% interval\"),\n    columns = 2:ncol(d_tbl)\n  )  |&gt;\n  cols_label(\n    rd_500 = \"500\",\n    rd_1000 = \"1000\",\n    rd_1500 = \"1500\",\n    rd_2000 = \"2000\",\n    rd_2500 = \"2500\"\n  )  |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 2, drop_trailing_zeros = TRUE)\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRisk difference (expectation of posterior means and 95% interval\n\n\n\ndomain\n500\n1000\n1500\n2000\n2500\n\n\n\n\nRD = 0 in all domains +silo specific d1\n\n\nSurgical\n0 (−0.13, 0.13)\n0 (−0.12, 0.11)\n0 (−0.11, 0.1)\n−0.01 (−0.11, 0.1)\n−0.01 (−0.11, 0.1)\n\n\nAB Duration\n0 (−0.22, 0.23)\n0 (−0.2, 0.2)\n0 (−0.2, 0.2)\n0 (−0.2, 0.2)\n0 (−0.19, 0.2)\n\n\nAB Ext-proph\n0 (−0.15, 0.16)\n0 (−0.13, 0.13)\n0 (−0.13, 0.12)\n0 (−0.12, 0.12)\n0 (−0.12, 0.12)\n\n\nAB Choice\n0 (−0.11, 0.11)\n0 (−0.08, 0.08)\n0 (−0.08, 0.07)\n0 (−0.08, 0.07)\n0 (−0.08, 0.07)\n\n\nRD = 0.12: surgical revision (one and two-stage) +silo specific d1\n\n\nSurgical\n0.11 (−0.03, 0.24)\n0.11 (−0.01, 0.22)\n0.12 (−0.01, 0.22)\n0.12 (0, 0.22)\n0.12 (0, 0.22)\n\n\nAB Duration\n0 (−0.21, 0.22)\n0 (−0.19, 0.19)\n0 (−0.19, 0.19)\n0 (−0.19, 0.19)\n0.01 (−0.19, 0.19)\n\n\nAB Ext-proph\n0 (−0.15, 0.15)\n0 (−0.13, 0.12)\n−0.01 (−0.12, 0.11)\n−0.01 (−0.12, 0.11)\n−0.01 (−0.12, 0.11)\n\n\nAB Choice\n0 (−0.11, 0.11)\n0 (−0.08, 0.08)\n0 (−0.08, 0.07)\n0 (−0.08, 0.06)\n0 (−0.08, 0.06)\n\n\nRD = 0.12: surgical revision (one-stage only) +silo specific d1\n\n\nSurgical\n0.02 (−0.12, 0.16)\n0.02 (−0.1, 0.15)\n0.02 (−0.09, 0.14)\n0.02 (−0.08, 0.13)\n0.02 (−0.08, 0.13)\n\n\nAB Duration\n0 (−0.22, 0.22)\n0 (−0.19, 0.2)\n0 (−0.19, 0.19)\n0 (−0.19, 0.19)\n0 (−0.18, 0.19)\n\n\nAB Ext-proph\n0 (−0.16, 0.15)\n0 (−0.13, 0.12)\n−0.01 (−0.13, 0.12)\n−0.01 (−0.13, 0.11)\n−0.01 (−0.13, 0.11)\n\n\nAB Choice\n0 (−0.11, 0.11)\n0 (−0.09, 0.08)\n0 (−0.08, 0.07)\n0 (−0.08, 0.06)\n0 (−0.08, 0.06)\n\n\nRD = 0.12: surgical revision (two-stage only) +silo specific d1\n\n\nSurgical\n0.08 (−0.06, 0.21)\n0.09 (−0.03, 0.2)\n0.09 (−0.03, 0.2)\n0.09 (−0.02, 0.2)\n0.09 (−0.02, 0.2)\n\n\nAB Duration\n0 (−0.23, 0.24)\n0 (−0.19, 0.21)\n0.01 (−0.19, 0.2)\n0.01 (−0.18, 0.2)\n0.01 (−0.18, 0.2)\n\n\nAB Ext-proph\n0 (−0.15, 0.16)\n0 (−0.12, 0.12)\n−0.01 (−0.12, 0.12)\n−0.01 (−0.12, 0.11)\n−0.01 (−0.12, 0.11)\n\n\nAB Choice\n0 (−0.1, 0.1)\n0 (−0.08, 0.08)\n0 (−0.07, 0.07)\n0 (−0.08, 0.06)\n0 (−0.07, 0.06)\n\n\nRD = 0.12: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0 (−0.15, 0.13)\n−0.01 (−0.13, 0.12)\n−0.01 (−0.13, 0.11)\n−0.01 (−0.13, 0.11)\n−0.01 (−0.13, 0.11)\n\n\nAB Duration\n0.1 (−0.11, 0.31)\n0.12 (−0.07, 0.31)\n0.12 (−0.05, 0.31)\n0.13 (−0.04, 0.31)\n0.13 (−0.02, 0.31)\n\n\nAB Ext-proph\n0 (−0.15, 0.16)\n0 (−0.13, 0.13)\n0 (−0.13, 0.13)\n0 (−0.13, 0.13)\n−0.01 (−0.13, 0.13)\n\n\nAB Choice\n0 (−0.11, 0.11)\n0 (−0.09, 0.08)\n0 (−0.08, 0.07)\n0 (−0.08, 0.07)\n0 (−0.08, 0.06)\n\n\nRD = 0.12: ext-proph 12wk effect +silo specific d1\n\n\nSurgical\n0.01 (−0.14, 0.14)\n0 (−0.11, 0.11)\n0 (−0.11, 0.11)\n0 (−0.11, 0.1)\n0 (−0.11, 0.1)\n\n\nAB Duration\n0 (−0.22, 0.22)\n0 (−0.2, 0.2)\n0 (−0.2, 0.2)\n0 (−0.19, 0.2)\n0 (−0.2, 0.2)\n\n\nAB Ext-proph\n0.11 (−0.04, 0.26)\n0.12 (−0.01, 0.25)\n0.12 (−0.01, 0.24)\n0.12 (−0.01, 0.24)\n0.12 (−0.01, 0.24)\n\n\nAB Choice\n0 (−0.1, 0.11)\n0 (−0.09, 0.08)\n0 (−0.08, 0.07)\n0 (−0.08, 0.06)\n0 (−0.08, 0.06)\n\n\nRD = 0.12: abx choice rif effect +silo specific d1\n\n\nSurgical\n0 (−0.14, 0.13)\n−0.01 (−0.12, 0.11)\n−0.01 (−0.11, 0.1)\n−0.01 (−0.11, 0.1)\n−0.01 (−0.11, 0.1)\n\n\nAB Duration\n0 (−0.21, 0.21)\n0 (−0.19, 0.2)\n0 (−0.19, 0.19)\n0 (−0.19, 0.19)\n0 (−0.19, 0.19)\n\n\nAB Ext-proph\n0 (−0.15, 0.15)\n0 (−0.13, 0.13)\n0 (−0.13, 0.13)\n0 (−0.13, 0.12)\n−0.01 (−0.13, 0.12)\n\n\nAB Choice\n0.12 (0.02, 0.22)\n0.12 (0.04, 0.2)\n0.12 (0.05, 0.2)\n0.12 (0.06, 0.2)\n0.12 (0.06, 0.2)\n\n\nRD = 0.12: all domains +silo specific d1\n\n\nSurgical\n0.12 (−0.02, 0.24)\n0.12 (−0.01, 0.22)\n0.12 (0, 0.22)\n0.12 (0, 0.22)\n0.12 (0, 0.22)\n\n\nAB Duration\n0.09 (−0.1, 0.28)\n0.11 (−0.04, 0.28)\n0.12 (−0.01, 0.28)\n0.12 (0, 0.28)\n0.12 (0.01, 0.28)\n\n\nAB Ext-proph\n0.11 (−0.02, 0.25)\n0.12 (0.01, 0.24)\n0.12 (0.01, 0.23)\n0.12 (0.01, 0.23)\n0.12 (0.01, 0.23)\n\n\nAB Choice\n0.12 (0.02, 0.21)\n0.12 (0.03, 0.2)\n0.12 (0.04, 0.19)\n0.12 (0.05, 0.19)\n0.12 (0.05, 0.19)\n\n\nRD = -0.05: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0 (−0.14, 0.13)\n0 (−0.12, 0.11)\n0 (−0.12, 0.11)\n0 (−0.12, 0.1)\n−0.01 (−0.12, 0.1)\n\n\nAB Duration\n−0.04 (−0.26, 0.19)\n−0.04 (−0.24, 0.16)\n−0.05 (−0.23, 0.15)\n−0.05 (−0.23, 0.15)\n−0.05 (−0.23, 0.15)\n\n\nAB Ext-proph\n0 (−0.15, 0.15)\n0 (−0.13, 0.13)\n0 (−0.13, 0.12)\n−0.01 (−0.13, 0.12)\n−0.01 (−0.13, 0.12)\n\n\nAB Choice\n0 (−0.1, 0.11)\n0 (−0.09, 0.08)\n0 (−0.08, 0.07)\n0 (−0.08, 0.06)\n0 (−0.08, 0.06)\n\n\nRD = 0.12 surgical, RD = 0.08 abx choice +silo specific d1\n\n\nSurgical\n0.11 (−0.03, 0.23)\n0.11 (0, 0.22)\n0.11 (0, 0.21)\n0.11 (0, 0.21)\n0.12 (0.01, 0.21)\n\n\nAB Duration\n0 (−0.2, 0.21)\n0 (−0.18, 0.19)\n0 (−0.17, 0.18)\n0.01 (−0.17, 0.18)\n0.01 (−0.17, 0.18)\n\n\nAB Ext-proph\n0 (−0.15, 0.15)\n0 (−0.11, 0.11)\n0 (−0.11, 0.1)\n−0.01 (−0.11, 0.1)\n−0.01 (−0.11, 0.09)\n\n\nAB Choice\n0.12 (0.01, 0.22)\n0.12 (0.04, 0.2)\n0.12 (0.05, 0.2)\n0.12 (0.06, 0.2)\n0.12 (0.06, 0.2)\n\n\n\n\n\n\n\n\nTable 4: Risk difference (expectation of posterior means and 95% interval)\n\n\n\n\n\n\n\n\n\nProportion with treatment success\nTable 5 shows the empirical proportion having treatment success within the randomised comparisons subsets averaged over the simulations. For example, the values for the surgical domain shows the empirical proportion having treatment success within the late acute silo by treatment arm (dair, rev(1), rev(2)).\n\n\nCode\nd_tbl_4_cur &lt;- dcast(d_tbl_4, scenario + desc + domain ~ arm, value.var = \"p_hat\")\nd_tbl_4_cur[, domain := factor(\n  domain, \n  levels = c(1, 2, 3, 4), \n  labels = c(\"Surgical\", \"AB Duration\",  \"AB Ext-proph\", \"AB Choice\"))]\nd_tbl_4_cur &lt;- d_tbl_4_cur[, .(desc, domain, `1`, `2`, `3`)]\n\ng_tbl &lt;- d_tbl_4_cur |&gt; \n  gt(groupname_col = \"desc\") |&gt; \n  gt::text_transform(\n    locations = cells_row_groups(),\n    fn = function(x) {\n      lapply(x, function(x) {\n        gt::md(paste0(\"*\", x, \"*\"))\n      })\n    }\n  ) |&gt;\n  cols_align(\n    columns = 1,\n    align = \"left\"\n  )  |&gt; \n  cols_align(\n    columns = 2:ncol(d_tbl_4_cur),\n    align = \"center\"\n  )  |&gt; \n  cols_label(\n    domain = \"Domain\"\n  )  |&gt;\n  tab_spanner(\n    label = html(\"Empirical risk by domain and treatment arm\"),\n    columns = 2:ncol(d_tbl_4_cur)\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt;\n  fmt_number(decimals = 2, drop_trailing_zeros = TRUE) |&gt;\n  sub_missing(\n    columns = everything(),\n    rows = everything(),\n    missing_text = \"-\"\n  )\n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEmpirical risk by domain and treatment arm\n\n\n\nDomain\n1\n2\n3\n\n\n\n\nRD = 0 in all domains +silo specific d1\n\n\nSurgical\n0.59\n0.62\n0.57\n\n\nAB Duration\n-\n0.65\n0.65\n\n\nAB Ext-proph\n-\n0.6\n0.6\n\n\nAB Choice\n-\n0.62\n0.62\n\n\nRD = 0.12: surgical revision (one and two-stage) +silo specific d1\n\n\nSurgical\n0.56\n0.71\n0.67\n\n\nAB Duration\n-\n0.7\n0.7\n\n\nAB Ext-proph\n-\n0.65\n0.65\n\n\nAB Choice\n-\n0.64\n0.64\n\n\nRD = 0.12: surgical revision (one-stage only) +silo specific d1\n\n\nSurgical\n0.56\n0.68\n0.55\n\n\nAB Duration\n-\n0.67\n0.68\n\n\nAB Ext-proph\n-\n0.59\n0.58\n\n\nAB Choice\n-\n0.61\n0.61\n\n\nRD = 0.12: surgical revision (two-stage only) +silo specific d1\n\n\nSurgical\n0.56\n0.6\n0.68\n\n\nAB Duration\n-\n0.63\n0.63\n\n\nAB Ext-proph\n-\n0.66\n0.66\n\n\nAB Choice\n-\n0.63\n0.63\n\n\nRD = 0.12: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0.59\n0.66\n0.57\n\n\nAB Duration\n-\n0.62\n0.75\n\n\nAB Ext-proph\n-\n0.6\n0.6\n\n\nAB Choice\n-\n0.62\n0.62\n\n\nRD = 0.12: ext-proph 12wk effect +silo specific d1\n\n\nSurgical\n0.59\n0.62\n0.62\n\n\nAB Duration\n-\n0.65\n0.65\n\n\nAB Ext-proph\n-\n0.58\n0.7\n\n\nAB Choice\n-\n0.63\n0.63\n\n\nRD = 0.12: abx choice rif effect +silo specific d1\n\n\nSurgical\n0.62\n0.65\n0.61\n\n\nAB Duration\n-\n0.69\n0.69\n\n\nAB Ext-proph\n-\n0.63\n0.63\n\n\nAB Choice\n-\n0.6\n0.72\n\n\nRD = 0.12: all domains +silo specific d1\n\n\nSurgical\n0.6\n0.79\n0.76\n\n\nAB Duration\n-\n0.71\n0.83\n\n\nAB Ext-proph\n-\n0.67\n0.78\n\n\nAB Choice\n-\n0.65\n0.76\n\n\nRD = -0.05: abx duration 6wk effect +silo specific d1\n\n\nSurgical\n0.59\n0.62\n0.57\n\n\nAB Duration\n-\n0.67\n0.62\n\n\nAB Ext-proph\n-\n0.6\n0.6\n\n\nAB Choice\n-\n0.62\n0.62\n\n\nRD = 0.12 surgical, RD = 0.08 abx choice +silo specific d1\n\n\nSurgical\n0.6\n0.75\n0.71\n\n\nAB Duration\n-\n0.74\n0.74\n\n\nAB Ext-proph\n-\n0.69\n0.69\n\n\nAB Choice\n-\n0.62\n0.74\n\n\n\n\n\n\n\n\nTable 5: Expected number of enrolments to hit any stopping rule (including reaching maximum sample size)",
    "crumbs": [
      "Simulations",
      "Simulation results 7"
    ]
  }
]