[
  {
    "objectID": "notebooks/simulation-pars.html",
    "href": "notebooks/simulation-pars.html",
    "title": "Simulation setup",
    "section": "",
    "text": "Various aspects of the initial conditions for the simulations are described.",
    "crumbs": [
      "Assumptions and setup",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#baseline-response",
    "href": "notebooks/simulation-pars.html#baseline-response",
    "title": "Simulation setup",
    "section": "Baseline response",
    "text": "Baseline response\nThe baseline probability/log-odds of treatment success is assumed to vary by silo and site of infection as detailed below.\n\n\nBaseline probability of treatment success by silo and site of infection\n\n\nSilo\nJoint\nPr(trt success)\nlog-odds\n\n\n\n\nearly\nknee\n0.65\n0.62\n\n\nearly\nhip\n0.75\n1.10\n\n\nlate\nknee\n0.55\n0.20\n\n\nlate\nhip\n0.6\n0.41\n\n\nchronic\nknee\n0.6\n0.41\n\n\nchronic\nhip\n0.65\n0.62",
    "crumbs": [
      "Assumptions and setup",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#accrual",
    "href": "notebooks/simulation-pars.html#accrual",
    "title": "Simulation setup",
    "section": "Accrual",
    "text": "Accrual\nAccrual is assumed to follow a non-homogeneous Poisson process event times with ramp up over the first 12 months of enrolment and then enrolment of around 1.5 per day.\n\n\nCode\n# events per day\nlambda = 1.52\n# ramp up over 12 months \nrho = function(t) pmin(t/360, 1)\n\nd_fig &lt;- data.table(\n  t = 0:(5 * 365),\n  # expected number enrolled\n  n = c(0, nhpp.mean(lambda, rho, t1 = 5 * 365, num.points = 5 * 365))\n)\n\nggplot(d_fig, aes(x = t/365, y = n)) +\n  geom_line() +\n  scale_x_continuous(\"Year\") +\n  scale_y_continuous(\"E[Accrual]\", breaks = seq(0, 2500, by = 500))\n\n\n\n\n\n\n\n\nFigure 1: Expected accrual",
    "crumbs": [
      "Assumptions and setup",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#domain-non-membership-effects",
    "href": "notebooks/simulation-pars.html#domain-non-membership-effects",
    "title": "Simulation setup",
    "section": "Domain non-membership effects",
    "text": "Domain non-membership effects\nWe assume a small effects for not being randomised to a domain for all domains.",
    "crumbs": [
      "Assumptions and setup",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#missingness",
    "href": "notebooks/simulation-pars.html#missingness",
    "title": "Simulation setup",
    "section": "Missingness",
    "text": "Missingness\nMissingness is not implemented.",
    "crumbs": [
      "Assumptions and setup",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#non-differential-follow-up",
    "href": "notebooks/simulation-pars.html#non-differential-follow-up",
    "title": "Simulation setup",
    "section": "Non-differential follow-up",
    "text": "Non-differential follow-up\nTo avoid artifacts associated with non-differential follow-up (e.g. early vs late deaths), participants will be included in the analyses only when they reach the primary endpoints (12 months) irrespective of whether they experienced treatment failure before that time.",
    "crumbs": [
      "Assumptions and setup",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/design-notes-08.html",
    "href": "notebooks/design-notes-08.html",
    "title": "MLM vs static regularisation",
    "section": "",
    "text": "Provides a cursory examination of the differences between static regularisation via L1 and L2 penalty vs multilevel approach which achieves dynamic shrinkage. Definitely no free lunch. The model we consider simply examines discrete group means with differential allocation across the groups.\n\n\nParameter specification\nget_par &lt;- function(\n    n_grp = 9,\n    mu = 1,\n    s_y = 0.3\n    ){\n  \n  l &lt;- list()\n  l$n_grp &lt;- n_grp\n\n  # overall mean effect across all intervention types\n  l$mu &lt;- mu\n  # within intervention variation attributable to group membership\n  l$s_y &lt;- s_y\n  # intervention type specific mean\n  l$mu_j &lt;- rnorm(n_grp, 0, l$s_y)\n\n  l$d_par &lt;- CJ(\n    j = factor(1:l$n_grp, levels = 1:l$n_grp)\n  )\n  l$d_par[, mu := l$mu]\n  l$d_par[, mu_j := l$mu_j[j]]\n  \n  l\n}\n\n\n\n\nData generation function\nget_data &lt;- function(\n    N = 2000, \n    par = NULL,\n    ff = function(par, j){\n      eta = par$mu + par$mu_j[j] \n      eta\n    }){\n  \n  # strata\n  d &lt;- data.table()\n  \n  # intervention - even allocation\n  z &lt;- rnorm(par$n_grp, 0, 0.5)\n  d[, j := sample(1:par$n_grp, size = N, replace = T, prob = exp(z)/sum(exp(z)))]\n  d[, eta := ff(par, j)]\n  d[, y := rbinom(.N, 1, plogis(eta))]\n  \n  d  \n}\n\n\n\n\nCode\nset.seed(1)\npar &lt;- get_par(n_grp = 3, mu = 1, s_y = 0.0)\n# 100 people per group - will this overcome the prior?\nn_per_grp &lt;- 100\nd &lt;- get_data(N = n_per_grp * par$n_grp, par)\n\n\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-04.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-05.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-06.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y,  J = length(unique(d$j)),  j = d$j, # intervention\n  pri_s_norm = 1, \n  pri_s_exp = 1, \n  pri_r = 1/2, \n  # when alpha = 1, we have pure lasso regression (double exp)\n  # when alpha = 0, we have pure ridge regression (normal with 1/lambda scale).\n  pri_alpha = 0.6,\n  pri_lambda = 1, # scale is 1/pri_lambda\n  prior_only = 1\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 5000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\nCode\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 5000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nf3 &lt;- m3$sample(\n  ld, iter_warmup = 1000, iter_sampling = 5000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.1 seconds.\n\n\nThe priors on the group level offsets. The elastic net priors are a preset combination of ridge and lasso regression.\n\n\nImplied priors on the group level deviations from the grand mean\nd_1 &lt;- data.table(f1$draws(variables = \"z_eta\", format = \"matrix\"))\nd_1 &lt;- melt(d_1, measure.vars = names(d_1))\nd_1[, desc := \"unpooled\"]\n\nd_2 &lt;- data.table(f2$draws(variables = \"z_eta\", format = \"matrix\"))\nd_2 &lt;- melt(d_2, measure.vars = names(d_2))\nd_2[, desc := \"elastic-net\"]\n\nd_3 &lt;- data.table(f3$draws(variables = \"z_eta\", format = \"matrix\"))\nd_3 &lt;- melt(d_3, measure.vars = names(d_3))\nd_3[, desc := \"mlm\"]\n\nd_fig &lt;- rbind(d_1, d_2, d_3)\nd_fig[, desc := factor(desc, levels = c(\"unpooled\", \"elastic-net\", \"mlm\"))]\n\nx &lt;- seq(min(d_fig$value), max(d_fig$value), len = 1000)\n# for ridge\nden_2a &lt;- dnorm(x, 0, 1/ld$pri_lambda)\n# for lasso\nden_2b &lt;- extraDistr::dlaplace(x, 0, 1/ld$pri_lambda)\n\nd_sta &lt;- rbind(\n  data.table(desc = \"elastic-net\", mod = \"ridge\", x = x, y = den_2a),\n  data.table(desc = \"elastic-net\", mod = \"lasso\", x = x, y = den_2b)\n)\nd_sta[, desc := factor(desc, levels = c(\"unpooled\", \"elastic-net\", \"mlm\"))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_line(\n    data = d_sta[mod == \"lasso\"],\n    aes(x = x, y = y, group = desc), inherit.aes = F,\n    col = 2, lty = 2, lwd = 0.7) +\n  geom_line(\n    data = d_sta[mod == \"ridge\"],\n    aes(x = x, y = y, group = desc), inherit.aes = F,\n    col = 3, lty = 5, lwd = 0.7) +\n  geom_density(lwd = 0.2) +\n  facet_wrap(~desc, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 1: Implied priors on the group level deviations from the grand mean\n\n\n\n\n\n\n\nCode\nset.seed(1)\npar &lt;- get_par(n_grp = 10, mu = 1, s_y = 0.5)\n# 100 people per group - will this overcome the prior?\nn_per_grp &lt;- 100\nd &lt;- get_data(N = n_per_grp * par$n_grp, par)\n\n\n\n\nCode\nld &lt;- list(\n  N = nrow(d), \n  y = d$y,  J = length(unique(d$j)),  j = d$j, # intervention\n  pri_s_norm = 2, \n  pri_s_exp = 1, \n  pri_r = 1/2,  \n  # when alpha = 1, we have pure lasso regression (double exp)\n  # when alpha = 0, we have pure ridge regression (normal with 1/lambda scale).\n  pri_alpha = 0.9,\n  pri_lambda = 0.76, # scale is 1/pri_lambda for both ridge and lasso\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.6 seconds.\nChain 2 finished in 0.7 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.6 seconds.\nTotal execution time: 0.7 seconds.\n\n\nCode\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.5 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.6 seconds.\n\n\nCode\nf3 &lt;- m3$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.6 seconds.\n\n\nTreatment group posteriors. By adjusting \\(\\alpha\\) and \\(\\lambda\\) in the elastic net model we can a-priori determine the magnitude of regularisation we want to achieve. In practice, the quantities should be pre-specified and a sensitivity analysis on the main analysis based on varying these quantities.\n\n\nPosterior inference on the group level means\nd_0 &lt;- d[, .(desc = \"observed\", eta = qlogis(mean(y))), keyby = j]\n\nd_1 &lt;- data.table(f1$draws(variables = \"eta\", format = \"matrix\"))\nd_1 &lt;- melt(d_1, measure.vars = names(d_1), value.name = \"eta\")\nd_1[, desc := \"unpooled\"]\n\nd_2 &lt;- data.table(f2$draws(variables = \"eta\", format = \"matrix\"))\nd_2 &lt;- melt(d_2, measure.vars = names(d_2), value.name = \"eta\")\nd_2[, desc := \"elastic-net\"]\n\nd_3 &lt;- data.table(f3$draws(variables = \"eta\", format = \"matrix\"))\nd_3 &lt;- melt(d_3, measure.vars = names(d_3), value.name = \"eta\")\nd_3[, desc := \"mlm\"]\n\nd_fig &lt;- rbind(d_1, d_2, d_3)\nd_fig[, j := gsub(\"eta[\", \"\", variable, fixed = T)]\nd_fig[, j := gsub(\"]\", \"\", j, fixed = T)]\nd_fig[, variable := NULL]\nd_fig[, desc := factor(\n  desc, levels = c(\"observed\", \"unpooled\", \"elastic-net\", \"mlm\"))]\nd_fig &lt;- rbind(d_fig, d_0)\n\nd_fig &lt;- d_fig[, .(\n  mu = mean(eta), \n  q5 = quantile(eta, prob = 0.05),\n  q95 = quantile(eta, prob = 0.95)), keyby = .(desc, j)]\n\nd_fig[, j := factor(j, levels = paste0(1:par$n_grp))]\n\nggplot(d_fig, aes(x = j, y = mu, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(\n    aes(ymin = q5, ymax = q95),\n    position = position_dodge2(width = 0.6)) +\n  scale_color_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_fig$q5, na.rm = T) - 0.2, \n                label = N), inherit.aes = F) \n\n\n\n\n\n\n\n\nFigure 2: Posterior inference on the group level means\n\n\n\n\n\n\n\nCode\nset.seed(2)\npar &lt;- get_par(n_grp = 10, mu = 1, s_y = 0.5)\nn_per_grp &lt;- 500\nd &lt;- get_data(N = n_per_grp * par$n_grp, par)\n\n\n\n\nCode\nld &lt;- list(\n  N = nrow(d), \n  y = d$y,  J = length(unique(d$j)),  j = d$j, # intervention\n  pri_s_norm = 2, \n  pri_s_exp = 1, \n  pri_r = 1/2,  \n  # when alpha = 1, we have pure lasso regression (double exp)\n  # when alpha = 0, we have pure ridge regression (normal with 1/lambda scale).\n  pri_alpha = 0.9,\n  pri_lambda = 0.76, # scale is 1/pri_lambda for both ridge and lasso\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 3.8 seconds.\nChain 2 finished in 4.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 3.9 seconds.\nTotal execution time: 4.1 seconds.\n\n\nCode\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 3.0 seconds.\nChain 1 finished in 3.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 3.1 seconds.\nTotal execution time: 3.2 seconds.\n\n\nCode\nf3 &lt;- m3$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 3.4 seconds.\nChain 2 finished in 3.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 3.5 seconds.\nTotal execution time: 3.7 seconds.\n\n\nHowever, note that larger data sets will still overwhelm the static regularisation as shown in Figure 3.\n\n\nPosterior inference on the group level means\nd_0 &lt;- d[, .(desc = \"observed\", eta = qlogis(mean(y))), keyby = j]\n\nd_1 &lt;- data.table(f1$draws(variables = \"eta\", format = \"matrix\"))\nd_1 &lt;- melt(d_1, measure.vars = names(d_1), value.name = \"eta\")\nd_1[, desc := \"unpooled\"]\n\nd_2 &lt;- data.table(f2$draws(variables = \"eta\", format = \"matrix\"))\nd_2 &lt;- melt(d_2, measure.vars = names(d_2), value.name = \"eta\")\nd_2[, desc := \"elastic-net\"]\n\nd_3 &lt;- data.table(f3$draws(variables = \"eta\", format = \"matrix\"))\nd_3 &lt;- melt(d_3, measure.vars = names(d_3), value.name = \"eta\")\nd_3[, desc := \"mlm\"]\n\nd_fig &lt;- rbind(d_1, d_2, d_3)\nd_fig[, j := gsub(\"eta[\", \"\", variable, fixed = T)]\nd_fig[, j := gsub(\"]\", \"\", j, fixed = T)]\nd_fig[, variable := NULL]\nd_fig[, desc := factor(\n  desc, levels = c(\"observed\", \"unpooled\", \"elastic-net\", \"mlm\"))]\nd_fig &lt;- rbind(d_fig, d_0)\n\nd_fig &lt;- d_fig[, .(\n  mu = mean(eta), \n  q5 = quantile(eta, prob = 0.05),\n  q95 = quantile(eta, prob = 0.95)), keyby = .(desc, j)]\n\nd_fig[, j := factor(j, levels = paste0(1:par$n_grp))]\n\nggplot(d_fig, aes(x = j, y = mu, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(\n    aes(ymin = q5, ymax = q95),\n    position = position_dodge2(width = 0.6)) +\n  scale_color_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_fig$q5, na.rm = T) - 0.2, \n                label = N), inherit.aes = F) \n\n\n\n\n\n\n\n\nFigure 3: Posterior inference on the group level means\n\n\n\n\n\n\n\nCode\nset.seed(7)\npar &lt;- get_par(n_grp = 2, mu = 1, s_y = 0.5)\nn_per_grp &lt;- 200\nd &lt;- get_data(N = n_per_grp * par$n_grp, par)\n\n\n\n\nCode\nld &lt;- list(\n  N = nrow(d), \n  y = d$y,  J = length(unique(d$j)),  j = d$j, # intervention\n  pri_s_norm = 2, \n  pri_s_exp = 1, \n  pri_r = 1/2,  \n  # when alpha = 1, we have pure lasso regression (double exp)\n  # when alpha = 0, we have pure ridge regression (normal with 1/lambda scale).\n  pri_alpha = 0.9,\n  pri_lambda = 0.76, # scale is 1/pri_lambda for both ridge and lasso\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.3 seconds.\nChain 2 finished in 0.3 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.3 seconds.\nTotal execution time: 0.4 seconds.\n\n\nCode\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.2 seconds.\nChain 2 finished in 0.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.2 seconds.\nTotal execution time: 0.3 seconds.\n\n\nCode\nf3 &lt;- m3$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.5 seconds.\n\n\nAnd in the case with smaller number of groups, there is probably immaterial differences between the approaches as shown in Figure 4.\n\n\nPosterior inference on the group level means\nd_0 &lt;- d[, .(desc = \"observed\", eta = qlogis(mean(y))), keyby = j]\n\nd_1 &lt;- data.table(f1$draws(variables = \"eta\", format = \"matrix\"))\nd_1 &lt;- melt(d_1, measure.vars = names(d_1), value.name = \"eta\")\nd_1[, desc := \"unpooled\"]\n\nd_2 &lt;- data.table(f2$draws(variables = \"eta\", format = \"matrix\"))\nd_2 &lt;- melt(d_2, measure.vars = names(d_2), value.name = \"eta\")\nd_2[, desc := \"elastic-net\"]\n\nd_3 &lt;- data.table(f3$draws(variables = \"eta\", format = \"matrix\"))\nd_3 &lt;- melt(d_3, measure.vars = names(d_3), value.name = \"eta\")\nd_3[, desc := \"mlm\"]\n\nd_fig &lt;- rbind(d_1, d_2, d_3)\nd_fig[, j := gsub(\"eta[\", \"\", variable, fixed = T)]\nd_fig[, j := gsub(\"]\", \"\", j, fixed = T)]\nd_fig[, variable := NULL]\nd_fig[, desc := factor(\n  desc, levels = c(\"observed\", \"unpooled\", \"elastic-net\", \"mlm\"))]\nd_fig &lt;- rbind(d_fig, d_0)\n\nd_fig &lt;- d_fig[, .(\n  mu = mean(eta), \n  q5 = quantile(eta, prob = 0.05),\n  q95 = quantile(eta, prob = 0.95)), keyby = .(desc, j)]\n\nd_fig[, j := factor(j, levels = paste0(1:par$n_grp))]\n\nggplot(d_fig, aes(x = j, y = mu, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(\n    aes(ymin = q5, ymax = q95),\n    position = position_dodge2(width = 0.6)) +\n  scale_color_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_fig$q5, na.rm = T) - 0.2, \n                label = N), inherit.aes = F) \n\n\n\n\n\n\n\n\nFigure 4: Posterior inference on the group level means",
    "crumbs": [
      "Design notes",
      "MLM vs static regularisation"
    ]
  },
  {
    "objectID": "notebooks/about.html",
    "href": "notebooks/about.html",
    "title": "About",
    "section": "",
    "text": "Version of quarto used for this site is 1.5.52.\n\n\n\n\n\n\nWarning\n\n\n\nThere is usually a version of quarto installed with RStudio. For example, on my machine this is /Applications/RStudio.app/Contents/Resources/app/quarto/bin/quarto. But, this is not the latest version. I leave the RStudio version alone, install a new version of quarto on my machine, independent to RStudio, and then render everything through the CLI.\n\n\n\n\nDetails on GitHub repository files, tags, commits follow:\n\n\nCode\nrepo &lt;- git2r::repository(path = \".\")\nsummary(repo)\n\n\nLocal:    main /Users/mark/Documents/project/roadmap/src/roadmap-sim\nRemote:   main @ origin (https://github.com/maj-biostat/roadmap-sim.git)\nHead:     [3b986a5] 2024-07-23: Correct ordering of interaction parameter spec\n\nBranches:          3\nTags:              0\nCommits:         164\nContributors:      2\nStashes:           0\nIgnored files:    47\nUntracked files:  41\nUnstaged files:    2\nStaged files:      0\n\nLatest commits:\n[3b986a5] 2024-07-23: Correct ordering of interaction parameter spec\n[714280a] 2024-07-22: wip\n[1af50ed] 2024-07-18: wip\n[acb7528] 2024-07-15: wip\n[2c293d6] 2024-07-11: wip",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "notebooks/about.html#repository-status",
    "href": "notebooks/about.html#repository-status",
    "title": "About",
    "section": "",
    "text": "Details on GitHub repository files, tags, commits follow:\n\n\nCode\nrepo &lt;- git2r::repository(path = \".\")\nsummary(repo)\n\n\nLocal:    main /Users/mark/Documents/project/roadmap/src/roadmap-sim\nRemote:   main @ origin (https://github.com/maj-biostat/roadmap-sim.git)\nHead:     [3b986a5] 2024-07-23: Correct ordering of interaction parameter spec\n\nBranches:          3\nTags:              0\nCommits:         164\nContributors:      2\nStashes:           0\nIgnored files:    47\nUntracked files:  41\nUnstaged files:    2\nStaged files:      0\n\nLatest commits:\n[3b986a5] 2024-07-23: Correct ordering of interaction parameter spec\n[714280a] 2024-07-22: wip\n[1af50ed] 2024-07-18: wip\n[acb7528] 2024-07-15: wip\n[2c293d6] 2024-07-11: wip",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "notebooks/decision-rules.html",
    "href": "notebooks/decision-rules.html",
    "title": "Decision rules",
    "section": "",
    "text": "In the following, all treatment effect parameters relate back to the model specification provided earlier.",
    "crumbs": [
      "Assumptions and setup",
      "Decision rules"
    ]
  },
  {
    "objectID": "notebooks/decision-rules.html#surgical-domain",
    "href": "notebooks/decision-rules.html#surgical-domain",
    "title": "Decision rules",
    "section": "Surgical domain",
    "text": "Surgical domain\nThe surgical domain considers the effect of revision relative to dair in the late-stage infection silo.\nFollowing the earlier model specification, let \\(\\Delta_R = \\beta_4 \\mathbb{E}[\\mathbb{I}(S_{R_P} == 1 \\land R == 1)] + \\beta_5 \\mathbb{E}[\\mathbb{I}(S_{R_P} == 2 \\land R == 1)]\\) correspond to the average conditional log-odds ratio associated with revision. The probability that revision is superior to dair is defined as:\n\\[\\begin{aligned}\nP_{\\text{surgical (sup)}} = Pr(\\Delta_R &gt; 0)\n\\end{aligned}\\]\nand enrolment is stopped for superiority if \\(P_{\\text{surgical (sup)}} &gt; 0.99\\).\nThe probability of futility for revision being superior to dair is defined as:\n\\[\\begin{aligned}\nP_{\\text{surgical (fut)}} = Pr(\\Delta_R &gt; \\log(1.2))\n\\end{aligned}\\]\nand enrolment is stopped for futility if \\(P_{\\text{surgical (fut)}} &lt; 0.05\\).",
    "crumbs": [
      "Assumptions and setup",
      "Decision rules"
    ]
  },
  {
    "objectID": "notebooks/decision-rules.html#duration-domain",
    "href": "notebooks/decision-rules.html#duration-domain",
    "title": "Decision rules",
    "section": "Duration domain",
    "text": "Duration domain\nThe duration domain considers the effect of short relative to long duration therapy depending on the type of revision received.\nIf, in the surgical domain, revision is found to be inferior to DAIR, then randomisation in the surgical domain will cease and DAIR will be recommended for all late acute who meet the domain eligibility criteria. But the duration domain will continue, because people in other silos will continue to have revision surgery (occasionally in Early and routinely in Chronic).\n\nDAIR\nNo duration effects are applicable for DAIR.\n\n\nOne-stage revision\nLet \\(\\beta_6\\) correspond to the conditional log-odds ratio associated with 6 weeks (short) duration antibiotics relative to 12 weeks (long) when one-stage revision is received. The probability that short is non-inferior to long is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-1 (ni)}} = Pr(\\beta_6 &gt; \\log(1/1.2))\n\\end{aligned}\\]\nand enrolment is stopped for non-inferiority if \\(P_{\\text{duration-1 (ni)}} &gt; 0.99\\).\nThe probability of futility for revision being superior to dair is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-1 (fut)}} = Pr(\\beta_6 &gt; \\log(1))\n\\end{aligned}\\]\nand enrolment is stopped for futility (with respect to being able to establish non-inferiority) if \\(P_{\\text{duration-1 (fut)}} &lt; 0.05\\).\n\n\nTwo-stage revision\nLet \\(\\beta_7\\) correspond to the conditional log-odds ratio associated with 12 weeks (long) duration antibiotics relative to 7 days (short) when two-stage revision is received. The probability that long duration is superior to short is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-2 (sup)}} = Pr(\\beta_7 &gt; 0)\n\\end{aligned}\\]\nand enrolment is stopped for superiority if \\(P_{\\text{duration-2 (sup)}} &gt; 0.99\\).\nThe probability of futility for long duration being superior to short is defined as:\n\\[\\begin{aligned}\nP_{\\text{duration-2 (fut)}} = Pr(\\beta_7 &gt; \\log(1.2))\n\\end{aligned}\\]\nand enrolment is stopped for futility if \\(P_{\\text{duration-2 (fut)}} &lt; 0.05\\).",
    "crumbs": [
      "Assumptions and setup",
      "Decision rules"
    ]
  },
  {
    "objectID": "notebooks/decision-rules.html#choice-domain",
    "href": "notebooks/decision-rules.html#choice-domain",
    "title": "Decision rules",
    "section": "Choice domain",
    "text": "Choice domain\nThe choice domain considers the effect of rifampacin relative to no-rifampacin.\nLet \\(\\beta_{9}\\) correspond to the conditional log-odds ratio associated with rifampacin relative to no-rifampacin The probability that rifampacin is superior to no-rifampacin is defined as:\n\\[\\begin{aligned}\nP_{\\text{choice (sup)}} = Pr(\\beta_{9} &gt; 0)\n\\end{aligned}\\]\nand enrolment is stopped for superiority if \\(P_{\\text{choice (sup)}} &gt; 0.99\\).\nThe probability of futility for rifampacin being superior to no-rifampacin is defined as:\n\\[\\begin{aligned}\nP_{\\text{choice (fut)}} = Pr(\\beta_{9} &gt; \\log(1.2))\n\\end{aligned}\\]\nand enrolment is stopped for futility if \\(P_{\\text{choice (fut)}} &lt; 0.05\\).",
    "crumbs": [
      "Assumptions and setup",
      "Decision rules"
    ]
  },
  {
    "objectID": "notebooks/sim-design1-results.html",
    "href": "notebooks/sim-design1-results.html",
    "title": "Simulation results 1",
    "section": "",
    "text": "Simulation 1 is a fixed sized trial with decision criteria for superiority, and non-inferiority and also for futility with respect to both superiority and non-inferiority.\nWe provide summaries of each simulation scenario and the results that were obtained.\n\n\nLoad simulation results\n# files of interest\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc01\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n\n\n\nConfiguration used for each simulated scenario\n# cfg used in each scenario\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\n# conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  N_pt = as.numeric(N_pt),\n  b_r1 = as.numeric(b_r1),\n  b_r2 = as.numeric(b_r2),\n  w_srp2 = as.numeric(w_srp2),\n  b_r1d = as.numeric(b_r1d),\n  b_r2d = as.numeric(b_r2d),\n  b_f = as.numeric(b_f),\n  d_sup = as.numeric(thresh_sup),\n  d_ni = as.numeric(thresh_non_inf),\n  d_fut_sup = as.numeric(thresh_fut_sup),\n  d_fut_ni = as.numeric(thresh_fut_ni)\n  )]\n\nd_cfg[, `:=`(w_srp2 = NULL)]\n\n\n\n\nProcess simulation results for variables of interest\n# Decisions\ni &lt;- 1\n\n\nd_sup &lt;- rbindlist(lapply(seq_along(l), function(i){\n  cbind(sc = d_cfg[i, sc], v = d_cfg[i, v], l[[i]]$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"p\")\nd_sup[, type := \"sup\"]\n\nd_trt_ni_ref &lt;- rbindlist(lapply(seq_along(l), function(i){\n  cbind(sc = d_cfg[i, sc], v = d_cfg[i, v], l[[i]]$d_pr_trt_ni_ref[, lapply(.SD, mean)])\n}))\nd_trt_ni_ref &lt;- melt(d_trt_ni_ref, id.vars = c(\"sc\", \"v\"), value.name = \"p\")\nd_trt_ni_ref[, type := \"trt_ni_ref\"]\n\nd_fut_sup &lt;- rbindlist(lapply(seq_along(l), function(i){\n  cbind(sc = d_cfg[i, sc], v = d_cfg[i, v], l[[i]]$d_fut_sup[, lapply(.SD, mean)])\n}))\nd_fut_sup &lt;- melt(d_fut_sup, id.vars = c(\"sc\", \"v\"), value.name = \"p\")\nd_fut_sup[, type := \"fut_sup\"]\n\nd_fut_ni &lt;- rbindlist(lapply(seq_along(l), function(i){\n  cbind(sc = d_cfg[i, sc], v = d_cfg[i, v], l[[i]]$d_fut_trt_ni_ref[, lapply(.SD, mean)])\n}))\nd_fut_ni &lt;- melt(d_fut_ni, id.vars = c(\"sc\", \"v\"), value.name = \"p\")\nd_fut_ni[, type := \"fut_ni\"]\n\nd_dec &lt;- rbind(\n  d_sup, d_trt_ni_ref, d_fut_sup, d_fut_ni\n)\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\n# Posterior summaries on effects of interest\nd_post_smry_2 &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- l[[i]]$d_post_smry_2\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n# Participant data from trial (grouped)\nd_all &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- l[[i]]$d_grp\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n\nTable 1 summarises the configurations used in each simulated scenario. Each treatment effect parameter is set to have the same magnitude of effect. The effects range from \\(\\log(1/2)\\) in scenario 1 to \\(\\log(2)\\) in scenario 7. Decision rules and thresholds remain constant over the entire enrolment period.\nRevision effects are computed as a weighted combination of the log-odds ratios for the one-stage and two-stage revision effects. The weights are the sample proportion receiving one-stage and two-stage surgery in those patients receiving randomised surgical treatment and randomised to revision.\n\n\nCode\nd_tbl &lt;- d_cfg[, .(v, N_pt, b_r1, b_r2, b_r1d, b_r2d, b_f, \n                   delta_sup = delta_sup,\n                   delta_sup_fut = delta_sup_fut,\n                   delta_ni = 1/delta_ni,\n                   thresh_sup, thresh_non_inf, thresh_fut_sup, thresh_fut_ni)]\n\ng_tbl &lt;- d_tbl |&gt; gt() |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = c(b_r1, b_r2, b_r1d, b_r2d, b_f,\n                delta_ni\n                ),\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_r1, b_r2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_r1d, b_r2d)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_f)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision setup\"),\n    columns = c(delta_sup, thresh_sup, \n                delta_sup_fut, thresh_fut_sup, \n                delta_ni, thresh_non_inf, thresh_fut_ni)\n  ) |&gt;\n  cols_label(\n    v = html(\"Configuration\"),\n    b_r1 = html(\"rev&lt;br&gt;(one-stage)\"),\n    b_r2 = html(\"rev&lt;br&gt;(two-stage)\"),\n    b_r1d = html(\"short&lt;br&gt;(one-stage)\"),\n    b_r2d = html(\"short&lt;br&gt;(two-stage)\"),\n    b_f = html(\"rif\"),\n    delta_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    thresh_sup = html(\"p&lt;sub&gt;sup&lt;/sub&gt;\"),\n    delta_sup_fut = html(\"delta&lt;sub&gt;fut-sup&lt;/sub&gt;\"),\n    thresh_fut_sup = html(\"p&lt;sub&gt;fut-sup&lt;/sub&gt;\"),\n    delta_ni = html(\"delta&lt;sub&gt;ni&lt;/sub&gt;\"),\n    thresh_non_inf = html(\"p&lt;sub&gt;ni&lt;/sub&gt;\"),\n    thresh_fut_ni = html(\"p&lt;sub&gt;fut-ni&lt;/sub&gt;\")\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"bottom\"), color = \"black\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = N_pt == 2500\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Surgical effects only applies to late silo, effect is relative to response under DAIR.\",\n    locations = cells_column_labels(columns = c(b_r1, b_r2))\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under long duration.\",\n    locations = cells_column_labels(columns = b_r1d)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under short duration.\",\n    locations = cells_column_labels(columns = b_r2d)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under no-rifampicin\",\n    locations = cells_column_labels(columns = b_f)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating superiority\",\n    locations = cells_column_labels(columns = delta_sup)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Probability threshold above which superiority is concluded\",\n    locations = cells_column_labels(columns = thresh_sup)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating futility wrt the superiority decision\",\n    locations = cells_column_labels(columns = delta_sup_fut)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold below which futility is concluded\",\n    locations = cells_column_labels(columns = thresh_fut_sup)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating non-inferiority\",\n    locations = cells_column_labels(columns = delta_ni)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold above which non-inferiority is concluded\",\n    locations = cells_column_labels(columns = thresh_non_inf)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold below which non-inferiority decision is deemed futile\",\n    locations = cells_column_labels(columns = thresh_fut_ni)\n  )   \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration\nN_pt\nSurgical (Da)\nDuration (Db)\nType (Dc)\nDecision setup\n\n\nrev\n(one-stage)1\nrev\n(two-stage)1\nshort\n(one-stage)2\nshort\n(two-stage)3\nrif4\ndeltasup5\npsup6\ndeltafut-sup7\npfut-sup8\ndeltani9\npni10\npfut-ni11\n\n\n\n\nv01\n2500\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv02\n2500\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv03\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv04\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv05\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv06\n2500\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\nv07\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.975\n1.2\n0.05\n0.833\n0.975\n0.05\n\n\n\n1 Surgical effects only applies to late silo, effect is relative to response under DAIR.\n\n\n2 Applies to all silos, effect is relative to response under long duration.\n\n\n3 Applies to all silos, effect is relative to response under short duration.\n\n\n4 Applies to all silos, effect is relative to response under no-rifampicin\n\n\n5 Reference OR for evaluating superiority\n\n\n6 Probability threshold above which superiority is concluded\n\n\n7 Reference OR for evaluating futility wrt the superiority decision\n\n\n8 Probability threshold below which futility is concluded\n\n\n9 Reference OR for evaluating non-inferiority\n\n\n10 Probability threshold above which non-inferiority is concluded\n\n\n11 Probability threshold below which non-inferiority decision is deemed futile\n\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 summarises the variation in the probability of declaring each decision type on each parameter with increasing effects size (odds ratios). The results based on 5000 simulations for a cohort sample size of 2500.\n\n\nCode\nd_fig &lt;- copy(d_dec)\n\nd_fig[, or := g_or_num[v]]\n\nd_fig[, type := factor(\n  type, levels = c(\"sup\", \"fut_sup\", \"trt_ni_ref\", \"fut_ni\"),\n  labels = c(\"sup\", \"fut_sup\", \"ni\", \"fut_ni\"))]\n\nggplot(d_fig, aes(x = or, y = p, group = type, col = type)) +\n  geom_point(size = 0.5) +\n  geom_line(lwd = 0.4) +\n  geom_hline(yintercept = 0.05, lwd = 0.4) +\n  ggthemes::scale_colour_tableau(\n    \"\", palette = \"Tableau 10\",\n  type = \"regular\",\n  direction = 1) +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Proportion sims with decision\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~variable, ncol = 2, scales = \"free\") \n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\nTable 2 shows the same detail as the above figure, but makes it easier to see what the magnitudes of the probabilities are.\n\n\nCode\n# Widen data so that power is shown by col with each col corresponding to an\n# analysis\nd_tbl &lt;- copy(d_fig)\nd_tbl &lt;- dcast(d_tbl, variable + or ~ type, value.var = \"p\")\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility\", \"fut\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"trt ni ref\", \"trt_ni_ref\", names(d_tbl))\nd_tbl &lt;- d_tbl[order(variable, or)]\n\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"variable\") |&gt; \n  cols_label(\n    or = html(\"Odds ratio&lt;br&gt;(true)\"),\n    sup = html(\"Superiority\"),\n    fut_sup = html(\"Futility (sup)\"),\n    ni = html(\"NI (trt ni ref)\"),\n    fut_ni = html(\"Futility (ni)\"),\n  )  |&gt;\n  fmt_number(\n    columns = everything(),\n    decimals = 3\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or == \"1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOdds ratio\n(true)\nSuperiority\nFutility (sup)\nNI (trt ni ref)\nFutility (ni)\n\n\n\n\nb_r\n\n\n0.500\n0.000\n1.000\n0.003\n0.988\n\n\n0.667\n0.000\n0.998\n0.113\n0.522\n\n\n0.833\n0.000\n0.883\n0.508\n0.046\n\n\n1.000\n0.024\n0.406\n0.847\n0.002\n\n\n1.200\n0.294\n0.043\n0.979\n0.000\n\n\n1.500\n0.864\n0.000\n0.999\n0.000\n\n\n2.000\n1.000\n0.000\n1.000\n0.000\n\n\nb_r1d\n\n\n0.500\n0.000\n0.991\n0.053\n0.735\n\n\n0.667\n0.000\n0.877\n0.226\n0.267\n\n\n0.833\n0.002\n0.554\n0.496\n0.043\n\n\n1.000\n0.021\n0.204\n0.737\n0.005\n\n\n1.200\n0.135\n0.041\n0.891\n0.000\n\n\n1.500\n0.437\n0.002\n0.971\n0.000\n\n\n2.000\n0.809\n0.000\n0.995\n0.000\n\n\nb_r2d\n\n\n0.500\n0.000\n1.000\n0.011\n0.945\n\n\n0.667\n0.000\n0.990\n0.147\n0.429\n\n\n0.833\n0.001\n0.795\n0.505\n0.043\n\n\n1.000\n0.022\n0.337\n0.812\n0.001\n\n\n1.200\n0.209\n0.049\n0.956\n0.000\n\n\n1.500\n0.711\n0.001\n0.996\n0.000\n\n\n2.000\n0.977\n0.000\n1.000\n0.000\n\n\nb_f\n\n\n0.500\n0.000\n1.000\n0.000\n0.999\n\n\n0.667\n0.000\n1.000\n0.072\n0.663\n\n\n0.833\n0.000\n0.967\n0.507\n0.047\n\n\n1.000\n0.030\n0.518\n0.894\n0.000\n\n\n1.200\n0.397\n0.053\n0.991\n0.000\n\n\n1.500\n0.954\n0.000\n1.000\n0.000\n\n\n2.000\n1.000\n0.000\n1.000\n0.000\n\n\n\n\n\n\n\n\nTable 2: Probability of decision\n\n\n\n\nFigure 2 shows the distribution of estimated posterior means by simulated effect size, parameter and scenario.\n\n\n\n\n\n\n\n\nFigure 2: Distribution of posterior means (true log OR shown in red).",
    "crumbs": [
      "Simulations",
      "Simulation results 1"
    ]
  },
  {
    "objectID": "notebooks/model-implementation.html",
    "href": "notebooks/model-implementation.html",
    "title": "Model implementation",
    "section": "",
    "text": "The model used for the simulations translates the binary outcome into a binomial outcome by aggregating over the unique groups. For example with the linear predictor:\n# data generation process\nformals(roadmap.data::get_trial_data)$g\n\nfunction(d, sim_spec) {\n    a0 &lt;- sim_spec$a0\n    m &lt;- sim_spec$m\n    b &lt;- sim_spec$b\n    eta &lt;- a0 + m[\"l1\"] * d$l1 + m[\"l2\"] * d$l2 + (b[\"erx\"] + \n        b[\"erx-r1\"] * d$srp1 + b[\"erx-r2\"] * d$srp2) * d$erx + \n        (b[\"r1\"] * d$srp1 + b[\"r2\"] * d$srp2) * d$r * d$er + \n        (b[\"r1d\"] * d$d * d$srp1 + b[\"r2d\"] * d$d * d$srp2) * \n            d$ed + b[\"efx\"] * d$efx + b[\"f\"] * d$f * d$ef\n    eta\n}\nI get:\n# simulate data\nset.seed(1)\nsim_spec &lt;- roadmap.data::get_sim_spec()\n\nunlist(sim_spec)\n\n         a0        m.l1        m.l2       b.erx    b.erx-r1    b.erx-r2 \n 0.61903921 -0.33718806 -0.08682239 -0.10000000 -0.05000000  0.05000000 \n       b.r1        b.r2       b.r1d       b.r2d       b.efx         b.f \n 0.20000000  0.09000000  0.30000000  0.10000000  0.25000000  0.15000000 \n\nll &lt;- roadmap.data::get_trial_data(N = 2500, sim_spec = sim_spec)\nd &lt;- copy(ll$d)\nhead(d[, .(y = sum(y), n = .N), keyby = .(l, er, ed, ef, r, srp0, srp1, srp2, d, f)])\n\nKey: &lt;l, er, ed, ef, r, srp0, srp1, srp2, d, f&gt;\n       l    er    ed    ef     r  srp0  srp1  srp2     d     f     y     n\n   &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;int&gt; &lt;int&gt;\n1:     0     0     0     0     0     1     0     0     0     0   167   247\n2:     0     0     0     1     0     1     0     0     0     0   112   193\n3:     0     0     0     1     0     1     0     0     0     1   116   197\n4:     0     0     1     0     0     0     1     0     0     0    12    15\n5:     0     0     1     0     0     0     1     0     1     0    11    12\n6:     0     0     1     1     0     0     1     0     0     0     5     7\nThe columns correspond to:\nDuration domain depends on what surgery was received, NOT what was originally planned/assigned. For one-stage 12-weeks is reference group (indicated by 0) vs 6 weeks. For two-stage 7 days is reference group (indicated by 0) vs 12 weeks (1).\nWithin early, late and chronic stage infection, the percentage (by silo, l) receiving each surgery type (srp) as a randomised or non-randomised treatment (er) are:\nPercent receiving each surgery type within silo\nll &lt;- roadmap.data::get_trial_data(N = 1e6, sim_spec = sim_spec)\nd_tbl &lt;- ll$d[, .(n = .N), keyby = .(l, er, srp)]\nd_tbl[, N_l := sum(n), keyby = l]\nd_tbl[, pct := 100 * n / N_l]\nd_tbl[, N_l := NULL]\nd_tbl\n\n\nKey: &lt;l&gt;\n        l    er   srp      n        pct\n    &lt;int&gt; &lt;num&gt; &lt;num&gt;  &lt;int&gt;      &lt;num&gt;\n 1:     0     0     0 270730 90.0593121\n 2:     0     0     1  29883  9.9406879\n 3:     1     0     0   2028  0.4059987\n 4:     1     0     1   2332  0.4668585\n 5:     1     0     2   5717  1.1445239\n 6:     1     1     0 244552 48.9584772\n 7:     1     1     1  73803 14.7751092\n 8:     1     1     2 171077 34.2490325\n 9:     2     0     0  39954 19.9891934\n10:     2     0     1  40146 20.0852520\n11:     2     0     2 119778 59.9255546",
    "crumbs": [
      "Assumptions and setup",
      "Model implementation"
    ]
  },
  {
    "objectID": "notebooks/model-implementation.html#stan-implementation",
    "href": "notebooks/model-implementation.html#stan-implementation",
    "title": "Model implementation",
    "section": "Stan implementation",
    "text": "Stan implementation\nThe model spec can be translated into stan, albeit using a different likelihood spec:\n\n\n\n\ndata {\n  int N;\n  array[N] int y;\n  array[N] int n;\n  // variation due to silo/joint\n  vector[N] l1;\n  vector[N] l2;\n  // reveal\n  vector[N] er;\n  vector[N] ed;\n  vector[N] ef;\n  // surgery\n  vector[N] r;\n  // duration\n  vector[N] d;\n  // vector[N] rp; // revision was recvd\n  vector[N] srp0; // dair recvd\n  vector[N] srp1; // one-stage revision recvd\n  vector[N] srp2; // two-stage revision recvd\n  // choice\n  vector[N] f;\n  \n  vector[2] pri_m_sd;\n  vector[9] pri_b_sd;\n  int prior_only;\n}\ntransformed data{\n  vector[N] erx;\n  vector[N] erx_srp1;\n  vector[N] erx_srp2;\n  vector[N] er_r;\n  vector[N] er_r_srp1;\n  vector[N] er_r_srp2;\n  vector[N] ed_d_srp1;\n  vector[N] ed_d_srp2;\n  vector[N] ef_f;\n  \n  erx = (1-er) ;\n  erx_srp1 = (1-er) .* srp1;\n  erx_srp2 = (1-er) .* srp2;\n  \n  er_r = er .* r;\n  \n  er_r_srp1 = er_r .* srp1;\n  er_r_srp2 = er_r .* srp2;\n\n// you can remove rp srp1 indicates one-stage happened, srp2 indicates two stage\n// the rp becomes redundant.\n  ed_d_srp1 = ed .* d .* srp1;\n  ed_d_srp2 = ed .* d .* srp2;\n\n  ef_f = ef .* f;\n}\nparameters {\n  real a0;\n  vector[2] m;\n  vector[9] b;\n}\ntransformed parameters{\n  vector[N] eta;\n \n  eta = a0 + \n      m[1]*l1 + m[2]*l2 +  \n      (b[1]*erx + b[2]*erx_srp1 + b[3]*erx_srp2)  +\n      (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n      // b[6] * (1 - ed) + \n      (b[6]*ed_d_srp1 + b[7]*ed_d_srp2)  + \n      b[8] * (1 - ef) + (b[9]*ef_f);\n      \n}\nmodel{\n  target += logistic_lpdf(a0 | 0, 1);\n  target += normal_lpdf(m | 0, pri_m_sd);\n  target += normal_lpdf(b | 0, pri_b_sd);\n  \n  // likelihood chunks pertaining to each silo\n  if(!prior_only){\n    target += binomial_logit_lpmf(y | n, eta) ;      \n  }\n  \n  \n}\ngenerated quantities{\n\n  // vector[N] eta_r_0;\n  // vector[N] eta_r_1;\n  // vector[N] eta_d_0;\n  // vector[N] eta_d_1;\n  // vector[N] eta_f_0;\n  // vector[N] eta_f_1;\n  // \n  // {\n  // \n  //   // predictions on log-odds scale setting all participants to the level\n  //   // of interest, e.g. assume all have r = 0\n  //   eta_r_0   =  a0 +\n  //     m[1]*l1   + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     // b[6] * (1 - ed  ) + \n  //     (b[6]*ed_d_srp1   + b[7]*ed_d_srp2)   +\n  //     b[8] * (1 - ef  ) + (b[9]*ef_f)  ;\n  //   // r = 1\n  //   // (only those revealed to surgery domain contribute due to the er term)\n  //   eta_r_1   =  a0 +\n  //     m[1]*l1   + m[2]*l2 +\n  //     // note the use of er here and not er_r, i.e. the r is set to 1 for\n  //     // everyone\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er .* srp1 + b[5]*er .* srp2) +\n  //     // b[6] * (1 - ed  ) + \n  //     (b[6]*ed_d_srp1   + b[7]*ed_d_srp2)   +\n  //     b[8] * (1 - ef  ) + (b[9]*ef_f);\n  // \n  //   // duration, d = 0\n  //   eta_d_0   =  a0 +\n  //     m[1]*l1 + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n  //     // b[6] * (1 - ed) +\n  //     b[8] * (1 - ef) + (b[9]*ef_f);\n  //   // d = 1\n  //   eta_d_1   =  a0 +\n  //     m[1]*l1 + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n  //     // note the use of ed and rp here and not ed_rp_d_srp1, i.e. the d is\n  //     // set to 1 for everyone\n  //     // b[6] * (1 - ed) + \n  //     (b[6]*ed .* srp1 + b[7]*ed .* srp2)  +\n  //     b[8] * (1 - ef) + (b[9]*ef_f);\n  // \n  //   // choice, f = 0\n  //   eta_f_0   =  a0 +\n  //     m[1]*l1 + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n  //     // b[6] * (1 - ed) + \n  //     (b[6]*ed_d_srp1 + b[7]*ed_d_srp2)  +\n  //     b[8] * (1 - ef)  ;\n  //   // f = 1\n  //   eta_f_1   =  a0 +\n  //     m[1]*l1 + m[2]*l2 +\n  //     (b[1] * erx_srp0 + b[2] * erx_srp1 + b[3] * erx_srp2) +\n  //     (b[4]*er_r_srp1 + b[5]*er_r_srp2) +\n  //     // b[6] * (1 - ed) + \n  //     (b[6]*ed_d_srp1 + b[7]*ed_d_srp2)  +\n  //     // note the use of ef here and not ef_f\n  //     b[8] * (1 - ef) + (b[9]*ef);\n  // \n  // }\n\n}\n\n\nThe model is fitted to a large dataset and the posterior summarised to determine if the parameter estimates approximate the known values.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThere are some terms in the model that under ‘ideal’ situation, i.e. where all patients are revealed as initially intended, that may cause estimation problems. These issues can manifest as sluggish MCMC or weird NA terms appearing in the regression results. In general an NA in the regression results from lm means that the coefficient is not estimable. This can happen due to exact collinearity, e.g. when Q3 = a Q1 + b Q2 + c for some a, b and c, but, it can also happen due to not having enough observations to estimate the relevant parameters (e.g. if p &gt;&gt; n). If you predictors are categorical and you’re adding interaction terms, an NA can also mean that there are no observations with that combination of levels of the factors.\n\n\n\n\n\nCode\nm4 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-04.stan\")\n\nset.seed(1)\n\nsim_spec &lt;- roadmap.data::get_sim_spec()\nsim_spec$a0  &lt;- qlogis(0.65)\nsim_spec$m[\"l1\"] &lt;- 0.57\nsim_spec$m[\"l2\"] &lt;- 0.64\nsim_spec$b[\"erx\"] &lt;- -0.1\nsim_spec$b[\"erx-r1\"] &lt;- -0.05\nsim_spec$b[\"erx-r2\"] &lt;- 0.05\nsim_spec$b[\"r1\"] &lt;- -0.6931472\nsim_spec$b[\"r2\"] &lt;- -0.6931472\n# sim_spec$b[\"edx\"] &lt;- -0.07\nsim_spec$b[\"r1d\"] &lt;- -0.6931472\nsim_spec$b[\"r2d\"] &lt;- -0.6931472\nsim_spec$b[\"efx\"] &lt;- -0.2\nsim_spec$b[\"f\"] &lt;- -0.6931472\n\n\nll &lt;- roadmap.data::get_trial_data(N = 2e6, sim_spec = sim_spec)\nlsd &lt;- roadmap.data::get_stan_data(ll$d)\n\nd &lt;- copy(ll$d)\nd_s &lt;- copy(lsd$d_s)\nld &lt;- lsd$ld\n\n\n# ld$pri_m_sd &lt;- rep(1, 2)\n# ld$pri_b_sd &lt;- rep(1, 9)\n\nf1 &lt;- m4$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 1.4 seconds.\nChain 2 finished in 1.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 1.5 seconds.\nTotal execution time: 1.6 seconds.\n\n\nCode\n# See note above. edx is dropped from the model as it is collinear with\n# srp1 and srp2 and leads to an estimation issue.\n\nf2 &lt;- glm(y ~ l1 + l2 +\n            erx + erx:srp1 + erx:srp2 +\n            er:r:srp1 + er:r:srp2 +\n            # edx +\n            ed:d:srp1 + ed:d:srp2 +\n            efx + ef:f,  \n          data = d, family = binomial())\n\n# summary(f2)\n\n# dtmp &lt;- data.table(model.matrix(f2)) \n# dtmp &lt;- cbind(model.matrix(f2), tot = 0)\n# pracma::rref(dtmp)\n# d_s\n\n# dtmp &lt;- data.table(model.matrix(f2))\n# \n# rref(dtmp)\n# dtmp.mean &lt;- apply(dtmp, 2, mean)\n# dtmp &lt;- sweep(dtmp, 2, dtmp.mean)\n# \n# f3 &lt;- prcomp(dtmp)\n# print(f3)\n# \n# # Fairly unsafe - checking for full rank on removal of each var\n# linearly_dep_cols(f2)\n\n\nThe parameter estimates align reasonably well to the simulation parameters used in the linear predictor:\n\n\nCode\npost1 &lt;- data.table(f1$draws(variables = c(c(\"a0\", \"m\", \"b\")), format = \"matrix\"))\ncf &lt;- coef(f2)\n\nround(rbind(\n  \"Simulation parameters\" = c(sim_spec$a0, sim_spec$m, sim_spec$b),\n  \"Posterior means\" = colMeans(post1),\n  \"Max likelihood\" = c(\n    cf[1:3], \n    cf[\"erx\"], cf[\"erx:srp1\"], cf[\"erx:srp2\"], \n    cf[\"srp1:er:r\"], cf[\"srp2:er:r\"] , \n    # cf[\"edx\"],\n    cf[\"srp1:ed:d\"], cf[\"srp2:ed:d\"],\n    cf[\"efx\"], cf[\"ef:f\"]\n  )\n), 4)\n\n\n                                 l1     l2     erx  erx-r1 erx-r2      r1\nSimulation parameters 0.6190 0.5700 0.6400 -0.1000 -0.0500 0.0500 -0.6931\nPosterior means       0.6201 0.5651 0.6365 -0.1042 -0.0585 0.0664 -0.6996\nMax likelihood        0.6203 0.5649 0.6365 -0.1045 -0.0585 0.0664 -0.6995\n                           r2     r1d     r2d    efx       f\nSimulation parameters -0.6931 -0.6931 -0.6931 -0.200 -0.6931\nPosterior means       -0.6927 -0.6844 -0.7004 -0.197 -0.6918\nMax likelihood        -0.6927 -0.6845 -0.7004 -0.197 -0.6918",
    "crumbs": [
      "Assumptions and setup",
      "Model implementation"
    ]
  },
  {
    "objectID": "notebooks/model-implementation.html#estimation---g-computation",
    "href": "notebooks/model-implementation.html#estimation---g-computation",
    "title": "Model implementation",
    "section": "Estimation - G-computation",
    "text": "Estimation - G-computation\nThis section is now incomplete due to the revised model specification.\n\n\n\n\n\n\nNote\n\n\n\n\n\nCalculations based on Bayesian model are complicated by virtue of use of binomial instead of bernoulli likelihood. To deal with this, we weight the log-odds contributions by the number of trials associated with each unique combination.\n\n\n\nPredictions on log-odds scale:\n\neta_r_0 &lt;- f1$draws(variables = c(\"eta_r_0\"), format = \"matrix\")\neta_r_1 &lt;- f1$draws(variables = c(\"eta_r_1\"), format = \"matrix\")\neta_d_0 &lt;- f1$draws(variables = c(\"eta_d_0\"), format = \"matrix\")\neta_d_1 &lt;- f1$draws(variables = c(\"eta_d_1\"), format = \"matrix\")\neta_f_0 &lt;- f1$draws(variables = c(\"eta_f_0\"), format = \"matrix\")\neta_f_1 &lt;- f1$draws(variables = c(\"eta_f_1\"), format = \"matrix\")\n\nThe G-formula allows you to go from a conditional estimate to a marginal one via standardisation or other means.\n\n# g-comp - calculations are complicated by virtue of use of binomial\n# instead of bernoulli model. Approach is to weight the log-odds contributions\n# by the number of trials associated with each unique combination.\n\nmax_rows &lt;- 1000\n\n# Compute the effect of revision\nb_r &lt;- do.call(rbind, mclapply(1:(min(nrow(eta_r_0), max_rows)), function(ii){\n  \n  # columns in eta_r_0 correspond to the covariate groups, i.e. the rows in d_s\n  \n  # The repitition gives the right contribution (weight) for each covariate \n  # combination i.e. each column (covariate combination) is replicated by \n  # the number of pts with this covariate combination. \n  \n  # This first one is averaged across both non-reveal and revealed. It is not\n  # what we want\n  lo_0 &lt;- eta_r_0[ii, rep(1:nrow(d_s), times = ld$n)]\n  lo_1 &lt;- eta_r_1[ii, rep(1:nrow(d_s), times = ld$n)]\n  mu_r = mean(lo_1 - lo_0)\n  \n  # Should be no effect of rev in those that were not rand to surg\n  # idx &lt;- d_s[er == 0 , which = T]\n  # lo_0_erx &lt;- eta_r_0[ii, rep(idx, times = ld$n[idx])]\n  # lo_1_erx &lt;- eta_r_1[ii, rep(idx, times = ld$n[idx])]\n  # mu_r_erx &lt;- sum(lo_1_erx - lo_0_erx) / sum(ld$n[idx])\n  \n  # Finally, these give the effect in those revealed to surgery domain. This\n  # is what we want.\n  idx &lt;- d_s[er == 1 , which = T]\n  lo_0_erx &lt;- eta_r_0[ii, rep(idx, times = ld$n[idx])]\n  lo_1_erx &lt;- eta_r_1[ii, rep(idx, times = ld$n[idx])]\n  mu_r_er &lt;- sum(lo_1_erx - lo_0_erx) / sum(ld$n[idx])\n  \n  # avg effect then effect in non-reveal and reveal\n  c(\"mu_r\" = mu_r, \n    # \"mu_r_erx\" = mu_r_erx, \n    \"mu_r_er\" = mu_r_er)\n}, mc.cores = 10))\n\n\n# Compute the effect of duration for the pt that received one-stage\n# and for those that received two-stage surgery.\nb_d &lt;- do.call(rbind, mclapply(1:(min(nrow(eta_d_0), max_rows)), function(ii){\n  \n  lo_0 &lt;- eta_d_0[ii, rep(1:nrow(d_s), times = ld$n)]\n  lo_1 &lt;- eta_d_1[ii, rep(1:nrow(d_s), times = ld$n)]\n\n  # stratification, silo/revision type that actually took place\n  # idx &lt;- d_s[ed == 0 & srp2 == 0, which = T]\n  # lo_0_edx_srp1 &lt;- eta_d_0[ii, rep(idx, times = ld$n[idx])]\n  # lo_1_edx_srp1 &lt;- eta_d_1[ii, rep(idx, times = ld$n[idx])]\n  # mu_d_edx_srp1 &lt;- sum(lo_1_edx_srp1 - lo_0_edx_srp1) / sum(ld$n[idx])\n  # \n  # idx &lt;- d_s[ed == 0 & srp2 == 1, which = T]\n  # lo_0_edx_srp2 &lt;- eta_d_0[ii, rep(idx, times = ld$n[idx])]\n  # lo_1_edx_srp2 &lt;- eta_d_1[ii, rep(idx, times = ld$n[idx])]\n  # mu_d_edx_srp2 &lt;- sum(lo_1_edx_srp2 - lo_0_edx_srp2) / sum(ld$n[idx])\n\n  idx &lt;- d_s[ed == 1 & srp2 == 0, which = T]\n  lo_0_ed_srp1 &lt;- eta_d_0[ii, rep(idx, times = ld$n[idx])]\n  lo_1_ed_srp1 &lt;- eta_d_1[ii, rep(idx, times = ld$n[idx])]\n  mu_d_ed_srp1 &lt;- sum(lo_1_ed_srp1 - lo_0_ed_srp1) / sum(ld$n[idx])\n\n  idx &lt;- d_s[ed == 1 & srp2 == 1, which = T]\n  lo_0_ed_srp2 &lt;- eta_d_0[ii, rep(idx, times = ld$n[idx])]\n  lo_1_ed_srp2 &lt;- eta_d_1[ii, rep(idx, times = ld$n[idx])]\n  mu_d_ed_srp2 &lt;- sum(lo_1_ed_srp2 - lo_0_ed_srp2) / sum(ld$n[idx])\n\n  c(\"mu_d\" = mean(lo_1 - lo_0), \n    # you need to base the mean on the n that were used in the strata\n    # \"mu_d_edx_srp1\" = mu_d_edx_srp1,  \"mu_d_edx_srp2\" = mu_d_edx_srp2,\n    \"mu_d_ed_srp1\" = mu_d_ed_srp1, \"mu_d_ed_srp2\" = mu_d_ed_srp2\n    )\n  \n}, mc.cores = 10))\n\n# Compute the effect of AB choice.\nb_f &lt;- do.call(rbind, mclapply(1:(min(nrow(eta_f_0), max_rows)), function(ii){\n  \n  # Avg effect of rif - what is the effect of rif in the sample population\n  # Might be wrong, but don't believe this is a meaningful/useful quantity.\n  lo_0 &lt;- eta_f_0[ii, rep(1:nrow(d_s), times = ld$n)]\n  lo_1 &lt;- eta_f_1[ii, rep(1:nrow(d_s), times = ld$n)]\n  mu_f &lt;- mean(lo_1 - lo_0)\n  \n  # Should be no effect of rif in those that were not rand to choice\n  # idx &lt;- d_s[ef == 0 , which = T]\n  # lo_0_efx &lt;- eta_f_0[ii, rep(idx, times = ld$n[idx])]\n  # lo_1_efx &lt;- eta_f_1[ii, rep(idx, times = ld$n[idx])]\n  # mu_f_efx &lt;- sum(lo_1_efx - lo_0_efx) / sum(ld$n[idx])\n\n  # Effect of rif in those rand to choice domain\n  idx &lt;- d_s[ef == 1 , which = T]\n  lo_0_ef &lt;- eta_f_0[ii, rep(idx, times = ld$n[idx])]\n  lo_1_ef &lt;- eta_f_1[ii, rep(idx, times = ld$n[idx])]\n  mu_f_ef &lt;- sum(lo_1_ef - lo_0_ef) / sum(ld$n[idx])\n  \n  c(\"mu_f\" = mu_f, \n    # \"mu_f_efx\" = mu_f_efx, \n    \"mu_f_ef\" = mu_f_ef)\n}, mc.cores = 10))\n\nThe following provides the results and also comparisons to combinations of parameters used in data simulation.\nFor the surgery domain, the comparison of interest is dair (ref) vs revision, which can be obtained by averaging over the distribution of surgery type that took place. The revision effects are silo-specific in that only the late silo is randomised which we obtain by producing a conditional treatment effect by stratifying on the reveal status (er).\n\n\n\n\n\n\nWarning\n\n\n\n\n\nI don’t believe that we currently need to worry about differential selection (\\(\\mathbb{P}(S=s|G=1)\\ne\\mathbb{P}(S=s|G=2)\\)) because only one silo is contributing to the randomised comparison and I think we are restricting to that silo by virtue of conditiong on er.\n\n\n\n\n# dair (ref)  vs revision (of any form)\navg_comparisons(f2, variables = \"r\", comparison = \"lnor\")\n\n\n Term              Contrast Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 % 97.5 %\n    r ln(odds(1) / odds(0))   -0.167    0.00118 -141   &lt;0.001 Inf -0.169 -0.165\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n# The above call to avg_comparisons is equivalent to:\n# w_eta_r0 &lt;- sweep(eta_r0, 1, ld$n, \"*\")\nd_new &lt;- copy(d)\nlo &lt;- copy(d_new[, r := 0])\nd_new &lt;- copy(d)\nhi &lt;- copy(d_new[, r := 1])\ny_lo &lt;- predict(f2, newdata = lo)\ny_hi &lt;- predict(f2, newdata = hi)\nmean(y_hi - y_lo)\n\n[1] -0.1701395\n\n# But we are only interested in the effect of r in the group that were revealed.\n# The following, in avg_comparisons, does not make sense to me. Need to revisit.\n# cmp &lt;- avg_comparisons(f2, newdata = d[er == 1 & r == 1], variables = \"r\", comparison = \"lnor\")\n# print(cmp, digits = 6)\n\n# The randomised comparison should approx map to a weighted combination of the pars.\n# The reason that the weights are computed conditional on r == 1 is so that we are\n# weight by the proportion within the revision group that receive each revision type \n# (approx 30% one-stage, 70% two-stage) and not the proportion receiving each revision \n# type over all those that received randomised surgery (approx 50% dair, 15% one, 35% two).\nmean(d[er == 1 & r == 1, mean(srp1)] * post1$`b[4]` + d[er == 1 & r == 1, mean(srp2)] * post1$`b[5]`) \n\n[1] -0.6947469\n\n\nThe above series of outputs suggest somewhat that we are able to recover the required parameters using various approaches.\nFor the choice domain, the comparison of interest is no-rf (ref) vs rif, which can be obtained directly from the parameter estimate that characterised the effects of the randomised comparisons. Choice domain effects reflect an average over the silos since all silos can enter this domain.\n\n# no-rif (ref)  vs rif (of any form)\n# NO - avg_comparisons(f2, variables = \"f\", comparison = \"lnor\")\n# We are only interested in the effect of choice for those revealed to choice\n# cmp &lt;- avg_comparisons(f2, newdata = d[ef == 1], variables = \"f\", comparison = \"lnor\")\n# print(cmp, digits = 6)\n\n# colMeans(b_f)\n# And this should just be the same as the coefficient from the model\nmean(post1$`b[9]`)\n\n[1] -0.6918082\n\n\nFor the duration domain, the comparison of interest can be obtained directly from the parameter estimates that characterised the effects of the randomised comparisons. Duration domain effects are also currently reflecting an average over the silos.\n\n# long (ref) vs short (specific to the type of surg recvd - one or two stage)\n\ncmp &lt;- avg_comparisons(f2, newdata = d[ed == 1 ], variables = \"d\", comparison = \"lnor\", by = \"d\")\nprint(cmp, digits = 6)\n\n\n Term              Contrast d  Estimate Std. Error        z Pr(&gt;|z|)   S\n    d ln(odds(1) / odds(0)) 0 -0.664385 0.00422153 -157.380  &lt; 0.001 Inf\n    d ln(odds(1) / odds(0)) 1 -0.664248 0.00422073 -157.377  &lt; 0.001 Inf\n     2.5 %    97.5 %\n -0.672659 -0.656111\n -0.672521 -0.655976\n\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\ncmp &lt;- avg_comparisons(f2, newdata = d[ed == 1 & srp2 == 1], variables = \"d\", comparison = \"lnor\")\nprint(cmp, digits = 6)\n\n\n Term              Contrast  Estimate Std. Error        z Pr(&gt;|z|)   S\n    d ln(odds(1) / odds(0)) -0.667456  0.0051575 -129.415  &lt; 0.001 Inf\n     2.5 %    97.5 %\n -0.677565 -0.657348\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n# colMeans(b_d)\n\n# The randomised comparison should approx map directly to the surg type \n# specific pars \nmean(post1$`b[6]`) \n\n[1] -0.6843975\n\nmean(post1$`b[7]` ) \n\n[1] -0.7003817\n\n\nBased on the above, we seem to be in the right ballpark.",
    "crumbs": [
      "Assumptions and setup",
      "Model implementation"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html",
    "href": "notebooks/design-notes-05.html",
    "title": "Marginal-ish effects",
    "section": "",
    "text": "The following DAG includes surgical, antibiotic backbone, extended prophylactic and choice domains. Additionally, site of infection (knee/hip) and baseline clinician preferences are included where the latter are assumed to take primacy in selection of surgery type etc. The setup is intended to represent the approximate structure, not to replicate the exact data generating process.\nPreference for surgery primarily impacts those assigned to revision but would also be applicable for a patient that ends up switching treatment, for example switch from dair to revision due to a irreparable loose joint. Preference for antibiotic duration comes into play for dair and two-stage patients since these units are never randomly assigned to duration. For example, if a unit received dair, then the preference would lead to some duration of backbone antibiotic therapy. Analogously, preference for extended prophylactic applies where the unit didn’t enter the extended prophylaxis domain even though they received a two-stage revision; here prophylaxis would be determined by the clinician assessment of what is best. For antibiotic choice (rifampicin), it is conceivable that patients are eligible for the domain but the clinician is not willing to risk them being allocated to the control arm, hence the possibility of clinical selection is included for that domain as well. Only a subset of the cohort will ever enter the choice domain anyway.\nA joint-by-surgical type (dair, one, two-stage) interaction is explicitly included (denoted with \\(S_A \\times J\\)). There may be others that are of interest. My guess is that infection site will also influence the approach adopted for revision, but that is not reflected here (I don’t think it would make any difference to the statistical considerations anyway).\nPreviously, we have talked about direct paths, but these are assumed not to exist. This is because you cannot define, for example surgical procedure, as a mediator because \\(Y(a,m)\\) would need to be defined for both \\(a=0\\) and \\(a=1\\) and it is only makes sense in the context of the latter. There are therefore no direct paths within the causal structure.\nMentally I am restricting myself to the late silo and specifically to the question of the surgical intervention and hence conditioning on that silo is implicit here and not mentioned within the DAG or models.\nGiven the above, some of the following may not align with a generic perspective applicable to the other silos.\nFigure 1: Late silo units DAG (extension incorporating interactions on the DAG follows the proposal by Attia (https://doi.org/10.1093/ije/dyac126))\nThroughout, I will represent the nodes with:\nThe total effect of surgery (\\(A\\)) on outcome (\\(Y\\)) is identifiable. However, the total effect is the effect of treatment through all paths, so it amounts to a comparison of surgery plus some possible antibiotic duration and extended prophylaxis, i.e. all the open paths below.\nCode\ndo.call(cbind, paths(dag1))\n\n\n     paths                        open   \n[1,] \"a -&gt; sa -&gt; axj -&gt; y\"        \"TRUE\" \n[2,] \"a -&gt; sa -&gt; axj &lt;- j -&gt; y\"   \"FALSE\"\n[3,] \"a -&gt; sa -&gt; sd1 -&gt; y\"        \"TRUE\" \n[4,] \"a -&gt; sa -&gt; sd1 &lt;- ud1 -&gt; y\" \"FALSE\"\n[5,] \"a -&gt; sa -&gt; sd2 -&gt; y\"        \"TRUE\" \n[6,] \"a -&gt; sa -&gt; sd2 &lt;- ud2 -&gt; y\" \"FALSE\"\n[7,] \"a -&gt; sa -&gt; y\"               \"TRUE\" \n[8,] \"a -&gt; sa &lt;- ua -&gt; y\"         \"FALSE\"\nNo adjustment is necessary to obtain the total effect but under the design this obfuscates attribution due to the various interventions.",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#surgical-domain-model",
    "href": "notebooks/design-notes-05.html#surgical-domain-model",
    "title": "Marginal-ish effects",
    "section": "Surgical domain model",
    "text": "Surgical domain model\nPer the above, we could simply regress on assigned surgical treatment to obtain the total effect. However, for the surgical domain it is informative to use the following model specification:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | \\pmb{Q}; \\pmb{\\zeta}] &= \\beta_0 + \\beta_1 (S_A = 1) + \\beta_2 (S_A = 2) + \\beta_3 U_A + \\\\\n& \\beta_4 S_{D1} + \\beta_5 U_{D1} + \\\\\n& \\beta_6 S_{C} + \\beta_7 U_{C} + \\\\\n& \\beta_8 J + \\\\\n& \\beta_9 S_{D2} + \\beta_{10} U_{D2} + \\\\\n& \\gamma_1 (S_A = 1) J + \\gamma_2 (S_A = 2) J\n\\end{aligned}\n\\]\nwhere \\(\\pmb{Q}\\) and \\(\\pmb{\\zeta}\\) represent the vector of conditional elements and with the parameters for \\(D2\\) (\\(\\beta_9\\) and \\(\\beta_{10}\\)) being relevant only for the cohort receiving two-stage revision.\nTo get back to a view on dair vs revision we can use the g-formula to average over all the other terms and then compute a weighted combination of the one-stage and two-stage effects based on the distribution of these in the sample. For example, say the only conditioning element we have is \\(U_A\\) and \\(Y(a)\\) denotes the potential outcomes with respect to the randomised surgery type:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y(0)] &= \\mathbb{E}_{U_A}[  \\mathbb{E}[Y | S_A = 0, U_A = u_a] ] \\\\\n  &= \\sum_{u_A} \\mathbb{P}(U_A = u_a) \\left(\\sum_{y} y \\mathbb{P}(Y = y | S_A = 0, U_A = u_a) \\right)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y(1)] &= \\mathbb{E}_{U_A}[  \\mathbb{E}[Y | S_A \\in \\{ 1, 2\\}, U_A = u_a] ] \\\\\n  &= \\sum_{u_A} \\mathbb{P}(U_A = u_a) \\left(\\sum_{y} y \\mathbb{P}(Y = y | S_A = \\in \\{ 1, 2\\}, U_A = u_a) \\right)\n\\end{aligned}\n\\]\nThe model is implemented in stan as follows:\n\n\nLogistic regression with bootstrap in stan\ndata {\n  int N;\n  array[N] int y;\n  array[N] int n;\n  // for one an two-stage indicators \n  // these are the main effects of interest\n  int P1;\n  matrix[N, P1] X1;\n  // other terms bar interactions and ext proph related\n  int P2;\n  matrix[N, P2] X2;\n  // extra fields for extended proph\n  int P3;\n  matrix[N, P3] X3;\n  // fields for interactions\n  int P4;\n  matrix[N, P4] X4;\n  // auxiliary terms\n  // observed probability of one-stage\n  real pr_one;\n  // number preferring 1/2 stage under rev\n  int N1;\n  int N2;\n  array[N1] int ix1;\n  array[N2] int ix2;\n  // priors\n  int prior_only;\n  real sd_a0;\n  real sd_b1;\n  real sd_b2;\n  real sd_b3;\n  real sd_b4;\n}\ntransformed data {\n}\nparameters{\n  real a0;\n  // surgical effects\n  vector[P1] b1;\n  // other terms\n  vector[P2] b2;\n  // ext prophy\n  vector[P3] b3;\n  // interactions\n  vector[P4] b4;\n}\ntransformed parameters{\n  vector[N] eta;\n  for(i in 1:N){\n    // X1[i,2] should be an indicator of whether two-stage has been done\n    if(X1[i,2] == 0){\n      eta[i] = a0 + X1[i,]*b1 + X2[i,]*b2 +             X4[i, ]*b4 ;    \n    }\n    if(X1[i,2] == 1){\n      eta[i] = a0 + X1[i,]*b1 + X2[i,]*b2 + X3[i,]*b3 + X4[i, ]*b4 ;     \n    }\n  }\n}\nmodel{\n  target += normal_lpdf(a0 | 0, sd_a0);\n  target += normal_lpdf(b1 | 0, sd_b1);\n  target += normal_lpdf(b2 | 0, sd_b2);\n  target += normal_lpdf(b3 | 0, sd_b3);\n  target += normal_lpdf(b4 | 0, sd_b4);\n  if(!prior_only){\n    target += binomial_logit_lpmf(y | n, eta);  \n  }\n}\ngenerated quantities{\n  vector[N] p;    \n  real marg_p0;                                               \n  real marg_p1;       \n  real rd;                                                    \n                                                              \n  vector[N] cond_p0;                                          \n  vector[N] cond_p1;                                               \n                                                              \n  // to get to pate rather than sate                          \n  // Bayesian bootstrap (weights)                             \n  vector[N] w = dirichlet_rng(to_vector(n)); \n                                                              \n  p = inv_logit(eta);\n  \n  // drop out the terms relating to sa == 1 and sa == 2\n  // drop out last two terms that are only applicable for sa == 2\n  // dair - no X4 since sa = 0 hence zero contribution.\n  cond_p0 = inv_logit(a0 +         X2*b2); \n  // one\n  cond_p1[ix1] = inv_logit(a0 + b1[1] + X2[ix1,]*b2 +         X4[ix1,]*b4); \n  // two\n  cond_p1[ix2] = inv_logit(a0 + b1[2] + X2[ix2,]*b2 + X3[ix2,]*b3 + X4[ix2,]*b4);                          \n                                                              \n  // taking average over bayesian bootstrap weights           \n  marg_p0 = w' * cond_p0;                                  \n  marg_p1 = w' * cond_p1;    \n\n  rd = marg_p1 - marg_p0;\n}\n\n\nwhere the bootstrap functionality is used as a standardisation procedure and which could be extended to estimate strata level effects such as those relating to site of infection (knee/hip).\nBelow are scenarios with different combinations of effects that aims to illustrate the main limitation of the design. The assumed effect sizes are purely illustrative.",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#example-1---null-case",
    "href": "notebooks/design-notes-05.html#example-1---null-case",
    "title": "Marginal-ish effects",
    "section": "Example 1 - null case",
    "text": "Example 1 - null case\n\n\nGeneric data generation function\nn = 200\nget_data &lt;- function(\n    n = 200,\n    ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n      # provide a sensible linear predictor.\n      p &lt;- rep(0.5, length(a))\n      p\n      \n      })\n{\n  # joint\n  j &lt;- rbinom(n, 1, 0.5)\n  \n  # choice\n  c &lt;- rbinom(n, 1, 0.5)\n  # The clinical perspective overlay encapsulate entry into the domain.\n  # Entry implies the unit meets the conditions for rand to rif\n  uc &lt;- rbinom(n, 1, 0.6)\n  # Type received \n  sc &lt;- rep(NA, n)\n  sc[uc == 0] &lt;- c[uc == 0]\n  # those that do not enter do not get rif\n  sc[uc == 1] &lt;- 0\n  \n  # assigned surgery - just assume that all enter into this domain\n  a &lt;- rbinom(n, 1, 0.5)\n  # under receipt of rev, most clinicians would prefer to use two-stage\n  ua &lt;- rbinom(n, 1, 0.75)\n  \n  # dair = 0, one = 1, two = 2\n  sa &lt;- rep(NA, n)\n  # assume full adherence in dair group\n  sa[a == 0] &lt;- 0\n  # assigned to rev:  gets either one or two stage\n  ix &lt;- which(a == 1); \n  sa[ix] &lt;- ua[ix] + 1\n  \n  \n  # random assignment of duration 6vs12\n  d1 &lt;- sample(c(6,12), n, T)\n  # pref for duration of therapy after first op is towards longer durn\n  ud1 &lt;- sample(seq(4, 12, by = 2), n, T, 1:5/sum(1:5))\n  \n  # random assignment of prophylaxis\n  d2 &lt;- rbinom(n, 1, 0.5)\n  # most prefer to use prophylaxis\n  ud2 &lt;- rbinom(n, 1, 0.7)\n  \n  \n  # duration of antibiotic following first procedure\n  sd1 &lt;- rep(NA, n)\n  # for those getting dair, duration after first opn is exactly per pref\n  sd1[sa == 0] &lt;- ud1[sa == 0]\n  # assume full adherence in one-stage group\n  # 6 wk vs 12 wk\n  sd1[sa == 1] &lt;- d1[sa == 1]\n  # for those getting two-stage, duration after first opn is per pref\n  sd1[sa == 2] &lt;- ud1[sa == 2]\n  \n  # prophylaxis\n  sd2 &lt;- rep(NA, n)\n  # for those getting two-stage it is per the randomisation\n  sd2[sa == 2] &lt;- d2[sa == 2]\n  # otherwise it isn't defined but assign it to what it would be set to \n  # if the unit were to get two-stage\n  # these units will not be used in the likelihood, but they would be used \n  # in the bootstrap step.\n  sd2[sa != 2] &lt;- d2[sa != 2]\n    \n  d &lt;- data.table(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc)\n  \n  # outcome\n  d[, p_y := ff(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc)]\n  d[, y := rbinom(.N, 1, prob = p_y)]\n\n  d\n}\n\n\nHere all domain treatment effects are set to zero, however, the some baseline variables have been assumed to create heterogeneity in the response. Rather than repeat simulation, the model is fit to a large simulated dataset to get a sense of consistency.\n\n\nData simulation and parameter estimation\nset.seed(987654321)\ng_pars &lt;- c(paste0(\"b1[\",1:2,\"]\"),\n          paste0(\"b2[\",1:6,\"]\"),\n          paste0(\"b3[\",1:2,\"]\"),\n          paste0(\"b4[\",1:2,\"]\")\n          )\nnames(g_pars) &lt;- c(\n  \"b1 (sa1)\", \"b2 (sa2)\", \"b3 (ua)\", \n  \"b4 (sd1)\", \"b5 (ud1)\",\n  \"b6 (sc)\", \"b7 (uc)\",\n  \"b8 (j)\",\n  \"b9 (sd2)\", \"b10 (ud2)\",\n  \"g1 (sa1 x j)\", \"g2 (sa2 x j)\"\n)\n\n\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-03.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-02.stan\")\n  \nd &lt;- get_data(\n  n = 1e5,\n  ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n  \n    p &lt;- rep(NA, length(a))\n    \n    # dair\n    ix &lt;- which(sa == 0)\n    # e.g.\n    # ua: pref for two-stage suggests less sev pt\n    # sa: one-stage does nothing\n    # sa: two-stage does nothing\n    # ud1: pref for longer duration suggests more sev pt\n    # d1: duration does nothing\n    # d2: is irrelevant for dair cohort\n    # uc: does nothing\n    # c: does nothing\n    \n    p[ix] &lt;- 0.6 + \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n      \n    # one-stage\n    ix &lt;- which(sa == 1)\n    p[ix] &lt;- 0.6 + \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n    \n    # two-stage\n    ix &lt;- which(sa == 2)\n    p[ix] &lt;- 0.6 +  \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2)  + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      # last two parameters not included for dair and one-stage\n      0.0*sd2[ix] + 0*ud2[ix] +\n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n      \n    p\n  })\n\n# d[, .(.N, mean(y)), keyby = a]\n\nd[, `:=`(sa1 = as.numeric(d$sa == 1), sa2 = as.numeric(d$sa == 2))]\nd_s &lt;- d[, .(y = sum(y), n = .N, p_y = unique(p_y)), keyby = .(\n  sa1, sa2, ua, sd1, ud1, sc, uc, j, sd2, ud2, j \n)]\n\n# Model treats X[, 2] as being indicator of two-stage\nX1 &lt;- cbind(d_s$sa1, d_s$sa2)\n# all others bar interactions\nX2 &lt;- cbind(d_s$ua, d_s$sd1, d_s$ud1, d_s$sc, d_s$uc, d_s$j)\n# extended prophylaxis terms - only applies to two-stage pt\nX3 &lt;- cbind(d_s$sd2, d_s$ud2)\n# interactions\nX4 &lt;- cbind(d_s$j*d_s$sa1, d_s$j*d_s$sa2)\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X1 = X1, X2 = X2, X3 = X3, X4 = X4,\n  P1 = ncol(X1), P2 = ncol(X2), P3 = ncol(X3), P4 = ncol(X4),\n  # number of recs preference for 1/2 under revision\n  N1 = d_s[ua == 0, .N], N2 = d_s[ua == 1, .N],\n  # idx for pref for 1/2\n  ix1 = d_s[ua == 0, which = T],\n  ix2 = d_s[ua == 1, which = T],\n  pr_one = d[, mean(ua == 0)],\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b1 = 3, sd_b2 = 3, sd_b3 = 3, sd_b4 = 3\n)   \n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 11.4 seconds.\nChain 2 finished in 12.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 11.8 seconds.\nTotal execution time: 12.3 seconds.\n\n\nData simulation and parameter estimation\n# snk &lt;- capture.output(\n#       f1 &lt;- m1$pathfinder(ld, num_paths=20, single_path_draws=200,\n#                              history_size=50, max_lbfgs_iters=100,\n#                              refresh = 0, draws = 2000)\n#     )\n# f_mode &lt;- m1$optimize(data = ld, jacobian = TRUE, refresh =0)\n# f1 &lt;- m1$laplace(data = ld, mode = f_mode, refresh = 0)\n\nd_s &lt;- d[, .(y = sum(y), n = .N), keyby = .(\n  a\n)]\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X = matrix(d_s$a),\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b = 3\n)   \n\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\n\nThe parameter estimates obviously do not align with the parameters used in the linear predictor as these are estimated on the log odds scale. But the magnitudes of the effects should be in line with the parameters on the risk scale. The parameters that had non-null effects in the data generation process have been shaded red.\n\n\nPosterior distributions for model parameters\nd_post &lt;- data.table(f1$draws(variables = c(\"a0\",\"b1\",\"b2\",\"b3\",\"b4\"), format = \"matrix\"))\nnames(d_post) &lt;- c(\"a0\", names(g_pars))\n\n# parameters\ncols &lt;- c(\"a0\", names(g_pars))\nd_fig &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig[variable == \"a0\", value := plogis(value)]\nd_fig[variable != \"a0\", value := exp(value)]\n\nd_col &lt;- unique(d_fig[, .(variable)])\nd_col[, fill := factor(c(\n  1, 1, 1, 2,\n  1, 2,\n  1, 1,\n  2,\n  1, 1,\n  1, 1\n))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_rect(data = d_col, aes(fill = fill),\n            xmin = -Inf,xmax = Inf,\n            ymin = -Inf,ymax = Inf, alpha = 0.1,\n            inherit.aes = F) +\n  scale_fill_manual(\"\", values = c(\"white\", \"red\")) +\n  geom_density() +\n  geom_vline(data = d_fig[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  scale_x_continuous(\n    labels = label_number(accuracy = 0.01)\n  ) +\n  facet_wrap(~variable, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 2: Posterior distributions for model parameters (coefficients all exponentiated, intercept on risk scale)\n\n\n\n\n\nBelow are the recovered marginal probabilities of \\(Y\\) under each surgical treatment type (dair vs rev). The red overlay shows the marginal probabilities of \\(Y\\) based on using a truncated model that includes a single fixed effect for surgical intervention (dair vs rev) and no other terms.\n\n\nMarginal probability of outcome by surgical type\ncols &lt;- c(\"marg_p0\", \"marg_p1\")\nd_post &lt;- data.table(f1$draws(variables = cols, format = \"matrix\"))\nnames(d_post) &lt;- cols\n \nd_fig1 &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig2 &lt;- data.table(f2$draws(variables = cols, format = \"matrix\"))\nd_fig2 &lt;- melt(d_fig2, measure.vars = cols)\n\nggplot(d_fig1, aes(x = value, group = variable)) +\n  geom_density() +\n  geom_density(data = d_fig2, aes(x = value, group = variable), \n               col = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(\n    \"Proportion with successful outcome\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  )\n\n\n\n\n\n\n\n\nFigure 3: Marginal probability of \\(Y\\) under each surgical type (DAIR, one-stage, two-stage)\n\n\n\n\n\nRisk difference (rev - dair). The red dashed line shows the posterior distribution obtained from a reduced model that includes a single term for surgical treatment assignment (dair/rev). The result is centred around zero and aligns with what we expect.\n\n\nRisk difference (dair vs revision)\nd_fig1 &lt;- data.table(f1$draws(variables = c(\"rd\"), format = \"matrix\"))\nd_fig2 &lt;- data.table(f2$draws(variables = c(\"rd\"), format = \"matrix\"))\n\nggplot(d_fig1, aes(x = rd)) +\n  geom_density() +\n  geom_density(data = d_fig2, \n               aes(x = rd), col = 2, lty = 2) +\n  scale_x_continuous(\n    \"Risk difference\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  ) +\n  geom_vline(data = d_fig1[, .(mu = mean(rd))], \n             aes(xintercept = mu))  +\n  geom_vline(data = d_fig2[, .(mu = mean(rd))], \n             aes(xintercept = mu), col = 2) \n\n\n\n\n\n\n\n\nFigure 4: Marginal risk difference of \\(Y\\) for DAIR vs revision",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#example-2---revision-effects",
    "href": "notebooks/design-notes-05.html#example-2---revision-effects",
    "title": "Marginal-ish effects",
    "section": "Example 2 - revision effects",
    "text": "Example 2 - revision effects\nHere equal magnitude effects are used for revision for both one-stage and two-stage approach with worse outcomes for hip joints but no interactions. In the other domains, the treatment effects are set to zero.\n\n\nData simulation and parameter estimation\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-03.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-02.stan\")\n  \nd &lt;- get_data(\n  n = 1e5,\n  ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n  \n    p &lt;- rep(NA, length(a))\n    \n    # dair\n    ix &lt;- which(sa == 0)\n    p[ix] &lt;- 0.6 + \n      0.1*(sa[ix] == 1) + 0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      -0.00*j[ix]**(sa[ix] == 1) -0.00*j[ix]**(sa[ix] == 2) \n      \n    # one-stage\n    ix &lt;- which(sa == 1)\n    p[ix] &lt;- 0.6 + \n      0.1*(sa[ix] == 1) + 0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] +  \n      -0.00*j[ix]**(sa[ix] == 1) -0.00*j[ix]**(sa[ix] == 2)\n    \n    # two-stage\n    ix &lt;- which(sa == 2)\n    p[ix] &lt;- 0.6 +  \n      0.1*(sa[ix] == 1) + 0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      # last two parameters not included for dair and one-stage\n      0.0*sd2[ix] + 0*ud2[ix] +\n      -0.00*j[ix]**(sa[ix] == 1) -0.00*j[ix]**(sa[ix] == 2)\n    \n    \n    # p[ix] &lt;- 0.6 +  \n    #   0.1*(sa[ix] == 1) + 0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n    #   0*sd1[ix] - 0.01*ud1[ix] +\n    #   0*sc[ix] + 0*uc[ix] +\n    #   -0.1*j[ix] + \n    #   # last two parameters not included for dair and one-stage\n    #   0.0*sd2[ix] + 0*ud2[ix] +\n    #   -0.03*j[ix]**(sa[ix] == 1) -0.03*j[ix]**(sa[ix] == 2)\n\n    p\n  })\n\nd[, `:=`(sa1 = as.numeric(d$sa == 1), sa2 = as.numeric(d$sa == 2))]\nd_s &lt;- d[, .(y = sum(y), n = .N, p_y = unique(p_y)), keyby = .(\n  sa1, sa2, ua, sd1, ud1, sc, uc, j, sd2, ud2, j \n)]\n\n# Model treats X[, 2] as being indicator of two-stage\nX1 &lt;- cbind(d_s$sa1, d_s$sa2)\n# all others bar interactions\nX2 &lt;- cbind(d_s$ua, d_s$sd1, d_s$ud1, d_s$sc, d_s$uc, d_s$j)\n# extended prophylaxis terms - only applies to two-stage pt\nX3 &lt;- cbind(d_s$sd2, d_s$ud2)\n# interactions\nX4 &lt;- cbind(d_s$j*d_s$sa1, d_s$j*d_s$sa2)\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X1 = X1, X2 = X2, X3 = X3, X4 = X4,\n  P1 = ncol(X1), P2 = ncol(X2), P3 = ncol(X3), P4 = ncol(X4),\n  # number of recs preference for 1/2 under revision\n  N1 = d_s[ua == 0, .N], N2 = d_s[ua == 1, .N],\n  # idx for pref for 1/2\n  ix1 = d_s[ua == 0, which = T],\n  ix2 = d_s[ua == 1, which = T],\n  pr_one = d[, mean(ua == 0)],\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b1 = 3, sd_b2 = 3, sd_b3 = 3, sd_b4 = 3\n)    \n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 10.9 seconds.\nChain 2 finished in 11.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 11.0 seconds.\nTotal execution time: 11.2 seconds.\n\n\nData simulation and parameter estimation\n# snk &lt;- capture.output(\n#       f1 &lt;- m1$pathfinder(ld, num_paths=20, single_path_draws=200,\n#                              history_size=50, max_lbfgs_iters=100,\n#                              refresh = 0, draws = 2000)\n#     )\n\n# f_mode &lt;- m1$optimize(data = ld, jacobian = TRUE, refresh =0)\n# f1 &lt;- m1$laplace(data = ld, mode = f_mode, refresh = 0)\n\nd_s &lt;- d[, .(y = sum(y), n = .N), keyby = .(\n  a\n)]\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X = matrix(d_s$a),\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b = 10\n)   \n\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\n\nParameters estimated on the log-odds scale, but exponentiated below (intercept reported on risk scale).\n\n\nPosterior distributions for model parameters\nd_post &lt;- data.table(f1$draws(variables = c(\"a0\",\"b1\",\"b2\",\"b3\",\"b4\"), format = \"matrix\"))\nnames(d_post) &lt;- c(\"a0\", names(g_pars))\n\n# parameters\ncols &lt;- c(\"a0\", names(g_pars))\nd_fig &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig[variable == \"a0\", value := plogis(value)]\nd_fig[variable != \"a0\", value := exp(value)]\n\nd_col &lt;- unique(d_fig[, .(variable)])\nd_col[, fill := factor(c(\n  1, 2, 2, 2,\n  1, 2,\n  1, 1,\n  2,\n  1, 1,\n  2, 2\n))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_rect(data = d_col, aes(fill = fill),\n            xmin = -Inf,xmax = Inf,\n            ymin = -Inf,ymax = Inf, alpha = 0.1,\n            inherit.aes = F) +\n  scale_fill_manual(\"\", values = c(\"white\", \"red\")) +\n  geom_density() +\n  geom_vline(data = d_fig[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  scale_x_continuous(\n    labels = label_number(accuracy = 0.01)\n  ) +\n  facet_wrap(~variable, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 5: Posterior distributions for model parameters (coefficients all exponentiated, intercept on risk scale)\n\n\n\n\n\nThe distribution of the marginal probability of \\(Y\\) under each treatment type.\n\n\nMarginal probability of outcome by surgical type\ncols &lt;- c(\"marg_p0\", \"marg_p1\")\nd_post &lt;- data.table(f1$draws(variables = cols, format = \"matrix\"))\nnames(d_post) &lt;- cols\n \nd_fig1 &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig2 &lt;- data.table(f2$draws(variables = cols, format = \"matrix\"))\nd_fig2 &lt;- melt(d_fig2, measure.vars = cols)\n\nggplot(d_fig1, aes(x = value, group = variable)) +\n  geom_density() +\n  geom_density(data = d_fig2, aes(x = value, group = variable), \n               col = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(\n    \"Proportion with successful outcome\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  )\n\n\n\n\n\n\n\n\nFigure 6: Marginal probability of \\(Y\\) under each surgical type (DAIR, one-stage, two-stage)\n\n\n\n\n\nRisk difference (rev - dair). The red dashed line shows the posterior distribution obtained from a reduced model that includes a single term for surgical treatment assignment (dair/rev). The result is suggests a positive effect of surgery as expected.\n\n\nRisk difference (dair vs revision)\nd_fig1 &lt;- data.table(f1$draws(variables = c(\"rd\"), format = \"matrix\"))\nd_fig2 &lt;- data.table(f2$draws(variables = c(\"rd\"), format = \"matrix\"))\n\nggplot(d_fig1, aes(x = rd)) +\n  geom_density() +\n  scale_x_continuous(\n    \"Risk difference\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  ) +\n  geom_density(data = d_fig2, \n               aes(x = rd), col = 2, lty = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(rd))], \n             aes(xintercept = mu))  +\n  geom_vline(data = d_fig2[, .(mu = mean(rd))], \n             aes(xintercept = mu), col = 2) \n\n\n\n\n\n\n\n\nFigure 7: Marginal risk difference of \\(Y\\) for DAIR vs revision",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#example-3---extended-prophylaxis-effects",
    "href": "notebooks/design-notes-05.html#example-3---extended-prophylaxis-effects",
    "title": "Marginal-ish effects",
    "section": "Example 3 - extended prophylaxis effects",
    "text": "Example 3 - extended prophylaxis effects\nHere revision effects are set to zero but a non-zero effect is set for the extended prophylaxis.\nThis is where things start to go awry.\nDue to the fact that extended prophylaxis is only applicable for patients receiving a two-stage revision (the revision being the important part), any extended prophylaxis effect will manifest as being an effect of revision. Thus the observed effect has nothing to do with the surgery performed but rather the intervention received in the entangled domain.\n\nIs there any way around this in the setting where we are referring to a generalised revision effect?\n\n\n\nData simulation and parameter estimation\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-03.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-02.stan\")\n\nd &lt;- get_data(\n  n = 1e5,\n  ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n  \n    p &lt;- rep(NA, length(a))\n    \n    # dair\n    ix &lt;- which(sa == 0)\n    p[ix] &lt;- 0.6 + \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n      \n    # one-stage\n    ix &lt;- which(sa == 1)\n    p[ix] &lt;- 0.6 + \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] +  \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2)\n    \n    # two-stage\n    ix &lt;- which(sa == 2)\n    p[ix] &lt;- 0.6 +  \n      0*(sa[ix] == 1) + 0*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      # last two parameters not included for dair and one-stage\n      0.2*sd2[ix] + 0*ud2[ix] +\n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2)\n      \n    p\n  })\n\nd[, `:=`(sa1 = as.numeric(d$sa == 1), sa2 = as.numeric(d$sa == 2))]\nd_s &lt;- d[, .(y = sum(y), n = .N, p_y = unique(p_y)), keyby = .(\n  sa1, sa2, ua, sd1, ud1, sc, uc, j, sd2, ud2, j \n)]\n\n# Model treats X[, 2] as being indicator of two-stage\nX1 &lt;- cbind(d_s$sa1, d_s$sa2)\n# all others bar interactions\nX2 &lt;- cbind(d_s$ua, d_s$sd1, d_s$ud1, d_s$sc, d_s$uc, d_s$j)\n# extended prophylaxis terms - only applies to two-stage pt\nX3 &lt;- cbind(d_s$sd2, d_s$ud2)\n# interactions\nX4 &lt;- cbind(d_s$j*d_s$sa1, d_s$j*d_s$sa2)\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X1 = X1, X2 = X2, X3 = X3, X4 = X4,\n  P1 = ncol(X1), P2 = ncol(X2), P3 = ncol(X3), P4 = ncol(X4),\n  # number of recs preference for 1/2 under revision\n  N1 = d_s[ua == 0, .N], N2 = d_s[ua == 1, .N],\n  # idx for pref for 1/2\n  ix1 = d_s[ua == 0, which = T],\n  ix2 = d_s[ua == 1, which = T],\n  pr_one = d[, mean(ua == 0)],\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b1 = 3, sd_b2 = 3, sd_b3 = 3, sd_b4 = 3\n)     \n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 11.3 seconds.\nChain 1 finished in 12.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 11.8 seconds.\nTotal execution time: 12.4 seconds.\n\n\nData simulation and parameter estimation\n# snk &lt;- capture.output(\n#       f1 &lt;- m1$pathfinder(ld, num_paths=20, single_path_draws=200,\n#                              history_size=50, max_lbfgs_iters=100,\n#                              refresh = 0, draws = 2000)\n#     )\n\n# f_mode &lt;- m1$optimize(data = ld, jacobian = TRUE, refresh =0)\n# f1 &lt;- m1$laplace(data = ld, mode = f_mode, refresh = 0)\n\nd_s &lt;- d[, .(y = sum(y), n = .N), keyby = .(\n  a\n)]\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X = matrix(d_s$a),\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b = 3\n)   \n\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\nParameters estimated on the log-odds scale, but exponentiated below (intercept reported on risk scale).\n\n\nPosterior distributions for model parameters\nd_post &lt;- data.table(f1$draws(variables = c(\"a0\",\"b1\",\"b2\",\"b3\",\"b4\"), format = \"matrix\"))\nnames(d_post) &lt;- c(\"a0\", names(g_pars))\n\n# parameters\ncols &lt;- c(\"a0\", names(g_pars))\nd_fig &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig[variable == \"a0\", value := plogis(value)]\nd_fig[variable != \"a0\", value := exp(value)]\n\nd_col &lt;- unique(d_fig[, .(variable)])\nd_col[, fill := factor(c(\n  1, 1, 1, 2,\n  1, 2,\n  1, 1,\n  2,\n  2, 1,\n  1, 1\n))]\n\n\n  \nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_rect(data = d_col, aes(fill = fill),\n            xmin = -Inf,xmax = Inf,\n            ymin = -Inf,ymax = Inf, alpha = 0.1,\n            inherit.aes = F) +\n  scale_fill_manual(\"\", values = c(\"white\", \"red\")) +\n  geom_density() +\n  geom_vline(data = d_fig[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  scale_x_continuous(\n    labels = label_number(accuracy = 0.01)\n  ) +\n  facet_wrap(~variable, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 8: Posterior distributions for model parameters (coefficients all exponentiated, intercept on risk scale)\n\n\n\n\n\nThe distribution of the marginal probability of \\(Y\\) under each treatment type.\n\n\nMarginal probability of outcome by surgical type\ncols &lt;- c(\"marg_p0\", \"marg_p1\")\nd_post &lt;- data.table(f1$draws(variables = cols, format = \"matrix\"))\nnames(d_post) &lt;- cols\n \nd_fig1 &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig2 &lt;- data.table(f2$draws(variables = cols, format = \"matrix\"))\nd_fig2 &lt;- melt(d_fig2, measure.vars = cols)\n\nggplot(d_fig1, aes(x = value, group = variable)) +\n  geom_density() +\n  geom_density(data = d_fig2, aes(x = value, group = variable), \n               col = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(\n    \"Proportion with successful outcome\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  )\n\n\n\n\n\n\n\n\nFigure 9: Marginal probability of \\(Y\\) under each surgical type (DAIR, one-stage, two-stage)\n\n\n\n\n\nRisk difference (rev - dair). The red dashed line shows the posterior distribution obtained from a reduced model that includes a single term for surgical treatment assignment (dair/rev). Even though there is no effect of surgery, a positive risk difference for dair vs revision manifests due to the presence of an effect in the extended prophylaxis domain.\n\n\nRisk difference (dair vs revision)\nd_fig1 &lt;- data.table(f1$draws(variables = c(\"rd\"), format = \"matrix\"))\nd_fig2 &lt;- data.table(f2$draws(variables = c(\"rd\"), format = \"matrix\"))\n\nggplot(d_fig1, aes(x = rd)) +\n  geom_density() +\n  scale_x_continuous(\n    \"Risk difference\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  ) +\n  geom_density(data = d_fig2, \n               aes(x = rd), col = 2, lty = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(rd))], \n             aes(xintercept = mu))  +\n  geom_vline(data = d_fig2[, .(mu = mean(rd))], \n             aes(xintercept = mu), col = 2) \n\n\n\n\n\n\n\n\nFigure 10: Marginal risk difference of \\(Y\\) for DAIR vs revision",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#example-4---combined-revision-and-extended-prophylaxis-effects",
    "href": "notebooks/design-notes-05.html#example-4---combined-revision-and-extended-prophylaxis-effects",
    "title": "Marginal-ish effects",
    "section": "Example 4 - combined revision and extended prophylaxis effects",
    "text": "Example 4 - combined revision and extended prophylaxis effects\nHere revision effects are set to negative values (i.e. people on revision do worse) and a positive effect is set for the extended prophylaxis.\nFor similar reasons as above, the negative effect of revision (people do worse under surgical removal and replacement of the joint) is cancelled out when evaluated at the margins due to the offsetting effect of extended prophylaxis.\n\n\nData simulation and parameter estimation\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-03.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-02.stan\")\n\nd &lt;- get_data(\n  n = 1e5,\n  ff = function(j, a, ua, sa, d1, ud1, sd1, d2, ud2, sd2, c, uc, sc){\n  \n    p &lt;- rep(NA, length(a))\n    \n    # dair\n    ix &lt;- which(sa == 0)\n    p[ix] &lt;- 0.6 + \n      -0.1*(sa[ix] == 1) + -0.1*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2) \n      \n    # one-stage\n    ix &lt;- which(sa == 1)\n    p[ix] &lt;- 0.6 + \n      -0.07*(sa[ix] == 1) + -0.07*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] +  \n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2)\n    \n    # two-stage\n    ix &lt;- which(sa == 2)\n    p[ix] &lt;- 0.6 +  \n      -0.07*(sa[ix] == 1) + -0.07*(sa[ix] == 2) + 0.05*ua[ix] +\n      0*sd1[ix] - 0.01*ud1[ix] +\n      0*sc[ix] + 0*uc[ix] +\n      -0.1*j[ix] + \n      # last two parameters not included for dair and one-stage\n      0.2*sd2[ix] + 0*ud2[ix] +\n      0*j[ix]**(sa[ix] == 1) + 0*j[ix]**(sa[ix] == 2)\n      \n    p\n  })\n\n\nd[, `:=`(sa1 = as.numeric(d$sa == 1), sa2 = as.numeric(d$sa == 2))]\nd_s &lt;- d[, .(y = sum(y), n = .N, p_y = unique(p_y)), keyby = .(\n  sa1, sa2, ua, sd1, ud1, sc, uc, j, sd2, ud2, j \n)]\n\n# Model treats X[, 2] as being indicator of two-stage\nX1 &lt;- cbind(d_s$sa1, d_s$sa2)\n# all others bar interactions\nX2 &lt;- cbind(d_s$ua, d_s$sd1, d_s$ud1, d_s$sc, d_s$uc, d_s$j)\n# extended prophylaxis terms - only applies to two-stage pt\nX3 &lt;- cbind(d_s$sd2, d_s$ud2)\n# interactions\nX4 &lt;- cbind(d_s$j*d_s$sa1, d_s$j*d_s$sa2)\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X1 = X1, X2 = X2, X3 = X3, X4 = X4,\n  P1 = ncol(X1), P2 = ncol(X2), P3 = ncol(X3), P4 = ncol(X4),\n  # number of recs preference for 1/2 under revision\n  N1 = d_s[ua == 0, .N], N2 = d_s[ua == 1, .N],\n  # idx for pref for 1/2\n  ix1 = d_s[ua == 0, which = T],\n  ix2 = d_s[ua == 1, which = T],\n  pr_one = d[, mean(ua == 0)],\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b1 = 3, sd_b2 = 3, sd_b3 = 3, sd_b4 = 3\n)         \n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 11.3 seconds.\nChain 2 finished in 11.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 11.4 seconds.\nTotal execution time: 11.5 seconds.\n\n\nData simulation and parameter estimation\n# snk &lt;- capture.output(\n#       f1 &lt;- m1$pathfinder(ld, num_paths=20, single_path_draws=200,\n#                              history_size=50, max_lbfgs_iters=100,\n#                              refresh = 0, draws = 2000)\n#     )\n\n# f_mode &lt;- m1$optimize(data = ld, jacobian = TRUE, refresh =0)\n# f1 &lt;- m1$laplace(data = ld, mode = f_mode, refresh = 0)\n\nd_s &lt;- d[, .(y = sum(y), n = .N), keyby = .(\n  a\n)]\n\nld &lt;- list(\n  N = nrow(d_s), \n  y = d_s$y,\n  n = d_s$n,\n  X = matrix(d_s$a),\n  prior_only = 0,\n  sd_a0 = 1.5,\n  sd_b = 3\n)   \n\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\nParameters estimated on the log-odds scale, but exponentiated below (intercept reported on risk scale).\n\n\nPosterior distributions for model parameters\nd_post &lt;- data.table(f1$draws(variables = c(\"a0\",\"b1\",\"b2\",\"b3\",\"b4\"), format = \"matrix\"))\nnames(d_post) &lt;- c(\"a0\", names(g_pars))\n\n# parameters\ncols &lt;- c(\"a0\", names(g_pars))\nd_fig &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig[variable == \"a0\", value := plogis(value)]\nd_fig[variable != \"a0\", value := exp(value)]\n\nd_col &lt;- unique(d_fig[, .(variable)])\nd_col[, fill := factor(c(\n  1, 2, 2, 2,\n  1, 2,\n  1, 1,\n  2,\n  2, 1,\n  1, 1\n))]\n\n\n  \nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_rect(data = d_col, aes(fill = fill),\n            xmin = -Inf,xmax = Inf,\n            ymin = -Inf,ymax = Inf, alpha = 0.1,\n            inherit.aes = F) +\n  scale_fill_manual(\"\", values = c(\"white\", \"red\")) +\n  geom_density() +\n  geom_vline(data = d_fig[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  scale_x_continuous(\n    labels = label_number(accuracy = 0.01)\n  ) +\n  facet_wrap(~variable, scales = \"free\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure 11: Posterior distributions for model parameters (coefficients all exponentiated, intercept on risk scale)\n\n\n\n\n\nThe distribution of the marginal probability of \\(Y\\) under each treatment type.\n\n\nMarginal probability of outcome by surgical type\ncols &lt;- c(\"marg_p0\", \"marg_p1\")\nd_post &lt;- data.table(f1$draws(variables = cols, format = \"matrix\"))\nnames(d_post) &lt;- cols\n \nd_fig1 &lt;- melt(d_post[, cols, with = F], measure.vars = cols)\nd_fig2 &lt;- data.table(f2$draws(variables = cols, format = \"matrix\"))\nd_fig2 &lt;- melt(d_fig2, measure.vars = cols)\n\nggplot(d_fig1, aes(x = value, group = variable)) +\n  geom_density() +\n  geom_density(data = d_fig2, aes(x = value, group = variable), \n               col = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu, group = variable)) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(\n    \"Proportion with successful outcome\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  )\n\n\n\n\n\n\n\n\nFigure 12: Marginal probability of \\(Y\\) under each surgical type (DAIR, one-stage, two-stage)\n\n\n\n\n\nRisk difference (rev - dair). The red dashed line shows the posterior distribution obtained from a reduced model that includes a single term for surgical treatment assignment (dair/rev).\n\n\nRisk difference (dair vs revision)\nd_fig1 &lt;- data.table(f1$draws(variables = c(\"rd\"), format = \"matrix\"))\nd_fig2 &lt;- data.table(f2$draws(variables = c(\"rd\"), format = \"matrix\"))\n\nggplot(d_fig1, aes(x = rd)) +\n  geom_density() +\n  scale_x_continuous(\n    \"Risk difference\",\n    # labels = label_number(accuracy = 0.001),\n    labels = scales::percent_format(accuracy = 0.1)\n  ) +\n  geom_density(data = d_fig2, \n               aes(x = rd), col = 2, lty = 2) +\n  geom_vline(data = d_fig1[, .(mu = mean(rd))], \n             aes(xintercept = mu))  +\n  geom_vline(data = d_fig2[, .(mu = mean(rd))], \n             aes(xintercept = mu), col = 2) \n\n\n\n\n\n\n\n\nFigure 13: Marginal risk difference of \\(Y\\) for DAIR vs revision",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-05.html#discussion",
    "href": "notebooks/design-notes-05.html#discussion",
    "title": "Marginal-ish effects",
    "section": "Discussion",
    "text": "Discussion\nIn a factorial design, the main effects could be isolated and have an interpretation conditional on all other terms in the model held at a constant level. When we are talking about an effect of \\(P\\) it relates specifically to intervening on \\(P\\). However, due to the roadmap design using the marginal perspective could lead us to identify positive or negative revision effects solely as a consequence of the non-zero effects in other domains.\nThe phenomena is an artefact of the design rather than the estimation process or the specification of the statistical model.\nThe only reasonable way to address this seems to be to define the concept of revision as a strategy that involves multiple domain elements. Probably the most interpretaable approach is to have dair vs revision corresponding to dair being a strict strategy of dair plus 12 weeks backbone therapy and where revision conrresponds to one-stage revision with 12 weeks backbone antibiotic or two-stage revision with 12 weeks backbone antibiotic and no extended prophylaxis. However, given that we do not have an intervention arm that is the absence of extended prophylaxis, we would have to settle on 7 days.\nIn no way does the above fix the design, but it provides a more coherent quantity to evaluate and report on than an arbitrary mix of strategies.",
    "crumbs": [
      "Design notes",
      "Marginal-ish effects"
    ]
  },
  {
    "objectID": "notebooks/misc-notes.html",
    "href": "notebooks/misc-notes.html",
    "title": "Reminders",
    "section": "",
    "text": "Just some brief notes/examples to act as basics stats reminders.",
    "crumbs": [
      "Design notes",
      "Reminders"
    ]
  },
  {
    "objectID": "notebooks/misc-notes.html#example---lotplote",
    "href": "notebooks/misc-notes.html#example---lotplote",
    "title": "Reminders",
    "section": "Example - LOTP/LOTE",
    "text": "Example - LOTP/LOTE\nAssume the following true joint distribution for some outcome \\(Y\\) and its distribution conditional on sex, smoking and vegetarianism.\n\n\nCode\nset.seed(1)\nd_tru &lt;- CJ(sex = 0:1, smk = 0:1, veg = 0:1)\ng &lt;- function(sex, smk, veg){\n  -1 + 2 * sex - 1 * smk + 3 * veg +\n    -1 * sex * smk - 3 * sex * veg + 1 * smk * veg +\n    0.5 * sex * smk * veg\n}\n# probability of group membership\nq &lt;- rnorm(nrow(d_tru))\nd_tru[, p_grp := exp(q)/sum(exp(q))]\n# probability of outcome\nd_tru[, p_y := plogis(g(sex,smk,veg))]\nd_tru\n\n\nKey: &lt;sex, smk, veg&gt;\n     sex   smk   veg      p_grp       p_y\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;      &lt;num&gt;     &lt;num&gt;\n1:     0     0     0 0.04225019 0.2689414\n2:     0     0     1 0.09498377 0.8807971\n3:     0     1     0 0.03427561 0.1192029\n4:     0     1     1 0.38968687 0.8807971\n5:     1     0     0 0.10989996 0.7310586\n6:     1     0     1 0.03479920 0.7310586\n7:     1     1     0 0.12870098 0.2689414\n8:     1     1     1 0.16540341 0.6224593\n\n\nTake a random sample from the population:\n\n\nCode\nn &lt;- 1e7\ni &lt;- sample(1:nrow(d_tru), n, T, prob = d_tru$p_grp)\nd &lt;- d_tru[i]\nd[, y := rbinom(.N, 1, p_y)]\n\n\nRecover the distribution of the covariates (the p_grp)\n\n\nCode\n# recover distribution of covariates\nd[, .(.N/nrow(d)), keyby = .(sex, smk, veg)]\n\n\nKey: &lt;sex, smk, veg&gt;\n     sex   smk   veg        V1\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;num&gt;\n1:     0     0     0 0.0421805\n2:     0     0     1 0.0950815\n3:     0     1     0 0.0343139\n4:     0     1     1 0.3898065\n5:     1     0     0 0.1096864\n6:     1     0     1 0.0348148\n7:     1     1     0 0.1288739\n8:     1     1     1 0.1652425\n\n\nRecover the joint distribution of the outcome (the p_y)\n\n\nCode\n# recover distribution of outcome\nd[, .(mu_y = mean(y)), keyby = .(sex, smk, veg)]\n\n\nKey: &lt;sex, smk, veg&gt;\n     sex   smk   veg      mu_y\n   &lt;int&gt; &lt;int&gt; &lt;int&gt;     &lt;num&gt;\n1:     0     0     0 0.2693899\n2:     0     0     1 0.8812230\n3:     0     1     0 0.1189314\n4:     0     1     1 0.8805292\n5:     1     0     0 0.7309010\n6:     1     0     1 0.7311000\n7:     1     1     0 0.2692407\n8:     1     1     1 0.6217244\n\n\nEstimate the probability of outcome by sex\n\n\nCode\nd[, .(mu_y = mean(y)), keyby = sex]\n\n\nKey: &lt;sex&gt;\n     sex      mu_y\n   &lt;int&gt;     &lt;num&gt;\n1:     0 0.7881758\n2:     1 0.5541419\n\n\nWe are interested in \\(\\mathbb{E}[y | sex]\\). Can we get to this via iterated expectation/LOTE?\nThink - is all we need LOTP (with extra conditioning), e.g.\n\\[\n\\begin{aligned}\nPr(y | sex = s) &= Pr(y | sex = s, smk = 0, veg = 0) Pr(smk = 0, veg = 0|sex = s) + \\\\\n& \\quad Pr(y | sex = s, smk = 0, veg = 1) Pr(smk = 0, veg = 1|sex = s) + \\\\\n& \\quad Pr(y | sex = s, smk = 1, veg = 0) Pr(smk = 1, veg = 0|sex = s) + \\\\\n& \\quad Pr(y | sex = s, smk = 1, veg = 1) Pr(smk = 1, veg = 1|sex = s)\n\\end{aligned}\n\\tag{1}\\]\nOperationalised, based on the known distributions, we get:\n\n\nCode\nc(\n  \"Pr(Y | sex = 0)\" = sum(d_tru[sex == 0, p_y] * d_tru[sex == 0, p_grp / sum(p_grp)] ),\n  \"Pr(Y | sex = 1)\" = sum(d_tru[sex == 1, p_y] * d_tru[sex == 1, p_grp / sum(p_grp)] )\n)\n\n\nPr(Y | sex = 0) Pr(Y | sex = 1) \n      0.7882179       0.5545841 \n\n\nAnd which can be estimated from the simulated data:\n\n\nCode\nc(\n  \"Pr(Y | sex = 0)\" = \n    sum(d[sex == 0, mean(y)] * \n          d[sex == 0, .(p_grp = .N/nrow(d[sex == 0])), keyby = .(smk, veg)]$p_grp ),\n  \"Pr(Y | sex = 1)\" = \n    sum(d[sex == 1, mean(y)] * \n          d[sex == 1, .(p_grp = .N/nrow(d[sex == 1])), keyby = .(smk, veg)]$p_grp)\n)\n\n\nPr(Y | sex = 0) Pr(Y | sex = 1) \n      0.7881758       0.5541419 \n\n\nTake Equation 1, multiply both sides by \\(y\\) and then sum over all \\(y\\)\n\\[\n\\begin{aligned}\n\\sum_y y Pr(y | sex = s) &= \\sum_y y Pr(y | sex = s, smk = 0, veg = 0) Pr(smk = 0, veg = 0|sex = s) + \\\\\n& \\quad \\sum_y y Pr(y | sex = s, smk = 0, veg = 1) Pr(smk = 0, veg = 1|sex = s) + \\\\\n& \\quad \\sum_y y Pr(y | sex = s, smk = 1, veg = 0) Pr(smk = 1, veg = 0|sex = s) + \\\\\n& \\quad \\sum_y y Pr(y | sex = s, smk = 1, veg = 1) Pr(smk = 1, veg = 1|sex = s)  \n\\end{aligned}\n\\tag{2}\\]\nwhich (I think) can be re-stated as\n\\[\n\\begin{aligned}\n\\mathbb{E}(Y|sex=s) &= \\mathbb{E}(Y|sex = s, smk = 0, veg = 0) Pr(smk = 0, veg = 0|sex = s) + \\\\\n& \\quad \\mathbb{E}(Y|sex = s, smk = 0, veg = 1)  Pr(smk = 0, veg = 1|sex = s)  + \\\\\n& \\quad \\mathbb{E}(Y|sex = s, smk = 1, veg = 0)  Pr(smk = 1, veg = 0|sex = s)  + \\\\\n& \\quad \\mathbb{E}(Y|sex = s, smk = 1, veg = 1)  Pr(smk = 1, veg = 1|sex = s)  \\\\\n&= \\sum_{smk,veg} \\mathbb{E}(Y|sex = s, smk, veg) Pr(smk, veg|sex = s)\n\\end{aligned}\n\\tag{3}\\]\nalso note1 (just in case one is easier to determine than another):\n\\[\nPr(smk, veg|sex) = Pr(smk|veg, sex) Pr(veg | sex)\n\\]\nso (perhaps) alternatively:\n\\[\n\\begin{aligned}\n\\mathbb{E}(Y|sex=s) &= \\sum_{smk,veg} \\mathbb{E}(Y|sex = s, smk, veg) Pr(smk|veg, sex = s) Pr(veg | sex = s)\n\\end{aligned}\n\\tag{4}\\]",
    "crumbs": [
      "Design notes",
      "Reminders"
    ]
  },
  {
    "objectID": "notebooks/misc-notes.html#footnotes",
    "href": "notebooks/misc-notes.html#footnotes",
    "title": "Reminders",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor the proof, consider \\(P(Y,X|Z) = \\frac{Pr(X,Y,Z)}{Pr(Z)}\\), \\(P(Y|X,Z) = \\frac{Pr(X,Y,Z)}{Pr(X,Z)}\\) and \\(Pr(X|Z) = \\frac{Pr(X,Z)}{Pr(Z)}\\).↩︎",
    "crumbs": [
      "Design notes",
      "Reminders"
    ]
  },
  {
    "objectID": "notebooks/design-notes-03.html",
    "href": "notebooks/design-notes-03.html",
    "title": "Design discussion (part 2)",
    "section": "",
    "text": "The DATIPO study investigated non-inferiority of 6 weeks vs 12 weeks in PJI patients. The primary outcome was persistent infection within 2 years after the completion of antibiotic therapy. Surgery type was not randomised, but most events occurred in patients who received DAIR.\nJust from a cursory read, if this were the only information I had available to me (and the only thing I cared about was “persistent infection at 2 years”), I would be wanting 12 weeks of AB duration not 6 weeks, irrespective of the type of surgery I was getting or the affected joint. Given how few events occurred in anyone who received one-stage, and assuming there is some level of homogeneity over surgery types, I wouldn’t have a different opinion for the one-stage group in particular. But this wouldn’t be a very strong belief given the small number of events in the trial overall. It would more so be a default simplification in the absence of any other information or experience, just this trial in isolation.\nIn the AB duration DSA they write:\n\nThis demonstrated that shorter course therapy was not non-inferior (I’d say that it “showed” it was inferior, not just not non-inferior) to longer course therapy. Interestingly this finding was consistent amongst patients treated with Debridement, antibiotics and implant retention (DAIR) and 2-stage revision. However, for single stage revisions, there was no meaningful difference between the 6 weeks and 12 weeks of antibiotics on the outcome of treatment success, though the study was underpowered for subgroup analyses (n=150 for one-stage revisions)… a larger trial is needed to confirm the findings in DATIPO that 6 weeks is non-inferior to 12 weeks in terms of treatment success.\n\nSo, it seems the opinion is that 6 weeks is (not non-)inferior to 12 weeks for DAIR and two-stage, but is possibly non-inferior (but perhaps not better) for one-stage. I don’t think the paper provides sufficient reason to think that the duration effect would differ by surgery type (but also not that it wouldn’t), but perhaps there are other justifications for why it might. If not willing to assume homogeneity of effect, to properly inform the duration decision in all surgery groups, you would probably want to assign 6/12 in all groups.\nBut generally, I can see where they are coming from, I see the difficulty in willingly assigning DAIR patients to 6 weeks over 12 weeks despite the uncertainties. The one-stage group is the less informed one, but if I were a patient who was to get a one-stage revision, I would want 12 weeks not 6 weeks if all I had was the information from that trial. They don’t mention any other studies, have you seen any others looking at the same kind of question?\n\n\nCode\nlibrary(dplyr)\nlibrary(marginaleffects)\n\ndat &lt;- tribble(\n  ~ type, ~ x, ~ n, ~ y,\n  \"DAIR\", 0, 76, 11,\n  \"DAIR\", 1, 75, 23,\n  \"Two\", 0, 41, 2,\n  \"Two\", 1, 40, 6,\n  \"One\", 0, 71, 2,\n  \"One\", 1, 75, 3\n)\n\nfit1 &lt;- glm(cbind(y, n - y) ~ type * x, data = dat, family = binomial())\nfit2 &lt;- glm(cbind(y, n - y) ~ type + x, data = dat, family = binomial())\n\n\n\n\nCode\nprint(avg_comparisons(fit1, variables = \"x\", by = \"type\"), digits = 1)\n\n\n\n Term          Contrast type Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    x mean(1) - mean(0) DAIR     0.16       0.07 2.4     0.02 6.0  0.03   0.29\n    x mean(1) - mean(0) One      0.01       0.03 0.4     0.69 0.5 -0.05   0.07\n    x mean(1) - mean(0) Two      0.10       0.07 1.5     0.12 3.0 -0.03   0.23\n\nColumns: term, contrast, type, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nCode\nprint(comparisons(fit1, variables = \"x\", by = \"type\", comparison = \"lnor\"), digits = 2)\n\n\n\n Term              Contrast type Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 %\n    x ln(odds(1) / odds(0)) DAIR     0.96       0.41 2.34    0.019 5.7  0.16\n    x ln(odds(1) / odds(0)) One      0.36       0.93 0.39    0.696 0.5 -1.46\n    x ln(odds(1) / odds(0)) Two      1.24       0.85 1.45    0.146 2.8 -0.43\n 97.5 %\n    1.8\n    2.2\n    2.9\n\nColumns: term, contrast, type, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nCode\nprint(comparisons(fit1, variables = \"x\", by = \"type\", comparison = \"lnor\", hypothesis = \"revpairwise\"), digits = 2)\n\n\n\n       Term Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n One - DAIR    -0.60       1.02 -0.59     0.56 0.8  -2.6    1.4\n Two - DAIR     0.28       0.94  0.29     0.77 0.4  -1.6    2.1\n Two - One      0.87       1.26  0.69     0.49 1.0  -1.6    3.3\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nCode\nanova(fit1, fit2)\n\n\nAnalysis of Deviance Table\n\nModel 1: cbind(y, n - y) ~ type * x\nModel 2: cbind(y, n - y) ~ type + x\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1         0    0.00000                     \n2         2    0.49699 -2 -0.49699     0.78\n\n\nCode\nAIC(fit1, fit2)\n\n\n     df      AIC\nfit1  6 32.30613\nfit2  4 28.80312\n\n\nThe differences in differences of log-odds are very uncertain as expected given the small numbers available in the subgroups:\nStandard model choice metrics would prefer the model in which the effect of duration is assumed constant across surgery types, and so has 6 weeks inferior to 12 weeks irrespective of surgery type.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 2)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-03.html#notes-on-bernard-2021",
    "href": "notebooks/design-notes-03.html#notes-on-bernard-2021",
    "title": "Design discussion (part 2)",
    "section": "",
    "text": "The DATIPO study investigated non-inferiority of 6 weeks vs 12 weeks in PJI patients. The primary outcome was persistent infection within 2 years after the completion of antibiotic therapy. Surgery type was not randomised, but most events occurred in patients who received DAIR.\nJust from a cursory read, if this were the only information I had available to me (and the only thing I cared about was “persistent infection at 2 years”), I would be wanting 12 weeks of AB duration not 6 weeks, irrespective of the type of surgery I was getting or the affected joint. Given how few events occurred in anyone who received one-stage, and assuming there is some level of homogeneity over surgery types, I wouldn’t have a different opinion for the one-stage group in particular. But this wouldn’t be a very strong belief given the small number of events in the trial overall. It would more so be a default simplification in the absence of any other information or experience, just this trial in isolation.\nIn the AB duration DSA they write:\n\nThis demonstrated that shorter course therapy was not non-inferior (I’d say that it “showed” it was inferior, not just not non-inferior) to longer course therapy. Interestingly this finding was consistent amongst patients treated with Debridement, antibiotics and implant retention (DAIR) and 2-stage revision. However, for single stage revisions, there was no meaningful difference between the 6 weeks and 12 weeks of antibiotics on the outcome of treatment success, though the study was underpowered for subgroup analyses (n=150 for one-stage revisions)… a larger trial is needed to confirm the findings in DATIPO that 6 weeks is non-inferior to 12 weeks in terms of treatment success.\n\nSo, it seems the opinion is that 6 weeks is (not non-)inferior to 12 weeks for DAIR and two-stage, but is possibly non-inferior (but perhaps not better) for one-stage. I don’t think the paper provides sufficient reason to think that the duration effect would differ by surgery type (but also not that it wouldn’t), but perhaps there are other justifications for why it might. If not willing to assume homogeneity of effect, to properly inform the duration decision in all surgery groups, you would probably want to assign 6/12 in all groups.\nBut generally, I can see where they are coming from, I see the difficulty in willingly assigning DAIR patients to 6 weeks over 12 weeks despite the uncertainties. The one-stage group is the less informed one, but if I were a patient who was to get a one-stage revision, I would want 12 weeks not 6 weeks if all I had was the information from that trial. They don’t mention any other studies, have you seen any others looking at the same kind of question?\n\n\nCode\nlibrary(dplyr)\nlibrary(marginaleffects)\n\ndat &lt;- tribble(\n  ~ type, ~ x, ~ n, ~ y,\n  \"DAIR\", 0, 76, 11,\n  \"DAIR\", 1, 75, 23,\n  \"Two\", 0, 41, 2,\n  \"Two\", 1, 40, 6,\n  \"One\", 0, 71, 2,\n  \"One\", 1, 75, 3\n)\n\nfit1 &lt;- glm(cbind(y, n - y) ~ type * x, data = dat, family = binomial())\nfit2 &lt;- glm(cbind(y, n - y) ~ type + x, data = dat, family = binomial())\n\n\n\n\nCode\nprint(avg_comparisons(fit1, variables = \"x\", by = \"type\"), digits = 1)\n\n\n\n Term          Contrast type Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    x mean(1) - mean(0) DAIR     0.16       0.07 2.4     0.02 6.0  0.03   0.29\n    x mean(1) - mean(0) One      0.01       0.03 0.4     0.69 0.5 -0.05   0.07\n    x mean(1) - mean(0) Two      0.10       0.07 1.5     0.12 3.0 -0.03   0.23\n\nColumns: term, contrast, type, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nCode\nprint(comparisons(fit1, variables = \"x\", by = \"type\", comparison = \"lnor\"), digits = 2)\n\n\n\n Term              Contrast type Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 %\n    x ln(odds(1) / odds(0)) DAIR     0.96       0.41 2.34    0.019 5.7  0.16\n    x ln(odds(1) / odds(0)) One      0.36       0.93 0.39    0.696 0.5 -1.46\n    x ln(odds(1) / odds(0)) Two      1.24       0.85 1.45    0.146 2.8 -0.43\n 97.5 %\n    1.8\n    2.2\n    2.9\n\nColumns: term, contrast, type, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nCode\nprint(comparisons(fit1, variables = \"x\", by = \"type\", comparison = \"lnor\", hypothesis = \"revpairwise\"), digits = 2)\n\n\n\n       Term Estimate Std. Error     z Pr(&gt;|z|)   S 2.5 % 97.5 %\n One - DAIR    -0.60       1.02 -0.59     0.56 0.8  -2.6    1.4\n Two - DAIR     0.28       0.94  0.29     0.77 0.4  -1.6    2.1\n Two - One      0.87       1.26  0.69     0.49 1.0  -1.6    3.3\n\nColumns: term, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nCode\nanova(fit1, fit2)\n\n\nAnalysis of Deviance Table\n\nModel 1: cbind(y, n - y) ~ type * x\nModel 2: cbind(y, n - y) ~ type + x\n  Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)\n1         0    0.00000                     \n2         2    0.49699 -2 -0.49699     0.78\n\n\nCode\nAIC(fit1, fit2)\n\n\n     df      AIC\nfit1  6 32.30613\nfit2  4 28.80312\n\n\nThe differences in differences of log-odds are very uncertain as expected given the small numbers available in the subgroups:\nStandard model choice metrics would prefer the model in which the effect of duration is assumed constant across surgery types, and so has 6 weeks inferior to 12 weeks irrespective of surgery type.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 2)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-03.html#ramble",
    "href": "notebooks/design-notes-03.html#ramble",
    "title": "Design discussion (part 2)",
    "section": "Ramble",
    "text": "Ramble\nMaybe going too in depth, but I think one issue we are having is getting across the difference between what is being compared and what is being assumed in the model. Depending on the model assumptions, some of the strategies might be assumed to be equal anyway and there might only be one decision/comparison in that sense. But it’s helpful to keep separate the model assumptions from the comparisons we are trying to make. When we say “revision vs DAIR”, that only defines a comparison if we think all revisions have equal effect or we are happy to completely ignore any varying effects. But that’s not what we believe (if we did, why would we bother looking at different A/B durations following revision?). As soon as we think A/B duration has a varying effect that we want to estimate, there is no “revision vs DAIR” there is only “revision + duration vs DAIR + duration”. But we are only assigning people to “revision + duration”, for DAIR, there is just one version “DAIR” with duration unspecified (but presumably 12 weeks). So long as duration is constant across revision and DAIR (at least the first-stage of revision), they think that the effect of “revision vs DAIR” will be the same. So, for them, we only need to compare one version of revision to DAIR (the one with 12-weeks duration following first-stage of revision).\nIn terms of the model, this is how I think about it…\nIf I recall correctly, they think that ~ 70% participants will probably refuse or be ineligible for participation in the duration domain. So, just thinking about the late-acute silo, ignoring everything else: amongst those who do not (or cannot) participate in duration, we have a comparison of some version of “DAIR vs revision” which we think is DAIR + 12 weeks, or revision with first-stage followed by 12 weeks and second-stage (if two-stage) followed by some short duration. This might include ~ 70% of late acute participants. Amongst those who do participate in duration, we have a comparison of some version of “DAIR vs revision + specified duration” where again, we think DAIR is with 12 weeks A/B duration, but is technically unspecified. This might be ~ 30%.\nAt the one extreme, we could just assume duration has no effect whatsoever, then we would obtain an effect of revision in those who do and those who do not participate in the duration domain. Say we might have a model assuming things are just additive on the log-odds.\nlog-odds(y) = (b0 + b1 * r) + (a0 + a1 * r) * p, where p just denotes participation in the duration domain, and r assignment to revision.\nWe’d have an effect of “DAIR vs. revision” amongst those who participate in duration assignment, b1, and one amongst those who do not, a1. We could choose to assume (model) b1 = a1, in which case there’s really just one effect of “DAIR vs. revision” which we think applies to everyone, or we could assume the effects might be different and consider both b1 and a1 as effects of “DAIR vs revision” in two different populations. If being Bayesian we could also do something in between, where b1 - a1 ~ Normal(0, s^2) for some small s. In this case, b1 ~= a1 unless we see some extreme difference, so a decision in one group would probably imply the same decision in the other. But irrespective of whether we assume a1 = b1 or not, we are making two comparisons/decisions: one for those who participate in A/B duration and one for those who do not.\nJust in the context of this model, there are then two in-trial decisions we might want to make: is b1 &gt; 0 and is a1 &gt; 0. If b1 &gt; 0, then for those who cannot participate in duration domain, we think revision is better, and might drop DAIR for that group. If a1 &gt; 0, then for those who can participate in duration domain, we think revision is better, and might drop DAIR for that group. If we assume in the model that a1 = b1, then we would drop DAIR or revision in both groups (duration participants and non-participants) at the same time. If we think a1 ~= b1, we will probably drop DAIR or revision in both groups or neither group but unlikely to make opposite decisions in groups. If we think |a1 - b1| could be large, then we might make different decisions in each group. But generally, sounds like we probably think |a1 - b1| is small, so we would expect to make the same decision for both groups. But the only way to certainly make the same decision (in the context of the model) in both groups is if we enforce a1 = b1. Sounds to me as though they would think a1 = b1.\nWe could also think of all the above as\n(b0 + b1 * E[r1|p=0] + b2 * E[r2|p=0]) + (a0 + a1 * E[r1|p=1] + a2 * E[r2|p=1]) * p\nwhere r1 is one-stage and r2 is two-stage, but we don’t really care about any of these selection differences for the comparison we are making.\n\nThe above ignores duration altogether. Alternatively, we think duration has some effect that we want to estimate, and we don’t want to ignore it altogether. To get to the heart of it, say that everyone who is assigned to revision gets a one-stage revision. Also, suppose that we did vary duration for both DAIR and revision participants. So for those who participate in duration domain, our model might be\na0 + a1r1 + a2d1 + a3r1d1\nwhere r1 = 1 if one-stage revision, and d1 = 1 if 6 weeks duration. r1 = 0 if DAIR and d1 = 0 if 12-weeks duration. In their mind, they already “know” that a2 = a3. So, revision + 12w vs DAIR + 12w effect is a1, and equivalently, revision + 6w vs DAIR + 6w effect is also a1 (because a3 - a2 = 0). Given they “know” a2 = a3, we are not assigning anyone to DAIR + 6w duration, instead we are only assigning DAIR + 12w, one-stage + 12w, one-stage + 6w. So our model is just a0 + a1r1 + a3r1*d1. Only two comparisons are of interest: DAIR + 12w vs one-stage + 12w (a1) and one-stage + 12w vs one-stage + 6w (a3). We don’t care about DAIR + 12w vs one-stage + 6w because we think if we shortened the DAIR duration to 6w this would be equivalent to DAIR + 12w vs one-stage + 12w.\nOf course, not all revisions are one-stage, so we have to allow for varying revision types given duration depends on revision type. We need to use the more general model (amongst those who choose to participate):\n(b0 + b1 * r) + (a0 + Er1|p=1 + E[r2|p=1] * (a2 + a4 * d2) * p\nwhere, say, d1 indicates 6 weeks after one-stage and d2 indicates short duration after two-stage. The reference is assumed to be the 12 week option for both revision types. But again, it now sounds to me like we only care about one-stage + 12w, two-stage + short vs DAIR, we aren’t interested in comparing one-stage + 6w, two-stage + whatever vs DAIR, because they believe if they also shortened A/B following DAIR the effect would be the same. There is still a question of the effect in participants and non-participants. Seems like we might think that b1 ~= Er1 + E[r2] * (a2), so if make a decision for one group, would happily apply that to both groups (A/B duration participants and non-participants). But more formally, could encode that in prior.\nBig picture we are still comparing a bunch of different strategies, it’s just in their model they choose to assume they all have the same equal effect so choosing one type of “revision” as better than DAIR implies choosing all types of revision are better than DAIR in all groups. Because of this, as noted above, it sounds to me like when we are considering “revision vs DAIR” they really only care about the version of revision where “one-stage with 12 weeks A/B duration or two-stage with first-stage 12 A/B weeks and second-stage short duration (&lt;24 hours)”. So that may be the only comparison we bother to make. To them, that effect would be the same as long as A/B duration following DAIR was equal to A/B duration following first-stage.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 2)"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html",
    "href": "notebooks/model-spec.html",
    "title": "Model specification",
    "section": "",
    "text": "The primary outcome is treatment success at 12 months post platform entry, defined as all of:\n\nAlive\nClinical cure (no clinical or microbiological evidence of infection)\nNo ongoing use of antibiotics for the index joint; and\nThe prosthesis present after the initial management strategy is complete (destination prosthesis) still in place\n\nreferred to as ‘treatment success’.",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#primary-outcome",
    "href": "notebooks/model-spec.html#primary-outcome",
    "title": "Model specification",
    "section": "",
    "text": "The primary outcome is treatment success at 12 months post platform entry, defined as all of:\n\nAlive\nClinical cure (no clinical or microbiological evidence of infection)\nNo ongoing use of antibiotics for the index joint; and\nThe prosthesis present after the initial management strategy is complete (destination prosthesis) still in place\n\nreferred to as ‘treatment success’.",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#early-infection",
    "href": "notebooks/model-spec.html#early-infection",
    "title": "Model specification",
    "section": "Early infection",
    "text": "Early infection\nPatients with early stage infection are not revealed1 to the surgical domain. The surgical intervention will usually be dair for which 12 weeks of antibiotics are recommended. There are, however, instances where early stage infection patients will receive a surgical intervention and these patients will therefore be able to enter the duration domain and receive randomised antibiotic duration. These patients will also enter the choice domain.",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#late-infection",
    "href": "notebooks/model-spec.html#late-infection",
    "title": "Model specification",
    "section": "Late infection",
    "text": "Late infection\nPatients with late infection enter all domains, but with some restrictions. They are randomised to dair vs revision in the surgical domain. Patients allocated to revision will receive a one or two-stage procedure. Both the planned surgery (one-stage/two-stage) and the surgery actually performed should be captured – the former should be recorded at the time of randomisation. These patients will also enter the choice domain.",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#chronic-infection",
    "href": "notebooks/model-spec.html#chronic-infection",
    "title": "Model specification",
    "section": "Chronic infection",
    "text": "Chronic infection\nPatients with chronic stage infection are not randomised into the surgical domain, but they can enter into the duration domain based on the type of surgery they receive. These patients will also enter the choice domain.",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#causal-structure",
    "href": "notebooks/model-spec.html#causal-structure",
    "title": "Model specification",
    "section": "Causal structure",
    "text": "Causal structure\nWe assume the following DAG, which is a simplified causal representation of how patients reach their treatment status across the domains:\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  ER(E&lt;sub&gt;R) --&gt; RA(R&lt;sub&gt;A) \n  ER --&gt; SR(S&lt;sub&gt;R)\n  ED(E&lt;sub&gt;D) --&gt; DA(D&lt;sub&gt;A) \n  SR --&gt; RA \n  SD(S&lt;sub&gt;D) --&gt; DA \n  R --&gt; RA\n  RA --&gt; RP(R&lt;sub&gt;P) \n  SRP(S&lt;sub&gt;R&lt;sub&gt;P) --&gt; RP\n  RA --&gt; Y\n  RP --&gt; ED\n  D --&gt; DA(D&lt;sub&gt;A)\n  DA --&gt; Y\n  F --&gt; FA(F&lt;sub&gt;A)\n  EF(E&lt;sub&gt;F) --&gt; FA\n  SF(S&lt;sub&gt;F) --&gt; FA \n  FA --&gt; Y\n  UER((U&lt;sub&gt;E&lt;sub&gt;R)) -.-&gt; ER\n  UED((U&lt;sub&gt;E&lt;sub&gt;D)) -.-&gt; ED\n  UEF((U&lt;sub&gt;E&lt;sub&gt;F)) -.-&gt; EF\n  UF((U&lt;sub&gt;F)) -.-&gt; F\n  URP((U&lt;sub&gt;R&lt;sub&gt;P)) -.-&gt; SRP\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  USR((U&lt;sub&gt;S&lt;sub&gt;R)) -.-&gt; SR\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  USD((U&lt;sub&gt;S&lt;sub&gt;D)) -.-&gt; SD\n  USF((U&lt;sub&gt;S&lt;sub&gt;F)) -.-&gt; SF\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 1: Assumed causal diagram representing the (simplified) processes on successful treatment\n\n\n\n\n\nwhere the following definitions apply:\n\n\\(E_R\\) reveal for surgical domain - 0: no, 1: yes\n\\(E_D\\) reveal for duration domain - 0: no, 1: yes\n\\(E_F\\) reveal for choice domain - 0: no, 1: yes\n\\(R\\) randomised surgery - 0: DAIR, 1: revision\n\\(S_R\\) revision type preference (pre-randomisation) - 0: DAIR, 1: one-stage, 2: two-stage\n\\(R_A\\) allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\n\\(R_P\\) performed surgery - 0: DAIR, 1: revision\n\\(S_{R_P}\\) revision type performed (post-randomisation) - 0: dair, 1: one-stage, 2: two-stage\n\\(D\\) randomised duration - 0: long, 1: short (for one-stage), 0: short, 1: long (for two-stage)\n\\(D_A\\) allocated duration - 0: long, 1: short, 2: other\n\\(S_D\\) selected duration - 0: long, 1: short, 2: other (sometimes duration will be selected rather than randomised)\n\\(F\\) randomised choice - 0: norif, 1: rif\n\\(F_A\\) allocated choice - 0: norif, 1: rif, 2: other\n\\(S_F\\) selected choice - 0: norif, 1: rif, 2: other\n\\(Y\\) treatment success - 0: no, 1: yes",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#research-questions",
    "href": "notebooks/model-spec.html#research-questions",
    "title": "Model specification",
    "section": "Research questions",
    "text": "Research questions\nThe questions of interest are:\n\nSurg Domain – Early Silo – Revision is superior to DAIR (reference group)\nAB Duration – One-stage revision – 6 weeks (short) is non-inferior to 12 weeks (long) (reference group)\nAB Duration – Two-stage revision – 12 weeks (long) is superior to 7 days (short) (reference group)\nAB Choice – All silos combined – Rifampicin is superior to no-rifampicin (reference group)",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#sec-model-spec",
    "href": "notebooks/model-spec.html#sec-model-spec",
    "title": "Model specification",
    "section": "Model specification",
    "text": "Model specification\nFor each silo \\(l\\) and site of infection \\(j\\) we therefore simulate and model the probability of treatment success as:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|Q; \\alpha,  \\beta,\\lambda] &=  \\text{expit}( \\alpha_0 + \\\\\n  &\\quad \\lambda_1 \\mathbb{I}(L = 1) + \\lambda_2 \\mathbb{I}(L = 2) + \\\\\n  &\\quad (\\beta_1 + \\beta_2 \\mathbb{I}(S_{R_P} = 1) + \\beta_3 \\mathbb{I}(S_{R_P} = 2) ) (1-E_R) +\\\\\n  &\\quad (\\beta_4 \\mathbb{I}(S_{R_P} = 1) + \\beta_5 \\mathbb{I}(S_{R_P} = 2) )R E_R + \\\\\n  &\\quad \\beta_6 (1-E_D) + \\\\\n  &\\quad (\\beta_{7} \\mathbb{I}(S_{R_P} = 1) + \\beta_{8} \\mathbb{I}(S_{R_P} = 2))D E_D + \\\\\n  &\\quad \\beta_{9} (1-E_F) + \\beta_{10} F E_F )\n\\end{aligned}\n\\tag{1}\\]\nwhere the \\(Q\\), \\(\\alpha\\), \\(\\lambda\\) and \\(\\beta\\) denote the terms and parameters included in the model and specifically\n\n\\(\\alpha_0\\) denotes the baseline log-odds of treatment success\n\\(\\lambda_1\\) change associated with membership of the late silo\n\\(\\lambda_2\\) change associated with membership of the chronic silo\n\\(\\beta_{1}\\) change under non-randomised surgical treatment relative to randomised surgical treatment\n\\(\\beta_{2}\\) relative change under non-randomised surgical treatment (receiving one-stage)\n\\(\\beta_{3}\\) relative change under non-randomised surgical treatment (receiving two-stage)\n\\(\\beta_{4}\\) change under randomised surgical treatment (revision) where one-stage procedure occurred\n\\(\\beta_{5}\\) change under randomised surgical treatment (revision) where two-stage procedure occurred\n\\(\\beta_{6}\\) change under non-randomised duration treatment\n\\(\\beta_{7}\\) change for randomised duration treatment (short duration) when one-stage surgical procedure occurred\n\\(\\beta_{8}\\) change for randomised duration treatment (long duration) when two-stage surgical procedure occurred\n\\(\\beta_{9}\\) change under non-randomised choice treatment\n\\(\\beta_{10}\\) change for randomised choice treatment (rif)\n\nIn order to easily evaluate the duration effects, we to make the reference arm 12-weeks (long) in the case of one-stage revision and 7-days (short) in the case of two-stage revision.\nIn the full model, there would be additional terms to capture time trends, site variation, prognostic covariates and joint (knee/hip) effects.\n\\(\\beta_1\\), \\(\\beta_2\\) and \\(\\beta_3\\) are required because there will be some patients who are not randomised to revision and yet will still receive either a one-stage or two-stage surgical procedure. These patients may be eligible to enter into the duration domain and therefore the duration domain effects are informed by patients receiving randomised and non-randomised surgical treatment. The \\(\\beta_1\\), \\(\\beta_2\\) and \\(\\beta_3\\) parameters provide adjustment for non-randomised surgical treatment and \\(\\beta_4\\) and \\(\\beta_5\\) provide adjustment for the patients that did.\nNotice that \\(E_D = 0\\) generally implies \\(S_{R_P} \\notin \\{1, 2\\}\\) such that \\(1-E_D\\) is some linear function of the other terms in the model. This can lead to estimation problems that might necessitate model re-parameterisation and it is for this reason that the simulation model drops the \\((1 - E_D)\\) term and re-index the \\(\\beta\\) parameters:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|Q; \\alpha,  \\beta,\\lambda] &=  \\text{expit}( \\alpha_0 + \\\\\n  &\\quad \\lambda_1 \\mathbb{I}(L = 1) + \\lambda_2 \\mathbb{I}(L = 2) + \\\\\n  &\\quad (\\beta_1 + \\beta_2 \\mathbb{I}(S_{R_P} = 1) + \\beta_3 \\mathbb{I}(S_{R_P} = 2) ) (1-E_R) +\\\\\n  &\\quad (\\beta_4 \\mathbb{I}(S_{R_P} = 1) + \\beta_5 \\mathbb{I}(S_{R_P} = 2) )R E_R + \\\\\n  &\\quad (\\beta_{6} \\mathbb{I}(S_{R_P} = 1) + \\beta_{7} \\mathbb{I}(S_{R_P} = 2))D E_D + \\\\\n  &\\quad \\beta_{8} (1-E_F) + \\beta_{9} F E_F )\n\\end{aligned}\n\\tag{2}\\]",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#examples",
    "href": "notebooks/model-spec.html#examples",
    "title": "Model specification",
    "section": "Examples",
    "text": "Examples\nThe following characterise how patients enter into the likelihood under various scenarios under Equation 2. The main consideration is whether randomised or non-randomised surgical treatment occurs and how this impacts the other terms in the model.\n\nRandomised surgical treatment\n\n\nLikelihood contributions under various scenarios\n\n\n\n\n\n\n\nID\nCovariate characteristics\nLog-odds treatment success\n\n\n\n\n1a\nLate silo receiving rand DAIR, non-rand AB duration and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_{9}\\)\n\n\n2a\nLate silo receiving rand rev (one-stage), rand 12 weeks AB (ref) and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_4 + \\beta_{9}\\)\n\n\n3a\nLate silo receiving rand rev (one-stage), rand 6 weeks AB and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_4 + \\beta_6 + \\beta_{9}\\)\n\n\n4a\nLate silo receiving rand rev (two-stage), rand 7 days AB (ref) and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_5 + \\beta_{9}\\)\n\n\n5a\nLate silo receiving rand rev (two-stage), rand 12 weeks AB and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_5 + \\beta_7 + \\beta_{9}\\)\n\n\n\n\n\n\nNon-randomised surgical treatment\n\n\n\n\n\n\nNote\n\n\n\n\n\nUnsure whether non-randomised surgical treatment would occur for the late-silo patients but have included anyway.\nIf the non-reveal parameters for the surgical domain were not split by surgery type, then, in the following table:\n\nID 7b would have the same terms as ID 9b\nID 12b would have the same terms as ID 14b\n\n\n\n\n\n\nLikelihood contributions under various scenarios\n\n\n\n\n\n\n\nID\nCovariate characteristics\nLog-odds treatment success\n\n\n\n\n1b\nEarly silo receiving non-rand DAIR, non-rand AB duration and rand rif\n\\(\\alpha_0 + \\beta_1 + \\beta_{9}\\)\n\n\n2b\nEarly silo receiving non-rand rev (one-stage), rand 12 weeks AB (ref) and rand rif\n\\(\\alpha_0 + \\beta_1 + \\beta_2 + \\beta_{9}\\)\n\n\n3b\nEarly silo receiving non-rand rev (one-stage), rand 6 weeks AB and rand rif\n\\(\\alpha_0 + \\beta_1 + \\beta_2 + \\beta_6 + \\beta_{9}\\)\n\n\n4b\nEarly silo receiving non-rand rev (two-stage), rand 7 days AB (ref) and rand rif\n\\(\\alpha_0 + \\beta_1 + \\beta_3 + \\beta_{9}\\)\n\n\n5b\nEarly silo receiving non-rand rev (two-stage), rand 12 weeks AB and rand rif\n\\(\\alpha_0 + \\beta_1 + \\beta_3 + \\beta_7 + \\beta_{9}\\)\n\n\n\n\n\n\n\n6b\nLate silo receiving non-rand DAIR, non-rand AB duration and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_1 + \\beta_{9}\\)\n\n\n7b\nLate silo receiving non-rand rev (one-stage), rand 12 weeks AB (ref) and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_1 + \\beta_2 + \\beta_{9}\\)\n\n\n8b\nLate silo receiving non-rand rev (one-stage), rand 6 weeks AB and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_1 + \\beta_2 + \\beta_6 + \\beta_{9}\\)\n\n\n9b\nLate silo receiving non-rand rev (two-stage), rand 7 days AB (ref) and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_1 + \\beta_3 + \\beta_{9}\\)\n\n\n10b\nLate silo receiving non-rand rev (two-stage), rand 12 weeks AB and rand rif\n\\(\\alpha_0 + \\lambda_1 + \\beta_1 + \\beta_3 + \\beta_7 + \\beta_{9}\\)\n\n\n\n\n\n\n\n11b\nChronic silo receiving non-rand DAIR, non-rand AB duration and rand rif\n\\(\\alpha_0 + \\lambda_2 + \\beta_1 + \\beta_{9}\\)\n\n\n12b\nChronic silo receiving non-rand rev (one-stage), rand 12 weeks AB (ref) and rand rif\n\\(\\alpha_0 + \\lambda_2 + \\beta_1 + \\beta_2 + \\beta_{9}\\)\n\n\n13b\nChronic silo receiving non-rand rev (one-stage), rand 6 weeks AB and rand rif\n\\(\\alpha_0 + \\lambda_2 + \\beta_1 + \\beta_2 + \\beta_6 + \\beta_{9}\\)\n\n\n14b\nChronic silo receiving non-rand rev (two-stage), rand 7 days AB (ref) and rand rif\n\\(\\alpha_0 + \\lambda_2 + \\beta_1 + \\beta_3 + \\beta_{9}\\)\n\n\n15b\nChronic silo receiving non-rand rev (two-stage), rand 12 weeks AB and rand rif\n\\(\\alpha_0 + \\lambda_2 + \\beta_1 + \\beta_3 + \\beta_7 + \\beta_{9}\\)",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#treatment-effects",
    "href": "notebooks/model-spec.html#treatment-effects",
    "title": "Model specification",
    "section": "Treatment effects",
    "text": "Treatment effects\nFor the surgical domain, the effect of interest is an average conditional log-odds ratio and is applicable to the late silo. This amounts to a weighted combination of \\(\\beta_2\\) and \\(\\beta_3\\) where the weights are the sample based expectations for the probability of receiving one-stage and two-stage surgery.\n\\[\n\\begin{aligned}\n\\Delta_R = \\beta_4 \\mathbb{E}[S_{R_P} == 1 \\land R == 1] + \\beta_5 \\mathbb{E}[S_{R_P} == 2 \\land R == 1]\n\\end{aligned}\n\\]\nFor the duration domain, the conditional log-odds ratios of interest are \\(\\beta_6\\) and \\(\\beta_7\\) which characterise the effect of 6 weeks (short) vs 12 weeks (long) under one-stage revision and 12 weeks (long) vs 7 days (short) in two-stage revision. For the choice domain, the conditional log-odd ratios of interest is \\(\\beta_{9}\\), characterising the effect of rifampacin vs no-rifampacin. For the duration and choice domains, the effects are applicable to all silos.",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#priors",
    "href": "notebooks/model-spec.html#priors",
    "title": "Model specification",
    "section": "Priors",
    "text": "Priors\nAs with the linear predictor, the priors are currently targeted towards the simulation work and may be modified in the final model.\n\nIntercepts\nThe silo and infection site intercepts are given independent normal priors\n\\[\\begin{aligned}\n\\alpha_0 \\sim \\mathcal{N}(0, 1.5^2)\n\\end{aligned}\\]\nOn the probability scale, these concentrate on 0.5 with 95% of the density between 0.04 and 0.96, approximately uniform across this interval.\n\n\nOther covariates\nIndependent standard normal priors are assumed for all other covariate terms effects.\n\n\nTreatment effects\nAll covariates relating to treatment effects have standard normal priors.",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#footnotes",
    "href": "notebooks/model-spec.html#footnotes",
    "title": "Model specification",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nDependent on how the randomisation process is designed and implemented, they might not even be randomised.↩︎",
    "crumbs": [
      "Assumptions and setup",
      "Model specification"
    ]
  },
  {
    "objectID": "backup/trial-data.html",
    "href": "backup/trial-data.html",
    "title": "Simulated trial data",
    "section": "",
    "text": "The following give a sense of the number of participants contributing to each treatment arm and cell. The data are simulated under the model specification with a total sample size of 2500.\nCode\nset.seed(1)\nll &lt;- get_trial_data(N = 2500)\n\nd &lt;- copy(ll$d)"
  },
  {
    "objectID": "backup/trial-data.html#surgical-domain",
    "href": "backup/trial-data.html#surgical-domain",
    "title": "Simulated trial data",
    "section": "Surgical domain",
    "text": "Surgical domain\nOnly patients in the late silo receive randomised surgical treatment (dair vs revision) with the type of revision selected by the clinician. Table 1 shows the allocation to dair vs rev for this cohort and the balance across the remaining group levels in the data.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[l1 == 1 & er == 1, .(er, r, ed, srp, d)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(r, ed, srp, d)]\nd_B &lt;- dcast(d_tmp2, ed + d + srp ~ r, value.var = \"N\")\nd_B[, domain := \"Duration\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", \"surgery\", \"dair\", \"rev\", \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[l1 == 1 & er == 1, .(er, r, ef, srp, f)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(r, ef, srp, f)]\nd_C &lt;- dcast(d_tmp2, ef + f + srp ~ r, value.var = \"N\")\nd_C[, domain := \"Choice\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", \"surgery\", \"dair\", \"rev\", \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C, fill = TRUE)\n# d_tbl[, group := factor(group, levels = c(\"w12\",\"w12p1\", \"w06p1\", \"w12p2\", \"d07p2\", \"other\", \"norif\", \"rif\"))]\nd_tbl &lt;- d_tbl[order(domain, rand, surgery, group)]\n\nd_tbl[, total := rowSums(d_tbl[, .(dair, rev)], na.rm = T)]\nd_tbl[domain == \"Choice\" & rand == 0, group := NA]\nd_tbl[domain == \"Duration\" & rand == 0, group := NA]\n\ncols &lt;- c(\"Domain\", \"Revealed\", \"Treatment\", \"Surgery recvd\", \"DAIR\", \"Revision\", \"Total\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  )  |&gt;\n  tab_spanner(\n    label = html(\"Domain A (late silo)\"),\n    columns = c(dair, rev),\n    id = \"da\"\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols) |&gt; \n  summary_rows(\n    columns = c(\"dair\", \"rev\", \"total\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )  |&gt;\n  tab_footnote(\n    footnote = \"Revealed indicates whether units were randomised into choice/duration domain (0: No, 1: Yes)\",\n    locations = cells_column_labels(columns = rand)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Surgery recvd indicates surgery type actually perfromed (0: dair, 1: one-stage, 2: two-stage). Surgery recvd may deviate from original randomisation/plan.\",\n    locations = cells_column_labels(columns = surgery)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Treatment indicates which treatment assigned within domain. For choice (0: no-rif, 1: rif). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the choice/duration domain have undefined randomised treatment status.\",\n    locations = cells_column_labels(columns = group)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Only units randomised to surgery domain reported.\",\n    locations = cells_column_spanners(spanners = \"da\")\n  )\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRevealed2\nTreatment3\nSurgery recvd4\nDomain A (late silo)1\nTotal\n\n\nDAIR\nRevision\n\n\n\n\nChoice\n\n\n\n0\n-\n0\n253\n-\n253\n\n\n\n0\n-\n1\n-\n77\n77\n\n\n\n0\n-\n2\n-\n178\n178\n\n\n\n1\n0\n0\n198\n-\n198\n\n\n\n1\n1\n0\n182\n-\n182\n\n\n\n1\n0\n1\n-\n68\n68\n\n\n\n1\n1\n1\n-\n56\n56\n\n\n\n1\n0\n2\n-\n121\n121\n\n\n\n1\n1\n2\n-\n142\n142\n\n\nsubtotal\n—\n—\n—\n633\n642\n1275\n\n\nDuration\n\n\n\n0\n-\n0\n633\n-\n633\n\n\n\n1\n0\n1\n-\n91\n91\n\n\n\n1\n1\n1\n-\n110\n110\n\n\n\n1\n0\n2\n-\n224\n224\n\n\n\n1\n1\n2\n-\n217\n217\n\n\nsubtotal\n—\n—\n—\n633\n642\n1275\n\n\n\n1 Only units randomised to surgery domain reported.\n\n\n2 Revealed indicates whether units were randomised into choice/duration domain (0: No, 1: Yes)\n\n\n3 Treatment indicates which treatment assigned within domain. For choice (0: no-rif, 1: rif). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the choice/duration domain have undefined randomised treatment status.\n\n\n4 Surgery recvd indicates surgery type actually perfromed (0: dair, 1: one-stage, 2: two-stage). Surgery recvd may deviate from original randomisation/plan.\n\n\n\n\n\n\n\n\n\nTable 1: Simulated trial data for (late silo) surgical domain - covariate balance across other groups"
  },
  {
    "objectID": "backup/trial-data.html#duration-domain",
    "href": "backup/trial-data.html#duration-domain",
    "title": "Simulated trial data",
    "section": "Duration domain",
    "text": "Duration domain\nTable 2 shows the allocation to the duration domain conditional on surgery type actually received and the balance across the remaining group levels in the data. Only units randomised within the duration domain are reported.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[ed == 1, .(ed, d, er, r, srp)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(d, er, r,srp)]\n# d_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_B &lt;- dcast(d_tmp2, er + r ~ srp + d, value.var = \"N\")\nd_B[, domain := \"Surgery\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", c(\"long_1\", \"short_1\", \"long_2\", \"short_2\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[ed == 1, .(ed, d, ef, f, srp)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(d, ef, f, srp)]\n# d_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_C &lt;- dcast(d_tmp2, ef + f ~ srp + d, value.var = \"N\")\nd_C[, domain := \"Choice\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", c(\"long_1\", \"short_1\", \"long_2\", \"short_2\"), \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C, fill = T)\n\nd_tbl[, total := rowSums(d_tbl[, .(long_1, short_1, long_2, short_2)], na.rm = T)]\nd_tbl[domain == \"Surgery\" & rand == 0, group := NA]\nd_tbl[domain == \"Choice\" & rand == 0, group := NA]\n\ncols &lt;- c(\"Domain\", \"Revealed\", \"Treatment\", c(\"long\", \"short\", \"long\", \"short\"), \"Total\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt; \n  summary_rows(\n    columns = c(\"long_1\", \"short_1\", \"long_2\", \"short_2\", \"total\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )   |&gt;\n  tab_spanner(\n    label = html(\"AB Duration &lt;br&gt;(one-stage)\"),\n    columns = c(\"long_1\", \"short_1\"),\n    id = \"d1\"\n  ) |&gt;\n  tab_spanner(\n    label = html(\"AB Duration &lt;br&gt;(two-stage)\"),\n    columns = c(\"long_2\", \"short_2\"),\n    id = \"d2\"\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)  |&gt;\n  tab_footnote(\n    footnote = \"Revealed indicates whether units were randomised into surgery/duration domain (0: No, 1: Yes)\",\n    locations = cells_column_labels(columns = rand)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Treatment indicates which treatment assigned within domain. For choice (0: no-rif, 1: rif). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the surgery/choice domain have undefined randomised treatment status.\",\n    locations = cells_column_labels(columns = group)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Only units randomised to interventions in the surgery domain reported. One-stage/two-stage is by clinician selection\",\n    locations = cells_column_spanners(spanners = c(\"d1\", \"d2\"))\n  )\n\n\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevealed2\nTreatment3\nAB Duration\n(one-stage)1\nAB Duration\n(two-stage)1\nTotal\n\n\nlong\nshort\nlong\nshort\n\n\n\n\nSurgery\n\n\n\n0\n-\n88\n88\n159\n147\n482\n\n\n\n1\n1\n91\n110\n224\n217\n642\n\n\nsubtotal\n—\n—\n179\n198\n383\n364\n1124\n\n\nChoice\n\n\n\n0\n-\n71\n83\n151\n151\n456\n\n\n\n1\n0\n56\n60\n100\n105\n321\n\n\n\n1\n1\n52\n55\n132\n108\n347\n\n\nsubtotal\n—\n—\n179\n198\n383\n364\n1124\n\n\n\n1 Only units randomised to interventions in the surgery domain reported. One-stage/two-stage is by clinician selection\n\n\n2 Revealed indicates whether units were randomised into surgery/duration domain (0: No, 1: Yes)\n\n\n3 Treatment indicates which treatment assigned within domain. For choice (0: no-rif, 1: rif). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the surgery/choice domain have undefined randomised treatment status.\n\n\n\n\n\n\n\n\n\nTable 2: Simulated trial data for AB duration domain - covariate balance across other groups"
  },
  {
    "objectID": "backup/trial-data.html#choice-domain",
    "href": "backup/trial-data.html#choice-domain",
    "title": "Simulated trial data",
    "section": "Choice domain",
    "text": "Choice domain\nTable 3 shows the allocation to the choice domain and the balance across the remaining group levels in the data. Only units randomised within the antibiotic choice domain are reported.\n\n\nCode\n# domain \nd_tmp1 &lt;- d[ef == 1, .(f, er, r, srp)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(f, er, r, srp)]\n# d_tmp2[, a := factor(a, levels = c(\"dair\", \"rev\", \"one\", \"two\"))]\n# d_tmp2[, qa := factor(qa, levels = c(\"dair\", \"one\", \"two\"))]\n# d_tmp2[, c := factor(c, levels = c(\"other\", \"norif\", \"rif\"))]\nd_A &lt;- dcast(d_tmp2, er + srp + r ~ f, value.var = \"N\")\nd_A[, domain := \"Surgery\"]\ncolnames(d_A) &lt;- c(\"rand\", \"surgery\",\"group\",  c(\"norif\", \"rif\"), \"domain\")\nsetcolorder(d_A, \"domain\")\n# domain\nd_tmp1 &lt;- d[ef == 1, .(f, ed, d, srp)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(f, ed, d, srp)]\n# d_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\n# d_tmp2[, c := factor(c, levels = c(\"other\", \"norif\", \"rif\"))]\nd_B &lt;- dcast(d_tmp2, ed + srp + d ~ f, value.var = \"N\")\nd_B[, domain := \"Duration\"]\ncolnames(d_B) &lt;- c(\"rand\", \"surgery\", \"group\", c(\"norif\", \"rif\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n\nd_tbl &lt;- rbind(d_A, d_B, fill = T)\n\nd_tbl[, total := rowSums(d_tbl[, .(norif, rif)], na.rm = T)]\n\nd_tbl[domain == \"Surgery\" & rand == 0, group := NA]\nd_tbl[domain == \"Duration\" & rand == 0, group := NA]\n\n\n\ncols &lt;- c(\"Domain\", \"Revealed\", \"Surgery recvd\", \"Treatment\", c(\"norif\", \"rif\"), \"Total\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt; \n  summary_rows(\n    columns = c(\"norif\", \"rif\", \"total\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  ) |&gt;\n  tab_spanner(\n    label = html(\"AB Choice\"),\n    columns = c(\"norif\", \"rif\"),\n    id = \"c1\"\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)|&gt;\n  tab_footnote(\n    footnote = \"Revealed indicates whether units were randomised into surgery/choice domain (0: No, 1: Yes)\",\n    locations = cells_column_labels(columns = rand)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Treatment indicates which treatment assigned within domain. For surgery (0: dair, 1: rev). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the surgery/duration domain have undefined randomised treatment status.\",\n    locations = cells_column_labels(columns = group)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Only units randomised to interventions in the antibiotic choice domain reported.\",\n    locations = cells_column_spanners(spanners = c(\"c1\"))\n  )\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRevealed2\nSurgery recvd\nTreatment3\nAB Choice1\nTotal\n\n\nnorif\nrif\n\n\n\n\nSurgery\n\n\n\n0\n0\n-\n229\n232\n461\n\n\n\n0\n1\n-\n48\n51\n99\n\n\n\n0\n2\n-\n84\n98\n182\n\n\n\n1\n0\n0\n198\n182\n380\n\n\n\n1\n1\n1\n68\n56\n124\n\n\n\n1\n2\n1\n121\n142\n263\n\n\nsubtotal\n—\n—\n—\n748\n761\n1509\n\n\nDuration\n\n\n\n0\n0\n-\n427\n414\n841\n\n\n\n1\n1\n0\n56\n52\n108\n\n\n\n1\n1\n1\n60\n55\n115\n\n\n\n1\n2\n0\n100\n132\n232\n\n\n\n1\n2\n1\n105\n108\n213\n\n\nsubtotal\n—\n—\n—\n748\n761\n1509\n\n\n\n1 Only units randomised to interventions in the antibiotic choice domain reported.\n\n\n2 Revealed indicates whether units were randomised into surgery/choice domain (0: No, 1: Yes)\n\n\n3 Treatment indicates which treatment assigned within domain. For surgery (0: dair, 1: rev). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the surgery/duration domain have undefined randomised treatment status.\n\n\n\n\n\n\n\n\n\nTable 3: Simulated trial data for AB choice domain - covariate balance across other groups"
  },
  {
    "objectID": "backup/design-notes-06.html",
    "href": "backup/design-notes-06.html",
    "title": "Multi-level model",
    "section": "",
    "text": "The following starts on restructuring the linear predictor into a multi-level form. The revision effects are constructed from a overall, joint and assignment level effects. The backbone duration will follow a similar template.\nBelow we consider parameters that characterise variation in the linear predictor due to:\n\\[\n\\begin{aligned}\n\\text{logit}(p) &= \\beta_0 + \\beta_{s,j} + \\\\\n  &\\beta_{u_{d1}} + \\beta_{d1,j}\n\\end{aligned}\n\\]\nFurther detail is provided below on the construction of the revision effects.\nThe idea is to produce the following structure:\nwith the idea that if there were more groups, you would be able to estimate the variance components and achieve some adaptive shrinkage."
  },
  {
    "objectID": "backup/design-notes-06.html#parameter-specificationgeneration",
    "href": "backup/design-notes-06.html#parameter-specificationgeneration",
    "title": "Multi-level model",
    "section": "Parameter specification/generation",
    "text": "Parameter specification/generation\n\n\nParameter specification\nget_par &lt;- function(seed = 1){\n  \n  set.seed(seed)\n  \n  l &lt;- list()\n  l$b0 &lt;- qlogis(0.6205)\n  \n  # silo by joint\n  l$b_s &lt;- matrix(\n    c(0.02, 0.4, -0.2) + rnorm(6, 0, 0.01),\n    ncol = 2)\n  \n  # baseline surgical pref\n  l$b_u_d1 &lt;- c(0, rnorm(2, 0, 1))\n  \n  # removed, think this is redundant.\n  # main effect of hip/knee\n  # hip (1), knee (2) make knee worse than hip\n  # l$b_j &lt;- c(0, -0.2)\n  \n  # surgery domain - \n  # averge effect of surgery\n  l$mu_d1_rev &lt;- 0.4\n  # between joint variation\n  l$tau_d1_rev &lt;- 0.1\n  # joint level means\n  l$mu_d1_rev_jnt &lt;- rnorm(2, l$mu_d1_rev, l$tau_d1_rev)\n  # within joint variation\n  l$s_d1_rev &lt;- 0.1\n  # trt effects, \n  # idx 1:3 non-rand (dair, one-stage, two-stage)\n  # idx 4: rand, reference group (dair)\n  # idx 5: rand rev (one-stage)\n  # idx 6: rand rev (two-stage)\n  # may add:\n  # idx ?: rand, not delivered/revealed (probably redundant, left out for now)\n  l$b_d1 &lt;- matrix(NA, nrow = 6, ncol = 2)\n  l$b_d1[1:3, ] &lt;- rnorm(6, 0, 1)\n  l$b_d1[4, ] &lt;- 0\n  l$b_d1[5, ] &lt;- rnorm(2, l$mu_d1_rev_jnt, l$s_d1_rev)\n  l$b_d1[6, ] &lt;- rnorm(2, l$mu_d1_rev_jnt, l$s_d1_rev)\n  \n  l\n  \n}"
  },
  {
    "objectID": "backup/design-notes-06.html#data-simulation",
    "href": "backup/design-notes-06.html#data-simulation",
    "title": "Multi-level model",
    "section": "Data simulation",
    "text": "Data simulation\n\n\nData generation function\nget_data &lt;- function(\n    N = 2000, \n    ff = function(par, s, j, d1, u_d1, i_d1, d2, d3, u_d4, d4){\n      \n      m1 &lt;- cbind(s, j)\n      m2 &lt;- cbind(i_d1, j)\n      \n      eta = par$b0 + par$b_s[m1] + par$b_u_d1[u_d1] +\n        par$b_d1[m2] \n        \n      eta\n      \n    }){\n  \n  # strata\n  d &lt;- data.table()\n  d[, s := sample(1:3, size = N, replace = T, prob = c(0.3, 0.5, 0.2))]\n  \n  # joint - there is bound to be some relation b/w joint and pref towards surg\n  d[, j := as.numeric(NA)]\n  d[s == 1, j := sample(1:2, size = .N, replace = T, prob = c(0.6, 0.4))]\n  d[s == 2, j := sample(1:2, size = .N, replace = T, prob = c(0.3, 0.7))]\n  d[s == 3, j := sample(1:2, size = .N, replace = T, prob = c(0.5, 0.5))]\n  \n  # rand and non-randomised surgery recorded (1 dair, 2:3 rev)  \n  d[, d1 := as.numeric(NA)]\n  d[s == 1, d1 := -1]\n  d[s == 1, u_d1 := sample(1:3, size = .N, replace = T, prob = c(0.9, 0.1, 0))]\n  d[s == 2, d1 := rbinom(.N, 1, 0.5)]\n  # late only has probs for 2:3 but really this should be split up into \n  # preference overall and preference given revision\n  d[s == 2, u_d1 := sample(1:3, size = .N, replace = T, prob = c(0, 0.3, 0.7))]\n  d[s == 3, d1 := -1]\n  d[s == 3, u_d1 := sample(1:3, size = .N, replace = T, prob = c(0.2, 0.2, 0.6))]\n  \n  # indices for surgery\n  d[, i_d1 := as.numeric(NA)]\n  d[s == 1, i_d1 := u_d1]\n  d[s == 2 & d1 == 0, i_d1 := 4]\n  d[s == 2 & d1 == 1 & u_d1 == 2, i_d1 := 5]\n  d[s == 2 & d1 == 1 & u_d1 == 3, i_d1 := 6]\n  d[s == 3, i_d1 := u_d1]\n  # table(d$s, d$i_d1)\n  \n  # some backbone dose b/w 0 and 12 wks\n  # based on surg recvd, e.g dair\n  d[u_d1 == 1, d2 := -1]\n  # recvd one\n  d[u_d1 == 2, d2 := rbinom(.N, 1, 0.5)]\n  # recvd two\n  d[u_d1 == 3, d2 := -1]\n  \n  \n  # ext proph\n  # based on surg recvd, e.g. dair\n  d[u_d1 == 1, d3 := -1]\n  # recvd one\n  d[u_d1 == 2, d3 := -1]\n  # recvd two\n  d[u_d1 == 3, d3 := rbinom(.N, 1, 0.5)]\n  \n  # choice - 60% pop enter\n  d[, u_d4 := rbinom(.N, 1, 0.6)]\n  d[u_d4 == 1, d4 := rbinom(.N, 1, 0.5)]\n  d[u_d4 == 0, d4 := -1]\n  \n  d[, eta := ff(par = get_par(), s, j, d1, u_d1, i_d1, d2, d3, u_d4, d4)]\n  \n  d[, y := rbinom(.N, 1, plogis(eta))]\n  \n  d  \n}\n\nset.seed(432)\nd &lt;- get_data(N = 2500)\n\n\nModel implementation\n\n\nLogistic regression\n// make it work, make it right, make it quicker\ndata {\n  int N;\n  array[N] int y;\n  // idx into silo\n  array[N] int silo;\n  // idx into joint\n  array[N] int jnt;\n  \n  // surg type pref (dair, one, two)\n  array[N] int u_d1;\n  // idx into domain 1 trts\n  array[N] int i_d1;\n}\ntransformed data {\n}\nparameters{\n  real b0;\n  \n  // silo\n  matrix[3, 2] b_s;\n  // baseline adj for surg pref (one-stage = 2, two-stage = 3)\n  vector[2] b_u_d1_raw;\n  \n  // domain 1\n  \n  // non-rand effects (dair/hip, one/hip, ..., two/knee)\n  vector[6] b_d1_non_rand;\n  \n  // overall mean for revision effect across one-stage (hip), two-stage (hip)\n  // one-stage (knee), two-stage (knee) groups\n  real mu_d1;\n  real&lt;lower=0&gt; s_mu_d1;\n  vector[2] z_mu_d1;\n  // within joint variation\n  real&lt;lower=0&gt; s_b_d1;\n  vector[4] z_b_d1;\n  \n}\ntransformed parameters{\n  \n  vector[N] eta;\n  vector[3] b_u_d1;\n  \n  // domain 1 effects, strat by joint\n  matrix[6, 2] b_d1;\n  // average effect (offset) of one-stage irrespective of joint\n  vector[2] mu_d1_j;\n  \n  // baseline pref adj \n  b_u_d1[1] = 0.0;\n  b_u_d1[2:3] = b_u_d1_raw;\n  \n  // within each joint type we have some mean effect of revision\n  mu_d1_j = mu_d1 + z_mu_d1 * s_mu_d1;\n  \n  // non-rand effects for those recv dair, one, two in hip and knee\n  b_d1[1, ] = to_row_vector(b_d1_non_rand[1:2]);\n  b_d1[2, ] = to_row_vector(b_d1_non_rand[3:4]);\n  b_d1[3, ] = to_row_vector(b_d1_non_rand[5:6]);\n  // reference group for hip and knee\n  b_d1[4, ] = rep_row_vector(0.0, 2);\n  // around the joint means, we have the effects of one-stage and two-stage rev\n  b_d1[5, ] = to_row_vector(mu_d1_j + z_b_d1[1:2] * s_b_d1);\n  b_d1[6, ] = to_row_vector(mu_d1_j + z_b_d1[3:4] * s_b_d1);\n\n  for(i in 1:N){\n    eta[i] = b0 + \n      b_s[silo[i], jnt[i]] + b_u_d1[u_d1[i]] +\n      b_d1[i_d1[i], jnt[i]];\n  }\n  \n}\nmodel{\n  \n  target += logistic_lpdf(b0 | 0, 1);\n  \n  // silo/baseline adj\n  target += std_normal_lpdf(to_vector(b_s));\n  target += std_normal_lpdf(b_u_d1_raw);\n  \n  // domain 1 effect components\n  target += std_normal_lpdf(b_d1_non_rand);\n  \n  target += std_normal_lpdf(mu_d1);\n  target += student_t_lpdf(s_mu_d1 | 3, 0, 2) - \n    1 * student_t_lccdf(0 | 3, 0, 2);\n  // target += exponential_lpdf(s_mu_d1 | 1);\n  target += std_normal_lpdf(z_mu_d1);\n  \n  target += student_t_lpdf(s_b_d1 | 3, 0, 2) - \n    1 * student_t_lccdf(0 | 3, 0, 2);\n  // target += exponential_lpdf(s_b_d1 | 1);\n  target += std_normal_lpdf(z_b_d1);\n  \n  target += bernoulli_logit_lpmf(y | eta);\n  \n}\ngenerated quantities{\n  \n}\n\n\n\n\nFit model to simulated data\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-04.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y, silo = d$s, jnt = d$j,\n  u_d1 = d$u_d1, i_d1 = d$i_d1\n)\n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 17.2 seconds.\nChain 1 finished in 18.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 17.9 seconds.\nTotal execution time: 18.7 seconds.\n\n\nWarning: 12 of 2000 (1.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nFit model to simulated data\n# quick work - but estimates will be rough, variance very rough\n# snk &lt;- capture.output(\n#       f1 &lt;- m1$pathfinder(ld, num_paths=20, single_path_draws=200,\n#                              history_size=50, max_lbfgs_iters=100,\n#                              refresh = 0, draws = 2000)\n#     )\n\n\nComparing parameter estimates with parameters used to simulate the data.\n\n\nParameter estimates vs true values\npar &lt;- get_par()\nd_fig &lt;- data.table(f1$summary(variables = c(\n  \"b0\", \"b_s\", \"b_u_d1\", \n  \"mu_d1\", \"s_mu_d1\", \"mu_d1_j\", \"s_b_d1\",\n  \"b_d1\"\n)))\nd_fig &lt;- d_fig[, .(variable, mean, q5, q95)]\nd_fig[, par_tru := unlist(par)]\nd_fig[, variable := factor(d_fig$variable, levels = d_fig$variable)]\n\nggplot(d_fig, aes(x = variable, y = mean)) +\n  geom_linerange(aes(ymin = q5, ymax = q95)) +\n  geom_point(size = 0.5) +\n  geom_point(aes(x = variable, y = par_tru), col = 2, size = 0.8) +\n  scale_x_discrete(\"Parameter\", limits=rev) +\n  coord_flip()\n\n\n\n\n\n\n\n\nFigure 1: Parameter estimates vs true values\n\n\n\n\n\nEstimating the log-odds of response averaged across the sample, comparing observed vs model.\n\n\nLog-odds response (surgery)\nd_post &lt;- data.table(f1$draws(variables = c(\"eta\"), format = \"matrix\"))\nd_post &lt;- melt(d_post, measure.vars = names(d_post))\nd_post[, i := gsub(\"eta[\",\"\",variable,fixed=T)]\nd_post[, i := as.numeric(gsub(\"]\",\"\",i,fixed=T))]\n\nd_fig &lt;- copy(d)\nd_fig[, i := 1:.N]\n\nd_post &lt;- merge(d_post, d_fig, by = \"i\")\n\n# create a new variable to indicate what was received\nd_post[, s_d1 := copy(u_d1)]\n# set all that assigned to dair to have recvd dair\nd_post[s == 2 & d1 == 0, s_d1 := 1]\n\nd_fig &lt;- d_post[\n  , .(mu = mean(value), eta = mean(eta)), keyby = .(s,j,d1,s_d1)]\n\nd_fig[, s := factor(s, labels = c(\"early\", \"late\", \"chronic\"))]\nd_fig[, j := factor(j, labels = c(\"hip\", \"knee\"))]\nd_fig[, s_d1 := factor(s_d1, labels = c(\"dair\", \"one\", \"two\"))]\nd_fig[, d1 := factor(d1, labels = c(\"not-rand\", \"rand-dair\", \"rand-rev\"))]\n\n\nggplot(d_fig, aes(x = d1, y = mu, col = s_d1)) + \n  geom_point(aes(x = d1, y = eta, col = s_d1), pch = 3, size= 2) +\n  geom_point(size = 1) +\n  scale_x_discrete(\"Assigned/selected trt arm\") +\n  scale_y_continuous(\"log-odds response\") +\n  scale_color_discrete(\"Selected surgery\") +\n  facet_grid(j ~ s, scales = \"free_x\")\n\n\n\n\n\n\n\n\nFigure 2: Estimated log-odds of treatment success vs true\n\n\n\n\n\nDecomposition of revision effects into group means, within group means and effects. Prior and posterior view on group variation - what you can take from this is that the variance components are poorly informed by the data, i.e. there isn’t going to be any pooling because there are not enough groups to learn from.\n\n\nVariance components (revision)\nd_fig &lt;- data.table(\n  f1$draws(variables = c(\"s_mu_d1\", \"s_b_d1\"), \n           format = \"matrix\"))\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\n\nggplot(d_fig, aes(x = value, group = variable)) + \n  geom_density() +\n  stat_function(fun = fGarch::dstd, \n                args = list(nu = 3, mean = 0, sd = 2), \n                col = 2, lty = 2) +\n  facet_wrap(~variable)\n\n\n\n\n\n\n\n\nFigure 3: Between and within SD\n\n\n\n\n\n\n\nRevision effects\n# effects\nd_fig &lt;- data.table(\n  f1$draws(variables = c(\"b_d1[5,1]\", \"b_d1[6,1]\",\n                         \"b_d1[5,2]\", \"b_d1[6,2]\"), \n           format = \"matrix\"))\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig &lt;- d_fig[, .(\n  mu_b_d1 = mean(value)), keyby = variable]\n\n# overall mean\nd_fig &lt;- cbind(\n  d_fig, \n  data.table(\n    f1$draws(variables = c(\"mu_d1\"), \n             format = \"matrix\"))[, .(mu_d1_rev = mean(mu_d1))]\n  )\n\n# joint level mean\nd_post &lt;- data.table(f1$draws(variables = c(\"mu_d1_j\"), format = \"matrix\"))\n\nd_fig[, mu_d1_rev_jnt := rep(colMeans(d_post), each = 2)]\n\n# joint\nd_fig[, j := gsub(\"b_d1\\\\[[5-6],\", \"\", variable)]\nd_fig[, j := gsub(\"\\\\],\", \"\", j)]\nd_fig[, j := factor(j, labels = c(\"hip\", \"knee\"))]\n\n# rev type (one/two)\nd_fig[, type := gsub(\"b_d1\\\\[\", \"\", variable)]\nd_fig[, type := substr(type, 1, 1)]\nd_fig[, type := factor(type, labels = c(\"one\", \"two\"))]\n\n# on any given small sample, probably isn't going to be that close.\n# d_fig[, tru_mu_d1_rev := par$mu_d1_rev]\n# d_fig[j == \"hip\", tru_mu_d1_rev_j := par$mu_d1_rev_jnt[1]]\n# d_fig[j == \"knee\", tru_mu_d1_rev_j := par$mu_d1_rev_jnt[2]]\n\nggplot(d_fig, aes(x = variable, y = mu_b_d1)) + \n  geom_point() +\n  geom_hline(aes(yintercept = mu_d1_rev)) +\n  geom_hline(aes(yintercept = mu_d1_rev_jnt), lty = 2) +\n  # geom_hline(aes(yintercept = tru_mu_d1_rev), col = 2) +\n  # geom_hline(aes(yintercept = tru_mu_d1_rev_j), lty = 2, col = 2) +\n  scale_x_discrete(\"Assigned/selected trt arm\") +\n  scale_y_continuous(\"log-odds ratio\") +\n  facet_wrap(j + type ~., nrow = 1, scales = \"free_x\")\n\n\n\n\n\n\n\n\nFigure 4: Revision effects, between, within and assignment level means"
  },
  {
    "objectID": "backup/design-notes-06.html#extend-to-other-domains",
    "href": "backup/design-notes-06.html#extend-to-other-domains",
    "title": "Multi-level model",
    "section": "Extend to other domains",
    "text": "Extend to other domains"
  },
  {
    "objectID": "backup/design-notes-06.html#rough-work",
    "href": "backup/design-notes-06.html#rough-work",
    "title": "Multi-level model",
    "section": "Rough work",
    "text": "Rough work\n\n\nCode\nodds &lt;- function(p){\n  p[p == 0] &lt;- 0.0001\n  p[p == 1] &lt;- 0.9999\n  p/(1-p)\n}\n\n\n# population/strata assumptions\nd_strat &lt;- data.table(\n  silo = c(\"e\", \"e\", \"l\", \"l\", \"c\", \"c\"),\n  joint = c(\"k\", \"h\", \"k\", \"h\", \"k\", \"h\"),\n  w_s_j = c(0.4, 0.6, 0.7, 0.3, 0.5, 0.5),\n  w_s = c(0.3, 0.3, 0.5, 0.5, 0.2, 0.2),\n  pr_y = c(0.65, 0.75, 0.55, 0.6, 0.6, 0.65)\n)\nd_p_s &lt;- d_strat[, .(pr_y_s = sum(w_s_j * pr_y)), keyby = .(silo)]\nd_pop &lt;- merge(\n  d_strat[, .(pr_y_s = sum(w_s_j * pr_y)), keyby = .(silo)],\n  d_strat[, .(w_s = unique(w_s)), keyby = silo],\n  by = \"silo\"\n)\n# should see treatment success around in assumed pop\np0 &lt;- d_pop[, .(pr_y = sum(w_s * pr_y_s))][[1]]\n\n\nset.seed(1)\n# intercept\nb0 &lt;- qlogis(p0)\n\n# silo level variation\nd_p_s[, lo := qlogis(pr_y_s)]\nd_p_s[, b_s := lo - b0]\nb_s &lt;- d_p_s$b_s\nnames(b_s) &lt;- d_p_s$silo\n\nexp(b_s)\n\nmu_d1_rev &lt;- 0.4\ntau_d1_rev &lt;- 0.1\ns_d1_rev &lt;- 0.1\n\n# knee/hip\nmu_d1_rev_jnt &lt;- rnorm(2, mu_d1_rev, tau_d1_rev)\n\n# one-stage knee/hip\nb_d1_one_2_jnt &lt;- rnorm(2, mu_d1_rev_jnt, s_d1_rev)\n# two-stage knee/hip\nb_d1_two_2_jnt &lt;- rnorm(2, mu_d1_rev_jnt, s_d1_rev)\n\n\nN &lt;- 2000\nN_s &lt;- N*c(0.3, 0.5, 0.2)\nnames(N_s) &lt;- c(\"e\", \"l\", \"c\")\n\ns &lt;- sample(1:3, size = N, replace = T, prob = c(0.3, 0.5, 0.2))"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "This site contains notes, data summaries and simulation results for the ROADMAP study.\nAll the code can be found on github, just use the icon to the top right. The functionality herein has a dependency on the roadmap.data R package, which can also be found via the above link (see the readme for this repo).",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "etc/readme.html",
    "href": "etc/readme.html",
    "title": "readme",
    "section": "",
    "text": "readme\nfile name format is\ncfg-sim&lt;sim-id&gt;-&lt;scenario-id&gt;-&lt;variant-id&gt;\nuse sed for efficient updating, e.g. \n\nChange number of simulations from 10 to 500:\n\ngsed -i 's/nsim:\\ 10/nsim:\\ 500/' cfg-sim01-sc01-0*.yml\ngsed -i 's/nsim:\\ 10/nsim:\\ 500/' cfg-sim02-sc01-v0*.yml\n\nUpdate scenario label:\n\ngsed -i 's/sc01/sc02/' cfg-sim01-sc02-0*.yml"
  },
  {
    "objectID": "backup/tmp.html",
    "href": "backup/tmp.html",
    "title": "Multi-level example",
    "section": "",
    "text": "Assume you have 5-10 treatment arms to which patients are randomised and within each treatment arm are a mix of participants with respect to some characteristic that could influence the response. We are interested in the overall treatment effect and heterogeneity due to the subgroup.\nWithin this setting there are multiple levels of variation. There is the between treatment arm variation that characterises how different the treatment arms are. There is also the within treatment arm variation due to the subgroup.\nWe could adopt a range of assumptions to model the responses for each combination of treatment and subgroup.\nPlus variations on these themes. All of the variance partition approaches require that there are sufficient groups to informed the variance parameters."
  },
  {
    "objectID": "backup/tmp.html#parameter-specificationgeneration",
    "href": "backup/tmp.html#parameter-specificationgeneration",
    "title": "Multi-level example",
    "section": "Parameter specification/generation",
    "text": "Parameter specification/generation\nAssume that the true treatment group means are normally distributed around some non-zero mean with standard deviation \\(s\\) and that the subgroup means are normally distributed around each treatment group mean with a common standard deviation \\(s_j\\).\n\n\nParameter specification\nget_par &lt;- function(\n    n_grp = 4, n_trt = 9,\n    mu = 1,\n    s = 0.1, s_j = 0.3\n    ){\n  \n  l &lt;- list()\n  l$n_grp &lt;- n_grp\n  l$n_trt &lt;- n_trt\n\n  # overall mean effect across all intervention types\n  l$mu &lt;- mu\n  # between intervention type variation\n  l$s &lt;- s\n  # intervention type specific mean\n  l$mu_j &lt;- l$mu + rnorm(n_trt, 0, l$s)\n  # within intervention variation attributable to group membership\n  l$s_j &lt;- s_j\n\n  # trt x group effects\n  l$mu_j_k &lt;- do.call(rbind, lapply(seq_along(l$mu_j), function(i){\n    rnorm(n_grp, l$mu_j[i], l$s_j)\n  }))\n  colnames(l$mu_j_k) &lt;- paste0(\"strata\", 1:ncol(l$mu_j_k))\n  rownames(l$mu_j_k) &lt;- paste0(1:nrow(l$mu_j_k))\n  \n  l$d_par &lt;- CJ(\n    j = factor(1:l$n_trt, levels = 1:l$n_trt),\n    k = factor(1:l$n_grp, levels = 1:l$n_grp)\n  )\n  l$d_par[, mu := l$mu]\n  l$d_par[, mu_j := l$mu_j[j]]\n  l$d_par[, mu_j_k := l$mu_j_k[cbind(j,k)]]\n  \n  l\n}\n\n\nAny single data set will not allow us to recover the parameters exactly, but the differences between the estimates from the various modelling assumptions is informative as to the general patterns that arise.\n\n\nData generation function\nget_data &lt;- function(\n    N = 2000, \n    par = NULL,\n    ff = function(par, j, k){\n      \n      m1 &lt;- cbind(j, k)\n      eta = par$mu_j_k[m1] \n      eta\n      \n    }){\n  \n  # strata\n  d &lt;- data.table()\n  \n  # intervention - even allocation\n  d[, j := sample(1:par$n_trt, size = N, replace = T)]\n  # table(d$j)\n  # uneven distribution of groups in the pop\n  z &lt;- rnorm(par$n_grp, 0, 0.5)\n  d[, k := sample(1:par$n_grp, size = N, replace = T, prob = exp(z)/sum(exp(z)))]\n  # d[, k := sample(1:par$n_grp, size = N, replace = T)]\n  # table(d$j, d$k)\n  \n  d[, eta := ff(par, j, k)]\n  \n  d[, y := rbinom(.N, 1, plogis(eta))]\n  \n  d  \n}\n\n\nGenerate data assuming the parameters below with the underlying truth shown in Figure 1. The dashed line shows the overall mean response, the crosses show the treatment arm means and the points show the subgroup heterogeneity around the treatment arm means.\n\n\nTrue treatment arm by subgroup mean response\nset.seed(1)\npar &lt;- get_par(n_grp = 5, n_trt = 8, mu = 1, s = 0.0, s_j = 0.5)\nd &lt;- get_data(N = 3000, par)\n\n\nd_fig_2 &lt;- unique(par$d_par[, .(mu_j, j)])\nd_fig_2[1, label := \"Treatment mean\"]\n       \n\np_fig &lt;- ggplot(par$d_par, aes(x = j, y = mu_j_k, col = k)) +\n  geom_point() +\n  geom_hline(yintercept = par$mu, lwd = 0.25, lty = 2) +\n  geom_text_repel(\n    data = data.table(\n      x = 2.5, y = par$mu, label = \"Overall mean\"\n    ),\n    aes(x = x, y = y, label = label),\n                  inherit.aes = F,\n                  nudge_x = 0.4,\n                  nudge_y = 0.1,\n                  segment.curvature = -0.1,\n                  segment.ncp = 3,\n                  segment.angle = 20,\n                  box.padding = 2, max.overlaps = Inf, col = 1) +\n  geom_text_repel(data = d_fig_2,\n                  aes(x = j, y = mu_j, label = label), \n                  inherit.aes = F,\n                  nudge_x = 0.4,\n                  nudge_y = -0.05,\n                  segment.curvature = -0.1,\n                  segment.ncp = 3,\n                  segment.angle = 20,\n                  box.padding = 2, max.overlaps = Inf, col = 1) +\n  geom_point(data = d_fig_2,\n             aes(x = j, y = mu_j),\n             inherit.aes = F, pch = 3, size = 3) +\n  scale_x_discrete(\"Treatment type\") +\n  scale_y_continuous(\"Odds of success (log-odds)\", \n                     breaks = seq(\n                       round(min(par$d_par$mu_j_k), 1), \n                       round(max(par$d_par$mu_j_k), 1), \n                       by = 0.1)) +\n  scale_color_discrete(\"Subgroup membership\")\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 1: True treatment arm by subgroup mean response"
  },
  {
    "objectID": "backup/tmp.html#parameter-estimation",
    "href": "backup/tmp.html#parameter-estimation",
    "title": "Multi-level example",
    "section": "Parameter estimation",
    "text": "Parameter estimation\nThe first model produces independent estimates of the means.\n\n\nFit model to simulated data\n# mle - reference point\nd_lm &lt;- copy(d)\nd_lm[, `:=`(j = factor(j), k = factor(k))]\nf0 &lt;- glm(y ~ j*k, data = d_lm, family = binomial)\nX &lt;- model.matrix(f0)\n# CI\nn_sim &lt;- 1000\nd_lm_j &lt;- matrix(NA, nrow = par$n_trt, ncol = n_sim)\nd_lm_j_k &lt;- matrix(NA, nrow = par$n_trt * par$n_grp, ncol = n_sim)\nfor(i in 1:n_sim){\n  ix &lt;- sort(sample(1:nrow(d_lm), replace = T))\n  f_boot &lt;- glm(y ~ j*k, data = d_lm[ix], family = binomial)\n  d_tmp_p &lt;- cbind(\n    d_lm[ix],\n    mu = predict(f_boot)\n  )\n  d_lm_j[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = j][, mean]\n  d_lm_j_k[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = .(k, j)][, mean]\n}\n# bootstrapped intervals for means on j and within group means\nd_lm_j &lt;- data.table(d_lm_j)\nd_lm_j[, j := 1:.N]\nd_lm_j &lt;- melt(d_lm_j, id.vars = \"j\")\nd_lm_j[, j := factor(j)]\n# d_lm_j[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = j]\n\nd_lm_j_k &lt;- data.table(d_lm_j_k)\nd_lm_j_k &lt;- cbind(CJ(k = 1:par$n_grp, j = 1:par$n_trt), d_lm_j_k)\nd_lm_j_k &lt;- melt(d_lm_j_k, id.vars = c(\"j\", \"k\"))\nd_lm_j_k[, `:=`(j = factor(j), k = factor(k))]\n# d_lm_j_k[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = .(k,j)]\n\nd_lm[, eta_hat := predict(f0)]\n\n# bayes\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-01.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-02.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-03.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y, \n  J = length(unique(d$j)), K = length(unique(d$k)),\n  j = d$j, # intervention\n  k = d$k, # subgroup\n  P = ncol(X),\n  X = X,\n  s = 3,\n  s_j = 3, # for the indep means offsets\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 6.5 seconds.\nChain 1 finished in 7.3 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 6.9 seconds.\nTotal execution time: 7.3 seconds.\n\n\nFit model to simulated data\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 2.6 seconds.\nChain 2 finished in 2.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 2.6 seconds.\nTotal execution time: 2.6 seconds.\n\n\nFit model to simulated data\nf3 &lt;- m3$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 2.5 seconds.\nChain 1 finished in 2.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 2.5 seconds.\nTotal execution time: 2.6 seconds.\n\n\nWarning: 3 of 2000 (0.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nFigure 2 shows the estimated treatment arm means, and treatment arm by subgroup means for each of the combinations.\nPatterns:\n\nThe observed and modelled overall mean are very similar.\nThe MLE and the no-pooling models produce similar estimates - they tend to reflect the observed response\nThe treatment arm means estimated using MLE and no-pooling are more influenced by outliers when compared to the estimates for the treatment arm means under the partially pooled models.\n\n\n\n\nParameter estimates vs true values\nd_1 &lt;- data.table(t(f1$draws(variables = \"eta\", format = \"matrix\")))\nd_1 &lt;- cbind(d, d_1)\nd_1 &lt;- melt(d_1, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_2 &lt;- data.table(t(f2$draws(variables = \"eta\", format = \"matrix\")))\nd_2 &lt;- cbind(d, d_2)\nd_2 &lt;- melt(d_2, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_3 &lt;- data.table(t(f3$draws(variables = \"eta\", format = \"matrix\")))\nd_3 &lt;- cbind(d, d_3)\nd_3 &lt;- melt(d_3, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_mu_j &lt;- rbind(\n  d_1[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_2[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_3[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j]\n)\n\n# d_mu_j &lt;- rbind(\n#   data.table(f2$summary(variables = c(\n#     \"mu_j\"\n#     )))[, .(desc = \"partial pool (trt)\", variable, mean, q5, q95)],\n#   data.table(f3$summary(variables = c(\n#     \"mu_j\"\n#     )))[, .(desc = \"partial pool (trt+subgrp)\", variable, mean, q5, q95)], \n#   fill = T)\n# d_mu_j[, j := gsub(\"mu_j[\", \"\", variable, fixed = T)]\n# d_mu_j[, j := gsub(\"]\", \"\", j, fixed = T)]\n\n# d_mu_j &lt;- rbind(\n#   d_mu_j,\n#   d_1[, .(mu = mean(value)), keyby = .(j, i_draw)][\n#   , .(desc = \"no pooling\", \n#       mean = mean(mu), \n#       q5 = quantile(mu, prob = 0.05), \n#       q95 = quantile(mu, prob = 0.95)), keyby = j],\n#   fill = T)\n  \n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j[, .(q5 = quantile(value, prob =0.05),\n           q95 = quantile(value, prob = 0.95)), keyby = j], \n  by = \"j\"\n)\n\nd_mu_j &lt;- rbind(d_mu_j, d_mle, fill = T)\n\n# Observed\n# Due to the imbalance between the subgroups, need to weight the\n# contributions to align (approx) with mle.\n# Easy here because only one other variable that we need to average\n# over.\nd_obs &lt;- merge(\n  d[, .(N_j = .N), keyby = .(j)],\n  d[, .(mu = qlogis(mean(y)), .N), keyby = .(j, k)],\n  by = \"j\"\n)\nd_mu_j &lt;- rbind(\n  d_mu_j,\n  d_obs[, .(\n    desc = \"observed\", \n    mean = sum(mu * N / N_j)), keyby = j]\n  , fill = T\n  )\n\n\nd_mu_j[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n# Grand mean\n# d_mu &lt;- rbind(\n#   data.table(f2$summary(variables = c(\n#     \"mu\"\n#     )))[, .(desc = \"partial pool (trt)\", variable, mean, q5, q95)],\n#   data.table(f3$summary(variables = c(\n#     \"mu\"\n#     )))[, .(desc = \"partial pool (trt+subgrp)\", variable, mean, q5, q95)]\n# )\n  \n\n# Same deal with grand mean, you need to weight the individual level\n# contributions in order to align with the model estimates\n\n# d_mu &lt;- rbind(\n#   d_mu, \n#   d[, .(mu = qlogis(mean(y)), \n#         w = .N/nrow(d)), keyby = .(j, k)][\n#           , .(desc = \"observed\", mean = sum(mu * w))], \n#   fill = T\n# )  \n\nd_mu &lt;- d[, .(mu = qlogis(mean(y)), \n         w = .N/nrow(d)), keyby = .(j, k)][\n           , .(desc = \"observed\", mean = sum(mu * w))]\n\n\np_fig &lt;- ggplot(d_mu_j, aes(x = j, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  geom_hline(data = d_mu,\n             aes(yintercept = mean, lty = desc),\n             lwd = 0.3, col = 1) +\n  scale_x_discrete(\"Treatment arm\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2))  +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_mu_j$q5, na.rm = T) - 0.1, \n                label = N), inherit.aes = F) +\n  theme(legend.position=\"bottom\", legend.box=\"vertical\", legend.margin=margin())\n\nsuppressWarnings(print(p_fig))  \n\n\n\n\n\n\n\n\nFigure 2: Parameter estimates vs true values\n\n\n\n\n\n\n\nParameter estimates vs true values\n# Posterior\n# d_mu_j_k &lt;- rbind(\n#   data.table(f2$summary(variables = c(\n#     \"mu_j_k\"\n#     )))[, .(desc = \"partial pool (trt)\", variable, mean, q5, q95)],\n#   data.table(f3$summary(variables = c(\n#     \"mu_j_k\"\n#     )))[, .(desc = \"partial pool (trt+subgrp)\", variable, mean, q5, q95)]\n# )\n# d_mu_j_k[, j := substr(variable, 8, 8)]\n# d_mu_j_k[, k := substr(variable, 10, 10)]\n\n# Manually calculate intervals for independent model\nd_mu_j_k &lt;- rbind(\n  # d_mu_j_k,\n  d_1[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_2[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_3[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)]\n  )\n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(k, j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j_k[, .(q5 = quantile(value, prob =0.05),\n               q95 = quantile(value, prob = 0.95)), keyby = .(k,j)], \n  by = c(\"j\",\"k\")\n)\n\nd_mu_j_k &lt;- rbind(d_mu_j_k, d_mle, fill = T)\n\n# Observed\nd_mu_j_k &lt;- rbind(\n  d_mu_j_k, \n  d[, .(desc = \"observed\", mean = qlogis(mean(y))), keyby = .(k, j)],\n  fill = T)\n\n\nd_mu_j_k[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n# \nd_mu_obs &lt;- d[, .(mu = qlogis(mean(y)))]\nd_mu_mod &lt;- data.table(f3$summary(variables = c(\n    \"mu\"\n    )))[, .(model = \"no pooling\", variable, mean, q5, q95)]\n\np_fig &lt;- ggplot(d_mu_j_k, aes(x = k, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  scale_x_discrete(\"Subgroup\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2)) +\n  geom_hline(data = d_mu_j[desc == \"observed\"],\n             aes(yintercept = mean, group = desc),\n             lwd = 0.3, col = 1) +\n  geom_text(data = d[, .N, keyby = .(j, k)],\n            aes(x = k, y = min(d_mu_j_k$q5, na.rm = T) - 0.1, label = N), \n            inherit.aes = F) +\n  facet_wrap(~paste0(\"Treatment \", j)) \n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 3: Parameter estimates vs true values\n\n\n\n\n\nThe mlm partitions the variance into a between treatment variance part that characterises the variation in the treatment arms and a within treatment variance that characterises the variation due to the subgroups.\nThe prior is shown as the dashed line and the posterior the black solid line. Clearly, something has been learnt about the variation from the data; the between group variation (variation due to treatment) is large relative to the within group variation (variation due to subgroups).\n\n\nVariance components (revision)\nd_fig &lt;- rbind(\n  cbind(desc = \"partial pool (trt)\",\n        data.table(f2$draws(variables = c(\"s_j\"), format = \"matrix\"))),\n  cbind(desc = \"partial pool (trt+subgrp)\",\n        data.table(f3$draws(variables = c(\"s\", \"s_j\"), format = \"matrix\"))  \n  ), fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = \"desc\")\nd_fig[variable == \"s\", label := \"variation b/w\"]\nd_fig[variable == \"s_j\", label := \"variation w/in\"]\n\nd_pri &lt;- CJ(\n  variable = c(\"s\", \"s_j\"),\n  desc = c(\"partial pool (trt)\", \"partial pool (trt+subgrp)\"),\n  x = seq(min(d_fig$value, na.rm = T), \n          max(d_fig$value, na.rm = T), len = 500)\n)\nd_pri[, y := fGarch::dstd(x, nu = 3, mean = 0, sd = 2)]\nd_pri[variable == \"s\", label := \"variation b/w\"]\nd_pri[variable == \"s_j\", label := \"variation w/in\"]\nd_pri[desc == \"partial pool (trt)\" & variable == \"s\", y := NA]\n# \n# d_smry &lt;- d_fig[, .(mu = mean(value)), keyby = .(label)]\n\np_fig &lt;- ggplot(d_fig, aes(x = value, group = variable)) + \n  geom_density() +\n  geom_line(\n    data = d_pri, \n    aes(x = x, y = y), col = 2, lwd = 0.2\n  ) +\n  # geom_vline(data = d_smry,  \n  #            aes(xintercept = mu), col = 2, lwd = 0.3) +\n  # stat_function(fun = fGarch::dstd, \n  #               args = list(nu = 3, mean = 0, sd = 1), \n  #               col = 3, lty = 2) +\n  scale_x_continuous(\"Standard deviation\") +\n  scale_y_continuous(\"Density\") +\n  facet_wrap(desc+label~., ncol = 2)\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 4: Between and within SD\n\n\n\n\n\nLot of within group variation, little between group variation. Discuss implications\n\n\nCode\nset.seed(1)\npar &lt;- get_par(n_grp = 2, n_trt = 2, mu = 1, s = 0.0, s_j = 0.5)\nd &lt;- get_data(N = 3000, par)\n\n\n\n\nFit model to simulated data\n# mle - reference point\nd_lm &lt;- copy(d)\nd_lm[, `:=`(j = factor(j), k = factor(k))]\nf0 &lt;- glm(y ~ j*k, data = d_lm, family = binomial)\nX &lt;- model.matrix(f0)\n# CI\nn_sim &lt;- 1000\nd_lm_j &lt;- matrix(NA, nrow = par$n_trt, ncol = n_sim)\nd_lm_j_k &lt;- matrix(NA, nrow = par$n_trt * par$n_grp, ncol = n_sim)\nfor(i in 1:n_sim){\n  ix &lt;- sort(sample(1:nrow(d_lm), replace = T))\n  f_boot &lt;- glm(y ~ j*k, data = d_lm[ix], family = binomial)\n  d_tmp_p &lt;- cbind(\n    d_lm[ix],\n    mu = predict(f_boot)\n  )\n  d_lm_j[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = j][, mean]\n  d_lm_j_k[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = .(k, j)][, mean]\n}\n# bootstrapped intervals for means on j and within group means\nd_lm_j &lt;- data.table(d_lm_j)\nd_lm_j[, j := 1:.N]\nd_lm_j &lt;- melt(d_lm_j, id.vars = \"j\")\nd_lm_j[, j := factor(j)]\n# d_lm_j[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = j]\n\nd_lm_j_k &lt;- data.table(d_lm_j_k)\nd_lm_j_k &lt;- cbind(CJ(k = 1:par$n_grp, j = 1:par$n_trt), d_lm_j_k)\nd_lm_j_k &lt;- melt(d_lm_j_k, id.vars = c(\"j\", \"k\"))\nd_lm_j_k[, `:=`(j = factor(j), k = factor(k))]\n# d_lm_j_k[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = .(k,j)]\n\nd_lm[, eta_hat := predict(f0)]\n\n# bayes\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-01.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-02.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-03.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y, \n  J = length(unique(d$j)), K = length(unique(d$k)),\n  j = d$j, # intervention\n  k = d$k, # subgroup\n  P = ncol(X),\n  X = X,\n  s = 3,\n  s_j = 3, # for the indep means offsets\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 1.4 seconds.\nChain 2 finished in 1.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 1.4 seconds.\nTotal execution time: 1.5 seconds.\n\n\nFit model to simulated data\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 6.2 seconds.\nChain 2 finished in 6.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 6.4 seconds.\nTotal execution time: 6.7 seconds.\n\n\nWarning: 4 of 2000 (0.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nFit model to simulated data\nf3 &lt;- m3$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 9.7 seconds.\nChain 1 finished in 15.6 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 12.6 seconds.\nTotal execution time: 15.6 seconds.\n\n\nWarning: 25 of 2000 (1.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\n\n\nParameter estimates vs true values\nd_1 &lt;- data.table(t(f1$draws(variables = \"eta\", format = \"matrix\")))\nd_1 &lt;- cbind(d, d_1)\nd_1 &lt;- melt(d_1, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_2 &lt;- data.table(t(f2$draws(variables = \"eta\", format = \"matrix\")))\nd_2 &lt;- cbind(d, d_2)\nd_2 &lt;- melt(d_2, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_3 &lt;- data.table(t(f3$draws(variables = \"eta\", format = \"matrix\")))\nd_3 &lt;- cbind(d, d_3)\nd_3 &lt;- melt(d_3, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_mu_j &lt;- rbind(\n  d_1[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_2[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_3[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j]\n)\n\n  \n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j[, .(q5 = quantile(value, prob =0.05),\n           q95 = quantile(value, prob = 0.95)), keyby = j], \n  by = \"j\"\n)\n\nd_mu_j &lt;- rbind(d_mu_j, d_mle, fill = T)\n\n# Observed\n# Due to the imbalance between the subgroups, need to weight the\n# contributions to align (approx) with mle.\n# Easy here because only one other variable that we need to average\n# over.\nd_obs &lt;- merge(\n  d[, .(N_j = .N), keyby = .(j)],\n  d[, .(mu = qlogis(mean(y)), .N), keyby = .(j, k)],\n  by = \"j\"\n)\nd_mu_j &lt;- rbind(\n  d_mu_j,\n  d_obs[, .(\n    desc = \"observed\", \n    mean = sum(mu * N / N_j)), keyby = j]\n  , fill = T\n  )\n\n\nd_mu_j[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n\n\nd_mu &lt;- d[, .(mu = qlogis(mean(y)), \n         w = .N/nrow(d)), keyby = .(j, k)][\n           , .(desc = \"observed\", mean = sum(mu * w))]\n\n\np_fig &lt;- ggplot(d_mu_j, aes(x = j, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  geom_hline(data = d_mu,\n             aes(yintercept = mean, lty = desc),\n             lwd = 0.3, col = 1) +\n  scale_x_discrete(\"Treatment arm\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2))  +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_mu_j$q5, na.rm = T) - 0.1, \n                label = N), inherit.aes = F) +\n  theme(legend.position=\"bottom\", legend.box=\"vertical\", legend.margin=margin())\n\nsuppressWarnings(print(p_fig))  \n\n\n\n\n\n\n\n\nFigure 5: Parameter estimates vs true values\n\n\n\n\n\n\n\nParameter estimates vs true values\n# Manually calculate intervals for independent model\nd_mu_j_k &lt;- rbind(\n  # d_mu_j_k,\n  d_1[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_2[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_3[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)]\n  )\n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(k, j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j_k[, .(q5 = quantile(value, prob =0.05),\n               q95 = quantile(value, prob = 0.95)), keyby = .(k,j)], \n  by = c(\"j\",\"k\")\n)\n\nd_mu_j_k &lt;- rbind(d_mu_j_k, d_mle, fill = T)\n\n# Observed\nd_mu_j_k &lt;- rbind(\n  d_mu_j_k, \n  d[, .(desc = \"observed\", mean = qlogis(mean(y))), keyby = .(k, j)],\n  fill = T)\n\n\nd_mu_j_k[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n# \nd_mu_obs &lt;- d[, .(mu = qlogis(mean(y)))]\nd_mu_mod &lt;- data.table(f3$summary(variables = c(\n    \"mu\"\n    )))[, .(model = \"no pooling\", variable, mean, q5, q95)]\n\np_fig &lt;- ggplot(d_mu_j_k, aes(x = k, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  scale_x_discrete(\"Subgroup\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2)) +\n  geom_hline(data = d_mu_j[desc == \"observed\"],\n             aes(yintercept = mean, group = desc),\n             lwd = 0.3, col = 1) +\n  geom_text(data = d[, .N, keyby = .(j, k)],\n            aes(x = k, y = min(d_mu_j_k$q5, na.rm = T) - 0.1, label = N), \n            inherit.aes = F) +\n  facet_wrap(~paste0(\"Treatment \", j)) \n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 6: Parameter estimates vs true values\n\n\n\n\n\n\n\nVariance components (revision)\nd_fig &lt;- rbind(\n  cbind(desc = \"partial pool (trt)\",\n        data.table(f2$draws(variables = c(\"s_j\"), format = \"matrix\"))),\n  cbind(desc = \"partial pool (trt+subgrp)\",\n        data.table(f3$draws(variables = c(\"s\", \"s_j\"), format = \"matrix\"))  \n  ), fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = \"desc\")\nd_fig[variable == \"s\", label := \"variation b/w\"]\nd_fig[variable == \"s_j\", label := \"variation w/in\"]\n\nd_pri &lt;- CJ(\n  variable = c(\"s\", \"s_j\"),\n  desc = c(\"partial pool (trt)\", \"partial pool (trt+subgrp)\"),\n  x = seq(min(d_fig$value, na.rm = T), \n          max(d_fig$value, na.rm = T), len = 500)\n)\nd_pri[, y := fGarch::dstd(x, nu = 3, mean = 0, sd = 2)]\nd_pri[variable == \"s\", label := \"variation b/w\"]\nd_pri[variable == \"s_j\", label := \"variation w/in\"]\nd_pri[desc == \"partial pool (trt)\" & variable == \"s\", y := NA]\n# \n# d_smry &lt;- d_fig[, .(mu = mean(value)), keyby = .(label)]\n\np_fig &lt;- ggplot(d_fig, aes(x = value, group = variable)) + \n  geom_density() +\n  geom_line(\n    data = d_pri, \n    aes(x = x, y = y), col = 2, lwd = 0.2\n  ) +\n  # geom_vline(data = d_smry,  \n  #            aes(xintercept = mu), col = 2, lwd = 0.3) +\n  # stat_function(fun = fGarch::dstd, \n  #               args = list(nu = 3, mean = 0, sd = 1), \n  #               col = 3, lty = 2) +\n  scale_x_continuous(\"Standard deviation\") +\n  scale_y_continuous(\"Density\") +\n  facet_wrap(desc+label~., ncol = 2)\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 7: Between and within SD"
  },
  {
    "objectID": "backup/design-notes-02-orig.html",
    "href": "backup/design-notes-02-orig.html",
    "title": "More Design Notes",
    "section": "",
    "text": "Setup\nsource(\"./R/init.R\")\nlog_info(\"Called design-notes-02 notebook\")\n\n\nThis starts with a digression to help frame some background technicalities and then considers the topics that have been discussed recently.\nStart by thinking about the representation of a linear regression versus a logistic regression and what they are aiming to achieve. This is easiest via an example so assume we have two independent factors that are predictive of independent continuous and binary outcomes. Assume that a is the effect of interest but b is still predictive of the outcome. In other words, assume something analogous to a randomised clinical trial setup where a corresponds to our set of randomised interventions and b is some prognostic baseline characteristic (age, sex etc). For the continuous outcome, adopt a linear model of the form \\(\\mathbb{E}[Y | a,b] = \\mu = \\alpha_0 + \\alpha_1 a + \\alpha_2 b\\) with \\(Y\\) normally distributed which encapsulates our assumptions (unknowable in real life) on the data generating process. For the binary outcome adopt a logistic model of the form \\(g(\\mathbb{E}[W | a,b]) = \\beta_0 + \\beta_1 a + \\beta_2 b\\) with \\(W\\) is bernoulli and \\(g\\) being the link function such that our conditional mean is now given by the inverse link \\(\\mathbb{E}[W | a,b] = g^{-1}(\\beta_0 + \\beta_1 a + \\beta_2 b)\\). You might be asking whether this latter representation make sense for the dichotomous response since what we are interested in is the probability of the event. It does, since\n\\[\n\\begin{aligned}\n\\mathbb{E}(W | X = x) &= \\sum_{w = W} w Pr(W=w | X = x) \\\\\n  &= 0 Pr(W = 0 | X = x) + 1 Pr(W = 1 | X = x) \\\\\n  &= Pr(W = 1 | X = x)\n\\end{aligned}\n\\]\nin other words, the conditional mean equates to the conditional probability. So far, hopefully so good.\nLet’s generate some data under these models and have a think.\n\n\nCode\nget_data &lt;- function(N = 200, p_a_tru = 0.5, p_b_tru = 0.3){\n  a &lt;- rbinom(N, 1, p_a_tru)\n  b &lt;- rbinom(N, 1, p_b_tru)\n  e &lt;- rnorm(N, 0, 1)\n  mu &lt;- 0.3 + 1.2*a - 0.4*b\n  eta &lt;- -0.6 + 0.7*a - 1.2*b\n  y1 &lt;- mu + e\n  y2 &lt;- rbinom(N, 1, plogis(eta))\n  \n  d &lt;- data.table(a, b, e, y1, y2)\n  list(d = d, p_a_tru = p_a_tru, p_b_tru = p_b_tru)\n}\n\n\nFirst thing to note is that for a linear regression, the point estimate for the treatment effect (associated with the a term) will be the same irrespective of whether we take a conditional perspective using a multivariable linear regression or consider the marginal effect by averaging over the distribution of the other predictors. For the conditional effect, the standard errors would be different (narrower for the conditional parameter estimate) but that’s irrelevant for the moment. The simulation below should establish that the conditional and marginal are equivalent.\n\n\nCode\nset.seed(1)\nnsim &lt;- 1e3\nm &lt;- matrix(NA, nsim, 3)\nfor(i in 1:nsim){\n  ld &lt;- get_data()\n  lm1 &lt;- lm(y1 ~ a + b, data = ld$d)\n  dn &lt;- CJ(a = 0:1, b = 0:1)\n  \n  # expected value of y conditional on a and b\n  dn[, mu := predict(lm1, newdata = dn, type = \"response\")]\n  \n  # true probability of b\n  dn[b == 1, p_b := ld$p_b_tru]\n  dn[b == 0, p_b := 1-ld$p_b_tru]\n  \n  # this is just applying:\n  # p(mu | a = 0) = sum_b p(y | a = 0, b = b)p(b = b) \n  # p(y | a = 1) = sum_b p(y | a = 1, b = b)p(b = b) \n  mu_a_0 &lt;- sum(dn[a == 0, mu * p_b])\n  mu_a_1 &lt;- sum(dn[a == 1, mu * p_b])\n\n  # effects\n  a_marg &lt;- mu_a_1 - mu_a_0\n  a_cond &lt;- coef(lm1)[\"a\"]\n  \n  m[i, ] &lt;- c(\n    a_cond, \n    a_marg,\n    a_cond - a_marg\n  )\n}\n\n# conditional and marginal point estimates are the same\n# true parameter value for a is 1.2\ncolnames(m) &lt;- c(\"cond\", \"marg\", \"diff\")\nround(colMeans(m), 4)\n\n\n  cond   marg   diff \n1.1984 1.1984 0.0000 \n\n\nFor a logistic regression, the above equivalence doesn’t hold as is discussed in the 2020 paper by Rhian Daniel.\n\n\nCode\nset.seed(1)\nnsim &lt;- 1e3\nm &lt;- matrix(NA, nsim, 3)\nfor(i in 1:nsim){\n  ld &lt;- get_data()\n  lm1 &lt;- glm(y2 ~ a + b, data = ld$d, family = binomial)\n  \n  dn &lt;- CJ(a = 0:1, b = 0:1)\n  \n  # expected value of y conditional on a and b, i.e. P(y | a, b)\n  dn[, p := predict(lm1, newdata = dn, type = \"response\")]\n  \n  # true probability of b\n  dn[b == 1, p_b := ld$p_b_tru]\n  dn[b == 0, p_b := 1-ld$p_b_tru]\n  \n  # this is just applying:\n  # p(mu | a = 0) = sum_b p(y | a = 0, b = b)p(b = b) \n  # p(y | a = 1) = sum_b p(y | a = 1, b = b)p(b = b) \n  p_a_0 &lt;- sum(dn[a == 0, p * p_b])\n  p_a_1 &lt;- sum(dn[a == 1, p * p_b])\n\n  # effects\n  a_marg &lt;- log( (p_a_1/(1-p_a_1)) / (p_a_0/(1-p_a_0)) )\n  a_cond &lt;- coef(lm1)[\"a\"]\n  \n  m[i, ] &lt;- c(\n    a_cond,\n    a_marg,\n    a_cond - a_marg\n  )\n  \n}\n\n# conditional and marginal point estimates are no longer the same\n# true parameter value for a is 1.2\ncolnames(m) &lt;- c(\"cond\", \"marg\", \"diff\")\nround(colMeans(m), 4)\n\n\n  cond   marg   diff \n0.7347 0.6899 0.0449 \n\n\nOk, so all we are saying so far is that for a logistic regression model we can expect to produce systematically different point estimates for the treatment effect under different modelling assumptions. This has nothing to do with Bayes or classical stats, it is simply a product of the non-linear link function in logistic regression.\nThis is a reasonable point to remind ourselves where the odds ratios actually come from. Consider the model of the dichotomous outcome introduced previously. However, instead of b mapping to a baseline characteristic, think of it as a second set of interventions such that we are now describing a factorial study (we conveniently ignore the possibility of interactions between the treatments). Both a and b remain dichotomous and independent random variables. In an experiment, we would usually randomise to all combinations of a and b. Once we fit the model, we can produce predictions of the expected response for any combination of a and b. Here is the model in mathematical terms:\n\\[\n\\begin{aligned}\ny &\\sim \\text{Bernoulli}(p) \\\\\n\\text{logit}(p) &= \\log(p/(1-p)) = \\log(odds) = \\eta = \\beta_0 + \\beta_1 a + \\beta_2 b\n\\end{aligned}\n\\]\nIn this conditional model we interpret the exponentiated version of \\(\\beta_1\\) as the multiplicative change in the odds of response that is associated with moving from the control to the intervention group, with the caveat that we are holding all other terms constant. The last bit is important.\nHow do we get to this? The covariate a is coded as 0 for control and 1 for the test intervention, e.g. we might have zero representing dair and 1 representing one-stage revision. We are thus considering a unit change in a as the treatment effect. Similarly, we might consider b as duration interventions and have zero representing 6 weeks and pone representing 12 weeks.\nAnyway, for the control group for a, the linear predictor tells us that the log-odds of response is:\n\\[\n\\begin{aligned}\n\\eta(a = 0, b) &= \\beta_0 + \\beta_2 b\n\\end{aligned}\n\\]\nand for the test intervention, the linear predictor is:\n\\[\n\\begin{aligned}\n\\eta(a = 1, b) &= \\beta_0 + \\beta_1 + \\beta_2 b\n\\end{aligned}\n\\]\nThe difference in the log-odds of response is:\n\\[\n\\begin{aligned}\n\\eta(a = 1, b) - \\eta(a = 0, b) &= (\\beta_0 + \\beta_1 + \\beta_2 b) - (\\beta_0 + \\beta_2 b) \\\\\n&= \\beta_1\n\\end{aligned}\n\\]\nthat is, the \\(\\beta_2\\) term simply cancels out. What we are left with is the log-odds-ratio, since from the properties of logarithms, the difference between two logged values corresponds to the log of their ratio:\n\\[\n\\begin{aligned}\nlog(\\phi) - \\log(\\psi) = \\log(\\frac{\\phi}{\\psi})\n\\end{aligned}\n\\]\nAll of the above should be pretty familiar, if not darn right tedious, but the point was to be explicit for how things are in the context of a complete factorial experiment where we have data on all groups.\nNow imagine a situation where we remove the secondary intervention factor (b) for one level of the primary intervention factor (a). This is equivalent to what we are currently doing in roadmap. To be concrete, if the interventions for a are dair and one-stage revision then we have no interventions under b for dair, but for one-stage we randomise 6 vs 12 wks. So what is the model for this scenario?\nThe easiest thing to do is simply estimate the groups independently. This is (statistically) inefficient, but it maps accurately to the data generation mechanism in this simplified setting. For dair:\n\\[\n\\begin{aligned}\n\\eta_{dair} = \\alpha_0\n\\end{aligned}\n\\]\nis all we need and is estimated based on the cohort that receive dair. Here we take it as implicit that those that receive dair will also receive 12 weeks of antibiotic.\nFor the one-stage group, we would have\n\\[\n\\begin{aligned}\n\\eta_{one} = \\gamma_0 + \\gamma_1 b\n\\end{aligned}\n\\]\nwhere the second term relates to the duration effects estimated solely on those receiving one-stage. Recalling our earlier discussion for how to get to the odds ratio for the treatment effect we would like to compute:\n\\[\n\\begin{aligned}\n\\eta_{one} - \\eta_{dair, b} = \\alpha_0 - (\\gamma_0 + \\gamma_1 b)\n\\end{aligned}\n\\]\nThus, if we set b = 0 then we get one answer for the effect of one vs dair, namely \\(\\alpha_0 - \\gamma_0\\) and if we set b = 1 then we get another answer \\(\\alpha_0 - (\\gamma_0+\\gamma_1)\\). Obviously these cannot be resolved any further unless some decisions are made about b or it is averaged out.\nBased on what I have seen for duration effects, there is still debate about what constitutes the best duration. For dair, it has been reported that 12 weeks is better than 6 weeks, but this was based on a small sample subgroup analysis and thus has all the caveats that we attribute to such samples. Over all surgical types it has been reported that 12 weeks is better, so maybe, in the above, we set b to 1 and take \\(\\alpha_0 - (\\gamma_0+\\gamma_1)\\) as the log-odds ratio of interest.\n\n\nCode\nset.seed(1)\n# Assumed truth of the complete factorial structure\nd_tru &lt;- data.table(id = 1:16)\n# dair/rev\nd_tru[, a := c(rep(0, 4), rep(1, 12))]\n# dair/one/two\nd_tru[, a_star := c(0,0,0,0,1,1,1,1,2,2,2,2,2,2,2,2)]\n# duration (after first op)\nd_tru[, b_1 := c(0,0,1,1,0,0,1,1,0,0,0,0,1,1,1,1)]\nd_tru[9:.N, b_2 := c(0,0,1,1,0,0,1,1)]\nd_tru[, u := rep(0:1, len = .N)]\nd_tru[, eta := rnorm(.N)]\nd_tru[, p := plogis(eta)]"
  },
  {
    "objectID": "notebooks/design-notes-02.html",
    "href": "notebooks/design-notes-02.html",
    "title": "Design discussion (part 1)",
    "section": "",
    "text": "This provides some technical background with the goal of aiding insight into the limitations and challenges associated with the present design.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#complete-design",
    "href": "notebooks/design-notes-02.html#complete-design",
    "title": "Design discussion (part 1)",
    "section": "Complete design",
    "text": "Complete design\nConceptually, roadmap is somewhat nested within an approximation of a complete design, see below. We have ignored the choice domain since it’s not relevant to the discussion here, neither are variations in participation and deviations from assignment. The boxes denote nodes where assignment is under statistical control, the circles are self selected.\nThe complete design as presented still has its quirks. There are multiple version of treatment under revision and these are self selected rather than randomised. Similarly with dair, we expect 12 weeks duration will be the recommended norm, but duration is ultimately self-selected for this group. Aspirationally, we posit 12 and 6 weeks duration following dair per the revision units.\nWhile the duration has been specified as a unified intervention. The figure decomposes the duration domain into duration of antibiotic following the first and second stage operations as this aligns more closely with the interventional procedures. The dashed lines indicate paths which are not available in the current design.\n\n\n\n\n\nflowchart TD\n  Z[Surgery] --&gt; T(Revision type selected) --&gt; W[1st stage duration] --&gt; X[2nd stage duration]\n  A1[DAIR] --&gt; A5((DAIR))\n  A5 --&gt; B0((12w))\n  A5 -.-&gt; B1((6w))\n\n  A2[Revision] --&gt; A3((One-stage))\n  A2 --&gt; A4((Two-stage))\n\n  A3 --&gt; B2[12w]\n  A3 --&gt; B3[6w]\n  A4 --&gt; B4[12w]\n  A4 -.-&gt; B5[6w]\n\n  B2 --- STOP[ ]\n  B2 --- STOP2[ ]\n  B4 --&gt; C1[12w]\n  B4 --&gt; C2[7d]\n  B5 -.-&gt; C3[12w]\n  B5 -.-&gt; C4[7d]\n\n  linkStyle 5 stroke: red;\n  linkStyle 11 stroke: red;\n  linkStyle 16 stroke: red;\n  linkStyle 17 stroke: red;\n  linkStyle 12 fill:#FFFFFF00, stroke: #FFFFFF00\n  linkStyle 13 fill:#FFFFFF00, stroke: #FFFFFF00\n  style STOP  fill:#FFFFFF00, stroke:#FFFFFF00;\n  style STOP2  fill:#FFFFFF00, stroke:#FFFFFF00;\n\n\n\n\n\n\nNeither nested, nor fractional properly characterise the nature of the roadmap design since some cells are self-selected and others fall outsize the specified set of factor levels. For want of a better descriptor, I will just say that roadmap approximately sits within the complete design.\n\n\n\n\n\nflowchart TD\n  Z[Surgery] --&gt; T(Revision type selected) --&gt; W[1st stage duration] --&gt; X[2nd stage duration]\n  A1[DAIR] --&gt; B1((DAIR))\n  B1 --&gt; C1((Usual care))\n\n  A2[Revision] --&gt; B2((One-stage))\n  A2 --&gt; B3((Two-stage))\n\n  B2 --&gt; C2[12w]\n  B2 --&gt; C3[6w]\n  B3 --&gt; C4((Usual care))\n  C4 --&gt; D1[12w]\n  C4 --&gt; D2[7d]\n\n  C2 --- STOP[ ]\n  C3 --- STOP2[ ]\n\n  linkStyle 12 fill:#FFFFFF00, stroke: #FFFFFF00\n  linkStyle 13 fill:#FFFFFF00, stroke: #FFFFFF00\n  style STOP  fill:#FFFFFF00, stroke:#FFFFFF00;\n  style STOP2  fill:#FFFFFF00, stroke:#FFFFFF00;\n\n\n\n\n\n\nIn all cases in the above Usual care following the first operation equates to 12 weeks but that there is some flexibility in this and additionally, a duration of 12 weeks may be precluded by logistical considerations. For example, if the second stage of a two-stage unit occurs within 12 weeks of the first operation then it is not logically possible to assign 12 weeks worth of antibiotic.\nNevertheless, tentatively, we might fill in usual care with 12 weeks to achieve the following structure.\n\n\n\n\n\nflowchart TD\n  Z[Surgery] --&gt; T(Revision type selected) --&gt; W[1st stage duration] --&gt; X[2nd stage duration]\n  A1[DAIR] --&gt; B1((DAIR))\n  B1 --&gt; C1((12w))\n\n  A2[Revision] --&gt; B2((One-stage))\n  A2 --&gt; B3((Two-stage))\n\n  B2 --&gt; C2[12w]\n  B2 --&gt; C3[6w]\n  B3 --&gt; C4((12w))\n  C4 --&gt; D1[12w]\n  C4 --&gt; D2[7d]\n\n  C2 --- STOP[ ]\n  C3 --- STOP2[ ]\n\n  linkStyle 12 fill:#FFFFFF00, stroke: #FFFFFF00\n  linkStyle 13 fill:#FFFFFF00, stroke: #FFFFFF00\n  style STOP  fill:#FFFFFF00, stroke:#FFFFFF00;\n  style STOP2  fill:#FFFFFF00, stroke:#FFFFFF00;\n\n\n\n\n\n\nNow, under the full design model, there would be 8 treatment cells of interest.\n\nDAIR with 12 weeks\nDAIR with 6 weeks\nRevision, one-stage with 12 weeks\nRevision, one-stage with 6 weeks\nRevision, two-stage with 12 weeks following 1st, 12 weeks following 2nd\nRevision, two-stage with 12 weeks following 1st, 7 days following 2nd\nRevision, two-stage with 6 weeks following 1st, 12 weeks following 2nd\nRevision, two-stage with 6 weeks following 1st, 7 days following 2nd\n\nBut in the current roadmap setup we are reduced to 5 treatment:\n\nDAIR with 12 weeks\nRevision, one-stage with 12 weeks\nRevision, one-stage with 6 weeks\nRevision, two-stage with 12 weeks following 1st, 12 weeks following 2nd\nRevision, two-stage with 12 weeks following 1st, 7 days following 2nd\n\nHowever, for 1, 4 and 5, 12 weeks following the first surgery might not be an entirely reasonable assumption. For now, we will put that thought on hold.\nFrom the current design, although there are 5 cells, there are 3 comparisons which are of interest:\n\nDAIR with 12 weeks vs. revision with 12 weeks following 1st and X (could be 12w, 7d, or a mixture) days following 2nd if two-stage\nRevision, one stage with 12 weeks vs. with 6 weeks\nRevision, two stage with 12 weeks after 1st and 2nd vs. 7 days after 2nd.\n\nIf 1 is what is meant by “Revision vs DAIR” then it is not entirely clear who would find this useful in practice since there is potential for substantial variation in the effect dependent on which components are included.\nA saturated model for the full design might be\n\\[\n\\begin{aligned}\n\\eta = &\\beta_0 + \\beta_1r_{\\text{one-stage}} + \\beta_2 r_{\\text{two-stage}} + \\beta_3 d_{\\text{1, 6 weeks}} \\\\\n&+ \\beta_4 r_{\\text{one-stage}}d_{\\text{1, 6 weeks}} + \\beta_5 r_{\\text{two-stage}}d_{\\text{1, 6 weeks}} \\\\\n&+ \\beta_6 r_{\\text{two-stage}} d_{2,\\text{7 days}} + \\beta_7 r_{\\text{two-stage}}d_{\\text{1, 6 weeks}} d_{2,\\text{7 days}}\n\\end{aligned}\n\\]\nwhere the reference group is “DAIR with 12 weeks” and variations in participation are ignored, ditto with respect to the consideration of any level of interactions.\nUnder the current roadmap design, only a reduced model can be considered. A saturated model for the reduced design could be:\n\\[\n\\eta = \\alpha_0 + \\alpha_1r_{\\text{one-stage}} + \\alpha_2 r_{\\text{two-stage}} + \\alpha_3 r_{\\text{one-stage}} d_{\\text{1, 6 weeks}} + \\beta_4 r_{\\text{two-stage}} d_{2,\\text{7 days}}\n\\]\nwhere the reference group is “DAIR with 12 weeks”.\nA reduced model could also be considered under the full design. For example, if we assumed that the effect of first-stage duration was constant across surgery types (which it seems we don’t), and assume that second stage duration is constant across first-stage duration types, then the model would be\n\\[\n\\eta = \\beta_0 + \\beta_1r_{\\text{one-stage}} + \\beta_2 r_{\\text{two-stage}} + \\beta_3 d_{\\text{1, 6 weeks}} + \\beta_6 r_{\\text{two-stage}} d_{2,\\text{7 days}}\n\\]\ni.e. assuming that \\(\\beta_4 = \\beta_5 = \\beta_7\\) from the earlier model are all set to zero.\nThis is basically equivalent to the reduced design model. The exception being that the reduced design is estimating \\(\\alpha_3\\), the effect of duration following one-stage revision specifically. The full design would by default estimate the effect of duration using data from all surgery types, \\(\\beta_3\\), assuming that the effect is constant across types, or additionally could target surgery specific interactions.\nWhy do we only consider the reduced design? Presumably, this is because of the results from other studies that DAIR with 6 weeks is inferior to DAIR with 12 weeks and that in two-stage revision, 6 weeks is considered inferior to 12 weeks. We are investigating 6w vs 12w for one-stage under the assumption that there is effect heterogenity of duration conditional on surgery type. So, inferiority of 6w amongst DAIR/two-stage is insufficient evidence to assume inferiority of 6w in one-stage.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#associational-effects",
    "href": "notebooks/design-notes-02.html#associational-effects",
    "title": "Design discussion (part 1)",
    "section": "Associational effects",
    "text": "Associational effects\nOne of the questions that has been raised relates to how it is that the surgical and duration domain are effectively coupled by design thereby necessitating a perspective on combined interventional strategies. To understand this it is worth stepping back for a moment and thinking about the structure and implications of the models we are using and how they are used to characterise measures of association.\nStart by thinking about the representation of a linear regression versus a logistic regression and what they are aiming to achieve. This is easiest way to do so via an example so assume we have two independent factors that are predictive of independent continuous and binary outcomes. Assume that we are interested in the effect of A but B is still predictive of the outcome. In other words, assume something analogous to a randomised clinical trial setup where A corresponds to our randomised intervention set (here just control vs test) and B is some prognostic baseline characteristic (age, sex etc). For a continuous outcome, adopt a linear model of the form \\(\\mathbb{E}[Y | A,B] = \\mu = \\alpha_0 + \\alpha_1 A + \\alpha_2 B\\) with \\(Y\\) normally distributed. This model encapsulates our assumptions (unknowable in real life) for the data generating process. For the binary outcome adopt a logistic model of the form \\(g(\\mathbb{E}[W | A,B]) = \\eta = \\beta_0 + \\beta_1 A + \\beta_2 B\\) with \\(W\\) is bernoulli \\(\\eta\\) being log-odds of response and \\(g\\) being the logit link function such that the conditional mean of the response is now given by applying the inverse link \\(\\mathbb{E}[W | A,B] = g^{-1}(\\beta_0 + \\beta_1 A + \\beta_2 B)\\) with \\(g^{-1}(z) = \\frac{1}{1+\\exp(-z)} = \\frac{\\exp(z)}{1 + \\exp(z)} = \\text{expit}(z)\\). This latter representation does make sense for the dichotomous response since what we are interested in is the probability of the event and that happens to equate to the expectation, e.g. the conditional expectation of \\(W\\), given \\(X = x\\):\n\\[\n\\begin{aligned}\n\\mathbb{E}(W | X = x) &= \\sum_{w \\in \\mathcal{W} } w Pr(W=w | X = x) \\\\\n  &= 0 Pr(W = 0 | X = x) + 1 Pr(W = 1 | X = x) \\\\\n  &= Pr(W = 1 | X = x)\n\\end{aligned}\n\\]\nIn other words, the conditional mean equates to the conditional probability; \\(\\mathbb{E}[W | A, B] = g^{-1}(\\beta_0 + \\beta_1 A + \\beta_2 B) = Pr(W = 1 | A, B)\\).\nNow, instead of B mapping in the logistic regression relating to the presence/absence of a baseline characteristic, think of it as a second set of interventions so that we are now describing a factorial setup (conveniently ignoring the possibility of interactions). Both A and B remain independent dichotomous random variables. In a complete factorial experiment we would randomise units to all combinations of A and B and usually take parameter estimates as the effects (e.g. log-odds-ratios or odds ratios) of interest. The exponentiated \\(\\beta_1\\) is the multiplicative change in the odds of response associated with moving from the control to the intervention group, with the important caveat that we are holding all other terms constant.\nIn case you need to see how this works out -\nRecall that the logistic regression gives us the probability of the outcome via the inverse logit transformation: \\(Pr(W = 1 | A, B) = g^{-1}(\\beta_0 + \\beta_1 A + \\beta_2 B)\\). The odds ratio for a unit change in A (i.e. a shift from control to test) is defined as:\n\\[\n\\begin{aligned}\nOR(a + 1, a | b) &= \\frac{\\frac{g^{-1}(\\beta_0 + \\beta_1 (a+1) + \\beta_2 b)}{1-g^{-1}(\\beta_0 + \\beta_1 (a+1) + \\beta_2 b)}}{\\frac{g^{-1}(\\beta_0 + \\beta_1 a + \\beta_2 b)}{1-g^{-1}(\\beta_0 + \\beta_1 a + \\beta_2 b)}} \\\\\n&= \\frac{\\exp(\\beta_0 + \\beta_1 (a+1) + \\beta_2 b)}{\\exp(\\beta_0 + \\beta_1 a + \\beta_2 b)} \\\\\n&= \\exp(\\beta_1)\n\\end{aligned}\n\\]\nThe \\(\\beta_2 b\\) term cancels out so long as whatever b was, was the same for both groups, which is what the holding all other terms constant part relates to.\nAnother way to get to this is to take the difference between the two logged values. We know that when we take the difference between two logged values (e.g. the log-odds of response in the treatment vs control group) this equates to the log of their ratio, hence \\(\\beta_1\\) being referred to as the log-odds-ratio.\n\\[\n\\begin{aligned}\nlog(\\phi) - \\log(\\psi) = \\log(\\frac{\\phi}{\\psi})\n\\end{aligned}\n\\]\nAll of the above should be comfortably familiar, but the point was to be explicit for how things are in the context of a conditional logistic regression model and a complete factorial experiment where we have the full set of parameters irrespective of what combination of interventions we are considering.\nNow imagine a situation where we remove the secondary intervention factor (B) for one level of the primary intervention factor (A). This is analogous to a simplified version of the current roadmap design where A is representing the surgical domain and B the duration domain. Here we are only thinking about dair vs one-stage revision for the surgical interventions and 12 vs 6 weeks duration following surgery, but only for those having the one-stage procedure.\nGiven the above setup, we might choose to model the groups independently as we do not intervene on antibiotic duration for the dair group and therefore the system has a distinct data generation processes for each group.\nFor dair we could model and estimate the log-odds of response in isolation, say \\(\\theta\\) estimated from the cohort that receive dair. We take it for granted that the dair intervention is well defined in all its supportive components, which may include some flexibility in the duration of antibiotics received but it isn’t something we have control over via randomisation. Based on the literature it seems like there might be variation in the response under dair conditional on duration but again we are putting that thought on hold for now.\nFor the one-stage group, we might model\n\\[\n\\begin{aligned}\n\\zeta = \\gamma_0 + \\gamma_1 B\n\\end{aligned}\n\\]\nwhere the first term is the log-odds of response for those receiving one-stage revision and the second term relates to how the duration of antibiotics impacts that response. Based on the earlier details for how to derive the log-odds-ratio, we take the difference between the two groups:\n\\[\n\\begin{aligned}\n\\log(OR) = (\\gamma_0 + \\gamma_1 B) - \\theta\n\\end{aligned}\n\\]\nClearly, we are left with the situation where we need to make some decision on what to do with B since it hasn’t dropped out of the calculations as it did under the complete design setup discussed previously. Specifically, if we set B = 0 then we get one answer for the effect of one-stage vs dair, namely \\(\\gamma_0 - \\theta\\) and if we set B = 1 then we get another answer \\(\\gamma_0+\\gamma_1 - \\theta\\). Furthermore, it doesn’t matter whether we use independent models or one large joint model, you still have to make a decision or an assumption about how to handle B. We haven’t got a single parameter to represent the odds-ratio and if such a parameter existed it would probably have a fairly unusual interpretation.\nOne response to the question of what to do with B is to average over B and to adopt a marginal view of the measure of association. This necessitates some assumption regarding the distribution of B. In a complete factorial 2x2 design where A and B are randomised 1:1, the distribution of B is known. However, this probably doesn’t reflect the distribution of B in the population.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#consequences-of-adjustment",
    "href": "notebooks/design-notes-02.html#consequences-of-adjustment",
    "title": "Design discussion (part 1)",
    "section": "Consequences of adjustment",
    "text": "Consequences of adjustment\nAnother thing to be aware of is the concept of collapsibility. Formally, measures of association are said to be collapsible if the marginal view equates to a weighted average of the strata specific effects. In a factorial design, for the comparison of treatments in factor A, units can be grouped in stratum based on the assignment of factor B. Odds-ratios are generally not collapsible and so this should probably be a consideration when using odds-ratios as the population-level summary measure for an estimand.\nAs an example, and with reference to the earlier model, assume that the OR for the treatment group in A relative to the control is 0.5 and for B the effect is 0.1. Additionally, assume that the probability of response in the strata that receive the reference level for both A and B is 0.5. The following simulates a large sample to simply demonstrate the occurrence of differing views of association dependent on the model that is adopted and thus the need to be clear in what we are trying to target in terms of the causal estimand of interest.\n\nlibrary(data.table)\n# Large sample size\nN &lt;- 1e6\n\n# 1:1 Randomisation of A and B\na &lt;- rbinom(N, 1, 0.5)\nb &lt;- rbinom(N, 1, 0.5)\n\n# No interaction by design\neta &lt;- 0 + log(0.5)*a + log(0.1)*b\ny &lt;- rbinom(N, 1, plogis(eta))\n\nd &lt;- data.table(a, b, eta, y)\n\n# Multivariable logistic regression\nl1 &lt;- glm(y ~ a + b, data = d, family = binomial)\n\n# Conditional probabilities for each treatment group\nd_pred &lt;- CJ(a=0:1,b=0:1)\nd_pred[, p := predict(l1, type = \"response\", newdata = d_pred)]\n\n# Observed distribution of b (should be 0.5)\np_b_obs &lt;- mean(b)\n\n# Standardisation to the marginal distribution of b\nd_pred[b == 1, p_b := p_b_obs]\nd_pred[b == 0, p_b := 1-p_b_obs]\np_a_0 &lt;- d_pred[a == 0, sum(p * p_b)]\np_a_1 &lt;- d_pred[a == 1, sum(p * p_b)]\n\n# Univariate logistic regression\nl2 &lt;- glm(y ~ a, data = d, family = binomial)\n\n# Measure of association (all odds-ratios)\n\n# Conditional measures\na_cond &lt;- unname(exp(coef(l1)[2]))\n# Marginal odds ratio computed from standardisation \na_marg_std &lt;- p_a_1/(1-p_a_1) / (p_a_0/(1-p_a_0))\n# Marginal odds ratio computed from univariate regression\na_marg_reg &lt;- unname(exp(coef(l2)[2]))\n\nc(a_cond = a_cond, a_marg_std = a_marg_std, a_marg_reg = a_marg_reg)\n\n    a_cond a_marg_std a_marg_reg \n 0.4994681  0.5607303  0.5595962 \n\n\nThe conditional esitmates give the strata level odds-ratios that we anticipate, however, the marginal odds-ratios are a reflection the observed distribution of B. Clearly, this has implications for the interpretation and generalisability of the results.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#causal-ambiguity",
    "href": "notebooks/design-notes-02.html#causal-ambiguity",
    "title": "Design discussion (part 1)",
    "section": "Causal ambiguity",
    "text": "Causal ambiguity\nNone of the above has considered the causal overlay, which is perhaps the primary motivation for running a randomised clinical trial - we want to be able to say that a change in the response was caused by an intervention rather than simply being associated with it. Some background on a popular causal framework follows.\nThe Neyman-Rubin (causal) model introudces potential outcomes as a means to specify the causal effects. For a treatment with two levels (e.g. control = 0 vs active = 1), the outcome has two possible (potential) values \\(Y_i(0)\\) and \\(Y_i(1)\\) for each experimental unit, \\(i\\). That is, a hypothetical world is posed where the outcomes under both the control and active treatment are available to us. Two assumptions are implicit in the definition of potential outcomes:\n\nno interference - the potential outcome for unit \\(i\\) does not depend on any other units’ treatment\nconsistency1 - if the treatment is \\(T\\) then the observed outcome is equal to the potential outcome under \\(T\\)\n\nUsing this notation we can define a unit level effect as say the difference between the potential outcomes \\(\\tau_i = Y_i(1) - Y_i(0)\\). The problem is that we can never observe both the response to both treatment levels on a single unit. We therefore resort to group level effects for a collection of units by defining an average treatment effect \\(\\tau = \\mathbb{E}(Y_i(1) - Y_i(0))\\). Unlike the unit level effect, the average treatment effect can be identified under certain conditions and then estimated from the observed data.\nOne statistical solution2 to the identification problem above (identification is the technical term for being able to produce a statistical estimand for a given causal estimand) is to randomly assign treatments to the experimental units so that the probability of assignment does not depend on anything other than the flip of a coin. This implies that the potential outcomes will be independent of the treatment which then means that the expected value of a potential outcome is equal to the expected value of the potential outcome conditioned on the treatment status, e.g. \\(\\mathbb{E}(Y(0)) = \\mathbb{E}(Y(0) | T = 0)\\). Formally, this is referred to as the exchaneability assumption and if the consistency assumption also holds then we can resolve the causal quantity into something we can observe and estimate, e.g. \\(\\mathbb{E}(Y(0) | T = 0) = \\mathbb{E}(Y | T = 0)\\). Of course, given that the conditional expection is defined as \\(\\mathbb{E}(Y | T = 0) = \\sum_{y\\in \\mathcal{Y}} y Pr(Y | T = 0) = \\sum_{y\\in \\mathcal{Y}} y \\frac{Pr(Y , T = 0)}{Pr(T = 0)}\\), there needs to be a non-zero probability of assigning \\(T\\), otherwise the quantities that we require will not be defined mathematically. Models will work around this, but we are taking a leap of faith (sometimes an unjustifiable one) in order to believe what they are telling us. This final assumption is known as positivity - we need to have a non-zero probability of treatment assignment for all treatments.\nSo, if our trial has a single domain A which is simply looking at dair (0) vs revision (1) and the outcome were binary then we might posit the causal effect of interest (causal estimand) as the ATE. For a binary outcome amounts to a risk difference, but we are not restricted to this estimand specification, it is just convenient and simple for the purposes of the discussion. Assuming that our modelling approach remains logistic regression we would have\n\\[\n\\begin{aligned}\n\\tau &= \\mathbb{E}(Y(1)) -  \\mathbb{E}(Y(0)) \\\\\n     &= \\mathbb{E}(Y(1)|A = 1) -  \\mathbb{E}(Y(0)|A = 0) \\\\\n     &= \\mathbb{E}(Y|A = 1) -  \\mathbb{E}(Y|A = 0) \\\\\n     &= g^{-1}(\\beta_0 + \\beta_1) - g^{-1}(\\beta_0)\n\\end{aligned}\n\\]\nwhich we can work with so long as the above identification assumptions are met. This would mean that what we get from our model can be given a causal interpretation.\nIf we have two interventional factors, e.g. surgical (A) and duration (B) then we have a larger number of causal estimands to consider under a complete 2x2 factorial design. The potential outcome for a given unit is now usually specified as \\(Y_i(a_i, b_i)\\) where \\(a_i\\) and \\(b_i\\) constitute specific levels of a treatment combination for unit \\(i\\). For concreteness, take the levels for A to be dair and one-stage and the levels for B to be 12wks and 6wks so that \\(Y(1,0)\\) would denote the potential outcome under dair and 12wks. A consequence of this setup is that we can no longer meaningfully discuss \\(Y(A)\\) in isolation as it omits a component of the treatment and is therefore inconsistent in the sense that \\(Y(1)\\) might refer to either \\(Y(1,0)\\) or \\(Y(1,1)\\).\nFor the factorial design, the exchangeability/unconfoundedness assumption required for identification needs to consider both factors, i.e. we need \\((Y(a,b))_{a\\in\\mathcal{A},b\\perp\\mathcal{B}} \\perp (A,B)\\) which can (again) be achieved via randomisation. The final assumption of positivity is also extended so that we require a non-zero probability of assignment for all treatment combinations \\(Pr(A = a, B = b) &gt; 0\\) for all \\(a \\in \\mathcal{A}\\) and \\(b \\in \\mathcal{B}\\). If you are going to adhere strictly to the framework, then I think this final point rules out the use of fractional factorial designs.\nAs mentioned above, with the factorial design we can consider a variety of causal estimands. In our case, these might hypothetically include:\n\nthe effect of one-stage vs dair under 12wks duration\nthe effect of one-stage vs dair under 6wks duration\nthe effect of one-stage vs dair under usual practice for duration\nthe effect of one-stage + 12wks vs dair + 6wks\n\nFor the sake of argument, pick (1) and use an analogous approach to earlier to identify the effect:\n\\[\n\\begin{aligned}\n\\tau &= \\mathbb{E}(Y(1,0)) -  \\mathbb{E}(Y(0,0)) \\\\\n     &= \\mathbb{E}(Y(1,0)|A = 1,B=0) -  \\mathbb{E}(Y(0,0)|A = 0,B=0) \\\\\n     &= \\mathbb{E}(Y|A = 1,B=0) -  \\mathbb{E}(Y|A = 0,B=0) \\\\\n     &= g^{-1}(\\beta_0 + \\beta_1) - g^{-1}(\\beta_0)\n\\end{aligned}\n\\]\nusing the same model specification (\\(\\mathbb{E}[W | A,B] = g^{-1}(\\beta_0 + \\beta_1 A + \\beta_2 B)\\)) as was used earlier and where \\(\\tau\\) now represents a combination effect. However, while \\(Y(A)\\) is ill-defined in the factorial setting, we can still address effects within a single factor through marginalisation:\n\\[\n\\begin{aligned}\n\\psi &= \\mathbb{E}_B[\\mathbb{E}[(Y(1,B) - Y(0,B)]]\n\\end{aligned}\n\\]\nwhere \\(\\psi\\) is the marginal effect for the selected levels of \\(A\\) although this still clearly depends on the distribution of B and therefore might not generalise well to the super population if the measure of association is non-collapsible (see earlier). The central point that I am trying to get across here is that under a complete factorial design we can provide a clear specification of the causal estimands, we can identify the associated statistical estimands and this allows us to estimate effects of interest.\nI do not believe that we have this level of clarity or unification within roadmap. Returning to the current simplified roadmap setup where we have dair vs one-stage and for one-stage we have 12 vs 6 wks, we have\n\ndair + 12 wks: \\(Y(0,0)\\)\none + 12 wks: \\(Y(1,0)\\)\none + 6 wks: \\(Y(1,1)\\)\n\n\\(Y(0,1)\\) is an impossibility by design even though it exists in principle. This looks somewhat like a violation in the positivity assumption but arguably we can work around it. Additionally, \\(Y(0,0)\\) is actually never formally assigned to any unit. What we have is \\(Y(0,U)\\) where \\(U\\) denotes whatever usual practice is, or perhaps a recommendation of usual practice. While we expect (and might assume) that \\(Y(0,U) := Y(0,0)\\) but that does not appear to be guaranteed. Again, we can potentially make assumptions that might help us with all of the above within the context of a model but I am currently uncertain as to whether the causal interpretation can truly be resolved under the present specification.\nThe above simplification is obviously (and purposefully a bit inaccurate) as we currently specify that the surgical domain randomises dair vs revision where the revision intervention is then selected to be either one-stage or two-stage by a clinician based on unobserved variables.\nConsidering a design where only the surgical domain was included, this would also seem to violate the consistency assumption. Recall that consistency connects the potential outcome with the observed data. It is defined as \\(Y_i = Y_i(x)\\) if \\(x = x_i\\); in words - the observed outcome for a unit equals the potential outcome for that unit with the intervention level set to the exposure that the unit received. However, given that what we observe under revision is consequence of either a one-stage or two-stage procedure, then there are two distinct values that singular \\(Y_i(1)\\) could take on, either \\(Y_{one}\\), the observed outcome under a one-stage revision or \\(Y_{two}\\), the observed outcome under a two-stage revision. The argument against this would be that the meaning of revision simply maps to a one or two-stage procedure and the distinction does not matter.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#summary",
    "href": "notebooks/design-notes-02.html#summary",
    "title": "Design discussion (part 1)",
    "section": "Summary",
    "text": "Summary\nThese notes are an attempt to provide some background and clarifications as well as formalise some of the thinking. Hopefully they can provide something of a common understanding in relation to some of the unusual aspects of the design.",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/design-notes-02.html#footnotes",
    "href": "notebooks/design-notes-02.html#footnotes",
    "title": "Design discussion (part 1)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHas no relation with statistical consistency.↩︎\nHolland (1986) talks about others.↩︎",
    "crumbs": [
      "Design notes",
      "Design discussion (part 1)"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html",
    "href": "notebooks/population-structure.html",
    "title": "Population structure",
    "section": "",
    "text": "The following provides some detail on the assumptions relating to important design variables. The outcome model is specified separately.",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#silo",
    "href": "notebooks/population-structure.html#silo",
    "title": "Population structure",
    "section": "Silo",
    "text": "Silo\nThe total sample size is divided across the silos in proportion to the values described in the table below. Each simulated dataset will vary somewhat from these proportions due to the stochastic nature of the data generation process.\n\n\nSilo categories (\\(\\pi\\) denotes probability of membership)\n\n\nSilo\n\\(\\pi\\)\n\n\n\n\nearly\n0.3\n\n\nlate\n0.5\n\n\nchronic\n0.2",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#site-of-infection-joint",
    "href": "notebooks/population-structure.html#site-of-infection-joint",
    "title": "Population structure",
    "section": "Site of infection (joint)",
    "text": "Site of infection (joint)\nEach silo comprises patients assumed to have primary infection in either knee or hip (not both). The assumed proportion of infections for each joint and for each silo are shown below.\n\n\nSite of infection (\\(\\pi\\) denotes probability of site infection conditional on silo membership)\n\n\nSilo\nJoint\n\\(\\pi\\)\n\n\n\n\n\nearly\nknee\n0.4\n\n\n\nearly\nhip\n0.6\n\n\n\nlate\nknee\n0.7\n\n\n\nlate\nhip\n0.3\n\n\n\nchronic\nknee\n0.5\n\n\n\nchronic\nhip\n0.5",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-surgery-domain-a",
    "href": "notebooks/population-structure.html#randomisation-into-surgery-domain-a",
    "title": "Population structure",
    "section": "Randomisation into surgery domain (A)",
    "text": "Randomisation into surgery domain (A)\nOnly the late-stage infection cohort has randomisation options for surgery type. Other silos are assigned by clinician/patient preference.",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#surgery-domain-a",
    "href": "notebooks/population-structure.html#surgery-domain-a",
    "title": "Population structure",
    "section": "Surgery domain (A)",
    "text": "Surgery domain (A)\nOnly late stage patients enter the surgery domain and are randomised 1:1 to DAIR/revision. The clinician selects what type of revision to perform.\nEarly stage patients do not receive randomisation and are assumed to mostly receive DAIR, although they may have any form of surgery. Chronic stage patients do not receive randomisation and are assumed to receive DAIR, one-stage and two-stage based on clinician assessment.",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#intended-surgery",
    "href": "notebooks/population-structure.html#intended-surgery",
    "title": "Population structure",
    "section": "Intended surgery",
    "text": "Intended surgery\nThe planned surgery will be based on a range of factors including clinician preference, hospital protocols etc.\nFor early stage infection patients, we assume the proportion of dair, one and two-stage surgery to be 90%, 10% and 0%.\nFor late stage infection patients randomised to revision, we assume that the preferences for one and two-stage are 30% and 70%. For late stage infection patients randomised to dair, we assume that the preferences for dair, one and two-stage are 20%, 24% and 56%.\nFor chronic stage infection patients, we assume that the preferences for dair, one and two-stage are 20%, 20% and 60%.",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-duration-domain-b",
    "href": "notebooks/population-structure.html#randomisation-into-duration-domain-b",
    "title": "Population structure",
    "section": "Randomisation into duration domain (B)",
    "text": "Randomisation into duration domain (B)\nEntry into domain B is dependent on the surgery that was actually received.\nSurgery received is dependent on whether surgery was randomised (as in late infection patients) and what the surgical preference is (as in chronic infection patients).\nThe surgery received may deviate from the original randomised allocation or preferred approach (in the case where randomisation was not applicable).",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#duration-domain-b",
    "href": "notebooks/population-structure.html#duration-domain-b",
    "title": "Population structure",
    "section": "Duration domain (B)",
    "text": "Duration domain (B)\nWithin the duration domain, allocation is to long vs short duration, the meaning of which differs under one and two-stage surgery. Patients receiving DAIR are assumed to have 12 wk duration (not randomised). The default randomisation is 1:1 for long vs short within surgery type.",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-antibiotic-choice-domain-c",
    "href": "notebooks/population-structure.html#randomisation-into-antibiotic-choice-domain-c",
    "title": "Population structure",
    "section": "Randomisation into antibiotic choice domain (C)",
    "text": "Randomisation into antibiotic choice domain (C)\nThe data generating process assumes that 60% of the total sample enter into this domain at random, unrelated to risk factors.",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#antibiotic-choice-domain-c",
    "href": "notebooks/population-structure.html#antibiotic-choice-domain-c",
    "title": "Population structure",
    "section": "Antibiotic choice domain (C)",
    "text": "Antibiotic choice domain (C)\nThe treatment options and allocation probabilities for domain C are 1:1.",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#encoded-specification",
    "href": "notebooks/population-structure.html#encoded-specification",
    "title": "Population structure",
    "section": "Encoded specification",
    "text": "Encoded specification\nThe above specification is bundled into an R package (roadmap.data) for consistent data generation for ROADMAP.\n\nroadmap.data::get_pop_spec()\n\n$r_silo\n  early    late chronic \n    0.3     0.5     0.2 \n\n$r_joint\n        knee hip\nearly    0.4 0.6\nlate     0.7 0.3\nchronic  0.5 0.5\n\n$r_a\n$r_a$early\n[1] NA\n\n$r_a$late\ndair  rev \n 0.5  0.5 \n\n$r_a$chronic\n[1] NA\n\n\n$r_a_q\n$r_a_q$early\ndair  one  two \n 0.9  0.1  0.0 \n\n$r_a_q$late\ndair  one  two \n0.20 0.24 0.56 \n\n$r_a_q$chronic\ndair  one  two \n 0.2  0.2  0.6 \n\n\n$r_b\n$r_b$dair\n[1] NA\n\n$r_b$one\n long short \n  0.5   0.5 \n\n$r_b$two\n long short \n  0.5   0.5 \n\n\n$r_c\nnorif   rif \n  0.5   0.5 \n\n\nThe following function simulates the design matrix.\n\nroadmap.data::get_design\n\nfunction (N = 2500, pop_spec = NULL, idx_s = 1) \n{\n    if (is.null(pop_spec)) {\n        pop_spec &lt;- get_pop_spec()\n    }\n    l &lt;- sample(0:2, N, replace = T, prob = pop_spec$r_silo)\n    l1 = as.numeric(l == 1)\n    l2 = as.numeric(l == 2)\n    j &lt;- rbinom(N, 1, pop_spec$r_joint[l + 1, 2])\n    if (all(is.na(unlist(pop_spec$r_a)))) {\n        er &lt;- rep(0, N)\n    }\n    else {\n        er &lt;- as.numeric(l == 1)\n        i_rec &lt;- as.logical(rbinom(er[l == 1], 1, 0.02))\n        er[l == 1][i_rec] &lt;- 0\n    }\n    r &lt;- rep(NA, N)\n    for (i in 1:length(pop_spec$r_a)) {\n        z &lt;- pop_spec$r_a[[i]]\n        if (all(!is.na(z))) {\n            r[l == (i - 1)] &lt;- sample(0:(length(z) - 1), sum(l == \n                (i - 1)), TRUE, z)\n        }\n        else {\n            r[l == (i - 1)] &lt;- 0\n        }\n    }\n    r[er == 0] &lt;- 0\n    dtmp &lt;- data.table(cbind(l, er, r, srp = rep(NA, N)))\n    for (i in 1:length(pop_spec$r_a_q)) {\n        z &lt;- pop_spec$r_a_q[[i]]\n        dtmp[l == i - 1 & er == 0, `:=`(srp, sample(0:(length(z) - \n            1), .N, TRUE, z))]\n        dtmp[l == i - 1 & er == 1 & r == 0, `:=`(srp, 0)]\n        dtmp[l == i - 1 & er == 1 & r == 1, `:=`(srp, sample(1:(length(z) - \n            1), .N, TRUE, z[2:length(z)]/sum(z[2:length(z)])))]\n    }\n    srp &lt;- dtmp$srp\n    dtmp &lt;- data.table(srp, ed = rep(0, N))\n    if (all(!is.na(pop_spec$r_b$one))) {\n        dtmp[srp == 1, `:=`(ed, 1)]\n    }\n    if (all(!is.na(pop_spec$r_b$two))) {\n        dtmp[srp == 2, `:=`(ed, 1)]\n    }\n    ed &lt;- dtmp$ed\n    dtmp &lt;- data.table(cbind(srp, ed, d = rep(NA, N)))\n    for (i in 1:length(pop_spec$r_b)) {\n        z &lt;- pop_spec$r_b[[i]]\n        if (all(!is.na(z))) {\n            dtmp[srp == (i - 1), `:=`(d, sample(0:(length(z) - \n                1), .N, TRUE, z))]\n        }\n        else {\n            dtmp[srp == (i - 1), `:=`(d, 0)]\n        }\n    }\n    d &lt;- dtmp$d\n    if (all(is.na(pop_spec$r_c))) {\n        ef &lt;- rep(0, N)\n        f &lt;- rep(0, N)\n    }\n    else {\n        ef &lt;- rbinom(N, 1, 0.6)\n        f &lt;- as.numeric((ef == 1) * rbinom(N, 1, pop_spec$r_c))\n    }\n    D &lt;- data.table(l, l1, l2, j, er, ed, ef, erx = 1 - er, edx = 1 - \n        ed, efx = 1 - ef, r, srp, srp0 = as.numeric(srp == 0), \n        srp1 = as.numeric(srp == 1), srp2 = as.numeric(srp == \n            2), d, f)\n    D[, `:=`(id, idx_s:(N + idx_s - 1))]\n    setcolorder(D, \"id\")\n    D\n}\n&lt;bytecode: 0x1279d2518&gt;\n&lt;environment: namespace:roadmap.data&gt;\n\n\nThe data generation assumptions imply unique patient groups on which we would observe the outcome. The outcome is known to be heterogenous across these groups and yet the stated goal is to aggregate measures of effect (odds ratios) across all these groups, e.g. no rif vs rif.\n\nd &lt;- roadmap.data::get_design()\nhead(d)\n\n      id     l    l1    l2     j    er    ed    ef   erx   edx   efx     r\n   &lt;int&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:     1     0     0     0     1     0     0     1     1     1     0     0\n2:     2     0     0     0     1     0     0     1     1     1     0     0\n3:     3     1     1     0     0     1     0     0     0     1     1     0\n4:     4     1     1     0     1     1     1     0     0     0     1     1\n5:     5     2     0     1     0     0     1     1     1     0     0     0\n6:     6     0     0     0     0     0     0     1     1     1     0     0\n     srp  srp0  srp1  srp2     d     f\n   &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n1:     0     1     0     0     0     1\n2:     0     1     0     0     0     0\n3:     0     1     0     0     0     0\n4:     1     0     1     0     1     0\n5:     2     0     0     1     1     1\n6:     0     1     0     0     0     0",
    "crumbs": [
      "Assumptions and setup",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html",
    "href": "notebooks/design-notes-01.html",
    "title": "Identification of effects",
    "section": "",
    "text": "Setup\nsource(\"./R/init.R\")\nlog_info(\"Called design-notes notebook\")\nStart by saying we were doing a trial in just the late acute patients. We are interested in surgery (DAIR/revision) and antibiotic duration (long/short), but we are limited in that, for whatever reason, we can not ethically randomise the type of revision surgery, only revision surgery itself.\nChoice of antibiotic duration is conditional on the type of revision surgery used, so surgery type needs to be considered in any joint analysis (alternatively, analyse separately).\nI just want to work through from a basic scenario to more involved ones to check understanding of potential issues. The following will ignore much of the complexity, but just want to get some basics down as a reference.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#surgery",
    "href": "notebooks/design-notes-01.html#surgery",
    "title": "Identification of effects",
    "section": "Surgery",
    "text": "Surgery\nAs a starting point, consider the following:\n\nR: randomised surgery - 0: DAIR, 1: revision\nS: preferred revision - 0: one-stage, 1: two-stage\nA: allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\nY: treatment success - 0: no, 1: yes\n\nPatients are randomised to a surgery type, \\(R\\): DAIR or revision. For every patient, if they were to have been allocated to revision, there is some preference/plan for one/two stage, \\(S\\). The value of \\(S\\) is determined by the surgeon/patient and I’m considering it here as just an attribute of the patient.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe above determination is actually dependent on the surgeon’s position as well as patient characteristics. In fact, one may dominate the other. For example, would a surgeon choose two-stage for all their patients simply because they have more experience or sucess with that approach, whereas another might choose one-stage for all theirs?\nNote to self - in practice, I actually think that what matters is that we know what selection is rather than what process occurs to decide. Additionally, later we see that this consideration becomes redundant.\n\n\n\nThe actual allocated treatment is a deterministic function of \\(R\\) and \\(S\\), i.e. \\(A = R \\times (S + 1)\\). Note that I’m assuming that \\(S\\) is known for every patient before \\(R\\) is revealed to the surgeon, irrespective of whether they are eventually assigned to DAIR or revision (if that it isn’t the case then perhaps some issues might arise, but I don’t think that it matters too much for what’s being considered here given randomisation).\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A \n  S --&gt; Y\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 1: Scenario 1, the \\(U\\) denote independent exogenous variables\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nThere are no back-door paths for the above, hence no open back-door paths\n\\(Y\\) is caused by/depends on some function of \\(R\\) and \\(S\\): \\(Y = f(R,S)\\)\nAssuming \\(S\\) causes \\(Y\\) a weaker/safer assumption than excluding that link.\nMaybe there should be some shared \\(U\\) that influences both \\(S\\) and \\(Y\\) rather than assuming \\(S\\) causes \\(Y\\)?\nThe graph implies:\n\n\\(S\\) and \\(R\\) are independent; \\(S \\mathrel{\\unicode{x2AEB}} R\\)\n\\(Y\\) is conditionally independent of \\(R\\) given \\(A\\) and \\(S\\); \\(Y \\mathrel{\\unicode{x2AEB}} R | A, S\\)\n\nWe can estimate the total effect of \\(R\\) on \\(Y\\) where \\(R = 1\\) is loosely defined as revision with expert selection of one-stage or two-stage procedure (or something along those lines)\nThink planned/intended procedure should be recorded prior to any elements of randomisation being revealed.\nNo adjustment is required to estimate the total effect of \\(R\\) on \\(Y\\)\n\n\n\n\nOur intervention is on \\(R\\), everything down stream from that (revision type, antibiotic use, physiotherapy, complications) is a consequence of the intervention. It’s the overall effect of allocation to \\(R=0\\) or \\(R=1\\) that we are trying to (the only thing we can, not necessarily want to) compare.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nIsn’t revision-type independent of intervention? I don’t think I understand why it is downstream.\nNot really sure what is meant by the statement the only thing we can, not necessarily want to compare\n\n\n\n\nIf \\(Y(a)\\) is the potential outcome of a patient under surgery of type \\(a\\) (dair, one-stage, two-stage), then:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y(a)] &= \\mathbb{E}[Y(a)|R=0] \\\\\n&= \\mathbb{E}[Y(a) | R=1] \\\\\n&= \\mathbb{E}[Y(a) | A = 0] \\\\\n&= \\mathbb{E}[Y(a) | A \\in \\{1,2\\}] \\\\\n&\\ne \\mathbb{E}[Y(a) | A = j], \\quad j\\in\\{1,2\\} \\\\\n\\end{aligned}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nAbove we establish exchangeability assumptions, which are a partial requirement for identifying causal effects, i.e. it gets you to \\(\\mathbb{E}[Y(1)] = \\mathbb{E}[Y|A=1]\\) and \\(\\mathbb{E}[Y(0)] = \\mathbb{E}[Y|A=0]\\) whereby you are learning about the potential outcomes from the observed data.\nAll come about due to randomisation of \\(R\\).\nWhere independence holds (as above for the majority of the cases) knowing the conditioning variable tells you nothing about \\(Y(a)\\) (the term on the LHS of the conditioning).\nFor example \\(\\mathbb{E}[Y(a)] = \\mathbb{E}[Y(a)|R=0]\\) tells us that the potential outcomes of \\(Y(a)\\) in those receive dair have the same distribution as those that do not.\nFor \\(\\mathbb{E}[Y(a)] \\ne \\mathbb{E}[Y(a) | A = 1]\\) and \\(\\mathbb{E}[Y(a)] \\ne \\mathbb{E}[Y(a) | A = 2]\\) we are saying that the distribution of potential outcomes in those for whom one-stage is planned do not share the same distribtion as for those for whom one-stage is not planned. And this is by virtue of the fact that revision type is selected rather than randomised.\n\n\n\n\nThe only randomised comparison we can make is \\(R=1\\) vs \\(R=0\\), but, given we want to eventually condition on which revision type is selected, we want to include terms for preferred revision type in the model. Assume logistic regression is the true model and specify\n\\[\n\\begin{align}\n\\mathbb{E}[Y | R] &= Pr(Y = 1 | R) = \\text{expit}(\\alpha_0 + \\alpha_1R) \\\\\n\\end{align}\n\\tag{1}\\]\n\\[\n\\begin{align}\n\\mathbb{E}[Y | A] &= Pr(Y = 1 | A) = \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(A=1) + \\beta_2\\mathbb{I}(A=2)) \\\\\n\\end{align}\n\\tag{2}\\]\nEquivalently, state in terms of \\(R\\) and \\(S\\).\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS) \\\\\n\\tag{3}\\]\nEquation 1 targets the thing we actually want to compare, the log-odds ratio of revision versus DAIR. Equation 3 splits this out into one and two stage which we would need to combine to get the overall revision effect. In Equation 3, the \\(\\beta_1\\) gives the effect of revision under a one-stage procedure and the \\(\\beta_2\\) gives the increment on that term when a two-stage procedure is undertaken. Some weighted combination of these terms will give us a view of the aggregated effect of revision.\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhat isn’t directly stated above is that the (primary?) reason we need to split \\(R\\) into one-stage and two-stage effects is so that we can incorporate the duration domain within a single model. The randomised interventions for duration are 12 weeks vs 6 weeks antibiotics for those receiving one-stage surgery and 12 weeks vs 7 days for those receiving two-stage surgery. If a patient received one-stage, the duration intervention parameters associated with two-stage are mostly irrelevant to estimating the log-odds of treatment success for this patient. Moreover, the response for the one-stage patient does not inform the two-stage duration intervention effects. To accommodate this, the one-stage and two-stage duration parameters enter the model independently, e.g.\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1 \\mathbb{I}(R = \\text{one-stage} \\land D = short) + \\beta_2 \\mathbb{I}(R = \\text{two-stage} \\land D = short)) \\\\\n\\]\nHowever, this means that the duration domain reference group for the one-stage and two-stage duration effects have the same log-odds of treatment success and this is very unlikely to be the case. Thus, by splitting \\(R\\) into one-stage and two-stage effects we allow the reference groups for the one-stage and two-stage duration effects to vary.\n\n\n\nThese models could also adjust for \\(S\\), i.e. in addition to any actual effect of one/two stage revision, the patients for whom a two-stage would be preferred may differ from those for who a one-stage is the preference. Interpretation of model parameters then changes of course.\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3S) \\\\\n\\tag{4}\\]\nWe don’t really care about the difference due to \\(S\\), as the revision type effects may still be confounded by other factors anyway. Due to the randomisation, I think that both the version with and without \\(S\\) are targeting the same estimand for revision vs. DAIR (the distribution of \\(S\\) is the same (in expectation) amongst DAIR and revision patients, so is not a confounder, but obviously, \\(S\\) is known exactly to be \\(A-1\\) when \\(R=1\\)).\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think what you are proposing for the \\(\\beta_3\\) term (the effect of \\(S\\)) boils down to the following:\n\nthe effect of \\(S\\), clinical selection of one-stage vs two-stage may be confounded and we can probably do very little about that\nhowever, the estimate we obtain for \\(\\beta_3\\) would be the same in the group that received revision as the group that did not due to the fact that dair vs revision was randomised\n\nProbably incorrectly, I think the selection effect is meaningless in the sense that receiving dair contradicts the possibility of a selection. It is analogous to a model for number of children whereby you make an adjustment for (randomised) marriage and (self-selected) age of marriage. The main effect of age of marriage is excluded, on the basis that it has no counterpart in reality and therefore no way to inform the effect.\nWhat is the counter-argument? Perhaps something along the lines of:\nTo justify the inclusion of \\(\\beta_3\\) we argue that the married and the non-married groups are balanced across age (and all other characteristics). Therefore, the married and unmarried groups are similar and the effect for age of married in the group is portable to the group that were not randomised to marriage, in the counterfactual world where they had been.\nOk, think I have convinced myself (if perhaps no-one else) that it makes sense.\n\n\n\nFor the second model above, in terms of \\(R\\) and \\(S\\), without adjustment for \\(S\\)\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | R] &= \\mathbb{E}[\\mathbb{E}[Y | S, R] | R] \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs)\\mathbb{P}(S = s | R) \\\\\n\\mathbb{E}[Y|R =0] &= \\text{expit}(\\beta_0) \\\\\n\\mathbb{E}[Y|R = 1] &=  \\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(S=0|R=1) \\\\\n& \\quad \\ + \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2)\\mathbb{P}(S=1|R=1)\n\\end{aligned}\n\\]\nso the log-odds ratio for the marginal success probability for revision vs. DAIR is\n\\[\n\\begin{aligned}\n\\ln\\frac{\\text{odds}(Y|R=1)}{\\text{odds}(Y|R=0)} &= \\text{logit}[\\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(S=0|R=1) + \\\\  \n& \\quad \\quad \\ \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2)\\mathbb{P}(S=1|R=1)] -  \\beta_0\n\\end{aligned}\n\\tag{5}\\]\nWe don’t know \\(\\mathbb{P}(S=s|R)\\) so estimate it from the sample. Due to randomisation \\(\\mathbb{P}(S=s|R) = \\mathbb{P}(S=s)\\).\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhich is just creating a standardised probability of treatment success under revision based on a weighted version of the probability of treatment success for each of the selection groups (one-stage and two-stage) where the weights are formed from the (unknown) distribution of \\(S\\) (estimated from the sample). The standardised probability of treatment success under revision is then converted to the log odds of treatment success and the reference group (DAIR) log-odds of treatment success is subtracted to come up with the log-OR.\nThe final line in the above derivation is just saying that we can assume that the probability distribution of \\(S\\) is independent to treatment group membership and so can be estimated from the full sample rather than condition on \\(R\\). Note that \\(\\mathbb{P}(S=s)\\) is not necessarily indicative of the probability distribution of \\(S\\) in the population because of our convenience sample, but this is true for all inference here and in the majority of trials.\n\n\n\nAn alternative to the above is to consider the “average” conditional log-odds ratio rather than the odds ratio of the marginal probabilities.\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S)}{\\text{odds}(Y|R=0,S)}\\right] = \\mathbb{E}[\\beta_1 + \\beta_2S] = \\beta_1 + \\beta_2\\mathbb{E}[S]\n\\tag{6}\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe expectation of \\(S\\) above is across the sample, but below the weighting is taken from the revision group. Would it not be preferable to use the mean derived from the full sample or am I thinking about it incorrectly?\n\n\n\nIf the model also adjusts for \\(S\\), then\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | R] &= \\mathbb{E}[\\mathbb{E}[Y | S, R] | R] \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs + \\beta_3s)\\mathbb{P}(S = s | R) \\\\\n\\mathbb{E}[Y|R = 0] &= \\text{expit}(\\beta_0)\\mathbb{P}(S = 0 | R=0) + \\text{expit}(\\beta_0 + \\beta_3)\\mathbb{P}(S=1|R=0)\\\\\n\\mathbb{E}[Y|R = 1] &= \\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(S = 0 | R = 1) + \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3)\\mathbb{P}(S=1 | R = 1) \\\\\n\\ln\\frac{\\text{odds}(Y|R=1)}{\\text{odds}(Y|R=0)} &= \\text{logit}(\\mathbb{E}[Y|R = 1]) - \\text{logit}(\\mathbb{E}[Y|R = 0])\n\\end{aligned}\n\\]\nWith the introduction of a main effect for \\(S\\) we can still report on the average conditional log-odds ratio in the same form as previously:\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S)}{\\text{odds}(Y|R=0,S)}\\right] = \\mathbb{E}[\\beta_1 + \\beta_2S] = \\beta_1 + \\beta_2\\mathbb{E}[S]\n\\]\ni.e. with the same terms as without adjustment for \\(S\\). However, the treatment effect parameter estimates produced from the model that includes the main effect for \\(S\\) (and the interaction term) and the model that only has the interaction term, are likely be different.\n\nExample\nHerein I am just assuming \\(n\\approx \\infty\\), i.e. checking consistency.\n\n\n\n\n\n\nNote\n\n\n\n\n\nConsistency is simply about whether the estimator produces an estimate that gets closer towards the true value as the sample size gets bigger; a consistent estimator does not negate the possibility of bias. For example, \\(\\frac{1}{N-1}\\sum_i (x_i)\\) is a consistent but biased estimator of the mean for a random vector, \\(x\\).\nThe default parameterisation for the data generating mechanism is to adopt the functional form from Equation 4, which includes terms for \\(R\\), \\(S\\) and an interaction between \\(R\\) and \\(S\\).\n\n\n\n\n\nGenerate data scenario 1\n# Assume ~ infinite population as just checking consistency\n# Precision will of course vary by approach at small sample sizes\ngenerate_data_1 &lt;- function(\n    n = 1000000,\n    f = function(r, s, x){-1 + s + 0.25 * r + 0.25 * r * s}) {\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  x &lt;- rbinom(n, 1, 0.25)\n  a &lt;- r * (s + 1)\n  y0 &lt;- rbinom(n, 1, plogis(f(0, s, x)))\n  y1 &lt;- rbinom(n, 1, plogis(f(1, s, x)))\n  y &lt;- (1 - r) * y0 + r * y1\n  w &lt;- mean(s) # Selection probability\n  D &lt;- data.table(r = r, x = x, s = s, a = a, y0 = y0, y1 = y1, y = y)[\n    ,\n    `:=`(\n      r_fac = factor(r),\n      a_fac = factor(a),\n      s_fac = factor(s),\n      a_cen = r * (a - 1 - mean(a[r == 1] - 1)),\n      s_cen = s - mean(s)\n    )\n  ]\n}\n\n\n\n\nSimulate null effect\nset.seed(123)\nD &lt;- generate_data_1(f = function(r, s, x){-1 + s})\n\n# Eqn 1\nfit1 &lt;- glm(y ~ r, data = D, family = binomial())\n\n# Eqn 3\nfit2 &lt;- glm(y ~ r + r:s, data = D, family = binomial())\n\n# Eqn 6?\nfit1s &lt;- glm(y ~ r + s, data = D, family = binomial())\n\n# Eqn 4\nfit2s &lt;- glm(y ~ r + r:s + s, data = D, family = binomial())\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nIn the use of “true” below, what is meant is the empirical log-odds ratios in the population (approximated by a very large sample) that we observe. We estimate the effects directly from the data by calculating the difference in the log-odds of treatment success in the strata of interest for those in the treated vs control groups.\nThe table just tries to line up the quantities, like with like as there were some minor differences in the naming.\n\n\n\n\n\nNull effect quantities\nw &lt;- mean(D$a == 2) / mean(D$a %in% c(1, 2))\nw_s1 &lt;- mean(D[r == 0]$s == 1)\nw_s2 &lt;- mean(D[r == 1]$s == 1)\n\nb1 &lt;- unname(coef(fit1))\nb2 &lt;- unname(coef(fit2))\nb1s &lt;- unname(coef(fit1s))\nb2s &lt;- unname(coef(fit2s))\n\nEY_R0_2 &lt;- expit(b2[1])\nEY_R1_2 &lt;- (1 - w) * expit(b2[1] + b2[2]) + w * expit(b2[1] + b2[2] + b2[3])\n\nEY_R0_1_S0 &lt;- expit(b1s[1])\nEY_R0_1_S1 &lt;- expit(b1s[1] + b1s[3])\nEY_R1_1_S0 &lt;- expit(b1s[1] + b1s[2])\nEY_R1_1_S1 &lt;- expit(b1s[1] + b1s[2] + b1s[3])\nEY_R0_1 &lt;- (1 - w_s1) * EY_R0_1_S0 + w_s1 * EY_R0_1_S1\nEY_R1_1 &lt;- (1 - w_s2) * EY_R1_1_S0 + w_s2 * EY_R1_1_S1\n\nEY_R0_2s_S0 &lt;- expit(b2s[1])\nEY_R0_2s_S1 &lt;- expit(b2s[1] + b2s[3])\nEY_R1_2s_S0 &lt;- expit(b2s[1] + b2s[2]) # Pr(A = 2 | S = 0) = 0\nEY_R1_2s_S1 &lt;- expit(b2s[1] + b2s[2] + b2s[3] + b2s[4]) # Pr(A = 2 | S = 1) = 1\nEY_R0_2s &lt;- (1 - w_s1) * EY_R0_2s_S0 + w_s1 * EY_R0_2s_S1\nEY_R1_2s &lt;- (1 - w_s2) * EY_R1_2s_S0 + w_s2 * EY_R1_2s_S1\n\nrbind(\n  \"True conditional (S = 0) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n  \"True conditional (S = 1) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n  \"True marginal log-odds ratio\" = qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  \"True weighted log-odds ratio\" =\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n  \"True average weighted log-odds ratio\" =\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y))),\n  \"fit1 marginal log-odds ratio\" = b1[2],\n  \"fit2 marginal log-odds ratio\" = qlogis(EY_R1_2) - qlogis(EY_R0_2),\n  \"fit2 conditional (weighted) log-odds ratio\" = b2[2] + w * b2[3],\n  \"fit1s conditional log-odds ratio\" = b1s[2], # Don't know what this targets\n  \"fit1s marginal log-odds ratio\" = qlogis(EY_R1_1) - qlogis(EY_R0_1),\n  \"fit2s conditional (S = 0) log-odds ratio\" = qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0),\n  \"fit2s conditional (S = 1) log-odds ratio\" = qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1),\n  \"fit2s marginal log-odds ratio\" = qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n  \"fit2s average (weighted) log-odds ratio\" = b2s[2] + w * b2s[4]\n)\n\n\n                                                   [,1]\nTrue conditional (S = 0) log-odds ratio    -0.003882742\nTrue conditional (S = 1) log-odds ratio     0.003222299\nTrue marginal log-odds ratio                0.002568068\nTrue weighted log-odds ratio               -0.018727631\nTrue average weighted log-odds ratio        0.001097800\nfit1 marginal log-odds ratio                0.002568068\nfit2 marginal log-odds ratio                0.002568068\nfit2 conditional (weighted) log-odds ratio -0.018727631\nfit1s conditional log-odds ratio            0.001436139\nfit1s marginal log-odds ratio               0.002568068\nfit2s conditional (S = 0) log-odds ratio   -0.003882742\nfit2s conditional (S = 1) log-odds ratio    0.003222299\nfit2s marginal log-odds ratio               0.002568068\nfit2s average (weighted) log-odds ratio     0.001097800\n\n\nNull effect quantities\nd_out &lt;- data.table(\n  desc = c(\n    \"conditional (S = 0) log-OR\",\n    \"conditional (S = 1) log-OR\",\n    \"conditional log-OR (?)\",\n    \"conditional (weighted) log-OR\",\n    \"marginal log-OR\",\n    \"weighted log-OR\",\n    \"average (weighted) log-OR\"\n  ),\n  true = c(\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n    NA,  \n    NA,\n    qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)))\n  ),\n  fit_1 = c(\n    NA, \n    NA,  \n    NA,\n    NA, \n    b1[2], \n    NA, \n    NA\n  ),\n  fit_2 = c(\n    NA, \n    NA,\n    NA, \n    b2[2] + w * b2[3], \n    qlogis(EY_R1_2) - qlogis(EY_R0_2), \n    NA,\n    NA\n  ),\n  fit_1s = c(\n    NA, \n    NA, \n    b1s[2],\n    NA,\n    qlogis(EY_R1_1) - qlogis(EY_R0_1), \n    NA,\n    NA\n  ),\n  fit_2s = c(\n    qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0), \n    qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1), \n    NA, \n    NA,\n    qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n    NA,\n    b2s[2] + w * b2s[4]\n  )\n)\n\n\n\n\nTabulate effect quantities\ngt_tbl &lt;- d_out |&gt; \n  gt(rowname_col = c(\"desc\")) |&gt; \n  cols_align(align = \"right\", columns = 2:6) |&gt;  \n  fmt_number(columns = everything(), decimals = 3) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") |&gt;\n  tab_options(table.font.size = \"80%\") |&gt;\n  tab_footnote(\n    footnote = \"y ~ r\",\n    locations = cells_column_labels(columns = fit_1)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s\",\n    locations = cells_column_labels(columns = fit_2)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + s\",\n    locations = cells_column_labels(columns = fit_1s)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + s\",\n    locations = cells_column_labels(columns = fit_2s)\n    ) |&gt;\n  tab_footnote(\n    footnote = md(\"Should be labelled *conditional (weighted) log-OR*?\"),\n    locations = cells_stub(rows = c(\n      \"weighted log-OR\"\n    ))\n  ) |&gt;\n  tab_footnote(\n    footnote = md(\"log-OR for R term in model, but interpretation unclear\"),\n    locations = cells_stub(rows = c(\n      \"conditional log-OR (?)\"))\n  )\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrue\nfit_11\nfit_22\nfit_1s3\nfit_2s4\n\n\n\n\nconditional (S = 0) log-OR\n−0.004\n\n\n\n\n\n\n−0.004\n\n\nconditional (S = 1) log-OR\n0.003\n\n\n\n\n\n\n0.003\n\n\nconditional log-OR (?)5\n\n\n\n\n\n\n0.001\n\n\n\n\nconditional (weighted) log-OR\n\n\n\n\n−0.019\n\n\n\n\n\n\nmarginal log-OR\n0.003\n0.003\n0.003\n0.003\n0.003\n\n\nweighted log-OR6\n−0.019\n\n\n\n\n\n\n\n\n\n\naverage (weighted) log-OR\n0.001\n\n\n\n\n\n\n0.001\n\n\n\n1 y ~ r\n\n\n2 y ~ r + r:s\n\n\n3 y ~ r + s\n\n\n4 y ~ r + r:s + s\n\n\n5 log-OR for R term in model, but interpretation unclear\n\n\n6 Should be labelled conditional (weighted) log-OR?\n\n\n\n\n\n\n\n\n\nTable 1: Null effects\n\n\n\n\n\n\nSimulate effect\nset.seed(123)\nD &lt;- generate_data_1()\nfit1 &lt;- glm(y ~ r, data = D, family = binomial())\nfit2 &lt;- glm(y ~ r + r:s, data = D, family = binomial())\nfit1s &lt;- glm(y ~ r + s, data = D, family = binomial())\nfit2s &lt;- glm(y ~ r + r:s + s, data = D, family = binomial())\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nSimulate from Equation 4 with a baseline probability of treatment success equal to 0.27 together with \\(\\beta_1 = 0.25\\), \\(\\beta_2 = 0.25\\) and \\(\\beta_3 = 1\\) for the log-ORs associated with treatment, the interaction between treatment and selection and selection, respectively.\n\n\n\n\n\nEffect quantities\nw &lt;- mean(D$a == 2) / mean(D$a %in% c(1, 2))\nw_s1 &lt;- mean(D[r == 0]$s == 1)\nw_s2 &lt;- mean(D[r == 1]$s == 1)\n\nb1 &lt;- unname(coef(fit1))\nb2 &lt;- unname(coef(fit2))\nb1s &lt;- unname(coef(fit1s))\nb2s &lt;- unname(coef(fit2s))\n\nEY_R0_2 &lt;- expit(b2[1])\nEY_R1_2 &lt;- (1 - w) * expit(b2[1] + b2[2]) + w * expit(b2[1] + b2[2] + b2[3])\n\nEY_R0_1_S0 &lt;- expit(b1s[1])\nEY_R0_1_S1 &lt;- expit(b1s[1] + b1s[3])\nEY_R1_1_S0 &lt;- expit(b1s[1] + b1s[2])\nEY_R1_1_S1 &lt;- expit(b1s[1] + b1s[2] + b1s[3])\nEY_R0_1 &lt;- (1 - w_s1) * EY_R0_1_S0 + w_s1 * EY_R0_1_S1\nEY_R1_1 &lt;- (1 - w_s2) * EY_R1_1_S0 + w_s2 * EY_R1_1_S1\n\nEY_R0_2s_S0 &lt;- expit(b2s[1])\nEY_R0_2s_S1 &lt;- expit(b2s[1] + b2s[3])\nEY_R1_2s_S0 &lt;- expit(b2s[1] + b2s[2]) # Pr(A = 2 | S = 0) = 0\nEY_R1_2s_S1 &lt;- expit(b2s[1] + b2s[2] + b2s[3] + b2s[4]) # Pr(A = 2 | S = 1) = 1\nEY_R0_2s &lt;- (1 - w_s1) * EY_R0_2s_S0 + w_s1 * EY_R0_2s_S1\nEY_R1_2s &lt;- (1 - w_s2) * EY_R1_2s_S0 + w_s2 * EY_R1_2s_S1\n\nrbind(\n  \"True conditional (S = 0) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n  \"True conditional (S = 1) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n  \"True marginal log-odds ratio\" = qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  \"True weighted log-odds ratio\" =\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n  \"True average (weighted) log-odds ratio\" =\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y))),\n  \"fit1 marginal log-odds ratio\" = b1[2],\n  \"fit2 marginal log-odds ratio\" = qlogis(EY_R1_2) - qlogis(EY_R0_2),\n  \"fit2 conditional (weighted) log-odds ratio\" = b2[2] + w * b2[3],\n  \"fit1s conditional log-odds ratio\" = b1s[2], # Don't know what this targets\n  \"fit1s marginal log-odds ratio\" = qlogis(EY_R1_1) - qlogis(EY_R0_1),\n  \"fit2s conditional (S = 0) log-odds ratio\" = qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0),\n  \"fit2s conditional (S = 1) log-odds ratio\" = qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1),\n  \"fit2s marginal log-odds ratio\" = qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n  \"fit2s average (weighted) log-odds ratio\" = b2s[2] + w * b2s[4]\n)\n\n\n                                                [,1]\nTrue conditional (S = 0) log-odds ratio    0.2462550\nTrue conditional (S = 1) log-odds ratio    0.4944007\nTrue marginal log-odds ratio               0.4038167\nTrue weighted log-odds ratio               0.4003765\nTrue average (weighted) log-odds ratio     0.4202020\nfit1 marginal log-odds ratio               0.4038167\nfit2 marginal log-odds ratio               0.4038167\nfit2 conditional (weighted) log-odds ratio 0.4003765\nfit1s conditional log-odds ratio           0.4285063\nfit1s marginal log-odds ratio              0.4038167\nfit2s conditional (S = 0) log-odds ratio   0.2462550\nfit2s conditional (S = 1) log-odds ratio   0.4944007\nfit2s marginal log-odds ratio              0.4038167\nfit2s average (weighted) log-odds ratio    0.4202020\n\n\nEffect quantities\nd_out &lt;- data.table(\n  desc = c(\n    \"conditional (S = 0) log-OR\",\n    \"conditional (S = 1) log-OR\",\n    \"conditional log-OR (?)\",\n    \"conditional (weighted) log-OR\",\n    \"marginal log-OR\",\n    \"weighted log-OR\",\n    \"average (weighted) log-OR\"\n  ),\n  true = c(\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n    NA,  \n    NA,\n    qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)))\n  ),\n  fit_1 = c(\n    NA, \n    NA,   \n    NA,\n    NA, \n    b1[2], \n    NA, \n    NA\n  ),\n  fit_2 = c(\n    NA, \n    NA, \n    NA, \n    b2[2] + w * b2[3], \n    qlogis(EY_R1_2) - qlogis(EY_R0_2), \n    NA,\n    NA\n  ),\n  fit_1s = c(\n    NA, \n    NA, \n    b1s[2],\n    NA,\n    qlogis(EY_R1_1) - qlogis(EY_R0_1), \n    NA,\n    NA\n  ),\n  fit_2s = c(\n    qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0), \n    qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1),  \n    NA, \n    NA,\n    qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n    NA,\n    b2s[2] + w * b2s[4]\n  )\n)\n\n\n\n\nTabulate effect quantities\ngt_tbl &lt;- d_out |&gt; \n  gt(rowname_col = c(\"desc\")) |&gt; \n  cols_align(align = \"right\", columns = 2:6) |&gt;  \n  fmt_number(columns = everything(), decimals = 3) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") |&gt;\n  tab_options(table.font.size = \"80%\") |&gt;\n  tab_footnote(\n    footnote = \"y ~ r\",\n    locations = cells_column_labels(columns = fit_1)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s\",\n    locations = cells_column_labels(columns = fit_2)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + s\",\n    locations = cells_column_labels(columns = fit_1s)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + s\",\n    locations = cells_column_labels(columns = fit_2s)\n    ) |&gt;\n  tab_footnote(\n    footnote = md(\"Should be labelled *conditional (weighted) log-OR*?\"),\n    locations = cells_stub(rows = c(\n      \"weighted log-OR\"))) |&gt;\n  tab_footnote(\n    footnote = md(\"log-OR for R term in model, but interpretation unclear\"),\n    locations = cells_stub(rows = c(\n      \"conditional log-OR (?)\"))\n  )\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrue\nfit_11\nfit_22\nfit_1s3\nfit_2s4\n\n\n\n\nconditional (S = 0) log-OR\n0.246\n\n\n\n\n\n\n0.246\n\n\nconditional (S = 1) log-OR\n0.494\n\n\n\n\n\n\n0.494\n\n\nconditional log-OR (?)5\n\n\n\n\n\n\n0.429\n\n\n\n\nconditional (weighted) log-OR\n\n\n\n\n0.400\n\n\n\n\n\n\nmarginal log-OR\n0.404\n0.404\n0.404\n0.404\n0.404\n\n\nweighted log-OR6\n0.400\n\n\n\n\n\n\n\n\n\n\naverage (weighted) log-OR\n0.420\n\n\n\n\n\n\n0.420\n\n\n\n1 y ~ r\n\n\n2 y ~ r + r:s\n\n\n3 y ~ r + s\n\n\n4 y ~ r + r:s + s\n\n\n5 log-OR for R term in model, but interpretation unclear\n\n\n6 Should be labelled conditional (weighted) log-OR?\n\n\n\n\n\n\n\n\n\nTable 2: Effects\n\n\n\n\nSo in the basic case, as \\(n\\to\\infty\\), these models are all in a sense equivalent, in that they are consistent for the treatment effects of interest.\nMore generally, can just use g-computation rather than analytic expressions\n\n\nCode\nm &lt;- rbind(\n  \"G-comp marginal mean\" =\n    c(avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\")$estimate, NA_real_),\n  \"G-comp marginal mean (adjust s)\" =\n    c(avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")$estimate, NA_real_),\n  \"G-comp average log-odds\" =\n    c(avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\")$estimate, NA_real_),\n  \"G-comp average log-odds (adjust s)\" = \n    c(avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\")$estimate, NA_real_),\n  \"G-comp conditional (S) average log-odds\" =\n    avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\", by = \"s\")$estimate,\n  \"G-comp conditional (S) average log-odds (adjust s)\" =\n    avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\", by = \"s\")$estimate\n)\ncolnames(m) &lt;- c(\"S = 0\", \"S = 1\")\nm\n\n\n                                                        S = 0     S = 1\nG-comp marginal mean                                0.4030520        NA\nG-comp marginal mean (adjust s)                     0.4024538        NA\nG-comp average log-odds                             0.4030520        NA\nG-comp average log-odds (adjust s)                  0.4024538        NA\nG-comp conditional (S) average log-odds            -0.4764725 0.7744050\nG-comp conditional (S) average log-odds (adjust s)  0.2462550 0.4944007\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think that the above are basically making predictions for the comparison of interest at each of the rows in the data set and then averaging to give a marginalised view.\nThe definitional differences between lnoravg and lnor amount to:\nlnor   \\(hi, lo) log((hi/(1 - hi))/(lo/(1 - lo)))\nvs.\nlnoravg    \\(hi, lo) log((mean(hi)/(1 - mean(hi)))/(mean(lo)/(1 - mean(lo)))\nso (I think but need to confirm) one is doing the calculation on every row and then averaging whereas the other averages first.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#covariate",
    "href": "notebooks/design-notes-01.html#covariate",
    "title": "Identification of effects",
    "section": "Covariate",
    "text": "Covariate\nSuppose we introduce a covariate \\(X\\) because it’s predictive of the outcome, e.g. sex. Our model, which does not adjust for \\(S\\), is\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R,S,X] &= \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3X) \\\\\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|R,S,X]|R,X] \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs + \\beta_3X)\\mathbb{P}(S=s|R,X) \\\\\n\\mathbb{E}[Y|R=0,X] &= \\text{expit}(\\beta_0 + \\beta_3X) \\\\\n\\mathbb{E}[Y|R=1,X] &= \\text{expit}(\\beta_0 + \\beta_1 + \\beta_3X)\\mathbb{P}(S=0|R=1,X)  \\\\\n&\\quad \\ + \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3X)\\mathbb{P}(S=1|R=1,X)\n\\end{aligned}\n\\]\nThe conditional (on \\(X\\)) log-odds ratio of marginal success probability for revision versus DAIR depends on the value of \\(X\\) (i.e. is not the same effect for every \\(X=x\\)) and cannot be simplified. It is\n\\[\n\\text{logit}(\\mathbb{E}[Y|R=1,X]) - (\\beta_0 + \\beta_3X).\n\\]\nBy marginalising over type of revision type (which is necessary for the comparison we want), we lose our one number summary. No way to avoid that other than perhaps considering fitting separate models for surgery and duration.\nTo maintain a one-number-summary, again an alternative is to consider the average conditional log-odds\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1|S,X)}{\\text{odds}(Y|R=0|S,X)}\\right] = \\beta_1 + \\beta_2\\mathbb{E}[S].\n\\]\nIf \\(S\\) has an effect, say in truth,\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|S,R,X] &= \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3S + \\beta_4X) \\\\\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|S,R,X]|R,X] \\\\\n&= \\sum_{s=0}^1 \\mathbb{E}[Y|S=s,R,X]\\mathbb{P}(S=s|R,X)\n\\end{aligned}\n\\]\nThen if our model does condition on \\(S\\),\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|R,X,S]|R,X] \\\\\n&= \\sum_{s=0}^1\n\\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs + \\beta_3s+\\beta_4X)\n\\mathbb{P}(S=s|R,X) \\\\\n\\mathbb{E}[Y|R=0,X] &= \\text{expit}(\\beta_0 + \\beta_4X)\\mathbb{P}(S=0|R=0,X) +\n\\text{expit}(\\beta_0 + \\beta_3 + \\beta_4X)\\mathbb{P}(S=1|R=0,X) \\\\\n\\mathbb{E}[Y|R=1,X] &= \\text{expit}(\\beta_0 + \\beta_1 + \\beta_4X)\\mathbb{P}(S=0|R=0,X) +\n\\text{expit}(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3 + \\beta_4X)\\mathbb{P}(S=1|R=0,X) \\\\\n\\ln\\frac{\\text{odds}(Y|R=1,X)}{\\text{odds}(Y|R=0,X)} &= \\text{logit}(\\mathbb{E}[Y|R=1,X]) - \\text{logit}(\\mathbb{E}[Y|R=0,X])\n\\end{aligned}\n\\]\nDue to randomisation, \\(\\mathbb{P}(S=s|R,X) = \\mathbb{P}(S=s|X)\\).\nThe model without adjustment for \\(S\\) assumes\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R,S,X] &= \\text{expit}(\\alpha_0 + \\alpha_1R + \\alpha_2RS + \\alpha_3X) \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3X + \\beta_4s)\\mathbb{P}(S=s|R,X)\n\\end{aligned}\n\\]\n\nExample\n\n\n\n\n\n\nNote\n\n\n\n\n\nBy definition, \\(x\\) has a 25% chance of occurrence in the sample data.\n\n\n\n\n\nGenerate data with covariate\nset.seed(6124)\nD &lt;- generate_data_1(\n  f = function(r, s, x){ -1 + s + x + 0.25 * r + 0.25 * r * s}\n)\nfit1 &lt;- glm(y ~ r + x, data = D, family = binomial())\nfit2 &lt;- glm(y ~ r + r:s + x, data = D, family = binomial())\nfit1s &lt;- glm(y ~ r + s + x, data = D, family = binomial())\nfit2s &lt;- glm(y ~ r + s + r:s + x, data = D, family = binomial())\n\n\nUsing G-computation to marginalise over \\(S\\) and \\(X\\).\n\n\nEffect quantities\ntt &lt;- cbind(\n  qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  NA,\n  qlogis(mean(D[r == 1 & x == 0]$y)) - qlogis(mean(D[r == 0 & x == 0]$y)),\n  qlogis(mean(D[r == 1 & x == 1]$y)) - qlogis(mean(D[r == 0 & x == 1]$y))\n)\nrownames(tt) &lt;- \"True\"\nm1 &lt;- rbind(\n  avg_comparisons(fit1, variables = \"r\", comparison = \"lnoravg\")$estimate,\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\")$estimate,\n  avg_comparisons(fit1s, variables = \"r\", comparison = \"lnoravg\")$estimate,\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")$estimate\n)\nm2 &lt;- rbind(\n  avg_comparisons(fit1, variables = \"r\", comparison = \"lnor\")$estimate,\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\")$estimate,\n  avg_comparisons(fit1s, variables = \"r\", comparison = \"lnor\")$estimate,\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\")$estimate\n)\nm3 &lt;- rbind(\n  avg_comparisons(fit1, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate,\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate,\n  avg_comparisons(fit1s, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate,\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate\n)\nm &lt;- cbind(m1, m2, m3)\ncols &lt;- c(\"Marginal log-odds ratio\", \"Average log-odds ratio\", \"Conditional (X = 0)\", \"Conditional (X = 1)\")\ncolnames(m) &lt;- cols\nrownames(m) &lt;- c(\"fit1\", \"fit2\", \"fit1s\", \"fit2s\")\nround(rbind(tt, m), 3)\n\n\n      Marginal log-odds ratio Average log-odds ratio Conditional (X = 0)\nTrue                    0.376                     NA               0.397\nfit1                    0.377                  0.377               0.391\nfit2                    0.378                  0.378               0.408\nfit1s                   0.378                  0.378               0.393\nfit2s                   0.378                  0.378               0.398\n      Conditional (X = 1)\nTrue                0.367\nfit1                0.391\nfit2                0.334\nfit1s               0.392\nfit2s               0.371\n\n\n\n\nTabulate effect quantities\nd_out &lt;- data.table(t(round(rbind(tt, m), 3)))\nd_out[, desc := cols]\nsetcolorder(d_out, \"desc\")\n\n\n\ngt_tbl &lt;- d_out |&gt; \n  gt(rowname_col = c(\"desc\")) |&gt; \n  cols_align(align = \"right\", columns = 2:6) |&gt;  \n  fmt_number(columns = everything(), decimals = 3) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") |&gt;\n  tab_options(table.font.size = \"80%\") |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + x\",\n    locations = cells_column_labels(columns = fit1)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + x\",\n    locations = cells_column_labels(columns = fit2)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + s + x\",\n    locations = cells_column_labels(columns = fit1s)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + s + x\",\n    locations = cells_column_labels(columns = fit2s)\n    ) \n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrue\nfit11\nfit22\nfit1s3\nfit2s4\n\n\n\n\nMarginal log-odds ratio\n0.376\n0.377\n0.378\n0.378\n0.378\n\n\nAverage log-odds ratio\n\n\n0.377\n0.378\n0.378\n0.378\n\n\nConditional (X = 0)\n0.397\n0.391\n0.408\n0.393\n0.398\n\n\nConditional (X = 1)\n0.367\n0.391\n0.334\n0.392\n0.371\n\n\n\n1 y ~ r + x\n\n\n2 y ~ r + r:s + x\n\n\n3 y ~ r + s + x\n\n\n4 y ~ r + r:s + s + x\n\n\n\n\n\n\n\n\n\nTable 3: G-computation estimates in presence of prognostic covariate",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#unmeasured-confounder",
    "href": "notebooks/design-notes-01.html#unmeasured-confounder",
    "title": "Identification of effects",
    "section": "Unmeasured Confounder",
    "text": "Unmeasured Confounder\nThe above hides some complexity because we assume everything is correctly specified. Suppose we introduce some unmeasured factor which influences which patients are preferred for a given revision type. Consider the following:\n\nR: randomised surgery - 0: DAIR, 1: revision\nS: preferred revision - 0: one-stage, 1: two-stage\nA: allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\nY: treatment success - 0: no, 1: yes\nZ: unmeasured factor, patient attributes/type - continuous\n\nWe assume \\(Z\\) is some immeasurable combination of factors which partly determines a patients risk of failure. We also think that this \\(Z\\) partly determines the surgeons choice of one/two stage. Say patients with higher values of \\(Z\\) are less likely to have successful treatment. However, the surgeon has some knowledge/experience/expertise/intuition which means that they are more likely to prefer a two-stage revision for patients with higher values of \\(Z\\), as they expect those types of patients will have better outcomes under two-stage. The allocated treatment and the underlying patient risk determines the patients outcome, \\(Y\\).\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A\n  Z(Z) --&gt; S & A & Y\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 2: Scenario 2, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\nGiven the randomisation, this does not really change anything, except making explicit that differences between one/two stage may just be due to confounding rather than effect of treatment. We can’t tell which without adjusting for all confounders.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#checkpoint",
    "href": "notebooks/design-notes-01.html#checkpoint",
    "title": "Identification of effects",
    "section": "Checkpoint",
    "text": "Checkpoint\nSo, perhaps the easiest quantity to consider is the average conditional log-odds, i.e.\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S,X,...)}{\\text{odds}(Y|R=0,S,X,...)}\\right] = \\beta_1 + \\beta_2\\mathbb{E}[S].\n\\]\nIs this sufficiently meaningful?\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think what you are saying is to adopt Equation 4 and then report our effect estimate for revision at the sample mean of observed selection, which is this case fully characterises the distribution anyway.\nThe terminology used for effects seems to vary a bit throughout, but my label would probably be more explicit conditional log-OR evaluated at the mean selection or something like that, whereas I think it has been previously referred to as conditional (weighted) log-OR earlier and average (weighted) log-OR earlier, probably because that is how they have been computed.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#duration",
    "href": "notebooks/design-notes-01.html#duration",
    "title": "Identification of effects",
    "section": "Duration",
    "text": "Duration\nDuration, \\(D\\), is randomised, however, the duration options depends upon assignment to revision \\(R\\), and the chosen revision type, \\(S\\). So it is random conditional on \\(R\\) and \\(S\\). Nothing else alters the distribution of \\(D\\). We expect that duration has an effect on the outcome.\nBelow we just use \\(D=0\\) for long and \\(D=1\\) for short, but note that the meaning of these is conditional on \\(R/S\\) (i.e. short for one-stage different to short for two-stage and only applies to revision)\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A & D\n  R --&gt; D\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 3: Scenario 3, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThere might be alternative representations of the above and also the potential for direct and indirect effects of \\(S\\), see below:\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A\n  S --&gt; Y\n  A --&gt; D\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; D\n  S --&gt; D\n  S --&gt; Y\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4\n\nFigure 5\nNow there are two interventions: \\(R\\) which has downstream unknown effects partly due to the unknown revision type, \\(S\\), which is selected, and \\(D\\) which is randomised.\nThe simplest approach is to analyse these separately. First, restrict the analysis to those patients who were assigned to one-stage and have an RCT for duration in embedded in that subset. Then, restrict analysis to only those assigned to two-stage and have an RCT for duration in that subset. However, we would like to have a joint model so that other effects can be shared (other domains/site/surgeon/age/whatever else). In the joint model, duration effect needs to be conditional on revision type.\nSay the true model were something like\n\\[\n\\mathbb{E}[Y|R,S,D] = \\text{expit}(\\beta_0 + \\beta_1S + \\beta_2R + \\beta_3RS + \\beta_4RD + \\beta_5RDS)\n\\tag{7}\\]\nso\n\n\\(\\beta_2\\) is the shift associated with revision and long duration (assuming long-duration is the refrence group)\n\\(\\beta_3\\) the additional shift associated with two-stage long duration,\n\\(\\beta_4\\) the relative shift for short duration given revision,\n\\(\\beta_5\\) the relative shift for short duration given two-stage.\n\nWe might choose to setup the design matrix so that it is orthonormal so that a-priori we don’t assign more uncertainty to a specific revision type. E.g.\n\\[\n\\mathbb{E}[Y|R,S] = \\text{expit}(\\beta_0 + \\beta_1(S - 0.5) + \\beta_2R + \\beta_3R(S-0.5) + \\beta_4R(D-0.5) + \\beta_5R(D-0.5)(S-0.5)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nIs the above missing a \\(D\\) from the conditioning?\n\n\n\nbut for simplicity, not doing this here.\nFrom the above, and with a focus on the surgical domain, we could compare (randomised comparison) any of:\n\nrevision long vs. DAIR\nrevision short vs. DAIR, but no other combinations of revision.\none-stage short + two-stage long vs. DAIR\ntwo-stage short + one-stage long vs. DAIR\n\nWhere (1) and (2) are the likely the most relevant comparisons of interest, but nothing precludes the comparisons stated in (3) and (4). The key point is the explicit statement of the duration type at which the comparison is made, which again is averaged over the empircal distribution of surgical procedure type (one-stage/two-stage).\nHowever, we always needs to marginalise over \\(S\\) (selection/plan):\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R=0] &= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1s)\\mathbb{P}(S=s|R=0) \\\\\n\\mathbb{E}[Y|R=1,D=0] &= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1s + \\beta_2 + \\beta_3s)\\mathbb{P}(S=s|R=1,D=0) \\\\\n\\mathbb{E}[Y|R=1,D=1] &= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1s + \\beta_2 + \\beta_3s + \\beta_4 + \\beta_5s)\\mathbb{P}(S=s|R=1,D=1)\n\\end{aligned}\n\\]\nAgain, can alternatively consider the average conditional log-odds ratio\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S,D)}{\\text{odds}(Y|R=0,S,D)}|D_0,D_1\\right] &= \\beta_2+\\beta_3\\mathbb{E}[S] + \\beta_4D_0 + \\beta_5D_1\\mathbb{E}[S]\n\\end{aligned}\n\\]\nwhere I’ve made it explicit that \\(D_0\\) (one-stage short) and \\(D_1\\) (two-stage short) may differ. However, in practice, these would likely be set to the same level.\nThe default data generating mechanism has the functional form:\n\\[\n\\mathbb{E}[Y|R,S,D] = \\text{expit}(\\beta_0 + \\beta_1X + \\beta_1S + \\beta_2R + \\beta_3RS + \\beta_4RD + \\beta_5RSD)\n\\]\nspecified with non-zero effects on all terms.\n\n\nGenerate duration data\ngenerate_data_2 &lt;- function(\n    n = 1000000,\n    f = function(x, r, s, d){ -1 + x + s + r + 0.5 * r * s - 0.5 * r * d - 0.25 * r * s * d}) {\n  x &lt;- rbinom(n, 1, 0.25)\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  a &lt;- r * (s + 1)\n  d &lt;- as.numeric((a &gt; 0) * rbinom(n, 1, 0.5))\n  y0 &lt;- rbinom(n, 1, plogis(f(x, 0, s, 0)))\n  y10 &lt;- rbinom(n, 1, plogis(f(x, 1, s, 0)))\n  y11 &lt;- rbinom(n, 1, plogis(f(x, 1, s, 1)))\n  y &lt;- (1 - r) * y0 + r * ((1 - d) * y10 + d * y11)\n  D &lt;- data.table(x = x, r = r, s = s, a = a, d = d, y0 = y0, y10 = y10, y11 = y11, y = y)[\n    ,\n    `:=`(\n      a1d1 = as.numeric(a == 1 & d == 1),\n      a2d1 = as.numeric(a == 2 & d == 1),\n      r_fac = factor(r),\n      a_fac = factor(a),\n      s_fac = factor(s),\n      a_cen = r * (a - 1 - mean(a[r == 1] - 1)),\n      s_cen = s - mean(s),\n      s_ort = s - 0.5\n    )\n  ]\n}\nset.seed(1246)\nD &lt;- generate_data_2(f = function(x, r, s, d){ -1 + s + x})\nfit2 &lt;- glm(y ~ x + r + r:s + r:d + r:s:d, data = D, family = binomial())\nfit2s &lt;- glm(y ~ x + s + r + r:s + r:d + r:s:d, data = D, family = binomial())\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nIn the following examples estimation under null effects is considered wherein the true data generation mechanism was \\(\\mathbb{E}[Y|S,X] = \\text{expit}(-1 + S + X)\\). That is, where there are no treatment effects in either the surgical or duration domains.\nThe estimates use G-computation. Specifically, all of the following average over all terms bar the comparison of interest.\n\n\n\n\n\nRevision vs. DAIR\n# Revision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %\n    r ln(odds(1) / odds(0)) -0.00856    0.00410 -2.09   0.0370 4.8 -0.0166\n    r ln(odds(1) / odds(0)) -0.00836    0.00406 -2.06   0.0396 4.7 -0.0163\n    97.5 %\n -0.000515\n -0.000400\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\nRevision (long) vs. DAIR and Revision (short) vs. DAIR\n# Revision (long) vs. DAIR and Revision (short) vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = \"d\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = \"d\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %\n    r ln(odds(1) / odds(0)) 0 -0.00864    0.00473 -1.83   0.0676 3.9 -0.0179\n    r ln(odds(1) / odds(0)) 1 -0.00832    0.00473 -1.76   0.0785 3.7 -0.0176\n    r ln(odds(1) / odds(0)) 0 -0.00863    0.00469 -1.84   0.0658 3.9 -0.0178\n    r ln(odds(1) / odds(0)) 1 -0.00755    0.00469 -1.61   0.1074 3.2 -0.0167\n   97.5 %\n 0.000627\n 0.000949\n 0.000562\n 0.001641\n\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nConditional on X\n# Conditional on X\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d x Estimate Std. Error      z Pr(&gt;|z|)    S\n    r ln(odds(1) / odds(0)) 0 0  0.00267    0.00493  0.541   0.5884  0.8\n    r ln(odds(1) / odds(0)) 0 1 -0.04726    0.00496 -9.525   &lt;0.001 69.0\n    r ln(odds(1) / odds(0)) 1 0  0.00270    0.00493  0.547   0.5842  0.8\n    r ln(odds(1) / odds(0)) 1 1 -0.04602    0.00496 -9.277   &lt;0.001 65.6\n    r ln(odds(1) / odds(0)) 0 0 -0.00895    0.00490 -1.829   0.0675  3.9\n    r ln(odds(1) / odds(0)) 0 1 -0.00909    0.00494 -1.841   0.0656  3.9\n    r ln(odds(1) / odds(0)) 1 0 -0.00822    0.00489 -1.680   0.0930  3.4\n    r ln(odds(1) / odds(0)) 1 1 -0.00667    0.00494 -1.350   0.1771  2.5\n    2.5 %    97.5 %\n -0.00700  0.012332\n -0.05699 -0.037538\n -0.00696  0.012360\n -0.05575 -0.036301\n -0.01855  0.000643\n -0.01878  0.000588\n -0.01782  0.001370\n -0.01635  0.003014\n\nColumns: term, contrast, d, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs Long (one-stage) and short vs. long (two-stage)\n# Short vs Long (one-stage) and short vs. long (two-stage)\nrbind(\n  avg_comparisons(fit2, variables = \"d\", by = \"s\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"d\", by = \"s\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast s Estimate Std. Error      z Pr(&gt;|z|)   S    2.5 %\n    d ln(odds(1) / odds(0)) 0  0.00603    0.00491  1.228    0.220 2.2 -0.00359\n    d ln(odds(1) / odds(0)) 1 -0.00174    0.00330 -0.528    0.597 0.7 -0.00821\n    d ln(odds(1) / odds(0)) 0  0.00664    0.00538  1.234    0.217 2.2 -0.00390\n    d ln(odds(1) / odds(0)) 1 -0.00176    0.00333 -0.527    0.598 0.7 -0.00829\n  97.5 %\n 0.01565\n 0.00472\n 0.01718\n 0.00478\n\nColumns: term, contrast, s, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs long conditional on x\n# Short vs long conditional on x\navg_comparisons(fit2, variables = \"d\", by = c(\"s\", \"x\"), comparison = \"lnoravg\")\n\n\n\n Term              Contrast s x Estimate Std. Error      z Pr(&gt;|z|)   S\n    d ln(odds(1) / odds(0)) 0 0  0.00599    0.00488  1.228    0.220 2.2\n    d ln(odds(1) / odds(0)) 0 1  0.00712    0.00580  1.228    0.220 2.2\n    d ln(odds(1) / odds(0)) 1 0 -0.00184    0.00349 -0.528    0.597 0.7\n    d ln(odds(1) / odds(0)) 1 1 -0.00172    0.00326 -0.528    0.597 0.7\n    2.5 %  97.5 %\n -0.00357 0.01555\n -0.00425 0.01850\n -0.00868 0.00499\n -0.00812 0.00467\n\nColumns: term, contrast, s, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nAnd now consider estimation under effects for all surgery and duration.\n\n\n\n\n\nData generation assuming effects in both domains\nD &lt;- generate_data_2()\nfit2 &lt;- glm(y ~ x + r + r:s + r:d + r:s:d, data = D, family = binomial())\nfit2s &lt;- glm(y ~ x + s + r + r:s + r:d + r:s:d, data = D, family = binomial())\n\n\n\n\nRevision vs. DAIR\n# Revision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))     1.03    0.00427 240   &lt;0.001 Inf  1.02   1.03\n    r ln(odds(1) / odds(0))     1.03    0.00423 243   &lt;0.001 Inf  1.02   1.03\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\nRevision (long) vs. DAIR and Revision (short) vs. DAIR\n# Revision (long) vs. DAIR and Revision (short) vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = \"d\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = \"d\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0)) 0    1.184    0.00518 228   &lt;0.001 Inf 1.174  1.194\n    r ln(odds(1) / odds(0)) 1    0.607    0.00482 126   &lt;0.001 Inf 0.598  0.617\n    r ln(odds(1) / odds(0)) 0    1.184    0.00515 230   &lt;0.001 Inf 1.174  1.194\n    r ln(odds(1) / odds(0)) 1    0.607    0.00478 127   &lt;0.001 Inf 0.598  0.616\n\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nConditional on X\n# Conditional on X\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d x Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 %\n    r ln(odds(1) / odds(0)) 0 0    1.239    0.00532 233   &lt;0.001 Inf 1.228\n    r ln(odds(1) / odds(0)) 0 1    1.153    0.00554 208   &lt;0.001 Inf 1.142\n    r ln(odds(1) / odds(0)) 1 0    0.645    0.00499 129   &lt;0.001 Inf 0.635\n    r ln(odds(1) / odds(0)) 1 1    0.573    0.00510 112   &lt;0.001 Inf 0.563\n    r ln(odds(1) / odds(0)) 0 0    1.230    0.00528 233   &lt;0.001 Inf 1.219\n    r ln(odds(1) / odds(0)) 0 1    1.191    0.00554 215   &lt;0.001 Inf 1.180\n    r ln(odds(1) / odds(0)) 1 0    0.635    0.00495 128   &lt;0.001 Inf 0.625\n    r ln(odds(1) / odds(0)) 1 1    0.610    0.00509 120   &lt;0.001 Inf 0.600\n 97.5 %\n  1.249\n  1.163\n  0.655\n  0.583\n  1.240\n  1.202\n  0.645\n  0.620\n\nColumns: term, contrast, d, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs Long (one-stage) and short vs. long (two-stage)\n# Short vs Long (one-stage) and short vs. long (two-stage)\nrbind(\n  avg_comparisons(fit2, variables = \"d\", by = \"s\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"d\", by = \"s\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast s Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %\n    d ln(odds(1) / odds(0)) 0   -0.235    0.00504 -46.6   &lt;0.001 Inf -0.245\n    d ln(odds(1) / odds(0)) 1   -0.264    0.00295 -89.7   &lt;0.001 Inf -0.270\n    d ln(odds(1) / odds(0)) 0   -0.242    0.00520 -46.6   &lt;0.001 Inf -0.252\n    d ln(odds(1) / odds(0)) 1   -0.277    0.00309 -89.7   &lt;0.001 Inf -0.283\n 97.5 %\n -0.225\n -0.258\n -0.232\n -0.271\n\nColumns: term, contrast, s, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs long conditional on x\n# Short vs long conditional on x\navg_comparisons(fit2, variables = \"d\", by = c(\"s\", \"x\"), comparison = \"lnoravg\")\n\n\n\n Term              Contrast s x Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %\n    d ln(odds(1) / odds(0)) 0 0   -0.246    0.00527 -46.6   &lt;0.001 Inf -0.256\n    d ln(odds(1) / odds(0)) 0 1   -0.243    0.00523 -46.5   &lt;0.001 Inf -0.253\n    d ln(odds(1) / odds(0)) 1 0   -0.286    0.00319 -89.7   &lt;0.001 Inf -0.292\n    d ln(odds(1) / odds(0)) 1 1   -0.212    0.00241 -87.9   &lt;0.001 Inf -0.217\n 97.5 %\n -0.235\n -0.233\n -0.280\n -0.207\n\nColumns: term, contrast, s, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#other-domains",
    "href": "notebooks/design-notes-01.html#other-domains",
    "title": "Identification of effects",
    "section": "Other Domains",
    "text": "Other Domains\nThe desire for a single model is incorporation of multiple silos and domains. Suppose we introduce the antibiotic type (rifampicin) domain, which is denoted by \\(F\\). Assume everyone were eligible. Our base model would be\n\\[\n\\mathbb{E}[Y|R,S,D,F] = \\text{expit}(\\beta_0 + \\beta_1S + \\beta_2R + \\beta_3RS + \\beta_4RD + \\beta_5RDS + \\beta_6F)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\n\\(\\beta_2\\) is now the shift for revision (under long duration irrespective of surgical type)\n\n\n\n\n\nGenerate rifampicin data\ngenerate_data_3 &lt;- function(\n    n = 1000000,\n    g = function(x, r, s, d, f){ -1 + x + s + r + 0.5 * r * s - 0.25 * r * d - 0.15 * r * s * d + 0.2 * f}) {\n  x &lt;- rbinom(n, 1, 0.25)\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  f &lt;- rbinom(n, 1, 0.5)\n  a &lt;- r * (s + 1)\n  d &lt;- as.numeric((a &gt; 0) * rbinom(n, 1, 0.5))\n  y &lt;- rbinom(n, 1, plogis(g(x, r, s, d, f)))\n  D &lt;- data.table(x = x, r = r, s = s, a = a, d = d, f = f, y = y)\n}\nset.seed(1246)\nD &lt;- generate_data_3()\nfit2 &lt;- glm(y ~ x + r + f + r:s + r:d + r:s:d, data = D, family = binomial())\nfit2s &lt;- glm(y ~ x + s + r + f + r:s + r:d + r:s:d, data = D, family = binomial())\n\n\n\n\nRevision vs. DAIR\n# Revision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))      1.1    0.00441 250   &lt;0.001 Inf   1.1   1.11\n    r ln(odds(1) / odds(0))      1.1    0.00437 253   &lt;0.001 Inf   1.1   1.11\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nRevision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\")\n)\n\n\n\n Term              Contrast Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))      1.1    0.00441 250   &lt;0.001 Inf   1.1   1.11\n    r ln(odds(1) / odds(0))      1.1    0.00437 253   &lt;0.001 Inf   1.1   1.11\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\nRevision vs. DAIR conditional\n# Revision vs. DAIR conditional\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = c(\"f\", \"x\", \"d\"), comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = c(\"f\", \"x\", \"d\"), comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast f x d Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 %\n    r ln(odds(1) / odds(0)) 0 0 0    1.245    0.00542 230   &lt;0.001 Inf 1.234\n    r ln(odds(1) / odds(0)) 0 0 1    0.945    0.00519 182   &lt;0.001 Inf 0.935\n    r ln(odds(1) / odds(0)) 0 1 0    1.159    0.00561 206   &lt;0.001 Inf 1.148\n    r ln(odds(1) / odds(0)) 0 1 1    0.861    0.00532 162   &lt;0.001 Inf 0.850\n    r ln(odds(1) / odds(0)) 1 0 0    1.225    0.00543 226   &lt;0.001 Inf 1.215\n    r ln(odds(1) / odds(0)) 1 0 1    0.926    0.00518 179   &lt;0.001 Inf 0.916\n    r ln(odds(1) / odds(0)) 1 1 0    1.145    0.00567 202   &lt;0.001 Inf 1.134\n    r ln(odds(1) / odds(0)) 1 1 1    0.852    0.00537 158   &lt;0.001 Inf 0.841\n    r ln(odds(1) / odds(0)) 0 0 0    1.232    0.00538 229   &lt;0.001 Inf 1.222\n    r ln(odds(1) / odds(0)) 0 0 1    0.931    0.00515 181   &lt;0.001 Inf 0.921\n    r ln(odds(1) / odds(0)) 0 1 0    1.192    0.00560 213   &lt;0.001 Inf 1.181\n    r ln(odds(1) / odds(0)) 0 1 1    0.896    0.00531 169   &lt;0.001 Inf 0.886\n    r ln(odds(1) / odds(0)) 1 0 0    1.221    0.00539 227   &lt;0.001 Inf 1.210\n    r ln(odds(1) / odds(0)) 1 0 1    0.922    0.00514 179   &lt;0.001 Inf 0.912\n    r ln(odds(1) / odds(0)) 1 1 0    1.188    0.00569 209   &lt;0.001 Inf 1.177\n    r ln(odds(1) / odds(0)) 1 1 1    0.894    0.00538 166   &lt;0.001 Inf 0.883\n 97.5 %\n  1.256\n  0.955\n  1.170\n  0.871\n  1.236\n  0.936\n  1.156\n  0.862\n  1.243\n  0.941\n  1.203\n  0.907\n  1.231\n  0.932\n  1.200\n  0.905\n\nColumns: term, contrast, f, x, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nRevision (long) vs. DAIR and Revision (short) vs. DAIR\n# Revision (long) vs. DAIR and Revision (short) vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = \"d\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = \"d\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0)) 0    1.182    0.00528 224   &lt;0.001 Inf 1.171  1.192\n    r ln(odds(1) / odds(0)) 1    0.889    0.00502 177   &lt;0.001 Inf 0.879  0.899\n    r ln(odds(1) / odds(0)) 0    1.182    0.00525 225   &lt;0.001 Inf 1.171  1.192\n    r ln(odds(1) / odds(0)) 1    0.890    0.00499 178   &lt;0.001 Inf 0.880  0.899\n\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nRifampicin vs not\n# Rifampicin vs not\nrbind(\n  avg_comparisons(fit2, variables = \"f\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"f\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    f ln(odds(1) / odds(0))    0.168    0.00387 43.4   &lt;0.001 Inf 0.161  0.176\n    f ln(odds(1) / odds(0))    0.168    0.00382 44.0   &lt;0.001 Inf 0.160  0.175\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\nShort vs Long (one-stage) and short vs. long (two-stage)\n# Short vs Long (one-stage) and short vs. long (two-stage)\nrbind(\n  avg_comparisons(fit2, variables = \"d\", by = \"s\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"d\", by = \"s\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast s Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 %\n    d ln(odds(1) / odds(0)) 0   -0.119    0.00505 -23.6   &lt;0.001 406.7 -0.129\n    d ln(odds(1) / odds(0)) 1   -0.121    0.00284 -42.6   &lt;0.001   Inf -0.127\n    d ln(odds(1) / odds(0)) 0   -0.120    0.00508 -23.6   &lt;0.001 407.5 -0.130\n    d ln(odds(1) / odds(0)) 1   -0.129    0.00302 -42.6   &lt;0.001   Inf -0.134\n 97.5 %\n -0.109\n -0.115\n -0.110\n -0.123\n\nColumns: term, contrast, s, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs long conditional on x\n# Short vs long conditional on x\navg_comparisons(fit2, variables = \"d\", by = c(\"s\", \"x\"), comparison = \"lnoravg\")\n\n\n\n Term              Contrast s x Estimate Std. Error     z Pr(&gt;|z|)     S\n    d ln(odds(1) / odds(0)) 0 0  -0.1250    0.00530 -23.6   &lt;0.001 406.9\n    d ln(odds(1) / odds(0)) 0 1  -0.1210    0.00513 -23.6   &lt;0.001 406.4\n    d ln(odds(1) / odds(0)) 1 0  -0.1309    0.00307 -42.6   &lt;0.001   Inf\n    d ln(odds(1) / odds(0)) 1 1  -0.0946    0.00223 -42.4   &lt;0.001   Inf\n   2.5 %  97.5 %\n -0.1354 -0.1146\n -0.1310 -0.1109\n -0.1370 -0.1249\n -0.0989 -0.0902\n\nColumns: term, contrast, s, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#silos",
    "href": "notebooks/design-notes-01.html#silos",
    "title": "Identification of effects",
    "section": "Silos",
    "text": "Silos\nThe above has considered the late-acute silo in isolation. Suppose we also had a chronic silo with the same limitations: randomise to DAIR vs. revision, then revision type is determined by the surgeon/patient, duration is randomised. In the new setting, nothing really changes, we can just introduce silo-specific parameters.\nFor lack of letters, let \\(G\\) denote group (silo). Then\n\\[\n\\mathbb{E}[Y|G=g,R,S,D] = \\text{expit}(\\beta_{0,g} + \\beta_{1,g}R + \\beta_{2,g}S + \\beta_{3,g}RS + \\beta_{4,g}RD + \\beta_{5,g}RSD + \\gamma_g^\\mathsf{T}X)\n\\]\nWe might choose to assume that some of the conditional effects are equal across groups. E.g. \\(\\gamma_g=\\gamma\\) for all \\(g\\). Or \\(\\beta_{4,g} = \\beta_4\\) and \\(\\beta_{5,g}=\\beta_5\\). Depends how realistic we think these assumptions may be and whether we have sufficient data to meaningfully estimate silo-specific effects.\nPerhaps the only new issue is that now \\(\\mathbb{P}(S=s|G=1)\\ne\\mathbb{P}(S=s|G=2)\\), so need to weight things within silo.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe other thing to consider here is that in the early silo, there is no information contributed to parameters characterising the surgical intervention effects. I am not sure that the above model addresses this in that \\(\\beta_{1,g}\\) for \\(g = early\\) would not be defined.",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#revision-type",
    "href": "notebooks/design-notes-01.html#revision-type",
    "title": "Identification of effects",
    "section": "Revision Type",
    "text": "Revision Type\nIn all the above I’ve been assuming that the revision type, \\(S\\), is an attribute of the patient. E.g. all surgeons would choose the same \\(S\\) for the same patient. More realistically, \\(S\\) might also partly depend on the surgeon (e.g. say a surgeon would choose \\(S=1\\) for all patients, but another would choose \\(S=0\\) for all patients, now \\(S\\) is conditional on the surgeon rather than the patient). Assume \\(S\\) is an attribute of the patient/surgeon combination rather than either alone. Do we need to change anything? How to interpret “revision effect”? An average effect over patients and surgeons?\nAlready expect that we should at least condition on the site/surgeon, but do we need anything extra to account for \\(S\\)? Distribution of \\(S\\) conditional on surgeon?",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#randomisation-reveal",
    "href": "notebooks/design-notes-01.html#randomisation-reveal",
    "title": "Identification of effects",
    "section": "Randomisation reveal",
    "text": "Randomisation reveal\nA number of simplifying assumptions have been made that result in an incomplete representation of the design. For example, at the start of the discussion on the duration domain, we assumed that duration is randomised, but depends on both \\(R\\) and \\(S\\). However, note:\n\n\\(R\\) presupposes eligibility and reveal for the surgical domain, which is not the general case, e.g. early stage infection silo.\nPatients may enter into the study without having being entered for a randomised comparison in the surgical domain (e.g. patients with early stage infection) in which case the allocated surgery (\\(R_A\\)) would have been determined entirely by clinician selection.\nPatients enter into the duration domain based on the surgical procedure that occurred. This is expected to usually align with the allocated procedure \\(R_A\\), but may deviate from that.\n\\(D\\) is random, conditional solely on \\(R_P\\) rather than both \\(R\\) and \\(S_{R_A}\\) (as stated in the duration section).\n\\(D\\) exists only for \\(R_P \\in \\{\\text{one-stage}, \\text{two-stage}\\}\\) otherwise reveal never occurs and duration allocated \\(D_A\\) is determined by clinician selection\nWhile the duration domain for one-stage and two-stage both contain long (reference) vs short levels for duration of antibiotic, the levels are distinct for each procedure.\n\nTo incorporate some of these ideas, start with the following definitions:\n\n\\(E_R\\) reveal for surgical domain - 0: no, 1: yes\n\\(E_D\\) reveal for duration domain - 0: no, 1: yes\n\\(E_F\\) reveal for choice domain - 0: no, 1: yes\n\\(R\\) randomised surgery - 0: DAIR, 1: revision\n\\(S_R\\) revision type preference (pre-randomisation) - 0: DAIR, 1: one-stage, 2: two-stage\n\\(R_A\\) allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\n\\(R_P\\) performed surgery - 0: DAIR, 1: revision\n\\(S_{R_P}\\) revision type performed (post-randomisation) - 0: one-stage, 1: two-stage\n\\(D\\) randomised duration - 0: long, 1: short\n\\(D_A\\) allocated duration - 0: long, 1: short, 2: other\n\\(S_D\\) selected duration - 0: long, 1: short, 2: other\n\\(F\\) randomised choice - 0: norif, 1: rif\n\\(F_A\\) allocated choice - 0: norif, 1: rif, 2: other\n\\(S_F\\) selected choice - 0: norif, 1: rif, 2: other\n\\(Y\\) treatment success - 0: no, 1: yes\n\nIn practice, we expect the allocated \\(R_A\\) and actual \\(R_P\\) surgical procedure performed will align, but in some cases they may not.\nContrived) example one: revision was randomised and the original surgeon only performs two-stage revision. The original surgeon becomes unavailable to do the procedure and another surgeon (who only performs one-stage revision) takes over the case. The patient enters into the duration domain for comparisons within the setting of one-stage revision.\nContrived) example two: revision was randomised and the surgeon intends to perform a two-stage revision. On the operating table, the surgeon switches to dair, for unknown reasons and the patient will no longer enter into randomised comparisons for the duration domain.\n\\(R_A\\) (allocation) is now determined by additional variables:\n\\[\nR_A = (1-E_R) S_R + E_R R S_R\n\\]\nso that when we have no revealed randomisation for the surgical domain, \\(R_A\\) aligns with the preferred procedure out of all those possible (dair, one-stage, two-stage). When randomisation revealed for the surgical domain, the first term disappears and for \\(R = 0\\), the allocation is dair, irrespective of preferred surgery, whereas when \\(R = 1\\) we get whatever one of one-stage (\\(S_R = 1\\)) or two-stage (\\(S_R = 2\\)) is preferred.\nFor duration allocated \\(D_A\\):\n\\[\nD_A = (1-E_D) S_D + E_D D\n\\]\nwhen no reveal, \\(E_D = 1\\) and \\(D_A = S_D\\) (long/short/other duration) and when revealed, \\(D_A = D\\) (long/short duration).\nFor choice allocated \\(F_A\\):\n\\[\nF_A = (1 - E_F) S_F + E_F F\n\\]\nwhen no reveal, \\(F_A = S_F\\) (norif/rif/other) and when revealed, \\(F_A = F\\) (norif/rif).\n\n\n\n\n\n\nNote\n\n\n\n\n\nAbove, I am assuming that you can randomise someone within a domain without first assessing their eligibility status or knowing anything about them other than they want to enter the platform, which I believe is the intention. Randomisation is only revealed if eligibility is confirmed and this process is independent to the randomisation process.\n\n\n\nThe edited DAG is shown below, which still has a number of simplications relative to the intended approach but is intended to represent a generalised silo and site of infection, implicitly acknowledging that the outcome will be dependent on both these factors. Patients may contribute to some or all domains, which influences the treatment regimen (combination of treatments across the domains) they receive and which suggests the various causal effects that are identifiable.\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  ER(E&lt;sub&gt;R) --&gt; RA(R&lt;sub&gt;A) \n  ER --&gt; SR(S&lt;sub&gt;R)\n  ED(E&lt;sub&gt;D) --&gt; DA(D&lt;sub&gt;A) \n  SR --&gt; RA \n  SD(S&lt;sub&gt;D) --&gt; DA \n  R --&gt; RA\n  RA --&gt; RP(R&lt;sub&gt;P) \n  SRP(S&lt;sub&gt;R&lt;sub&gt;P) --&gt; RP\n  RA --&gt; Y\n  RP --&gt; ED\n  D --&gt; DA(D&lt;sub&gt;A)\n  DA --&gt; Y\n  F --&gt; FA(F&lt;sub&gt;A)\n  EF(E&lt;sub&gt;F) --&gt; FA\n  SF(S&lt;sub&gt;F) --&gt; FA \n  FA --&gt; Y\n  UER((U&lt;sub&gt;E&lt;sub&gt;R)) -.-&gt; ER\n  UED((U&lt;sub&gt;E&lt;sub&gt;D)) -.-&gt; ED\n  UEF((U&lt;sub&gt;E&lt;sub&gt;F)) -.-&gt; EF\n  UF((U&lt;sub&gt;F)) -.-&gt; F\n  URP((U&lt;sub&gt;R&lt;sub&gt;P)) -.-&gt; SRP\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  USR((U&lt;sub&gt;S&lt;sub&gt;R)) -.-&gt; SR\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  USD((U&lt;sub&gt;S&lt;sub&gt;D)) -.-&gt; SD\n  USF((U&lt;sub&gt;S&lt;sub&gt;F)) -.-&gt; SF\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 6: Scenario 4, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThere is potentially a direct as well as the indirect effect of both \\(S_R\\) on \\(Y\\) and \\(S_{R_P}\\) on \\(Y\\) but these have been left out of the DAG for now. \\(S_R\\) is actually representing multiple ideas:\n\nwhen the surgical domain is not applicable (randomisation never revealed) e.g. for the chronic patients, then \\(S_R\\) is the selection from dair, one-stage, two-stage\nwhen surgical domain is applicable (randomisation is revealed) then \\(S_R\\) is the option between one-stage and two-stage that is most prefered.\n\nIn essence, \\(S_R\\) involves a conditional ranking of which surgical procedure is prefered.\nFor example, say the selection is: dair, two-stage, one-stage in order of preference. If randomisation is not reveal, dair is would be the selection. If randomisation is revealed, two-stage would be as it is the most prefered surgical procedure applicable to revision.\nOriginally, \\(D\\) was said to depend on some of the selection elements. However, subsequently it was decided that \\(D\\) (long/short) should be viewed like all other randomisation processes, i.e. independent of all other nodes, but is only manifest through \\(D_A\\) for certain surgery types.\n\n\n\nAgain consider intervening on surgical procedure whereby we are interested in the effect of dair vs revision on treatment success. There are no open backdoor paths apparent and therefore no adjustment is required to identify the total effect of \\(R\\) on \\(Y\\). Similarly, neither \\(D\\) nor \\(F\\) have backdoor paths.\nPostulate the following model:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|L; \\beta] &=  \\text{expit}( \\beta_0 + \\\\\n  &\\quad \\beta_1 \\mathbb{I}[G = 1] + \\beta_2 \\mathbb{I}[G = 2] + \\beta_3 J + \\\\\n  &\\quad \\beta_4 J \\mathbb{I}[G = 1] + \\beta_5 J \\mathbb{I}[G = 2] + \\\\\n  &\\quad \\beta_6 \\mathbb{I}(1-E_R) + ([\\beta_7 R + \\beta_8 R \\mathbb{I}(S_{R_P} = 2) ])\\mathbb{I}(E_R) + \\\\\n  &\\quad \\beta_9 \\mathbb{I}(1-E_D) + ([\\beta_{10} R_P D + \\beta_{11} R_P D \\mathbb{I}(S_{R_P} = 2)])\\mathbb{I}(E_D) + \\\\\n  &\\quad \\beta_{12} \\mathbb{I}(1-E_F) + \\beta_{13} F E_F )\n\\end{aligned}\n\\]\nwhere the \\(L\\) stands for the set of model variables and \\(\\beta\\) the vector of parameters. The following describe the reference/movements in the log-odds of treatment success:\n\n\\(\\beta_{0}\\) baseline log-odds of treatment success in the early silo / knee site\n\\(\\beta_{1}\\) shift for late-silo membership relative to early\n\\(\\beta_{2}\\) shift for chronic-silo membership relative to early\n\\(\\beta_{3}\\) shift for hip\n\\(\\beta_{4}\\) relative shift for late-silo membership with hip\n\\(\\beta_{5}\\) relative shift for chronic-silo membership with hip\n\\(\\beta_{6}\\) shift under non-reveal (surgery1)\n\\(\\beta_{7}\\) shift under revision that was performed with one-stage procedure for long duration and no-rif\n\\(\\beta_{8}\\) relative shift under revision that was performed with two-stage procedure for long duration and no-rif\n\\(\\beta_{9}\\) shift under non-reveal (duration) with no differentiation for surgical nor duration preference\n\\(\\beta_{10}\\) shift for short duration when one-stage was actually performed\n\\(\\beta_{11}\\) shift for short duration when two-stage was actually performed\n\\(\\beta_{12}\\) shift under non-reveal (choice) with no differentiation for choice preference\n\\(\\beta_{13}\\) shift for rif\n\nWith the complicating factor being that the surgical allocation may inform the type of surgery that the patient gets (but may deviate) and the randomisation that the patient is revealed to in the duration domain is determined by what surgical intervention the patient actually got.\nWe replace pre-randomised preference for surgical type with post-randomised surgical type performed and marginalise out this term.\n\n\n\n\n\n\nNote\n\n\n\n\n\nFull disclosure, I am not entirely sure as to whether the above addresses the full impacts of deviations between allocated and performed surgery or whether the DAG is sufficiently complete representation of the dependencies.\n\n\n\nAs previously, for the surgical domain, we are interested the effect of intervening on \\(R\\). For the duration domain, we are interested in the effect of intervening on \\(D|R_P\\). For the choice domain, we are interested in the effect of intervening on \\(F\\).\n\n\n\n\n\n\nNote\n\n\n\n\n\nNote that for the following specification, the design matrix can become singular (linear dependence between some of the variables) e.g. if surgical reveal is equivalent to silo membership. I am assuming some small amount of noise in reveal such that this isn’t a problem.\n\n\n\n\n\nGenerate complete data\ngenerate_data_4 &lt;- function(\n    n = 1e6,\n    g = function(p_a, l1, l2, j, er, ed, ef, r, rp, d, srp, f){ \n      -1 + -0.04 * l1 - 0.07 * l2 - 0.02 * j - 0.01 * l1 * j - 0.06 * l2 * j +\n        -0.1*(1-er) + (0.2*r + 0.4*r*(srp==2))*(er) +\n        -0.05*(1-ed) + (0.4*rp*d + 0.1*rp*d*(srp==2))*(ed) +\n        -0.25*(1-ef) + 0.15*f*(ef) \n      }\n    ) {\n  \n  p_a = array(\n    c(0.65, 0.55, 0.6, 0.75, 0.6, 0.65),\n    dim = c(3, 2), dimnames = list(c(\"early\", \"late\", \"chronic\"),c(\"knee\", \"hip\")))\n  \n  # silo (l) and joint (j)\n  l &lt;- sample(0:2, n, replace = T, prob = c(0.3, 0.5, 0.2)) \n  l1 = as.numeric(l == 1)\n  l2 = as.numeric(l == 2)\n  \n  p_j &lt;- array(c(0.4,0.7,0.5,0.6,0.3,0.5), dim = c(3, 2), \n               dimnames = list(c(\"early\", \"late\", \"chronic\"), c(\"knee\", \"hip\")))\n  j &lt;- rbinom(n, 1, p_j[l+1, 2])\n  # reveal for late only, with a small number who never get revealed even if they\n  # were in late. you can leave this out but the model spec will need to be updated\n  # because there will be linearly depenedent cols in the design matrix\n  er &lt;- as.numeric(l == 1)\n  er[l==1][as.logical(rbinom(er[l==1], 1, 0.05))] &lt;- 0\n  # randomise dair vs rev\n  r &lt;- rbinom(n, 1, 0.5)\n  # (approx) 70% chance of clinician choosing two-stage if pt is rand to revision \n  sr &lt;- numeric(n)\n  sr[r == 0] &lt;- sample(0:2, sum(r == 0), replace = T, prob = c(0.2, 0.2, 0.6))\n  sr[r == 1] &lt;- sample(1:2, sum(r == 1), replace = T, prob = c(0.3, 0.7))\n  # pref towards two-stage, assuming revision\n  sra &lt;- as.numeric(sr == 2)\n  # determine allocation of surgery type\n  ra &lt;- er * sr + (1-er) * r * (sr) \n  \n  # 10% of the allocated treatments may have switch to a different surg type\n  srp &lt;- ra\n  ic &lt;- rbinom(n, 1, 0.1)\n  srp[as.logical(ic)] &lt;- sample(0:2, sum(ic), replace = T, prob = c(0.2, 0.2, 0.6))\n  # was the procedure type dair or revision?\n  rp &lt;- as.numeric(srp %in% 1:2)\n  \n  # non-reveal of duration if rp is dair (0)\n  ed &lt;- as.numeric(rp == 1)\n  # rand to long (0), short (1) based on surgery received\n  d &lt;- as.numeric((rp &gt; 0) * rbinom(n, 1, 0.5))\n  # 60% reveal ab choice\n  ef &lt;- rbinom(n, 1, 0.6)\n  f &lt;- as.numeric((ef == 1) * rbinom(n, 1, 0.5))\n  \n  y &lt;- rbinom(n, 1, plogis(g(p_a, l1, l2, j, er, ed, ef, r, rp, d, srp, f)))\n  # table(y, useNA = \"always\")\n  \n  D &lt;- data.table(\n    l1, l2, j, \n    er, ed, ef,\n    erx = 1-er, edx = 1-ed, efx=1-ef,\n    r, sr, sra, ra, \n    ic, rp, srp, srp2 = as.numeric(srp == 2), d,\n    f, y\n  )\n}\nset.seed(102)\nD &lt;- generate_data_4()\n\n# early silo, should be non-reveal with no r options (default to 0)\n# D[, .N, keyby = .(l, j, er, r)]\n# those who received rev are revealed for d (ed = 0) and are 0:1 conditional on revision type (srp)\n# D[, .N, keyby = .(rp, ed, srp, d)]\n# those entering ab choice should come from all strata, infec site\n# D[ef == 0, .N, keyby = .(l, j, f)]\n# those that dont should also be dist across sample\n# D[ef == 1, .N, keyby = .(l, j, f)]\n\nfit2 &lt;- glm(y ~ l1 + l2 + j + l1:j + l2:j +\n              erx + er:r + er:r:srp2 +\n              edx + ed:rp:d + ed:d:rp:srp2 +\n              efx + ef:f, \n            data = D, family = binomial())\nsummary(fit2)\n\n\n\nCall:\nglm(formula = y ~ l1 + l2 + j + l1:j + l2:j + erx + er:r + er:r:srp2 + \n    edx + ed:rp:d + ed:d:rp:srp2 + efx + ef:f, family = binomial(), \n    data = D)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.992730   0.017361 -57.182  &lt; 2e-16 ***\nl1           -0.036997   0.016251  -2.277  0.02281 *  \nl2           -0.081398   0.009886  -8.234  &lt; 2e-16 ***\nj            -0.028103   0.008548  -3.288  0.00101 ** \nerx          -0.101703   0.015480  -6.570 5.04e-11 ***\nedx          -0.045398   0.006282  -7.227 4.94e-13 ***\nefx          -0.251435   0.005446 -46.167  &lt; 2e-16 ***\nl1:j         -0.022724   0.010840  -2.096  0.03605 *  \nl2:j         -0.052919   0.013561  -3.902 9.53e-05 ***\ner:r          0.187560   0.009727  19.283  &lt; 2e-16 ***\nef:f          0.147332   0.005624  26.198  &lt; 2e-16 ***\ner:r:srp2     0.407762   0.010375  39.302  &lt; 2e-16 ***\ned:rp:d       0.414709   0.008222  50.439  &lt; 2e-16 ***\nsrp2:ed:rp:d  0.085740   0.008749   9.800  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1216852  on 999999  degrees of freedom\nResidual deviance: 1179406  on 999986  degrees of freedom\nAIC: 1179434\n\nNumber of Fisher Scoring iterations: 4\n\n\nGenerate complete data\n# linearly_dep_cols(fit2)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nUsing g-computation to determine the marginal effects. lnor and lnoravg are used as the comparisons.\nThe first (lnor) approach (average log odds?)\n\npredicts the log-odds of treatment success for all units with the surgical approach set to revision.\npredicts the log-odds of treatment success for all units with the surgical approach set to dair.\ncomputes the difference between the response on the log odds scale and takes the mean\n\nAlso can be derived from a weigted combination of the parameters from the regression model. What is an accurate interpretation of this parameter? How would you explain it to a non-statistician?\nThe second (lnoravg) approach (marginal mean?)\n\npredicts the probability of treatment success for all units with the surgical approach set to revision and computes the mean\npredicts the probability of treatment success for all units with the surgical approach set to dair and computes the mean\nconverts the mean probability of treatment success to the log-odds scale and takes the difference\n\n\n\n\n\n\nCode\n# Revision vs. DAIR\ncmp &lt;- avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\")\n\n# avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\", by = \"er\")\n\nd_new &lt;- copy(D)\n\n# equivalent to using lnor\nd_new[, `:=`(r = 1)]\nlo1 &lt;- predict(fit2, newdata = d_new)\nd_new[, `:=`(r = 0)]\nlo0 &lt;- predict(fit2, newdata = d_new)\n\n# in this setting is equivalent to weighted combination of parameters\nb &lt;- coef(fit2)\n\nw_srp &lt;- D[er == 1, mean(srp2)]\nw_er &lt;- D[, mean(er)]\n\nrbind(\n  \"predict at r = 0/1\" = mean(lo1 - lo0),\n  \"weighting coef by er and srp (condit on reveal)\" = w_er * b[\"er:r\"] + w_er * w_srp * b[\"er:r:srp2\"] , \n  \"avg_comparisons (lnor)\" = cmp$estimate\n)\n\n\n                                                     er:r\npredict at r = 0/1                              0.2136018\nweighting coef by er and srp (condit on reveal) 0.2136018\navg_comparisons (lnor)                          0.2292898\n\n\nCode\ncmp\n\n\n\n Term              Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))    0.229    0.00314 73.1   &lt;0.001 Inf 0.223  0.235\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\nCode\n# using lnoravg\navg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\")\n\n\n\n Term              Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))    0.229    0.00314 73.1   &lt;0.001 Inf 0.223  0.235\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nCode\nd_new[, r := 1]\np1 &lt;- predict(fit2, newdata = d_new, type = \"response\")\nd_new[, r := 0]\np0 &lt;- predict(fit2, newdata = d_new, type = \"response\")\nqlogis(mean(p1)) - qlogis(mean(p0))\n\n\n[1] 0.2292898\n\n\nAnd for duration and choice.\n\n\nCode\n# Short vs Long (one-stage) and short vs. long (two-stage)\navg_comparisons(fit2, variables = \"d\", by = \"srp2\", comparison = \"lnoravg\")\n\n\n\n Term              Contrast srp2 Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 %\n    d ln(odds(1) / odds(0))    0    0.179    0.00361 49.8   &lt;0.001 Inf 0.172\n    d ln(odds(1) / odds(0))    1    0.486    0.00558 87.1   &lt;0.001 Inf 0.475\n 97.5 %\n  0.187\n  0.497\n\nColumns: term, contrast, srp2, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nCode\n# Rifampicin vs not\navg_comparisons(fit2, variables = \"f\", comparison = \"lnoravg\")\n\n\n\n Term              Contrast Estimate Std. Error    z Pr(&gt;|z|)     S  2.5 %\n    f ln(odds(1) / odds(0))   0.0894    0.00341 26.2   &lt;0.001 500.7 0.0827\n 97.5 %\n  0.096\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-01.html#footnotes",
    "href": "notebooks/design-notes-01.html#footnotes",
    "title": "Identification of effects",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe parameter ignores potential differentiation for surgical type.↩︎",
    "crumbs": [
      "Design notes",
      "Identification of effects"
    ]
  },
  {
    "objectID": "notebooks/design-notes-04.html",
    "href": "notebooks/design-notes-04.html",
    "title": "Estimands, ITT and PP",
    "section": "",
    "text": "The ICH E9(R1) addendum on estimands and sensitivity analysis in clinical trials (estimand framework) provides an alternative to the traditional approach of specifying treatment effects. A more explicit definition of the causal effect of interest is advocated, the goal being to measure how the outcome of an intervention compares to the outcome that would have happened to the same units under a different intervention. As we never see the unit level outcomes under all interventions, clinical trials employ randomisation as the structural mechanism to enable these effects to be identified. The causal aspects are therefore linked with randomised assignment rather than received treatment. It is, however, assumed that units will follow the assigned treatment and therefore, in the ideal case, the causal relationship can be extended to the actual taking of treatment. Intercurrent event (unit level events that occur after randomisation that alter the interpretation or existence of the outcome) can compromise the causal effects and thus need to be considered in the estimand definitions. The specification of the treatment regimen is critical in understanding what constitutes an IE.\nThe components of an estimand are: treatment condition, population, outcome, intercurrent event handling and summary measure. In English, these correspond to\n\ntreatment condition \\(:=\\) “what is the trial comparing?”\npopulation \\(:=\\) “what people/condition are we trying to help?”\noutcome \\(:=\\) “what is being measured?”\nie handling \\(:=\\) “how do we intend to handle treatment related events that disrupt the existence or interpretation of the outcome?” and\nsummary measure \\(:=\\) “what statistical measure is going to be used?”\n\nEven though the estimand framework never refers to it directly, it has causal inference very much in mind and therefore the notation used by the potential outcomes framework is a natural way to define the causal effects that are being targeted by the estimands.\nAs a way to give some insight into the concepts and notation implicit in the specification of an estimand, consider a simple two-arm randomised trial. The trial has units \\(i = 1 \\dots n\\) where each can be assigned to either control \\(a=0\\) or test \\(a = 1\\). Take \\(Y_i\\) to denote an observable binary response variable of interest and \\(M_i\\) to denote a binary IE such as discontinuation due to availability of treatment (\\(m=1\\) being discontinued, \\(m = 0\\) completed). We expect that the IE to encode characteristics \\(U_i\\) of the unit \\(i\\) as well as the treatment.\nLet \\(M_i(a)\\) denote the potential outcome for the IE and let \\(Y_i(a,m)\\) be the potential outcome for the response for unit \\(i\\) assigned to \\(a\\) and \\(m\\). Each unit has potential outcomes for the outcome:\n\n\\(Y(0,0)\\) the outcome under control without discontinuation\n\\(Y(0,1)\\) the outcome under control with discontinuation\n\\(Y(1,0)\\) the outcome under test without discontinuation\n\\(Y(1,1)\\) the outcome under test with discontinuation\n\nAdditionally:\n\n\\(M_i(a=1)\\) is the potential outcome for the IE when unit \\(i\\) is assigned to the test group\n\\(Y_i(a, m = 0)\\) is the potential outcome for the response when intervening intervening with \\(a\\) and \\(m=0\\) (assuming that intervening on \\(m\\) is somehow possible, i.e. it is a hypothetical world)\n\\(Y_i(a,M_i(a))\\) is the potential outcome for the response when the assigned treatment is \\(a\\) and the natural state that IE has when the assigned treatment is \\(a\\)\n\\(Y_i(a=1,M_i(a=1)=0) \\equiv Y_i(1,M_i(1)=0)\\) is the potential outcome for the response when under \\(a=1\\) for those who do not have the IE\n\nFor any given unit we can only observe one set of potential outcomes, that is if \\(i\\) is assigned to test \\(a = 1\\) then what becomes observable are \\(M_i(a=1)\\) and \\(Y_i(a=1,M(a=1)) \\equiv Y_i(a=1)\\), where the abbreviation follows from the composition assumption.\nA graphical representation of the study is shown below.\n\n\n\n\n\nflowchart LR\n  U --&gt; Y\n  U((\"U\")) --&gt; M\n  A((\"A\" )) --&gt; M((\"M\")) --&gt; Y((\"Y\"))\n  A --&gt; Y\n  \n  style U stroke-dasharray: 5 5\n\n\n\n\n\n\nThe ITT principle involves what units to include and what data to include on each unit. If IEs are thought of as mediators of treatment, then the ITT effect aligns with the total effect of assigned treatment, i.e. the effect of treatment through all paths. One way to implement ITT is to include all randomised units and all their outcomes ignoring post-randomisation changes in treatment, protocol violations, non-adherence etc. The implied treatment regimen is therefore the offer of the assigned treatment with potential for discontinuation of that treatment and/or the use of any other treatment at any time without restriction. Under this formulation, IEs may break the link between assignment and received treatment and this can make the results less relevant for some applications. In the estimand framework, treatment policy is aligned with ITT and under randomised treatment is identified (converted from a causal quantity to a statistical quantity) via:\n\\[\n\\begin{aligned}\n\\Delta_{ITT} &= \\mathbb{E}[Y(1)] - \\mathbb{E}[Y(0)] \\\\\n   &= \\mathbb{E}[Y(1)|A = 1] - \\mathbb{E}[Y(0) | A = 0] \\\\\n   &= \\mathbb{E}[Y|A = 1] - \\mathbb{E}[Y | A = 0] \\\\\n\\end{aligned}\n\\]\nA per-protocol analysis aims at offering a specific perspective on the trial results; the implicit goal is usually that of evaluating the effect of treatment in those that adhere to the protocol. However, a traditional per-protocol analysis simply subsets the trial data to those units that have adhered and performs the primary analysis (unchanged) on that part of the data. This is insufficient to define a causal effect.\nFirst we need to identify the relevant IEs and we need to determine how these (discontinuation, treatment switching (non-compliance), rescue medication, toxicity, AEs etc) might impact the existence or interpretation of the outcome. We should also think about how likely each of these events are and document that. Then, let’s say we are interested in the effect of received treatment when used as intended with no need for variation or additional medication or intervention. We might be able to use the hypothetical strategy here. This approach imagines an idealised world where the IE does not occur, assuming that such a counterfactual reality is possible and applicable, which isn’t always the case. For example, if the outcome were just treatment success (i.e. imagine we were not using a composite outcome) then trying to use a hypothetical strategy to address the IE of death would not make sense as it would effectively disregard the most serious consequence of the interventions. However, it may well be reasonable to use the hypothetical strategy to address an IE of extended use of some therapy beyond what is defined in the protocol.\nFor the hypothetical strategy, if we let \\(m = 0\\) represent the absence the IE, then the estimand could be specified as:\n\\[\n\\begin{aligned}\n\\Delta_{HYP} &= \\mathbb{E}[Y(1,m=0)] - \\mathbb{E}[Y(0,m=0)]\n\\end{aligned}\n\\]\nwhich is the difference in the expectations of the potential outcomes under test and control where in the hypothetical setting where no IE occurs. If we attempt to estimate this effect by subsetting the data to the cohort that did not have the IE then what we are implicitly conditioning on \\(M\\) in the above DAG and because \\(M\\) is a collider, this opens a backdoor path through \\(U\\). This means that the potential outcome \\(Y(a,m)\\) is dependent on \\(M(a)\\):\n\\[\n\\begin{aligned}\n\\Delta_{HYP} &= \\mathbb{E}[Y(1,m=0)] - \\mathbb{E}[Y(0,m=0)]  \\ne \\mathbb{E}[Y|A=1,M=0] - \\mathbb{E}[Y|A=0,M=0]\n\\end{aligned}\n\\]\nIn other words, the estimand is no longer identified and cannot be converted into a statistical quantity using such an approach, which is why the traditional per-protocol analysis does not produce a causal effect.\nThe intuition is simple - say we had placebo vs test and the IE is toxicity leading to discontinuation and this is more likely in units with severe illness. If we condition on those that did not have the IE, then we will be comparing the placebo group that has a mix of illness severities with the test group that only contains units with lower severity of disease. In other words, the groups are no longer directly comparable.\nHowever, if we do have access to \\(U\\) or some proxy for \\(U\\) then we might be able to assume conditional independence within levels of \\(U\\), i.e. \\(Y(a,m) \\perp M(a) | U\\). This gives us a way to estimate the direct effect of treatment, which is effect solely due to the intervention. With \\(U\\) we can identify the estimand:\n\\[\n\\begin{aligned}\n\\Delta_{HYP} &= \\mathbb{E}[Y(1,m=0)] - \\mathbb{E}[Y(0,m=0)]  \\\\\n   &= \\sum_\\mathcal{U} \\mathbb{E}[Y | U = u, M = 0, A = 1]Pr(U = u) - \\sum_\\mathcal{U} \\mathbb{E}[Y | U = u, M = 0, A = 0]Pr(U = u)\n\\end{aligned}\n\\]\nand so we can produce an estimate of the causal effect of the hypothetical situation where the IE does not occur. Of course, this still comes at the cost of assumptions that we cannot entirely verify and we therefore need to be cautious in the reporting. There are also other ways that we might approach this.\nBelow is a simple simulation to show the difference between the ITT, the naive per protocol approach and the hypothetical estimand obtained from standardisation over the distribution of \\(U\\). It assumes the following setup\n\\[\n\\begin{aligned}\nU_i &\\sim \\text{Bernoulli}(0.35) \\\\\nA_i &\\sim \\text{Bernoulli}(0.5) \\\\\n\\pi_{m(i)} &= 0.05 + 0.15 A + 0.3 AU \\\\\nM_i &\\sim \\text{Bernoulli}(\\pi_{m(i)}) \\\\\n\\pi_{y(i)} &= 0.5 + 0*a - 0.35*u  \\\\\nY_i &\\sim \\text{Bernoulli}(\\pi_{y(i)}) \\\\\n\\end{aligned}\n\\]\nwhere the probability of the risk factor \\(U\\) is 35% in the population, the interventions are randomised 1:1, the occurrence of the IE is a function of \\(A\\) and \\(U\\) and the probability of \\(Y\\) is a function of \\(A\\), \\(U\\). The direct effect of \\(A\\) is fixed at zero.\nThe ITT and hypothetical strategy effects are consistent whereas the naive per-protocol approach inflates the effect estimate.\n\n\nCode\n# number of simulations\nN_sim &lt;- 1e3\n# sample size of each study\nN &lt;- 1e3\n# probability of factor that is external determinant of ice \np_u &lt;- 0.35\n# rand to ctl vs test\np_a &lt;- 0.5\n\nm_rd &lt;- do.call(rbind, mclapply(1:N_sim, FUN = function(i){\n  \n  rd &lt;- rep(NA, 3)\n  \n  u &lt;- rbinom(N, 1, p_u)\n  a &lt;- rbinom(N, 1, p_a)\n  d &lt;- data.table(u, a)\n  \n  # chance of ice increases when in the test group and where u is present\n  # probability that m occurs.\n  d[, m := rbinom(N, 1, 0.05 + 0.15*a + 0.3*a*u)]\n  \n  # say occurrence of y is desirable\n  # occurrence of y dependent on a, m and u \n  # a has no effect on outcome\n  # u decreases prob of y e.g. effect of risk factor\n  # m only influences y through a\n  d[, p_y := 0.5 + 0*a - 0.35*u]  \n  \n  d[, y := rbinom(N, 1, p_y)]\n  \n  # if we ignore the occurrence of the ice then we are aligned with an itt \n  # perspective and there should be negligible difference between the groups \n  # on the risk of the outcome\n  m_p_y &lt;- c(d[a == 0, mean(y)], d[a == 1, mean(y)])\n  rd[1] &lt;- diff(m_p_y)\n  # however if we restrict attention to the subset for whom the ice did not occur\n  # e.g. the subset that adhered to the protocol then we note an increase in the\n  # risk of the outcome in the treatment group.\n  \n  # this arises due to the backdoor path from m through to y\n  m_p_y &lt;- c(d[a == 0 & m == 0, mean(y)], d[a == 1 & m == 0, mean(y)])\n  rd[2] &lt;- diff(m_p_y)\n  \n  # observed marginal distribution of u\n  p_u_obs &lt;- d[, mean(u)]\n  p_a_0 &lt;- sum( d[m == 0 & a == 0 & u == 1, .(mu_y = mean(y)),]*p_u_obs + \n                  d[m == 0 & a == 0 & u == 0, .(mu_y = mean(y)),]*(1-p_u_obs))\n  p_a_1 &lt;- sum( d[m == 0 & a == 1 & u == 1, .(mu_y = mean(y)),]*p_u_obs + \n                  d[m == 0 & a == 1 & u == 0, .(mu_y = mean(y)),]*(1-p_u_obs))\n  \n  m_p_y &lt;- c(p_a_0, p_a_1)\n  rd[3] &lt;- diff(m_p_y)\n  \n  rd\n  \n}, mc.cores = 10))\n  \ncolnames(m_rd) &lt;- c(\"ITT\", \"Per protocol\", \"Hypothetical\") \n\nd_rd &lt;- data.table(m_rd)\nd_rd &lt;- melt(d_rd, measure.vars  = names(d_rd))\nd_rd[, variable := factor(variable, levels = c(\"ITT\", \"Per protocol\", \"Hypothetical\"))]\n\n\n\n\nCode\nggplot(d_rd, aes(x = value, group = variable)) + \n  geom_histogram(fill = \"white\", col = \"black\", bins = 15) +\n  geom_vline(xintercept = 0, col = 2, lwd = 1) +\n  geom_vline(data = d_rd[, .(mu = mean(value)), keyby = variable], \n             aes(xintercept = mu), lty = 2) + \n  scale_x_continuous(\"Risk difference (Test vs Ctl)\") +\n  scale_y_continuous(\"Frequency\") +\n  facet_grid(variable ~.)\n\n\n\n\n\n\n\n\nFigure 1: Distribution of estimates of effect estimates under different estimand strategies\n\n\n\n\n\nSo far, only a single IE has been discussed, which isn’t realistic, but it is just intended to give some intuition into what is already a well known characteristic of a naive per-protocol analyses. In practice, we (1) need to think through the implications of the multiple IEs that exist in the study and (2) need multiple variables to account for the IE.\nAs noted above, in some settings a hypothetical estimand might be appropriate but in another it might not. For example, in roadmap (thinking about the surgical domain in isolation, forgetting the other domains for now) we might have \\(U\\) corresponding to a loose joint and as such treatment switching could be inevitable and it would be difficult to conceive of a world where this did not happen given the loose joint. The hypothetical strategy would possible not be suitable here but an effect that focuses on the strata of the population might be and this might direct us towards a principal stratum strategy. This approach attemtps to target causal effects in specific strata. For example, if a patient with an intact joint (not loose) was particularly frail then the surgeon might decide that assignment to revision was not warranted, whereas a loose joint would perhaps always lead to revision irrespective of the randomised treatment.\nTo give some insight into the principal stratum approach, let \\(M\\) denote the treatment actually received with \\(M=0\\) representing that control was received and \\(M=1\\) representing that test was received. We can then define a strata as \\(S_i = (M_i(0), M_i(1))\\) where \\(M_i(0)\\) and \\(M_i(1)\\) are the received treatment when assigned to control and test respectively. This gives us four combinations: \\(S_i \\in \\{ (0,0), (0,1), (1,0), (1,1)\\}\\) and these are usually described as never takers, compliers, defiers and always takers. For example, in the \\(S_i = (0, 0)\\) strata, the members take control when assigned to that arm and when assigned to the test arm, i.e. they never take the treatment. For a principal stratum strategy we are interested in the causal effect within one (or a combination) of these strata, usually the compliers and so the estimand could be specified as\n\\[\n\\begin{aligned}\n\\Delta_{PS} &= \\mathbb{E}[Y(a=1,m)|M(a = 1)=1] - \\mathbb{E}[Y(a=0,m)|M(a = 0)=0]  \n\\end{aligned}\n\\]\ni.e. the average treatment effect in those units that would have received their assigned treatment had they been assigned to either the control or test group, which is not the same as the subset of units who were observed to have adhered to the treatment they were assigned to.\nThe problem is that for a unit \\(i\\) we only ever observe one of the components in the above definition and what we do observe represents membership in a mixture of strata rather than a single strata. For example, a unit who is assigned to control and is observed to receive control could belong to the compliers strata or the never takes test strata etc.\nTo overcome these, the common assumptions are:\n\nfor the never takers and always takers, the potential outcomes are the same irrespective of the treatment they are assigned to\nthere are no defiers\nthere is a non-zero probability for membership in the compliers strata\n\nhowever, there are actually a lot of different perspectives and approaches. Anyway, the point is that after making various assumptions, some principal strata are, in principle, identifiable.",
    "crumbs": [
      "Design notes",
      "Estimands, ITT and PP"
    ]
  },
  {
    "objectID": "notebooks/design-notes-07.html",
    "href": "notebooks/design-notes-07.html",
    "title": "Missingness considerations",
    "section": "",
    "text": "Missingness is classed into three types:\nwhich apply to both the response data and covariate data.\nThe way that you approach the analysis where you have missingness is strongly influenced by the assumptions you can make about the missing data process. Complete case analysis is often chastised but it is sometimes quite a reasonable approach. The following attempts to clarify some of the concepts by way of a simple example.\nThe following encodes a two-arm parallel group setting where the outcome is treatment failure indicated by \\(y = 1\\). This will be used as the running example.\nData generation function\nget_data &lt;- function(\n    N = 2000, \n    par = NULL,\n    # outcome model\n    f_y = function(par, x, a, ae){\n      eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a + par$b_out[4]*ae\n      eta\n    },\n    # model for adverse events\n    f_ae = function(par, x, a){\n      eta = par$b_ae[1] + par$b_ae[2]*x + par$b_ae[3]*a\n      eta\n    }\n    ){\n  \n  # strata\n  d &lt;- data.table()\n  \n  # intervention - even allocation\n  d[, x := rbinom(N, 1, par$pr_x)]\n  # baseline covariate indep to x\n  d[, a := rbinom(N, 1, par$pr_a)]\n  # dep on both x and a\n  d[, eta_ae := f_ae(par, x, a)]\n  d[, ae := rbinom(.N, 1, plogis(eta_ae))]\n  # outcome model\n  d[, eta_y := f_y(par, x, a, ae)]\n  # y = 1 implies treatment failure\n  d[, y := rbinom(.N, 1, plogis(eta_y))]\n\n  d  \n}\nCode\npar &lt;- list(\n  # betas for outcome model (need to align with f_y)\n  # intervention arm is detrimental (increases the chance of failure)\n  b_out = c(0.4, 0.3, 0.2, 0.5),\n  # betas for ae model b0, b_x, b_a  (need to align with f_ae)\n  # intervention arm increases likelihood of ae, as does baseline cov\n  b_ae = c(-2, 0.5, 0.1),\n  pr_x = 0.5,\n  pr_a = 0.7\n)\n\n# sanity check/consistency\n\nset.seed(2222222)\nd &lt;- get_data(1e6, par)\n# align with the outcome model\nX &lt;- as.matrix(CJ(x = 0:1, a = 0:1, ae = 0:1))\nd_X &lt;- cbind(X, eta = as.numeric(cbind(1, X) %*% par$b_out))\n\n# total effect of exposure (x) on y through all paths \n# i.e. possibly through any adverse events as well as the direct path\nate_obs &lt;- coef(glm(y ~ x, data = d, family = binomial))[2]\nBelow is a sanity check that the generated data, specifically the outcome, is consistent with the underlying true parameters via empirical validation.\nCode\nknitr::kable(merge(\n  d_X, \n  d[, .(eta_obs = round(qlogis(mean(y)), 2)), keyby = .(x, a, ae)], \n  by = c(\"x\", \"a\", \"ae\")))\n\n\n\n\n\nx\na\nae\neta\neta_obs\n\n\n\n\n0\n0\n0\n0.4\n0.40\n\n\n0\n0\n1\n0.9\n0.90\n\n\n0\n1\n0\n0.6\n0.60\n\n\n0\n1\n1\n1.1\n1.11\n\n\n1\n0\n0\n0.7\n0.70\n\n\n1\n0\n1\n1.2\n1.18\n\n\n1\n1\n0\n0.9\n0.89\n\n\n1\n1\n1\n1.4\n1.40",
    "crumbs": [
      "Design notes",
      "Missingness considerations"
    ]
  },
  {
    "objectID": "notebooks/design-notes-07.html#missing-completely-at-random",
    "href": "notebooks/design-notes-07.html#missing-completely-at-random",
    "title": "Missingness considerations",
    "section": "Missing completely at random",
    "text": "Missing completely at random\nFor mcar, the probability of missingness depends on neither the observed or unobserved data. In Figure 1 (a), the indicator of missingness (\\(m\\)) arises as a function of an independent process - it has nothing to do with the observed or unobserved covariates or response.\n\n\n\n\n\n\n\n\n\n\n\n(a) DAG MCAR\n\n\n\n\n\n\n\n\n\n\n\n(b) Model MCAR\n\n\n\n\n\n\n\nFigure 1: MCAR\n\n\n\n\n\nCode\nd &lt;- get_data(\n  1e5, \n  par, \n  f_y = function(par, x, a, ae){\n    eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n    eta\n    })\n\n# missingness is simply stochastic\nd[, m := rbinom(.N, 1, 0.2)]\n\n\nWe would not observe the outcome for those records that were missing (i.e. hose that have \\(m=1\\)) but the distribution of the outcome is approximately the same in the observed and the missing data anyway.\n\n\nObserved mean response stratified by missingness status\nd_fig &lt;- copy(d)\nd_fig[, `:=`(x=factor(x, labels = c(\"ctl\", \"test\")), \n             a=factor(a, labels = c(\"&lt;50\", \"&gt;=50\")), \n             ae=factor(ae, labels = c(\"no-ae\", \"ae\")), \n             m = factor(m, labels = c(\"obs\", \"mis\")))]\n\nd_fig &lt;- d_fig[, .(y = sum(y), n = .N), keyby = .(x, a, m)]\nd_fig[, eta_obs := qlogis(y / n)]\n\nggplot(d_fig, \n       aes(x= x, y = eta_obs)) + \n  geom_bar(position=\"dodge\", stat = \"identity\") +\n  scale_x_discrete(\"Exposure\") +\n  scale_y_continuous(\"log-odds response\") +\n  facet_grid(a ~ m)\n\n\n\n\n\n\n\n\nFigure 2: Observed mean response\n\n\n\n\n\nGiven that the missingness is independent of the outcome, the complete case analysis is unbiased, but inefficient.\n\n\nCode\nd_m &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\nf1_ref &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_ref &lt;- summary(f1_ref)$coef\n  \n# only select the observed cases\nd_m &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\nf1_cc &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_cc &lt;- summary(f1_cc)$coef\n\nd_tbl &lt;- rbind(\n  data.table(desc = \"full data\", par = rownames(coef_f1_ref), coef_f1_ref),\n  data.table(desc = \"complete case\", par = rownames(coef_f1_cc), coef_f1_cc)\n)\nd_tbl[, mu_se := sprintf(\"%.2f (%.3f)\", Estimate, `Std. Error`)]\nd_tbl[, par := factor(par, levels = c(\"(Intercept)\", \"x\", \"a\"))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, desc ~ par, value.var = \"mu_se\")\n))\n\n\n\n\n\ndesc\n(Intercept)\nx\na\n\n\n\n\ncomplete case\n0.41 (0.015)\n0.29 (0.015)\n0.20 (0.016)\n\n\nfull data\n0.41 (0.014)\n0.30 (0.013)\n0.19 (0.015)\n\n\n\n\n\nWe can use multiple imputation (which assumes MAR) for both the MAR and MCAR setting (the latter being a special case of the former). The mice package will default to predicting missing columns on all other variables in the data in line with attempting to maximal uncertainty. There isn’t really any benefit to imputation when the missing data mechanism is MCAR.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/missing-ex-01.stan\")\n\nd &lt;- get_data(\n    1e5, par,  \n    f_y = function(par, x, a, ae){\n      eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n      eta\n    })\n# missingness is indep process\nd[, m := rbinom(.N, 1, 0.2)]\n\nd_bin &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# full data\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_ref &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.2 seconds.\n\n\nCode\nd_post_ref &lt;- data.table(f1_ref$draws(variables = \"b\", format = \"matrix\"))\nd_post_ref[, desc := \"full data\"]\n# d_post_ref[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\nd_bin &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# complete case\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_cc &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_cc &lt;- data.table(f1_cc$draws(variables = \"b\", format = \"matrix\"))\nd_post_cc[, desc := \"complete case\"]\n# d_post_cc[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\n# number that are missing\n# d[, .N, keyby = m]\n\n# imputation sets\nd_imp &lt;- copy(d[, .(x, a, y, m)])\nd_imp[m == 1, y := NA]\nd_imp[, m := NULL]\nn_imp &lt;- 50\n# dumb mice needs factor if you use logreg\nd_imp[, `:=`(x = factor(x), a = factor(a), y = factor(y))]\nl_imp &lt;- mice(d_imp, m = n_imp, \n              method = \"logreg\",\n              seed = 23109, printFlag = F)\n# print(l_imp)\ni &lt;- 1\n\nd_post_imp &lt;- rbindlist(mclapply(1:n_imp, function(i){\n  \n  # pick up the imputed data set\n  d_cur &lt;- data.table(complete(l_imp, i))\n  d_cur[, `:=`(x=as.numeric(as.character(x)),\n               a=as.numeric(as.character(a)),\n               y=as.numeric(as.character(y)))]\n  \n  d_bin &lt;- d_cur[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n  # full (imputed) data\n  ld &lt;- list(\n    N_obs = nrow(d_bin),\n    y = d_bin[, y], n = d_bin[, n], P = 3,\n    X_obs = model.matrix(~ x + a, data = d_bin),\n    prior_only = 0\n  )\n\n  snk &lt;- capture.output(\n    f1_imp &lt;- m1$sample(\n      ld, iter_warmup = 1000, iter_sampling = 1000,\n      parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n      max_treedepth = 10)\n  )\n  \n  d_post &lt;- data.table(f1_imp$draws(variables = \"b\", format = \"matrix\"))\n  d_post\n}), idcol = \"id_imp\")\n\nd_post_imp[, desc := \"mi\"]\n# d_post_imp[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\n\n\n\nPosterior inference on parameters for full data, complete case and MI\nd_fig &lt;- rbind(\n  d_post_ref, d_post_cc, d_post_imp, fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = c(\"desc\", \"id_imp\"))\nd_fig[variable == \"b[1]\", variable := \"(Intercept)\"]\nd_fig[variable == \"b[2]\", variable := \"x\"]\nd_fig[variable == \"b[3]\", variable := \"a\"]\nd_fig[, variable := factor(variable, levels = c(\"(Intercept)\", \"x\", \"a\"))]\nd_fig[, desc := factor(desc, levels = c(\"full data\", \"complete case\", \"mi\"))]\n\nggplot(data = d_fig, aes(x = value, group = desc, col = desc)) +\n  geom_density() +\n  geom_vline(\n    data = d_fig[, .(mu = mean(value)), keyby = .(desc, variable)],\n    aes(xintercept = mu, group = desc, col = desc)\n  ) +\n  geom_vline(\n    data = d_fig[desc == \"full data\", .(mu = mean(value)), keyby = .(variable)],\n    aes(xintercept = mu), col = 2, lwd = 0.4\n  ) +\n  facet_wrap(desc~variable) +\n  scale_color_discrete(\"\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFigure 3: Posterior inference on parameters for full data, complete case and MI",
    "crumbs": [
      "Design notes",
      "Missingness considerations"
    ]
  },
  {
    "objectID": "notebooks/design-notes-07.html#missing-at-random",
    "href": "notebooks/design-notes-07.html#missing-at-random",
    "title": "Missingness considerations",
    "section": "Missing at random",
    "text": "Missing at random\nFor mar, the probability of missingness depends only on the observed data.\nIn Figure 4 (a), the indicator of missingness arises as a function of the exposure (\\(x\\)). Again, we would not observe the outcome for those records with \\(m=1\\). From the DAG you can see that \\(y\\) and \\(m\\) are conditionally independent given \\(x\\). Given that we include \\(x\\) in the model, the estimates for the treatment effect will be unbiased.\n\n\n\n\n\n\n\n\n\n\n\n(a) DAG MAR\n\n\n\n\n\n\n\n\n\n\n\n(b) Model MAR\n\n\n\n\n\n\n\nFigure 4: MAR\n\n\n\n\n\nCode\nd &lt;- get_data(\n  1e5, \n  par, \n  f_y = function(par, x, a, ae){\n    eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n    eta\n    })\n\n# missingness is a function of observed covariates\nf_mar &lt;- function(par, x, a){\n  eta = -1 + 2*x\n  eta\n}\n\nd[, eta_m := f_mar(par, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\n\nIn the simulated data, cross tabulating \\(y\\) and \\(m\\) (the observed data and the indicator of missingness) indicates they are dependent.\n\n\nCode\nd_tbl &lt;- table(d[, .(y, m)])\nX &lt;- chisq.test(d_tbl)\nX\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  d_tbl\nX-squared = 115.95, df = 1, p-value &lt; 2.2e-16\n\n\nBut when stratified by the exposure and baseline covariates, we cannot conclude any dependence.\n\n\nCode\nd_tbl &lt;- table(d[x == 1, .(y, m)])\nX &lt;- chisq.test(d_tbl)\nX\n\n\n\n    Pearson's Chi-squared test with Yates' continuity correction\n\ndata:  d_tbl\nX-squared = 0.16968, df = 1, p-value = 0.6804\n\n\nConditional on the covariates, the probability of missingness is the same for all levels of the outcome across all strata.\n\n\nCode\nd_tbl &lt;- CJ(x = 0:1, a = 0:1, y = 0:1)\nd_tbl[, p_mis := plogis(f_mar(par, x, a))]\n# d_tbl &lt;- unique(d_tbl[, .(x, y, p_mis)])\n\nknitr::kable(rbind(\n  dcast(d_tbl, x + a ~ y, value.var = \"p_mis\")\n), col.names = c(\"x\", \"a\",\"trt.success\", \"trt.failure\"), digits = 2)\n\n\n\n\n\nx\na\ntrt.success\ntrt.failure\n\n\n\n\n0\n0\n0.27\n0.27\n\n\n0\n1\n0.27\n0.27\n\n\n1\n0\n0.73\n0.73\n\n\n1\n1\n0.73\n0.73\n\n\n\n\n\nWhich means that the distribution of outcome will be approximately the same in each strata; the missingness is independent of the outcome conditional on the covariates.\n\n\nObserved mean response stratified by missingness status\nd_fig &lt;- copy(d)\nd_fig[, `:=`(x=factor(x, labels = c(\"ctl\", \"test\")), \n             a=factor(a, labels = c(\"&lt;50\", \"&gt;=50\")), \n             ae=factor(ae, labels = c(\"no-ae\", \"ae\")), \n             m = factor(m, labels = c(\"obs\", \"mis\")))]\n\nd_fig &lt;- d_fig[, .(y = sum(y), n = .N), keyby = .(x, a, m)]\nd_fig[, eta_obs := qlogis(y / n)]\n\nggplot(d_fig, \n       aes(x= x, y = eta_obs)) + \n  geom_bar(position=\"dodge\", stat = \"identity\") +\n  scale_x_discrete(\"Exposure\") +\n  scale_y_continuous(\"log-odds response\") +\n  facet_grid(a ~ m)\n\n\n\n\n\n\n\n\nFigure 5: Observed mean response\n\n\n\n\n\nSo, as long as we condition on the predictor of missingness, the complete case estimates are unbiased, albeit inefficient.\n\n\nCode\nd_m &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\nf1_ref &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_ref &lt;- summary(f1_ref)$coef\n  \n# only select the observed cases\nd_m &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\nf1_cc &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_cc &lt;- summary(f1_cc)$coef\n\nd_tbl &lt;- rbind(\n  data.table(desc = \"full data\", par = rownames(coef_f1_ref), coef_f1_ref),\n  data.table(desc = \"complete case\", par = rownames(coef_f1_cc), coef_f1_cc)\n)\nd_tbl[, mu_se := sprintf(\"%.2f (%.3f)\", Estimate, `Std. Error`)]\nd_tbl[, par := factor(par, levels = c(\"(Intercept)\", \"x\", \"a\"))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, desc ~ par, value.var = \"mu_se\")\n))\n\n\n\n\n\ndesc\n(Intercept)\nx\na\n\n\n\n\ncomplete case\n0.41 (0.018)\n0.30 (0.022)\n0.19 (0.020)\n\n\nfull data\n0.39 (0.014)\n0.31 (0.013)\n0.21 (0.015)\n\n\n\n\n\nSimilarly, if the missingness arises because of some baseline covariate, then the estimate for the exposure remains unbiased so long as we adjust for the relevant covariate.\n\n\nCode\nd &lt;- get_data(\n  1e5, \n  par, \n  f_y = function(par, x, a, ae){\n    eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n    eta\n    })\n\n# missingness is a function of observed covariates\nf_mar &lt;- function(par, y, x, a){\n  eta = -1 + 2*a\n  eta\n}\n\nd[, eta_m := f_mar(par, y, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\n\n\n\nCode\nd_m &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\nf1_ref &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_ref &lt;- summary(f1_ref)$coef\n  \n# only select the observed cases\nd_m &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\nf1_cc &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_cc &lt;- summary(f1_cc)$coef\n\nd_tbl &lt;- rbind(\n  data.table(desc = \"full data\", par = rownames(coef_f1_ref), coef_f1_ref),\n  data.table(desc = \"complete case\", par = rownames(coef_f1_cc), coef_f1_cc)\n)\nd_tbl[, mu_se := sprintf(\"%.2f (%.3f)\", Estimate, `Std. Error`)]\nd_tbl[, par := factor(par, levels = c(\"(Intercept)\", \"x\", \"a\"))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, desc ~ par, value.var = \"mu_se\")\n))\n\n\n\n\n\ndesc\n(Intercept)\nx\na\n\n\n\n\ncomplete case\n0.40 (0.017)\n0.29 (0.021)\n0.21 (0.021)\n\n\nfull data\n0.39 (0.014)\n0.30 (0.013)\n0.21 (0.014)\n\n\n\n\n\nFor mcar and mar, the missing data mechanism is referred to as ignorable because we don’t need to specify a model for the missingness in order to make valid inference. We can again use multiple imputation but because we have conditioned the model correctly, there still isn’t any real benefit in the multiple imputation approach.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/missing-ex-01.stan\")\n\nd &lt;- get_data(\n    1e5, par,\n    f_y = function(par, x, a, ae){\n      eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n      eta\n    })\n# missingness is mar\n# a function of observed covariates\nf_mar &lt;- function(par, x, a){\n  eta = -1 + 2*x\n  eta\n}\nd[, eta_m := f_mar(par, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\n\nd_bin &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# full data\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_ref &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_ref &lt;- data.table(f1_ref$draws(variables = \"b\", format = \"matrix\"))\nd_post_ref[, desc := \"full data\"]\n# d_post_ref[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\nd_bin &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# complete case\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_cc &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_cc &lt;- data.table(f1_cc$draws(variables = \"b\", format = \"matrix\"))\nd_post_cc[, desc := \"complete case\"]\n# d_post_cc[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\n# number that are missing\n# d[, .N, keyby = m]\n\n# imputation sets\nd_imp &lt;- copy(d[, .(x, a, y, m)])\nd_imp[m == 1, y := NA]\nd_imp[, m := NULL]\n# dumb mice needs factor if you use logreg\nd_imp[, `:=`(x = factor(x), a = factor(a), y = factor(y))]\nn_imp &lt;- 50\nl_imp &lt;- mice(d_imp, m = n_imp, \n              method = \"logreg\",\n              seed = 23109, printFlag = F)\n# print(l_imp)\ni &lt;- 1\n\nd_post_imp &lt;- rbindlist(mclapply(1:n_imp, function(i){\n  \n  # pick up the imputed data set\n  d_cur &lt;- data.table(complete(l_imp, i))\n  d_cur[, `:=`(x=as.numeric(as.character(x)),\n               a=as.numeric(as.character(a)),\n               y=as.numeric(as.character(y)))]\n  \n  d_bin &lt;- d_cur[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n  # full (imputed) data\n  ld &lt;- list(\n    N_obs = nrow(d_bin),\n    y = d_bin[, y], n = d_bin[, n], P = 3,\n    X_obs = model.matrix(~ x + a, data = d_bin),\n    prior_only = 0\n  )\n\n  snk &lt;- capture.output(\n    f1_imp &lt;- m1$sample(\n      ld, iter_warmup = 1000, iter_sampling = 1000,\n      parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n      max_treedepth = 10)\n  )\n  \n  d_post &lt;- data.table(f1_imp$draws(variables = \"b\", format = \"matrix\"))\n  d_post\n}), idcol = \"id_imp\")\n\nd_post_imp[, desc := \"mi\"]\n# d_post_imp[, lapply(.SD, mean), .SDcols = paste0(\"b[\", 1:3, \"]\")]\n\n\n\n\nPosterior inference on parameters for full data, complete case and MI\nd_fig &lt;- rbind(\n  d_post_ref, d_post_cc, d_post_imp, fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = c(\"desc\", \"id_imp\"))\nd_fig[variable == \"b[1]\", variable := \"(Intercept)\"]\nd_fig[variable == \"b[2]\", variable := \"x\"]\nd_fig[variable == \"b[3]\", variable := \"a\"]\nd_fig[, variable := factor(variable, levels = c(\"(Intercept)\", \"x\", \"a\"))]\nd_fig[, desc := factor(desc, levels = c(\"full data\", \"complete case\", \"mi\"))]\n\nggplot(data = d_fig, aes(x = value, group = desc, col = desc)) +\n  geom_density() +\n  geom_vline(\n    data = d_fig[, .(mu = mean(value)), keyby = .(desc, variable)],\n    aes(xintercept = mu, group = desc, col = desc)\n  ) +\n  geom_vline(\n    data = d_fig[desc == \"full data\", .(mu = mean(value)), keyby = .(variable)],\n    aes(xintercept = mu), col = 2, lwd = 0.4\n  ) +\n  facet_wrap(desc~variable) +\n  scale_color_discrete(\"\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFigure 6: Posterior inference on parameters for full data, complete case and MI",
    "crumbs": [
      "Design notes",
      "Missingness considerations"
    ]
  },
  {
    "objectID": "notebooks/design-notes-07.html#missing-not-at-random",
    "href": "notebooks/design-notes-07.html#missing-not-at-random",
    "title": "Missingness considerations",
    "section": "Missing not at random",
    "text": "Missing not at random\nIf neither mcar or mar hold, then the data are mnar. For mnar, the missing value tells us something about what the value might have been; missingness here is informative, e.g. a salary reporting - people who get paid more tend not to disclose their salary.\n\n\n\n\n\n\n\n\n\n\n\n(a) DAG MNAR\n\n\n\n\n\n\n\n\n\n\n\n(b) Model MNAR\n\n\n\n\n\n\n\nFigure 7: MNAR\n\n\n\n\n\nCode\nd &lt;- get_data(\n  1e5, \n  par, \n  f_y = function(par, x, a, ae){\n    eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n    eta\n    })\n\n# missingness is a function of observed covariates and outcome\nf_mnar &lt;- function(par, y, x, a){\n  eta = -1 + 0.5*x + 0.5*y\n  eta\n}\n\nd[, eta_m := f_mnar(par, y, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\n\nThe probability of the outcome being missing is now conditional on what would have been observed in the outcome as well as the exposure level with a higher likelihood of missingness in people who would have treatment failure (\\(y = 1\\) here).\n\n\nCode\nd_tbl &lt;- CJ(y = 0:1, x = 0:1, a = 0:1)\nd_tbl[, p_mis := plogis(f_mnar(par, y, x, a))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, x + a ~ y, value.var = \"p_mis\")\n), col.names = c(\"x\", \"a\", \"trt.success\", \"trt.failure\"), digits = 2)\n\n\n\n\n\nx\na\ntrt.success\ntrt.failure\n\n\n\n\n0\n0\n0.27\n0.38\n\n\n0\n1\n0.27\n0.38\n\n\n1\n0\n0.38\n0.50\n\n\n1\n1\n0.38\n0.50\n\n\n\n\n\nAs a consequence, the distribution of the outcome is no longer same in the observed and the missing data.\n\n\nObserved mean response stratified by missingness status\nd_fig &lt;- copy(d)\nd_fig[, `:=`(x=factor(x, labels = c(\"ctl\", \"test\")), \n             a=factor(a, labels = c(\"&lt;50\", \"&gt;=50\")), \n             ae=factor(ae, labels = c(\"no-ae\", \"ae\")), \n             m = factor(m, labels = c(\"obs\", \"mis\")))]\n\nd_fig &lt;- d_fig[, .(y = sum(y), n = .N), keyby = .(x, a, m)]\nd_fig[, eta_obs := qlogis(y / n)]\n\nggplot(d_fig, \n       aes(x= x, y = eta_obs)) + \n  geom_bar(position=\"dodge\", stat = \"identity\") +\n  scale_x_discrete(\"Exposure\") +\n  scale_y_continuous(\"log-odds response\") +\n  facet_grid(a ~ m)\n\n\n\n\n\n\n\n\nFigure 8: Observed mean response\n\n\n\n\n\nNow, even after we have conditioned on \\(x\\) a dependency exists between \\(y\\) and \\(m\\). For example, people who have early signs of treatment failure (or success) might choose to leave the study. Under this setting, the treatment effect will generally be biased.\n\n\nCode\nd_m &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\nf1_ref &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_ref &lt;- summary(f1_ref)$coef\n  \n# only select the observed cases\nd_m &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\nf1_cc &lt;- glm(cbind(y, n-y) ~ x + a, data = d_m, family = binomial)\ncoef_f1_cc &lt;- summary(f1_cc)$coef\n\nd_tbl &lt;- rbind(\n  data.table(desc = \"full data\", par = rownames(coef_f1_ref), coef_f1_ref),\n  data.table(desc = \"complete case\", par = rownames(coef_f1_cc), coef_f1_cc)\n)\nd_tbl[, mu_se := sprintf(\"%.2f (%.3f)\", Estimate, `Std. Error`)]\nd_tbl[, par := factor(par, levels = c(\"(Intercept)\", \"x\", \"a\"))]\n\nknitr::kable(rbind(\n  dcast(d_tbl, desc ~ par, value.var = \"mu_se\")\n))\n\n\n\n\n\ndesc\n(Intercept)\nx\na\n\n\n\n\ncomplete case\n0.24 (0.017)\n0.24 (0.017)\n0.17 (0.018)\n\n\nfull data\n0.40 (0.014)\n0.32 (0.013)\n0.18 (0.014)\n\n\n\n\n\nAgain, we can try multiple imputation but because MI assumes MAR, things go wrong without some additional assumptions.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/missing-ex-01.stan\")\n\nd &lt;- get_data(\n    1e5, par,\n    f_y = function(par, x, a, ae){\n      eta = par$b_out[1] + par$b_out[2]*x + par$b_out[3]*a\n      eta\n    })\n# missingness is a function of observed covariates and outcome\nf_mnar &lt;- function(par, y, x, a){\n  eta = -1 + 0.5*x + 0.5*y\n  eta\n}\n\nd[, eta_m := f_mnar(par, y, x, a)]\nd[, m := rbinom(.N, 1, plogis(eta_m))]\n\nd_bin &lt;- d[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# full data\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_ref &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_ref &lt;- data.table(f1_ref$draws(variables = \"b\", format = \"matrix\"))\nd_post_ref[, desc := \"full data\"]\n\nd_bin &lt;- d[m == 0, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n# complete case\nld &lt;- list(\n  N_obs = nrow(d_bin),\n  y = d_bin[, y], n = d_bin[, n], P = 3,\n  X_obs = model.matrix(~ x + a, data = d_bin),\n  prior_only = 0\n)\n\nf1_cc &lt;- m1$sample(ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.0 seconds.\nChain 2 finished in 0.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.0 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nd_post_cc &lt;- data.table(f1_cc$draws(variables = \"b\", format = \"matrix\"))\nd_post_cc[, desc := \"complete case\"]\n\n# number that are missing\n# d[, .N, keyby = m]\n\n# imputation sets\nd_imp &lt;- copy(d[, .(x, a, y, m)])\nd_imp[m == 1, y := NA]\nd_imp[, m := NULL]\nn_imp &lt;- 50\n# dumb mice needs factor if you use logreg\nd_imp[, `:=`(x = factor(x), a = factor(a), y = factor(y))]\nl_imp &lt;- mice(d_imp, m = n_imp, \n              method = \"logreg\",\n              seed = 23109, printFlag = F)\n# print(l_imp)\ni &lt;- 1\n\nd_post_imp &lt;- rbindlist(mclapply(1:n_imp, function(i){\n  \n  # pick up the imputed data set\n  d_cur &lt;- data.table(complete(l_imp, i))\n  d_cur[, `:=`(x=as.numeric(as.character(x)),\n               a=as.numeric(as.character(a)),\n               y=as.numeric(as.character(y)))]\n  \n  d_bin &lt;- d_cur[, .(y = sum(y), n = .N), keyby = .(x, a)]\n\n  # full (imputed) data\n  ld &lt;- list(\n    N_obs = nrow(d_bin),\n    y = d_bin[, y], n = d_bin[, n], P = 3,\n    X_obs = model.matrix(~ x + a, data = d_bin),\n    prior_only = 0\n  )\n\n  snk &lt;- capture.output(\n    f1_imp &lt;- m1$sample(\n      ld, iter_warmup = 1000, iter_sampling = 1000,\n      parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n      max_treedepth = 10)\n  )\n  \n  d_post &lt;- data.table(f1_imp$draws(variables = \"b\", format = \"matrix\"))\n  d_post\n}), idcol = \"id_imp\")\n\nd_post_imp[, desc := \"mi\"]\n\n\n\n\nPosterior inference on parameters for full data, complete case and MI\nd_fig &lt;- rbind(\n  d_post_ref, d_post_cc, d_post_imp, fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = c(\"desc\", \"id_imp\"))\nd_fig[variable == \"b[1]\", variable := \"(Intercept)\"]\nd_fig[variable == \"b[2]\", variable := \"x\"]\nd_fig[variable == \"b[3]\", variable := \"a\"]\nd_fig[, variable := factor(variable, levels = c(\"(Intercept)\", \"x\", \"a\"))]\nd_fig[, desc := factor(desc, levels = c(\"full data\", \"complete case\", \"mi\"))]\n\nggplot(data = d_fig, aes(x = value, group = desc, col = desc)) +\n  geom_density() +\n  geom_vline(\n    data = d_fig[, .(mu = mean(value)), keyby = .(desc, variable)],\n    aes(xintercept = mu, group = desc, col = desc)\n  ) +\n  geom_vline(\n    data = d_fig[desc == \"full data\", .(mu = mean(value)), keyby = .(variable)],\n    aes(xintercept = mu), col = 2, lwd = 0.4\n  ) +\n  facet_wrap(desc~variable) +\n  scale_color_discrete(\"\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nFigure 9: Posterior inference on parameters for full data, complete case and MI\n\n\n\n\n\nA complete case analysis will be unbiased for the treatment effect of interest when the missingness is not depenendent on that term. However, the parameter estimates for the baseline log-odds (intercept) and any term on which the missingness is dependent will be biased.\nThese results are specific to logistic regression (or more accurately odds ratios, which are a relative measure) and are in contrast to linear regression where the treatment effect will be biased if the missingness is dependent on the outcome regardless of whether adjustment is made. In linear regression the treatment effect from a complete case analysis will be biased if the missingness is due to (1) the outcome alone (2) the outcome and treatment exposure (3) the outcome and baseline factors and is only unbiased under MCAR and when the missingness depends only on the exposure.",
    "crumbs": [
      "Design notes",
      "Missingness considerations"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html",
    "href": "notebooks/design-notes-06.html",
    "title": "Multi-level model perspective",
    "section": "",
    "text": "The central idea with modeling discrete heterogeneity in multilevel models is that the variation is assumed to arise within the context of a dependency structure. Under a complete pooling model, the variation is ignored and we assume that the effect is captured within a single parameter such as modeling a treatment effect across groups. For example, consider the model\n\\[\n\\begin{aligned}\n\\text{logit}(p_i) &= \\alpha + \\beta x_i\n\\end{aligned}\n\\]\nwhere \\(p\\) parameterises a bernoulli observational model conditional on some exposure \\(x\\) and we are taking a monolithic perspective on the treatment effect. To account for discrete heterogeneity we would replace \\(\\beta\\) with \\(\\{ \\beta_1, \\beta_2, \\dots \\beta_K \\}\\). However, to complete the model we neeed to place a prior on \\(\\beta_k\\). Under the assumption of no latent interactions (as in no pooling) we would adopt \\(\\pi(\\beta_1, \\dots, \\beta_K) = \\pi_1(\\beta_1)\\dots\\pi_K(\\beta_K)\\). Under a partial pooling perspective, we would assume some structure to the prior.\nREMAP-CAP uses a multilevel perspective for modeling treatment effects within a domain, across strata, that I have translated to the ROADMAP context although I have made some simplifications for the purposes of illustration.\nAssume the following structure for the linear predictor\n\\[\n\\begin{aligned}\n\\text{logit}(p) &= \\beta_0 + \\beta_{d1[x], j}\n\\end{aligned}\n\\]\nwhere the second term represents a joint specific effect of exposure \\(x\\) within the first domain (I am ignoring silo for the moment and treating everything as generic).\nThe parameters and priors are structured as follows\nThe idea is to produce a structure whereby estimation of the variance components produces dynamic shrinkage of the treatment effect estimates.\nSpecifically, when the variance components are estimated to be large then more variation in the strata specific treatment effects is permitted. However, to estimate the variance components well, you will need multiple groups (more than two).",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html#example---large-number-of-groups-and-exposure-levels",
    "href": "notebooks/design-notes-06.html#example---large-number-of-groups-and-exposure-levels",
    "title": "Multi-level model perspective",
    "section": "Example - large number of groups and exposure levels",
    "text": "Example - large number of groups and exposure levels\nFor the sake of an example, assume you have a setting with 8 treatment arms to which patients are randomised and within each treatment arm are a mix of participants with respect to some characteristic that could influence the response. I am only using this many treatment arms because it allows us to see a clear difference between the different analysis approaches. We are interested in the overall treatment effect and heterogeneity due to some membership to a group.\nWithin this setting there are multiple levels of variation. There is the between treatment arm variation that characterises how different the treatment arms are. There is also the within treatment arm variation due to the subgroup.\nWe could adopt a range of assumptions to model the responses for each combination of treatment and subgroup.\n\nModel the responses for each treatment arm by subgroup combination independently; no information is shared between any of the combinations. This approach will recover the observed point estimates and could be achieved using a logistic regression to estimate each combination’s mean response.\nModel the treatment groups independently, but estimate the variation within each treatment arm due to subgroup membership by sharing a common variance parameter across all the treatment arms. This will reflect the observed mean response in each treatment arm but shrink the subgroup variation towards these means. It will only do this if there is sufficient data to inform the relevant variance estimate.\nModel both the between treatment arm variation and the within treatment arm variation by partitioning the total variation. This will tend to shrink the treatment arm means towards an overall mean and the subgroup estimates towards each treatment arm mean. The within group variation could be modelled for each treatment arm independently or be shared across all treatments.\n\nPlus variations on these themes. All of the variance partition approaches require that there are sufficient groups to informed the variance parameters.\nHere I assume the following represents the true model\n\\[\n\\begin{aligned}\ny_{ijk} &\\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\nu_{jk})) \\\\\n\\nu_{jk} &\\sim \\text{Normal}(\\delta_j, \\tau) \\\\\n\\delta_j &\\sim \\text{Normal}(\\mu, \\sigma)\n\\end{aligned}\n\\]\nand adopt hyper priors and hyper parameters\n\\[\n\\begin{aligned}\n\\mu &\\sim \\text{Normal}(0, 1) \\\\\n\\tau &\\sim \\text{Student-t}(\\text{df} = 3,0, \\text{scale} = 2) \\\\\n\\sigma &\\sim \\text{Student-t}(3,0,2) \\\\\n\\end{aligned}\n\\]",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html#parameter-specificationgeneration",
    "href": "notebooks/design-notes-06.html#parameter-specificationgeneration",
    "title": "Multi-level model perspective",
    "section": "Parameter specification/generation",
    "text": "Parameter specification/generation\nAssume that the true treatment group means are normally distributed around some non-zero mean with standard deviation \\(s\\) and that the subgroup means are normally distributed around each treatment group mean with a common standard deviation \\(s_j\\).\n\n\nParameter specification\nget_par &lt;- function(\n    n_grp = 4, n_trt = 9,\n    mu = 1,\n    s = 0.1, s_j = 0.3\n    ){\n  \n  l &lt;- list()\n  l$n_grp &lt;- n_grp\n  l$n_trt &lt;- n_trt\n\n  # overall mean effect across all intervention types\n  l$mu &lt;- mu\n  # between intervention type variation\n  l$s &lt;- s\n  # intervention type specific mean\n  l$mu_j &lt;- l$mu + rnorm(n_trt, 0, l$s)\n  # within intervention variation attributable to group membership\n  l$s_j &lt;- s_j\n\n  # trt x group effects\n  l$mu_j_k &lt;- do.call(rbind, lapply(seq_along(l$mu_j), function(i){\n    rnorm(n_grp, l$mu_j[i], l$s_j)\n  }))\n  colnames(l$mu_j_k) &lt;- paste0(\"strata\", 1:ncol(l$mu_j_k))\n  rownames(l$mu_j_k) &lt;- paste0(1:nrow(l$mu_j_k))\n  \n  l$d_par &lt;- CJ(\n    j = factor(1:l$n_trt, levels = 1:l$n_trt),\n    k = factor(1:l$n_grp, levels = 1:l$n_grp)\n  )\n  l$d_par[, mu := l$mu]\n  l$d_par[, mu_j := l$mu_j[j]]\n  l$d_par[, mu_j_k := l$mu_j_k[cbind(j,k)]]\n  \n  l\n}\n\n\nAny single data set will not allow us to recover the parameters exactly, but the differences between the estimates from the various modelling assumptions is informative as to the general patterns that arise.\n\n\nData generation function\nget_data &lt;- function(\n    N = 2000, \n    par = NULL,\n    ff = function(par, j, k){\n      \n      m1 &lt;- cbind(j, k)\n      eta = par$mu_j_k[m1] \n      eta\n      \n    }){\n  \n  # strata\n  d &lt;- data.table()\n  \n  # intervention - even allocation\n  d[, j := sample(1:par$n_trt, size = N, replace = T)]\n  # table(d$j)\n  # uneven distribution of groups in the pop\n  z &lt;- rnorm(par$n_grp, 0, 0.5)\n  d[, k := sample(1:par$n_grp, size = N, replace = T, prob = exp(z)/sum(exp(z)))]\n  # d[, k := sample(1:par$n_grp, size = N, replace = T)]\n  # table(d$j, d$k)\n  \n  d[, eta := ff(par, j, k)]\n  \n  d[, y := rbinom(.N, 1, plogis(eta))]\n  \n  d  \n}\n\n\nGenerate data assuming the parameters below with the underlying truth shown in Figure 1. The dashed line shows the overall mean response, the crosses show the treatment arm means and the points show the subgroup heterogeneity around the treatment arm means. Within this first setup, all the treatment arms have the same response and none of the subgroups show any treatment effect either.\n\n\nTrue treatment arm by subgroup mean response\nset.seed(1)\npar &lt;- get_par(n_grp = 5, n_trt = 8, mu = 1, s = 0.0, s_j = 0)\nd &lt;- get_data(N = 3000, par)\n\n\nd_fig_2 &lt;- unique(par$d_par[, .(mu_j, j)])\nd_fig_2[1, label := \"Treatment mean\"]\n       \nd_fig_3 &lt;- copy(par$d_par)\nd_fig_3[6, label := \"Subgroup mean\"]\n\n\np_fig &lt;- ggplot(d_fig_3, aes(x = j, y = mu_j_k, col = k)) +\n  geom_jitter(width = 0.2, height = 0.01) +\n  geom_hline(yintercept = par$mu, lwd = 0.25, lty = 2) +\n  geom_text_repel(\n    aes(label = label),\n                  nudge_x = 0.5,\n                  nudge_y = -0.2,\n                  segment.curvature = -0.1,\n                  segment.ncp = 3,\n                  segment.angle = 20,\n                  box.padding = 2, max.overlaps = Inf, col = 1) +\n  geom_text_repel(\n    data = data.table(\n      x = 2.5, y = par$mu, label = \"Overall mean\"\n    ),\n    aes(x = x, y = y, label = label),\n                  inherit.aes = F,\n                  nudge_x = 0.4,\n                  nudge_y = 0.1,\n                  segment.curvature = -0.1,\n                  segment.ncp = 3,\n                  segment.angle = 20,\n                  box.padding = 2, max.overlaps = Inf, col = 1) +\n  geom_text_repel(data = d_fig_2,\n                  aes(x = j, y = mu_j, label = label), \n                  inherit.aes = F,\n                  nudge_x = 0.4,\n                  nudge_y = -0.05,\n                  segment.curvature = -0.1,\n                  segment.ncp = 3,\n                  segment.angle = 20,\n                  box.padding = 2, max.overlaps = Inf, col = 1) +\n  geom_point(data = d_fig_2,\n             aes(x = j, y = mu_j),\n             inherit.aes = F, pch = 3, size = 3) +\n  scale_x_discrete(\"Treatment type\") +\n  scale_y_continuous(\"Odds of success (log-odds)\", \n                     breaks = seq(\n                       0.5, \n                       1.5, \n                       by = 0.1), limits = c(0.5, 1.5)) +\n  scale_color_discrete(\"Subgroup membership\")\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 1: True treatment arm by subgroup mean response",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html#parameter-estimation",
    "href": "notebooks/design-notes-06.html#parameter-estimation",
    "title": "Multi-level model perspective",
    "section": "Parameter estimation",
    "text": "Parameter estimation\nBelow are models that provide the observed, ML, unpooled and partially pooled estimates.\n\n\nFit model to simulated data\n# mle - reference point\nd_lm &lt;- copy(d)\nd_lm[, `:=`(j = factor(j), k = factor(k))]\nf0 &lt;- glm(y ~ j*k, data = d_lm, family = binomial)\nX &lt;- model.matrix(f0)\n# CI\nn_sim &lt;- 1000\nd_lm_j &lt;- matrix(NA, nrow = par$n_trt, ncol = n_sim)\nd_lm_j_k &lt;- matrix(NA, nrow = par$n_trt * par$n_grp, ncol = n_sim)\nfor(i in 1:n_sim){\n  ix &lt;- sort(sample(1:nrow(d_lm), replace = T))\n  f_boot &lt;- glm(y ~ j*k, data = d_lm[ix], family = binomial)\n  d_tmp_p &lt;- cbind(\n    d_lm[ix],\n    mu = predict(f_boot)\n  )\n  d_lm_j[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = j][, mean]\n  d_lm_j_k[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = .(k, j)][, mean]\n}\n# bootstrapped intervals for means on j and within group means\nd_lm_j &lt;- data.table(d_lm_j)\nd_lm_j[, j := 1:.N]\nd_lm_j &lt;- melt(d_lm_j, id.vars = \"j\")\nd_lm_j[, j := factor(j)]\n# d_lm_j[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = j]\n\nd_lm_j_k &lt;- data.table(d_lm_j_k)\nd_lm_j_k &lt;- cbind(CJ(k = 1:par$n_grp, j = 1:par$n_trt), d_lm_j_k)\nd_lm_j_k &lt;- melt(d_lm_j_k, id.vars = c(\"j\", \"k\"))\nd_lm_j_k[, `:=`(j = factor(j), k = factor(k))]\n# d_lm_j_k[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = .(k,j)]\nd_lm[, eta_hat := predict(f0)]\n\n# bayes\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-01.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-02.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-03.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y, \n  J = length(unique(d$j)), K = length(unique(d$k)),\n  j = d$j, # intervention\n  k = d$k, # subgroup\n  P = ncol(X),\n  X = X,\n  s = 3,\n  s_j = 3, # for the indep means offsets\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 7.9 seconds.\nChain 1 finished in 9.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 8.6 seconds.\nTotal execution time: 9.3 seconds.\n\n\nFit model to simulated data\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 2.1 seconds.\nChain 2 finished in 2.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 2.1 seconds.\nTotal execution time: 2.2 seconds.\n\n\nFit model to simulated data\nf3 &lt;- m3$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 2.4 seconds.\nChain 1 finished in 2.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 2.4 seconds.\nTotal execution time: 2.6 seconds.\n\n\nFigure 2 shows the estimated treatment arm means. The mlm correctly identifies the absence of between treatment variation and as a result, the means are pulled towards the grand mean.\n\n\nParameter estimates vs true values\nd_1 &lt;- data.table(t(f1$draws(variables = \"eta\", format = \"matrix\")))\nd_1 &lt;- cbind(d, d_1)\nd_1 &lt;- melt(d_1, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_2 &lt;- data.table(t(f2$draws(variables = \"eta\", format = \"matrix\")))\nd_2 &lt;- cbind(d, d_2)\nd_2 &lt;- melt(d_2, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_3 &lt;- data.table(t(f3$draws(variables = \"eta\", format = \"matrix\")))\nd_3 &lt;- cbind(d, d_3)\nd_3 &lt;- melt(d_3, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_mu_j &lt;- rbind(\n  d_1[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_2[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_3[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j]\n)\n  \n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j[, .(q5 = quantile(value, prob =0.05),\n           q95 = quantile(value, prob = 0.95)), keyby = j], \n  by = \"j\"\n)\n\nd_mu_j &lt;- rbind(d_mu_j, d_mle, fill = T)\n\n# Observed\n# Due to the imbalance between the subgroups, need to weight the\n# contributions to align (approx) with mle.\n# Easy here because only one other variable that we need to average\n# over.\nd_obs &lt;- merge(\n  d[, .(N_j = .N), keyby = .(j)],\n  d[, .(mu = qlogis(mean(y)), .N), keyby = .(j, k)],\n  by = \"j\"\n)\nd_mu_j &lt;- rbind(\n  d_mu_j,\n  d_obs[, .(\n    desc = \"observed\", \n    mean = sum(mu * N / N_j)), keyby = j]\n  , fill = T\n  )\n\n\nd_mu_j[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \n  \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n  \n\n\nd_mu &lt;- d[, .(mu = qlogis(mean(y)), \n         w = .N/nrow(d)), keyby = .(j, k)][\n           , .(desc = \"observed\", mean = sum(mu * w))]\n\n\np_fig &lt;- ggplot(d_mu_j, aes(x = j, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  geom_hline(data = d_mu,\n             aes(yintercept = mean, lty = desc),\n             lwd = 0.3, col = 1) +\n  scale_x_discrete(\"Treatment arm\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2))  +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_mu_j$q5, na.rm = T) - 0.1, \n                label = N), inherit.aes = F) +\n  theme(legend.position=\"bottom\", legend.box=\"vertical\", legend.margin=margin())\n\nsuppressWarnings(print(p_fig))  \n\n\n\n\n\n\n\n\nFigure 2: Parameter estimates vs true values\n\n\n\n\n\nFigure 3 shows the estimated treatment by subgroup means. Similar to above, the mlm has determined that the within group variance is negligible and has pulled the subgroup estimates towards the treatment means. In contrast, the ML and independent models follow the data leading to suggest some material subgroup effects.\n\n\nParameter estimates vs true values\n# Posterior\n# d_mu_j_k &lt;- rbind(\n#   data.table(f2$summary(variables = c(\n#     \"mu_j_k\"\n#     )))[, .(desc = \"partial pool (trt)\", variable, mean, q5, q95)],\n#   data.table(f3$summary(variables = c(\n#     \"mu_j_k\"\n#     )))[, .(desc = \"partial pool (trt+subgrp)\", variable, mean, q5, q95)]\n# )\n# d_mu_j_k[, j := substr(variable, 8, 8)]\n# d_mu_j_k[, k := substr(variable, 10, 10)]\n\n# Manually calculate intervals for independent model\nd_mu_j_k &lt;- rbind(\n  # d_mu_j_k,\n  d_1[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_2[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_3[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)]\n  )\n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(k, j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j_k[, .(q5 = quantile(value, prob =0.05),\n               q95 = quantile(value, prob = 0.95)), keyby = .(k,j)], \n  by = c(\"j\",\"k\")\n)\n\nd_mu_j_k &lt;- rbind(d_mu_j_k, d_mle, fill = T)\n\n# Observed\nd_mu_j_k &lt;- rbind(\n  d_mu_j_k, \n  d[, .(desc = \"observed\", mean = qlogis(mean(y))), keyby = .(k, j)],\n  fill = T)\n\n\nd_mu_j_k[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n# \nd_mu_obs &lt;- d[, .(mu = qlogis(mean(y)))]\nd_mu_mod &lt;- data.table(f3$summary(variables = c(\n    \"mu\"\n    )))[, .(model = \"no pooling\", variable, mean, q5, q95)]\n\np_fig &lt;- ggplot(d_mu_j_k, aes(x = k, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  scale_x_discrete(\"Subgroup\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2)) +\n  geom_hline(data = d_mu_j[desc == \"observed\"],\n             aes(yintercept = mean, group = desc),\n             lwd = 0.3, col = 1) +\n  geom_text(data = d[, .N, keyby = .(j, k)],\n            aes(x = k, y = min(d_mu_j_k$q5, na.rm = T) - 0.1, label = N), \n            inherit.aes = F) +\n  facet_wrap(~paste0(\"Treatment \", j)) \n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 3: Parameter estimates vs true values\n\n\n\n\n\nThe mlm partitions the variance into a between treatment variance part that characterises the variation in the treatment arms and a within treatment variance that characterises the variation due to the subgroups.\nIn Figure 4 shows the prior (red) and the posterior (black) for the variance components (actually the standard deviations). Given the differentiation between the prior and posterior, it is clear that something has been learnt about the variation in the data and the posterior is well identified, although not fully concentrated on the true value of zero. Moreover, both the between group variation (variation due to treatment) and within group variation (variation due to subgroups) are small which leads to the dynamic shrinkage as shown in the subgroup level means.\n\n\nVariance components (revision)\nd_fig &lt;- rbind(\n  cbind(desc = \"partial pool (trt)\",\n        data.table(f2$draws(variables = c(\"s_j\"), format = \"matrix\"))),\n  cbind(desc = \"partial pool (trt+subgrp)\",\n        data.table(f3$draws(variables = c(\"s\", \"s_j\"), format = \"matrix\"))  \n  ), fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = \"desc\")\nd_fig[variable == \"s\", label := \"variation b/w\"]\nd_fig[variable == \"s_j\", label := \"variation w/in\"]\n\nd_pri &lt;- CJ(\n  variable = c(\"s\", \"s_j\"),\n  desc = c(\"partial pool (trt)\", \"partial pool (trt+subgrp)\"),\n  x = seq(min(d_fig$value, na.rm = T), \n          max(d_fig$value, na.rm = T), len = 500)\n)\nd_pri[, y := fGarch::dstd(x, nu = 3, mean = 0, sd = 2)]\nd_pri[variable == \"s\", label := \"variation b/w\"]\nd_pri[variable == \"s_j\", label := \"variation w/in\"]\nd_pri[desc == \"partial pool (trt)\" & variable == \"s\", y := NA]\n# \n# d_smry &lt;- d_fig[, .(mu = mean(value)), keyby = .(label)]\n\np_fig &lt;- ggplot(d_fig, aes(x = value, group = variable)) + \n  geom_density() +\n  geom_line(\n    data = d_pri, \n    aes(x = x, y = y), col = 2, lwd = 0.2\n  ) +\n  scale_x_continuous(\"Standard deviation\") +\n  scale_y_continuous(\"Density\") +\n  facet_wrap(desc+label~., ncol = 2)\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 4: Between and within SD",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/design-notes-06.html#example---small-number-of-groups-and-exposure-levels",
    "href": "notebooks/design-notes-06.html#example---small-number-of-groups-and-exposure-levels",
    "title": "Multi-level model perspective",
    "section": "Example - small number of groups and exposure levels",
    "text": "Example - small number of groups and exposure levels\nNow repeat the same exercise with a small number of groups and exposure levels, again we simulate the data assuming no effects are present.\n\n\nCode\nset.seed(1)\npar &lt;- get_par(n_grp = 2, n_trt = 2, mu = 1, s = 0.0, s_j = 0.0)\nd &lt;- get_data(N = 3000, par)\n\n\n\n\nFit model to simulated data\n# mle - reference point\nd_lm &lt;- copy(d)\nd_lm[, `:=`(j = factor(j), k = factor(k))]\nf0 &lt;- glm(y ~ j*k, data = d_lm, family = binomial)\nX &lt;- model.matrix(f0)\n# CI\nn_sim &lt;- 1000\nd_lm_j &lt;- matrix(NA, nrow = par$n_trt, ncol = n_sim)\nd_lm_j_k &lt;- matrix(NA, nrow = par$n_trt * par$n_grp, ncol = n_sim)\nfor(i in 1:n_sim){\n  ix &lt;- sort(sample(1:nrow(d_lm), replace = T))\n  f_boot &lt;- glm(y ~ j*k, data = d_lm[ix], family = binomial)\n  d_tmp_p &lt;- cbind(\n    d_lm[ix],\n    mu = predict(f_boot)\n  )\n  d_lm_j[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = j][, mean]\n  d_lm_j_k[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = .(k, j)][, mean]\n}\n# bootstrapped intervals for means on j and within group means\nd_lm_j &lt;- data.table(d_lm_j)\nd_lm_j[, j := 1:.N]\nd_lm_j &lt;- melt(d_lm_j, id.vars = \"j\")\nd_lm_j[, j := factor(j)]\n# d_lm_j[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = j]\n\nd_lm_j_k &lt;- data.table(d_lm_j_k)\nd_lm_j_k &lt;- cbind(CJ(k = 1:par$n_grp, j = 1:par$n_trt), d_lm_j_k)\nd_lm_j_k &lt;- melt(d_lm_j_k, id.vars = c(\"j\", \"k\"))\nd_lm_j_k[, `:=`(j = factor(j), k = factor(k))]\n# d_lm_j_k[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = .(k,j)]\n\nd_lm[, eta_hat := predict(f0)]\n\n# bayes\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-01.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-02.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-03.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y, \n  J = length(unique(d$j)), K = length(unique(d$k)),\n  j = d$j, # intervention\n  k = d$k, # subgroup\n  P = ncol(X),\n  X = X,\n  s = 3,\n  s_j = 3, # for the indep means offsets\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 1.4 seconds.\nChain 2 finished in 1.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 1.4 seconds.\nTotal execution time: 1.6 seconds.\n\n\nFit model to simulated data\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 2.3 seconds.\nChain 2 finished in 2.8 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 2.5 seconds.\nTotal execution time: 2.9 seconds.\n\n\nWarning: 22 of 2000 (1.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nFit model to simulated data\nf3 &lt;- m3$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 5.1 seconds.\nChain 2 finished in 6.0 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 5.5 seconds.\nTotal execution time: 6.1 seconds.\n\n\nWarning: 57 of 2000 (3.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\n\n\nParameter estimates vs true values\nd_1 &lt;- data.table(t(f1$draws(variables = \"eta\", format = \"matrix\")))\nd_1 &lt;- cbind(d, d_1)\nd_1 &lt;- melt(d_1, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_2 &lt;- data.table(t(f2$draws(variables = \"eta\", format = \"matrix\")))\nd_2 &lt;- cbind(d, d_2)\nd_2 &lt;- melt(d_2, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_3 &lt;- data.table(t(f3$draws(variables = \"eta\", format = \"matrix\")))\nd_3 &lt;- cbind(d, d_3)\nd_3 &lt;- melt(d_3, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_mu_j &lt;- rbind(\n  d_1[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_2[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_3[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j]\n)\n\n  \n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j[, .(q5 = quantile(value, prob =0.05),\n           q95 = quantile(value, prob = 0.95)), keyby = j], \n  by = \"j\"\n)\n\nd_mu_j &lt;- rbind(d_mu_j, d_mle, fill = T)\n\n# Observed\n# Due to the imbalance between the subgroups, need to weight the\n# contributions to align (approx) with mle.\n# Easy here because only one other variable that we need to average\n# over.\nd_obs &lt;- merge(\n  d[, .(N_j = .N), keyby = .(j)],\n  d[, .(mu = qlogis(mean(y)), .N), keyby = .(j, k)],\n  by = \"j\"\n)\nd_mu_j &lt;- rbind(\n  d_mu_j,\n  d_obs[, .(\n    desc = \"observed\", \n    mean = sum(mu * N / N_j)), keyby = j]\n  , fill = T\n  )\n\n\nd_mu_j[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n\n\nd_mu &lt;- d[, .(mu = qlogis(mean(y)), \n         w = .N/nrow(d)), keyby = .(j, k)][\n           , .(desc = \"observed\", mean = sum(mu * w))]\n\n\np_fig &lt;- ggplot(d_mu_j, aes(x = j, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  geom_hline(data = d_mu,\n             aes(yintercept = mean, lty = desc),\n             lwd = 0.3, col = 1) +\n  scale_x_discrete(\"Treatment arm\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2))  +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_mu_j$q5, na.rm = T) - 0.1, \n                label = N), inherit.aes = F) +\n  theme(legend.position=\"bottom\", legend.box=\"vertical\", legend.margin=margin())\n\nsuppressWarnings(print(p_fig))  \n\n\n\n\n\n\n\n\nFigure 5: Parameter estimates vs true values\n\n\n\n\n\n\n\nParameter estimates vs true values\n# Manually calculate intervals for independent model\nd_mu_j_k &lt;- rbind(\n  # d_mu_j_k,\n  d_1[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_2[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_3[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)]\n  )\n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(k, j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j_k[, .(q5 = quantile(value, prob =0.05),\n               q95 = quantile(value, prob = 0.95)), keyby = .(k,j)], \n  by = c(\"j\",\"k\")\n)\n\nd_mu_j_k &lt;- rbind(d_mu_j_k, d_mle, fill = T)\n\n# Observed\nd_mu_j_k &lt;- rbind(\n  d_mu_j_k, \n  d[, .(desc = \"observed\", mean = qlogis(mean(y))), keyby = .(k, j)],\n  fill = T)\n\n\nd_mu_j_k[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n# \nd_mu_obs &lt;- d[, .(mu = qlogis(mean(y)))]\nd_mu_mod &lt;- data.table(f3$summary(variables = c(\n    \"mu\"\n    )))[, .(model = \"no pooling\", variable, mean, q5, q95)]\n\np_fig &lt;- ggplot(d_mu_j_k, aes(x = k, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  scale_x_discrete(\"Subgroup\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2)) +\n  geom_hline(data = d_mu_j[desc == \"observed\"],\n             aes(yintercept = mean, group = desc),\n             lwd = 0.3, col = 1) +\n  geom_text(data = d[, .N, keyby = .(j, k)],\n            aes(x = k, y = min(d_mu_j_k$q5, na.rm = T) - 0.1, label = N), \n            inherit.aes = F) +\n  facet_wrap(~paste0(\"Treatment \", j)) \n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 6: Parameter estimates vs true values\n\n\n\n\n\nThe posterior estimates for the variance components are now poorly informed by the data and therefore highly uncertain. Accordingly, the prior is having a much greater influence under this scenario.\n\n\nVariance components (revision)\nd_fig &lt;- rbind(\n  cbind(desc = \"partial pool (trt)\",\n        data.table(f2$draws(variables = c(\"s_j\"), format = \"matrix\"))),\n  cbind(desc = \"partial pool (trt+subgrp)\",\n        data.table(f3$draws(variables = c(\"s\", \"s_j\"), format = \"matrix\"))  \n  ), fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = \"desc\")\nd_fig[variable == \"s\", label := \"variation b/w\"]\nd_fig[variable == \"s_j\", label := \"variation w/in\"]\n\nd_pri &lt;- CJ(\n  variable = c(\"s\", \"s_j\"),\n  desc = c(\"partial pool (trt)\", \"partial pool (trt+subgrp)\"),\n  x = seq(min(d_fig$value, na.rm = T), \n          max(d_fig$value, na.rm = T), len = 500)\n)\nd_pri[, y := fGarch::dstd(x, nu = 3, mean = 0, sd = 2)]\nd_pri[variable == \"s\", label := \"variation b/w\"]\nd_pri[variable == \"s_j\", label := \"variation w/in\"]\nd_pri[desc == \"partial pool (trt)\" & variable == \"s\", y := NA]\n\np_fig &lt;- ggplot(d_fig, aes(x = value, group = variable)) + \n  geom_density() +\n  geom_line(\n    data = d_pri, \n    aes(x = x, y = y), col = 2, lwd = 0.2\n  ) +\n  scale_x_continuous(\"Standard deviation\") +\n  scale_y_continuous(\"Density\") +\n  facet_wrap(desc+label~., ncol = 2)\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 7: Between and within SD\n\n\n\n\n\nBased on the above, it is unclear whether the additional complexity of an mlm is warranted when only two groups are available since the results are basically analogous to those of simpler approaches.\nThe results are also somewhat unsatisfying when assuming non-zero effects between treatments and within subgroups as shown below.\n\n\nCode\nset.seed(2)\npar &lt;- get_par(n_grp = 2, n_trt = 2, mu = 1, s = 0.4, s_j = 0.2)\nd &lt;- get_data(N = 3000, par)\n\n\n\n\nFit model to simulated data\n# mle - reference point\nd_lm &lt;- copy(d)\nd_lm[, `:=`(j = factor(j), k = factor(k))]\nf0 &lt;- glm(y ~ j*k, data = d_lm, family = binomial)\nX &lt;- model.matrix(f0)\n# CI\nn_sim &lt;- 1000\nd_lm_j &lt;- matrix(NA, nrow = par$n_trt, ncol = n_sim)\nd_lm_j_k &lt;- matrix(NA, nrow = par$n_trt * par$n_grp, ncol = n_sim)\nfor(i in 1:n_sim){\n  ix &lt;- sort(sample(1:nrow(d_lm), replace = T))\n  f_boot &lt;- glm(y ~ j*k, data = d_lm[ix], family = binomial)\n  d_tmp_p &lt;- cbind(\n    d_lm[ix],\n    mu = predict(f_boot)\n  )\n  d_lm_j[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = j][, mean]\n  d_lm_j_k[, i] &lt;- d_tmp_p[, .(mean = mean(mu)), keyby = .(k, j)][, mean]\n}\n# bootstrapped intervals for means on j and within group means\nd_lm_j &lt;- data.table(d_lm_j)\nd_lm_j[, j := 1:.N]\nd_lm_j &lt;- melt(d_lm_j, id.vars = \"j\")\nd_lm_j[, j := factor(j)]\n# d_lm_j[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = j]\n\nd_lm_j_k &lt;- data.table(d_lm_j_k)\nd_lm_j_k &lt;- cbind(CJ(k = 1:par$n_grp, j = 1:par$n_trt), d_lm_j_k)\nd_lm_j_k &lt;- melt(d_lm_j_k, id.vars = c(\"j\", \"k\"))\nd_lm_j_k[, `:=`(j = factor(j), k = factor(k))]\n# d_lm_j_k[, .(q5 = quantile(value, prob =0.05), \n#            q95 = quantile(value, prob = 0.95)), keyby = .(k,j)]\n\nd_lm[, eta_hat := predict(f0)]\n\n# bayes\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-01.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-02.stan\")\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/mlm-ex-03.stan\")\n\nld &lt;- list(\n  N = nrow(d), \n  y = d$y, \n  J = length(unique(d$j)), K = length(unique(d$k)),\n  j = d$j, # intervention\n  k = d$k, # subgroup\n  P = ncol(X),\n  X = X,\n  s = 3,\n  s_j = 3, # for the indep means offsets\n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 1.4 seconds.\nChain 2 finished in 1.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 1.4 seconds.\nTotal execution time: 1.5 seconds.\n\n\nFit model to simulated data\nf2 &lt;- m2$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 3.1 seconds.\nChain 2 finished in 3.9 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 3.5 seconds.\nTotal execution time: 4.0 seconds.\n\n\nWarning: 25 of 2000 (1.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nFit model to simulated data\nf3 &lt;- m3$sample(\n    ld, iter_warmup = 1000, iter_sampling = 1000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 6.6 seconds.\nChain 1 finished in 7.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 7.0 seconds.\nTotal execution time: 7.4 seconds.\n\n\nWarning: 81 of 2000 (4.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\n\nFor the treatment group means, the multi-level model produces estimates that are again basically equivalent to those of the simpler modelling approaches.\n\n\nParameter estimates vs true values\nd_1 &lt;- data.table(t(f1$draws(variables = \"eta\", format = \"matrix\")))\nd_1 &lt;- cbind(d, d_1)\nd_1 &lt;- melt(d_1, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_2 &lt;- data.table(t(f2$draws(variables = \"eta\", format = \"matrix\")))\nd_2 &lt;- cbind(d, d_2)\nd_2 &lt;- melt(d_2, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_3 &lt;- data.table(t(f3$draws(variables = \"eta\", format = \"matrix\")))\nd_3 &lt;- cbind(d, d_3)\nd_3 &lt;- melt(d_3, id.vars = c(\"j\", \"k\", \"eta\", \"y\"), variable.name = \"i_draw\")\n\nd_mu_j &lt;- rbind(\n  d_1[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_2[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j],\n  d_3[, .(mu = mean(value)), keyby = .(j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = j]\n)\n\n  \n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j[, .(q5 = quantile(value, prob =0.05),\n           q95 = quantile(value, prob = 0.95)), keyby = j], \n  by = \"j\"\n)\n\nd_mu_j &lt;- rbind(d_mu_j, d_mle, fill = T)\n\n# Observed\n# Due to the imbalance between the subgroups, need to weight the\n# contributions to align (approx) with mle.\n# Easy here because only one other variable that we need to average\n# over.\nd_obs &lt;- merge(\n  d[, .(N_j = .N), keyby = .(j)],\n  d[, .(mu = qlogis(mean(y)), .N), keyby = .(j, k)],\n  by = \"j\"\n)\nd_mu_j &lt;- rbind(\n  d_mu_j,\n  d_obs[, .(\n    desc = \"observed\", \n    mean = sum(mu * N / N_j)), keyby = j]\n  , fill = T\n  )\n\n\nd_mu_j[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \n  \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n\n\nd_mu &lt;- d[, .(mu = qlogis(mean(y)), \n         w = .N/nrow(d)), keyby = .(j, k)][\n           , .(desc = \"observed\", mean = sum(mu * w))]\n\n\np_fig &lt;- ggplot(d_mu_j, aes(x = j, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  geom_hline(data = d_mu,\n             aes(yintercept = mean, lty = desc),\n             lwd = 0.3, col = 1) +\n  scale_x_discrete(\"Treatment arm\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2))  +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  geom_text(data = d[, .N, keyby = .(j)],\n            aes(x = j, y = min(d_mu_j$q5, na.rm = T) - 0.1, \n                label = N), inherit.aes = F) +\n  theme(legend.position=\"bottom\", legend.box=\"vertical\", legend.margin=margin())\n\nsuppressWarnings(print(p_fig))  \n\n\n\n\n\n\n\n\nFigure 8: Parameter estimates vs true values\n\n\n\n\n\nFor the subgroups, the estimates were shrunk towards the treatment group means for the data set simulated here.\n\n\nParameter estimates vs true values\n# Manually calculate intervals for independent model\nd_mu_j_k &lt;- rbind(\n  # d_mu_j_k,\n  d_1[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"no pooling\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_2[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)],\n  d_3[, .(mu = mean(value)), keyby = .(k, j, i_draw)][\n  , .(desc = \"partial pool (trt+subgrp)\", \n      mean = mean(mu), \n      q5 = quantile(mu, prob = 0.05), \n      q95 = quantile(mu, prob = 0.95)), keyby = .(k, j)]\n  )\n\n# MLE\nd_mle &lt;- cbind(\n  desc = \"mle\", \n  d_lm[, .(mean = mean(eta_hat)), keyby = .(k, j)])\nd_mle &lt;- merge(\n  d_mle, \n  d_lm_j_k[, .(q5 = quantile(value, prob =0.05),\n               q95 = quantile(value, prob = 0.95)), keyby = .(k,j)], \n  by = c(\"j\",\"k\")\n)\n\nd_mu_j_k &lt;- rbind(d_mu_j_k, d_mle, fill = T)\n\n# Observed\nd_mu_j_k &lt;- rbind(\n  d_mu_j_k, \n  d[, .(desc = \"observed\", mean = qlogis(mean(y))), keyby = .(k, j)],\n  fill = T)\n\n\nd_mu_j_k[, desc := factor(desc, levels = c(\n  \"observed\", \"mle\", \"no pooling\", \n  \"partial pool (trt)\", \"partial pool (trt+subgrp)\"\n))]\n\n# \nd_mu_obs &lt;- d[, .(mu = qlogis(mean(y)))]\nd_mu_mod &lt;- data.table(f3$summary(variables = c(\n    \"mu\"\n    )))[, .(model = \"no pooling\", variable, mean, q5, q95)]\n\np_fig &lt;- ggplot(d_mu_j_k, aes(x = k, y = mean, group = desc, col = desc)) +\n  geom_point(position = position_dodge(width = 0.6)) +\n  geom_linerange(aes(ymin=q5, ymax=q95), position = position_dodge2(width = 0.6)) +\n  scale_x_discrete(\"Subgroup\") +\n  scale_y_continuous(\"log-odds treatment success\", breaks = seq(-3, 3, by = 0.2)) +\n  geom_hline(data = d_mu_j[desc == \"observed\"],\n             aes(yintercept = mean, group = desc),\n             lwd = 0.3, col = 1) +\n  geom_text(data = d[, .N, keyby = .(j, k)],\n            aes(x = k, y = min(d_mu_j_k$q5, na.rm = T) - 0.1, label = N), \n            inherit.aes = F) +\n  facet_wrap(~paste0(\"Treatment \", j)) \n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 9: Parameter estimates vs true values\n\n\n\n\n\nHowever, while the variance is indicated as being possibly small, it is poorly informed by the data and therefore our uncertainty regarding these parameters is high.\n\n\nVariance components (revision)\nd_fig &lt;- rbind(\n  cbind(desc = \"partial pool (trt)\",\n        data.table(f2$draws(variables = c(\"s_j\"), format = \"matrix\"))),\n  cbind(desc = \"partial pool (trt+subgrp)\",\n        data.table(f3$draws(variables = c(\"s\", \"s_j\"), format = \"matrix\"))  \n  ), fill = T\n)\nd_fig &lt;- melt(d_fig, id.vars = \"desc\")\nd_fig[variable == \"s\", label := \"variation b/w\"]\nd_fig[variable == \"s_j\", label := \"variation w/in\"]\n\nd_pri &lt;- CJ(\n  variable = c(\"s\", \"s_j\"),\n  desc = c(\"partial pool (trt)\", \"partial pool (trt+subgrp)\"),\n  x = seq(min(d_fig$value, na.rm = T), \n          max(d_fig$value, na.rm = T), len = 500)\n)\nd_pri[, y := fGarch::dstd(x, nu = 3, mean = 0, sd = 2)]\nd_pri[variable == \"s\", label := \"variation b/w\"]\nd_pri[variable == \"s_j\", label := \"variation w/in\"]\nd_pri[desc == \"partial pool (trt)\" & variable == \"s\", y := NA]\n# \n# d_smry &lt;- d_fig[, .(mu = mean(value)), keyby = .(label)]\n\np_fig &lt;- ggplot(d_fig, aes(x = value, group = variable)) + \n  geom_density() +\n  geom_line(\n    data = d_pri, \n    aes(x = x, y = y), col = 2, lwd = 0.2\n  ) +\n  scale_x_continuous(\"Standard deviation\") +\n  scale_y_continuous(\"Density\") +\n  facet_wrap(desc+label~., ncol = 2)\n\nsuppressWarnings(print(p_fig))\n\n\n\n\n\n\n\n\nFigure 10: Between and within SD\n\n\n\n\n\nWe could certainly use a multi-level approach for ROADMAP, but given the small number of groups available, a fixed regularising prior might be more defensible and conceptually reasonable than a dynamic prior. The challenge would be to specify hyper-parameters such that are sufficiently informative to moderate extreme parameter estimates.",
    "crumbs": [
      "Design notes",
      "Multi-level model perspective"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html",
    "href": "notebooks/example-trials.html",
    "title": "Example trials",
    "section": "",
    "text": "Example trials are provided to give insight into typical cell sample sizes as well as the level of uncertainty associated with the parameter estimation process. Examples are from trials at their maximum sample size with all follow up completed. Sequential variants with adaptations will be added later.",
    "crumbs": [
      "Assumptions and setup",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html#null-scenario",
    "href": "notebooks/example-trials.html#null-scenario",
    "title": "Example trials",
    "section": "Null scenario",
    "text": "Null scenario\nTable 1 shows a summary of the treatment sucesses based on the \\(n\\) patients associated with each combination of design variables when no treatment effects (non-membership effects still retained) in the simulated data of 2500 patients. Given that this is a summary of a single data set, some variation from the underlying simulation parameters is to be expected.\n\n\nCode\nset.seed(11)\n\nsim_spec &lt;- get_sim_spec()\n\nsim_spec$b['r1'] &lt;- 0\nsim_spec$b['r2'] &lt;- 0\nsim_spec$b['r1d'] &lt;- 0\nsim_spec$b['r2d'] &lt;- 0\nsim_spec$b['f'] &lt;- 0\n\nll &lt;- get_trial_data(N = 2500, sim_spec = sim_spec)\n\ngt_tbl &lt;- tbl_ex_trial(ll$d)\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSurgical Da\nDuration Db\nType Dc\nResponse\n\n\nreveal\nassigned\nreceived\nreveal\nassigned\nreveal\nassigned\ny\nn\nMLE (py)\nTRUE (py)1\n\n\n\n\nearly\n\n\n\n0\n0\n0\n0\n0\n0\n0\n188\n270\n0.70\n0.68\n\n\n\n0\n0\n0\n0\n0\n1\n0\n122\n195\n0.63\n0.63\n\n\n\n0\n0\n0\n0\n0\n1\n1\n149\n228\n0.65\n0.63\n\n\n\n0\n0\n1\n1\n0\n0\n0\n9\n13\n0.69\n0.67\n\n\n\n0\n0\n1\n1\n0\n1\n0\n8\n13\n0.62\n0.62\n\n\n\n0\n0\n1\n1\n0\n1\n1\n6\n10\n0.60\n0.62\n\n\n\n0\n0\n1\n1\n1\n0\n0\n12\n18\n0.67\n0.67\n\n\n\n0\n0\n1\n1\n1\n1\n0\n5\n8\n0.62\n0.62\n\n\n\n0\n0\n1\n1\n1\n1\n1\n6\n10\n0.60\n0.62\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n505\n765\n0.66\n—\n\n\nlate\n\n\n\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1.00\n0.61\n\n\n\n0\n0\n0\n0\n0\n1\n0\n2\n5\n0.40\n0.55\n\n\n\n0\n0\n0\n0\n0\n1\n1\n1\n1\n1.00\n0.55\n\n\n\n0\n0\n1\n1\n0\n1\n1\n1\n3\n0.33\n0.53\n\n\n\n0\n0\n1\n1\n1\n0\n0\n3\n4\n0.75\n0.59\n\n\n\n0\n0\n1\n1\n1\n1\n0\n0\n1\n0.00\n0.53\n\n\n\n0\n0\n1\n1\n1\n1\n1\n0\n2\n0.00\n0.53\n\n\n\n0\n0\n2\n1\n0\n0\n0\n3\n3\n1.00\n0.62\n\n\n\n0\n0\n2\n1\n0\n1\n0\n2\n2\n1.00\n0.56\n\n\n\n0\n0\n2\n1\n0\n1\n1\n0\n3\n0.00\n0.56\n\n\n\n0\n0\n2\n1\n1\n0\n0\n1\n3\n0.33\n0.62\n\n\n\n0\n0\n2\n1\n1\n1\n0\n3\n4\n0.75\n0.56\n\n\n\n0\n0\n2\n1\n1\n1\n1\n1\n2\n0.50\n0.56\n\n\n\n1\n0\n0\n0\n0\n0\n0\n146\n233\n0.63\n0.63\n\n\n\n1\n0\n0\n0\n0\n1\n0\n108\n192\n0.56\n0.57\n\n\n\n1\n0\n0\n0\n0\n1\n1\n99\n172\n0.58\n0.57\n\n\n\n1\n1\n1\n1\n0\n0\n0\n21\n41\n0.51\n0.63\n\n\n\n1\n1\n1\n1\n0\n1\n0\n15\n28\n0.54\n0.57\n\n\n\n1\n1\n1\n1\n0\n1\n1\n26\n45\n0.58\n0.57\n\n\n\n1\n1\n1\n1\n1\n0\n0\n26\n44\n0.59\n0.63\n\n\n\n1\n1\n1\n1\n1\n1\n0\n19\n30\n0.63\n0.57\n\n\n\n1\n1\n1\n1\n1\n1\n1\n15\n25\n0.60\n0.57\n\n\n\n1\n1\n2\n1\n0\n0\n0\n48\n79\n0.61\n0.63\n\n\n\n1\n1\n2\n1\n0\n1\n0\n34\n62\n0.55\n0.57\n\n\n\n1\n1\n2\n1\n0\n1\n1\n33\n56\n0.59\n0.57\n\n\n\n1\n1\n2\n1\n1\n0\n0\n54\n78\n0.69\n0.63\n\n\n\n1\n1\n2\n1\n1\n1\n0\n35\n61\n0.57\n0.57\n\n\n\n1\n1\n2\n1\n1\n1\n1\n28\n54\n0.52\n0.57\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n725\n1234\n0.59\n—\n\n\nchronic\n\n\n\n0\n0\n0\n0\n0\n0\n0\n23\n38\n0.61\n0.66\n\n\n\n0\n0\n0\n0\n0\n1\n0\n23\n30\n0.77\n0.61\n\n\n\n0\n0\n0\n0\n0\n1\n1\n21\n33\n0.64\n0.61\n\n\n\n0\n0\n1\n1\n0\n0\n0\n10\n17\n0.59\n0.65\n\n\n\n0\n0\n1\n1\n0\n1\n0\n12\n19\n0.63\n0.59\n\n\n\n0\n0\n1\n1\n0\n1\n1\n12\n17\n0.71\n0.59\n\n\n\n0\n0\n1\n1\n1\n0\n0\n12\n20\n0.60\n0.65\n\n\n\n0\n0\n1\n1\n1\n1\n0\n8\n17\n0.47\n0.59\n\n\n\n0\n0\n1\n1\n1\n1\n1\n5\n12\n0.42\n0.59\n\n\n\n0\n0\n2\n1\n0\n0\n0\n46\n60\n0.77\n0.68\n\n\n\n0\n0\n2\n1\n0\n1\n0\n27\n47\n0.57\n0.62\n\n\n\n0\n0\n2\n1\n0\n1\n1\n23\n33\n0.70\n0.62\n\n\n\n0\n0\n2\n1\n1\n0\n0\n41\n56\n0.73\n0.68\n\n\n\n0\n0\n2\n1\n1\n1\n0\n31\n44\n0.70\n0.62\n\n\n\n0\n0\n2\n1\n1\n1\n1\n30\n58\n0.52\n0.62\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n324\n501\n0.65\n—\n\n\ntotal\n—\n—\n—\n—\n—\n—\n—\n1554\n2500\n0.62\n—\n\n\n\n1 Transformed from the log-odds of response as used in the linear predictor to simulate data.\n\n\n\n\n\n\n\n\n\nTable 1: Summary of simulated trial data when no treatment effects present\n\n\n\n\nModel the simulated data first using standard normal priors on the domain level treatment effects, then increasing the prior standard deviation to ten in order to see if there is any movement in the posterior summary.\n\n\nCode\nlsd &lt;- get_stan_data(ll$d)\nld &lt;- lsd$ld\nd_s &lt;- copy(lsd$d_s)\n\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-04.stan\")\n\nf_null_1 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 10000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 4.6 seconds.\nChain 2 finished in 5.2 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 4.9 seconds.\nTotal execution time: 5.3 seconds.\n\n\nCode\npost_1 &lt;- data.table(f_null_1$draws(variables = c(c(\"a0\", \"m\", \"b\")), format = \"matrix\"))\npost_1 &lt;- melt(post_1, measure.vars = names(post_1))\nd_tbl_1 &lt;- post_1[, .(\n  prior = \"normal(0, 1)\",\n  mu = mean(value),\n  q_025 = quantile(value, prob = 0.025), \n  q_975 = quantile(value, prob = 0.975)\n), keyby = variable]\nd_tbl_1[, name_tru := names(unlist(sim_spec))]\nd_tbl_1[, tru := unlist(sim_spec)]\n\n# compare when prior sd is set to 10 for trt effects\n\nld$pri_m_sd &lt;- rep(10, length(ld$pri_m_sd))\nld$pri_b_sd &lt;- rep(10, length(ld$pri_b_sd))\n\nf_null_2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 10000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 5.1 seconds.\nChain 1 finished in 5.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 5.3 seconds.\nTotal execution time: 5.6 seconds.\n\n\nCode\npost_2 &lt;- data.table(f_null_2$draws(variables = c(c(\"a0\", \"m\", \"b\")), format = \"matrix\"))\npost_2 &lt;- melt(post_2, measure.vars = names(post_2))\nd_tbl_2 &lt;- post_2[, .(\n  prior = \"normal(0, 10)\",\n  mu = mean(value), \n  q_025 = quantile(value, prob = 0.025), \n  q_975 = quantile(value, prob = 0.975)\n), keyby = variable]\nd_tbl_2[, name_tru := names(unlist(sim_spec))]\nd_tbl_2[, tru := unlist(sim_spec)]\n\n\n\n\nCode\nd_fig &lt;- rbind(\n  d_tbl_1, d_tbl_2\n)\nd_fig$name_tru &lt;- factor(d_fig$name_tru, levels = unique(d_fig$name_tru))\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = name_tru, y = mu, col = prior)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR\") +\n  geom_point(data = d_fig, aes(x = name_tru, y = mu), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = q_025, ymax = q_975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = name_tru, y = tru), col = 1, pch = 2) \n\n\n\n\n\n\n\n\nFigure 1: Posterior median and 95% CI for baseline log-odds of treatment success domain A (independent estimates for late and chronic silo).",
    "crumbs": [
      "Assumptions and setup",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html#all-domains-effective-scenario",
    "href": "notebooks/example-trials.html#all-domains-effective-scenario",
    "title": "Example trials",
    "section": "All domains effective scenario",
    "text": "All domains effective scenario\nshows a summary of the treatment sucesses based on the \\(n\\) patients associated with each combination of design variables when all treatment effects set to log(2) (with non-membership effects retained as before) in the simulated data of 2500 patients.\n\n\nCode\nset.seed(2)\nsim_spec$b['r1'] &lt;- log(2)\nsim_spec$b['r2'] &lt;- log(2)\nsim_spec$b['r1d'] &lt;- log(2)\nsim_spec$b['r2d'] &lt;- log(2)\nsim_spec$b['f'] &lt;- log(2)\n\nll &lt;- get_trial_data(N = 2500, sim_spec = sim_spec)\n\ngt_tbl &lt;- tbl_ex_trial(ll$d)\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSurgical Da\nDuration Db\nType Dc\nResponse\n\n\nreveal\nassigned\nreceived\nreveal\nassigned\nreveal\nassigned\ny\nn\nMLE (py)\nTRUE (py)1\n\n\n\n\nearly\n\n\n\n0\n0\n0\n0\n0\n0\n0\n166\n245\n0.68\n0.68\n\n\n\n0\n0\n0\n0\n0\n1\n0\n112\n172\n0.65\n0.63\n\n\n\n0\n0\n0\n0\n0\n1\n1\n156\n207\n0.75\n0.77\n\n\n\n0\n0\n1\n1\n0\n0\n0\n17\n23\n0.74\n0.67\n\n\n\n0\n0\n1\n1\n0\n1\n0\n6\n7\n0.86\n0.62\n\n\n\n0\n0\n1\n1\n0\n1\n1\n10\n12\n0.83\n0.76\n\n\n\n0\n0\n1\n1\n1\n0\n0\n9\n13\n0.69\n0.80\n\n\n\n0\n0\n1\n1\n1\n1\n0\n6\n6\n1.00\n0.76\n\n\n\n0\n0\n1\n1\n1\n1\n1\n12\n14\n0.86\n0.86\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n494\n699\n0.71\n—\n\n\nlate\n\n\n\n0\n0\n0\n0\n0\n0\n0\n1\n1\n1.00\n0.61\n\n\n\n0\n0\n0\n0\n0\n1\n0\n0\n1\n0.00\n0.55\n\n\n\n0\n0\n0\n0\n0\n1\n1\n3\n4\n0.75\n0.71\n\n\n\n0\n0\n1\n1\n0\n1\n1\n1\n2\n0.50\n0.70\n\n\n\n0\n0\n1\n1\n1\n0\n0\n2\n2\n1.00\n0.75\n\n\n\n0\n0\n1\n1\n1\n1\n0\n1\n1\n1.00\n0.70\n\n\n\n0\n0\n1\n1\n1\n1\n1\n3\n3\n1.00\n0.82\n\n\n\n0\n0\n2\n1\n0\n0\n0\n5\n7\n0.71\n0.62\n\n\n\n0\n0\n2\n1\n0\n1\n0\n0\n2\n0.00\n0.56\n\n\n\n0\n0\n2\n1\n0\n1\n1\n3\n3\n1.00\n0.72\n\n\n\n0\n0\n2\n1\n1\n0\n0\n2\n2\n1.00\n0.76\n\n\n\n0\n0\n2\n1\n1\n1\n0\n4\n5\n0.80\n0.72\n\n\n\n0\n0\n2\n1\n1\n1\n1\n1\n1\n1.00\n0.83\n\n\n\n1\n0\n0\n0\n0\n0\n0\n156\n245\n0.64\n0.63\n\n\n\n1\n0\n0\n0\n0\n1\n0\n111\n192\n0.58\n0.57\n\n\n\n1\n0\n0\n0\n0\n1\n1\n133\n181\n0.73\n0.73\n\n\n\n1\n1\n1\n1\n0\n0\n0\n25\n30\n0.83\n0.77\n\n\n\n1\n1\n1\n1\n0\n1\n0\n18\n31\n0.58\n0.73\n\n\n\n1\n1\n1\n1\n0\n1\n1\n30\n35\n0.86\n0.84\n\n\n\n1\n1\n1\n1\n1\n0\n0\n26\n30\n0.87\n0.87\n\n\n\n1\n1\n1\n1\n1\n1\n0\n28\n32\n0.88\n0.84\n\n\n\n1\n1\n1\n1\n1\n1\n1\n23\n30\n0.77\n0.91\n\n\n\n1\n1\n2\n1\n0\n0\n0\n53\n68\n0.78\n0.77\n\n\n\n1\n1\n2\n1\n0\n1\n0\n43\n61\n0.70\n0.73\n\n\n\n1\n1\n2\n1\n0\n1\n1\n50\n58\n0.86\n0.84\n\n\n\n1\n1\n2\n1\n1\n0\n0\n81\n92\n0.88\n0.87\n\n\n\n1\n1\n2\n1\n1\n1\n0\n58\n67\n0.87\n0.84\n\n\n\n1\n1\n2\n1\n1\n1\n1\n60\n67\n0.90\n0.91\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n921\n1253\n0.74\n—\n\n\nchronic\n\n\n\n0\n0\n0\n0\n0\n0\n0\n25\n37\n0.68\n0.66\n\n\n\n0\n0\n0\n0\n0\n1\n0\n20\n34\n0.59\n0.61\n\n\n\n0\n0\n0\n0\n0\n1\n1\n29\n43\n0.67\n0.75\n\n\n\n0\n0\n1\n1\n0\n0\n0\n11\n22\n0.50\n0.65\n\n\n\n0\n0\n1\n1\n0\n1\n0\n9\n12\n0.75\n0.59\n\n\n\n0\n0\n1\n1\n0\n1\n1\n13\n18\n0.72\n0.75\n\n\n\n0\n0\n1\n1\n1\n0\n0\n18\n21\n0.86\n0.79\n\n\n\n0\n0\n1\n1\n1\n1\n0\n23\n29\n0.79\n0.75\n\n\n\n0\n0\n1\n1\n1\n1\n1\n17\n20\n0.85\n0.85\n\n\n\n0\n0\n2\n1\n0\n0\n0\n51\n69\n0.74\n0.68\n\n\n\n0\n0\n2\n1\n0\n1\n0\n30\n45\n0.67\n0.62\n\n\n\n0\n0\n2\n1\n0\n1\n1\n35\n55\n0.64\n0.76\n\n\n\n0\n0\n2\n1\n1\n0\n0\n43\n57\n0.75\n0.81\n\n\n\n0\n0\n2\n1\n1\n1\n0\n24\n36\n0.67\n0.76\n\n\n\n0\n0\n2\n1\n1\n1\n1\n41\n50\n0.82\n0.87\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n389\n548\n0.71\n—\n\n\ntotal\n—\n—\n—\n—\n—\n—\n—\n1804\n2500\n0.72\n—\n\n\n\n1 Transformed from the log-odds of response as used in the linear predictor to simulate data.\n\n\n\n\n\n\n\n\n\nTable 2: Summary of simulated trial data when all domains associated with positive effects\n\n\n\n\n\n\nCode\nlsd &lt;- get_stan_data(ll$d)\nld &lt;- lsd$ld\nd_s &lt;- copy(lsd$d_s)\n\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-04.stan\")\n\nf_alleff_1 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 10000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 4.5 seconds.\nChain 2 finished in 4.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 4.5 seconds.\nTotal execution time: 4.6 seconds.\n\n\nCode\npost_1 &lt;- data.table(f_alleff_1$draws(variables = c(c(\"a0\", \"m\", \"b\")), format = \"matrix\"))\npost_1 &lt;- melt(post_1, measure.vars = names(post_1))\nd_tbl_1 &lt;- post_1[, .(\n  prior = \"normal(0, 1)\",\n  mu = mean(value),\n  q_025 = quantile(value, prob = 0.025), \n  q_975 = quantile(value, prob = 0.975)\n), keyby = variable]\nd_tbl_1[, name_tru := names(unlist(sim_spec))]\nd_tbl_1[, tru := unlist(sim_spec)]\n\n# compare when prior sd is set to 10 for trt effects\n\nld$pri_m_sd &lt;- rep(10, length(ld$pri_m_sd))\nld$pri_b_sd &lt;- rep(10, length(ld$pri_b_sd))\n\nf_alleff_2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 10000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 5.5 seconds.\nChain 2 finished in 5.9 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 5.7 seconds.\nTotal execution time: 6.0 seconds.\n\n\nCode\npost_2 &lt;- data.table(f_alleff_2$draws(variables = c(c(\"a0\", \"m\", \"b\")), format = \"matrix\"))\npost_2 &lt;- melt(post_2, measure.vars = names(post_2))\nd_tbl_2 &lt;- post_2[, .(\n  prior = \"normal(0, 10)\",\n  mu = mean(value), \n  q_025 = quantile(value, prob = 0.025), \n  q_975 = quantile(value, prob = 0.975)\n), keyby = variable]\nd_tbl_2[, name_tru := names(unlist(sim_spec))]\nd_tbl_2[, tru := unlist(sim_spec)]\n\n\n\n\nCode\nd_fig &lt;- rbind(\n  d_tbl_1, d_tbl_2\n)\nd_fig$name_tru &lt;- factor(d_fig$name_tru, levels = unique(d_fig$name_tru))\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = name_tru, y = mu, col = prior)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR\") +\n  geom_point(data = d_fig, aes(x = name_tru, y = mu), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = q_025, ymax = q_975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = name_tru, y = tru), col = 1, pch = 2) \n\n\n\n\n\n\n\n\nFigure 2: Posterior median and 95% CI for baseline log-odds of treatment success (triangles show true values).",
    "crumbs": [
      "Assumptions and setup",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/sim-design3-results.html",
    "href": "notebooks/sim-design3-results.html",
    "title": "Simulation results 3",
    "section": "",
    "text": "Simulation 3 is a sequential trial with decision criteria for superiority, and non-inferiority and also for futility with respect to both superiority and non-inferiority.\n\nFor the surgical domain we evaluate whether revision is superior to dair and futility for superiority.\nFor the duration domain (one-stage) we evaluate whether short duration is non-inferior to long duration antibiotic treatment. We also evaluate whether the non-inferiority decision is futile.\nFor the duration domain (two-stage) we evaluate whether long duration is superior to short duration antibiotic treatment (equivalently whether short duration is inferior to long). We also evaluate whether the superiority decision is futile.\nFor the choice domain we evaluate whether rif is superior to no-rif. We also evaluate whether the superiority decision is futile.\n\nEnrolment stops for the respective domain/cells when any of the above are triggered based the decision rules described earlier.\nWe provide summaries of each simulation scenario and the results that were obtained.\n\n\nLoad simulation results\n# files of interest\nflist &lt;- list.files(\"data\", pattern = \"sim03-sc01\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n\n\n\nConfiguration used for each simulated scenario\n# cfg used in each scenario\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\n# conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  N_pt = as.numeric(N_pt),\n  b_r1 = as.numeric(b_r1),\n  b_r2 = as.numeric(b_r2),\n  w_srp2 = as.numeric(w_srp2),\n  b_r1d = as.numeric(b_r1d),\n  b_r2d = as.numeric(b_r2d),\n  b_f = as.numeric(b_f),\n  d_sup = as.numeric(thresh_sup),\n  d_ni = as.numeric(thresh_non_inf),\n  d_fut_sup = as.numeric(thresh_fut_sup),\n  d_fut_ni = as.numeric(thresh_fut_ni)\n  )]\n\n# derive the 'true' effect for surgery based on weight combination\n# d_cfg[, b_r := b_r1 + w_srp2 * b_r2]\n# d_cfg[, `:=`(b_r1 = NULL, b_r2 = NULL, w_srp2 = NULL)]\n\nd_cfg[, `:=`(w_srp2 = NULL)]\n\n# d_tru &lt;- melt(d_cfg[\n#   , .SD, .SDcols = c(\"sc\", \"v\", \"analys\", \n#                      \"b_r\", \"b_r1d\", \"b_r2d\", \"b_f\")], \n#   id.vars = c(\"sc\", \"v\", \"analys\"), value.name = \"lor_tru\")\n\n\n\n\nProcess simulation results for variables of interest\n# Decisions\ni &lt;- 1\nd_dec &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  # l[[i]]$d_decision\n\n  d_decision &lt;- copy(l[[i]]$d_decision)\n  m &lt;- melt(d_decision, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"parname\")\n  \n  # Should be right, but just in case...\n  if(any(is.na(m$value))){\n    message(\"Some of the decision values are NA in index \", i, \" file \", flist[i])\n    m[is.na(value), value := FALSE]\n  }\n  \n  # compute the cumulative instances of a decision being made by sim, each \n  # decision type and by parameter\n  m[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, parname)]\n  # summarise by analysis, decision type and parameter\n  m &lt;- m[, .(pr_val = mean(value)), keyby = .(analys, quant, parname)]\n  # put into wide format\n  m &lt;- dcast(m, parname + analys ~ quant, value.var = \"pr_val\")\n\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n# Posterior summaries on effects of interest\nd_post_smry_2 &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- l[[i]]$d_post_smry_2\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n# Participant data from trial (grouped)\nd_all &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- l[[i]]$d_grp\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n\nTable 1 summarises the configurations used in each simulated scenario. Each treatment effect parameter is set to have the same magnitude of effect. The effects range from \\(\\log(1/2)\\) in scenario 1 to \\(\\log(2)\\) in scenario 7. Decision rules and thresholds remain constant over the entire enrolment period. The decision processes are documented in the Decision rules page.\nRevision effects are computed as a weighted combination of the log-odds ratios for the one-stage and two-stage revision effects. The weights are the sample proportion receiving one-stage and two-stage surgery in those patients receiving randomised surgical treatment and randomised to revision.\n\n\nCode\nd_tbl &lt;- d_cfg[, .(v, N_pt, b_r1, b_r2, b_r1d, b_r2d, b_f, \n                   delta_sup = delta_sup,\n                   delta_sup_fut = delta_sup_fut,\n                   delta_ni = 1/delta_ni,\n                   thresh_sup, thresh_non_inf, thresh_fut_sup, thresh_fut_ni)]\n\ng_tbl &lt;- d_tbl |&gt; gt() |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = c(b_r1, b_r2, b_r1d, b_r2d, b_f,\n                delta_ni\n                ),\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_r1, b_r2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_r1d, b_r2d)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_f)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision setup\"),\n    columns = c(delta_sup, thresh_sup, \n                delta_sup_fut, thresh_fut_sup, \n                delta_ni, thresh_non_inf, thresh_fut_ni)\n  ) |&gt;\n  cols_label(\n    v = html(\"Configuration\"),\n    b_r1 = html(\"rev&lt;br&gt;(one-stage)\"),\n    b_r2 = html(\"rev&lt;br&gt;(two-stage)\"),\n    b_r1d = html(\"short&lt;br&gt;(one-stage)\"),\n    b_r2d = html(\"short&lt;br&gt;(two-stage)\"),\n    b_f = html(\"rif\"),\n    delta_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    thresh_sup = html(\"p&lt;sub&gt;sup&lt;/sub&gt;\"),\n    delta_sup_fut = html(\"delta&lt;sub&gt;fut-sup&lt;/sub&gt;\"),\n    thresh_fut_sup = html(\"p&lt;sub&gt;fut-sup&lt;/sub&gt;\"),\n    delta_ni = html(\"delta&lt;sub&gt;ni&lt;/sub&gt;\"),\n    thresh_non_inf = html(\"p&lt;sub&gt;ni&lt;/sub&gt;\"),\n    thresh_fut_ni = html(\"p&lt;sub&gt;fut-ni&lt;/sub&gt;\")\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"bottom\"), color = \"black\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = N_pt == 2500\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"70%\"\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Surgical effects only applies to late silo, effect is relative to response under DAIR.\",\n    locations = cells_column_labels(columns = c(b_r1, b_r2))\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under long duration.\",\n    locations = cells_column_labels(columns = b_r1d)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under short duration.\",\n    locations = cells_column_labels(columns = b_r2d)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Applies to all silos, effect is relative to response under no-rifampicin\",\n    locations = cells_column_labels(columns = b_f)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating superiority\",\n    locations = cells_column_labels(columns = delta_sup)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Probability threshold above which superiority is concluded\",\n    locations = cells_column_labels(columns = thresh_sup)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating futility wrt the superiority decision\",\n    locations = cells_column_labels(columns = delta_sup_fut)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold below which futility is concluded\",\n    locations = cells_column_labels(columns = thresh_fut_sup)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Reference OR for evaluating non-inferiority\",\n    locations = cells_column_labels(columns = delta_ni)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold above which non-inferiority is concluded\",\n    locations = cells_column_labels(columns = thresh_non_inf)\n  ) |&gt; \n  tab_footnote(\n    footnote = \"Probability threshold below which non-inferiority decision is deemed futile\",\n    locations = cells_column_labels(columns = thresh_fut_ni)\n  )   \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration\nN_pt\nSurgical (Da)\nDuration (Db)\nType (Dc)\nDecision setup\n\n\nrev\n(one-stage)1\nrev\n(two-stage)1\nshort\n(one-stage)2\nshort\n(two-stage)3\nrif4\ndeltasup5\npsup6\ndeltafut-sup7\npfut-sup8\ndeltani9\npni10\npfut-ni11\n\n\n\n\nv01\n500\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv01\n1000\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv01\n1500\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv01\n2000\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv01\n2500\n−0.693\n−0.693\n−0.693\n−0.693\n−0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n500\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n1000\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n1500\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n2000\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv02\n2500\n−0.405\n−0.405\n−0.405\n−0.405\n−0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n1000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n1500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n2000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv03\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n500\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n1000\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n1500\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n2000\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv04\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n500\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n1000\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n1500\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n2000\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv05\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n500\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n1000\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n1500\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n2000\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv06\n2500\n0.405\n0.405\n0.405\n0.405\n0.405\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n500\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n1000\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n1500\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n2000\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\nv07\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n1\n0.99\n1.2\n0.05\n0.833\n0.99\n0.05\n\n\n\n1 Surgical effects only applies to late silo, effect is relative to response under DAIR.\n\n\n2 Applies to all silos, effect is relative to response under long duration.\n\n\n3 Applies to all silos, effect is relative to response under short duration.\n\n\n4 Applies to all silos, effect is relative to response under no-rifampicin\n\n\n5 Reference OR for evaluating superiority\n\n\n6 Probability threshold above which superiority is concluded\n\n\n7 Reference OR for evaluating futility wrt the superiority decision\n\n\n8 Probability threshold below which futility is concluded\n\n\n9 Reference OR for evaluating non-inferiority\n\n\n10 Probability threshold above which non-inferiority is concluded\n\n\n11 Probability threshold below which non-inferiority decision is deemed futile\n\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 shows the cumulative probability of each decision quantity. Once answered, the questions are no longer evaluated.\n\nThe first row details the cumulative probability of decisions within the surgical domain, which currently applies only to the late silo. Superiority (sup in legend) and futility (fut_sup) are the relevant quantities of interest.\nThe second row details the cumulative probability of decisions within the duration domain under one-stage revision. Non-inferiority (ni) and inferiority (fut_ni) are the relevant quantities of interest.\nThe third row details the cumulative probability of decisions within the duration domain under two-stage revision. Superiority (sup) and futility (fut_sup) are the relevant quantities of interest.\nThe fourth row details the cumulative probability of decisions within the choice domain. Superiority (sup) and futility (fut_sup) are the relevant quantities of interest.\n\n\n\nCode\n# put power by scenario, variant and analysis in long format\nd_fig_0_01 &lt;- melt(d_dec, id.vars = c(\"sc\", \"v\", \"analys\", \"parname\"), variable.name = \"quant\")\nd_fig_0_01[, quant := factor(quant, \n                        levels = c(\"sup\", \"fut_sup\", \"trt_ni_ref\", \"fut_trt_ni_ref\"))]\n# add in the number of pts having reached 12 months post rand by analysis num\nd_fig_0_01 &lt;- merge(d_fig_0_01, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig_0_01 &lt;- rbind(\n  d_fig_0_01[parname == \"b_r\" & quant %in% c(\"sup\", \"fut_sup\"), ],\n  d_fig_0_01[parname == \"b_r1d\" & quant %in% c(\"trt_ni_ref\", \"fut_trt_ni_ref\"), ],\n  d_fig_0_01[parname == \"b_r2d\" & quant %in% c(\"sup\", \"fut_sup\"), ],\n  d_fig_0_01[parname == \"b_f\" & quant %in% c(\"sup\", \"fut_sup\"), ]\n)\n\nd_fig_0_01[, or_tru := g_or_lab[v]]\nd_fig_0_01[, or_tru := factor(\n  or_tru, labels = g_or_lab, levels = g_or_lab)]\n\nfx &lt;- g_fx\nnames(fx) &lt;- c(\"rev vs dair\", \"6-wk vs 12-wk (one)\", \"12-wk vs 7-day (two)\", \"rif vs no-rif\")\nd_fig_0_01[, parname_lab := factor(\n  names(fx[parname]), levels = c(\"rev vs dair\", \"6-wk vs 12-wk (one)\", \"12-wk vs 7-day (two)\", \"rif vs no-rif\")\n  ) ]\n\nd_text &lt;- unique(d_fig_0_01[, .(parname_lab, or_tru, quant)])\nd_text[parname_lab == \"rev vs dair\" & or_tru %in% c(\"OR 1/2\"),\n       `:=`(label = c(\"rev fut (sup)\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"rev vs dair\" & or_tru %in% c(\"OR 2\"),\n       `:=`(label = c(\"rev sup \\nto dair\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"6-wk vs 12-wk (one)\" & or_tru %in% c(\"OR 1/2\"),\n       `:=`(label = c(\"short fut (ni)\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"6-wk vs 12-wk (one)\" & or_tru %in% c(\"OR 2\"),\n       `:=`(label = c(\"short ni \\nto long\"), x = 500, y = 0.2)]\n\n\nd_text[parname_lab == \"12-wk vs 7-day (two)\" & or_tru %in% c(\"OR 1/2\"),\n       `:=`(label = c(\"long fut (sup)\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"12-wk vs 7-day (two)\" & or_tru %in% c(\"OR 2\"),\n       `:=`(label = c(\"long sup \\nto short\"), x = 500, y = 0.2)]\n\nd_text[parname_lab == \"rif vs no-rif\" & or_tru %in% c(\"OR 1/2\"),\n       `:=`(label = c(\"rif fut (sup)\"), x = 500, y = 0.2)]\nd_text[parname_lab == \"rif vs no-rif\" & or_tru %in% c(\"OR 2\"),\n       `:=`(label = c(\"rif sup \\nto no-rif\"), x = 500, y = 0.2)]\n\n\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility (sup)\", \"fut_sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"NI (trt ni ref)\", \"trt_ni_inf\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility (NI)\", \"fut_trt_ni_ref\", names(d_tbl))\n\nd_fig_0_01$quant &lt;- factor(\n  d_fig_0_01$quant, \n  levels = c(\"sup\", \"fut_sup\", \"trt_ni_ref\", \"fut_trt_ni_ref\"),\n  labels = c(\"sup\", \"fut_sup\", \"ni\", \"fut_ni\"))\n\np &lt;- ggplot(d_fig_0_01, aes(x = N_pt, y = value, group = quant, col = quant)) +\n  geom_point(size = 0.5) +\n  geom_line(lwd = 0.4) +\n  geom_hline(yintercept = 0.05, lwd = 0.2) +\n  ggthemes::scale_colour_tableau(\n    \"\", palette = \"Tableau 10\",\n  type = \"regular\",\n  direction = 1) +\n  geom_text(\n    data = d_text,\n    aes(x = x, y = y, label = label),\n    hjust   = 0,\n    vjust   = 0, col = 1, size = 3) +\n  scale_linetype_discrete(\"\") +\n  scale_x_continuous(\"N (12-months post rand)\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Cumulative probability\", breaks = seq(0, 1, by = 0.1)) +\n  facet_grid(parname_lab ~ or_tru)\n\nsuppressWarnings(print(p))\n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\nTable 2 provides the same detail as the above figure, but makes it easier to see what the magnitudes of the cumulate probabilities are.\n\n\nCode\n# Widen data so that power is shown by col with each col corresponding to an\n# analysis\nd_tbl &lt;- d_fig_0_01[quant %in% c(\"sup\", \"fut_sup\", \"ni\", \"fut_ni\")]\nd_tbl &lt;- dcast(d_tbl, parname + or_tru ~ quant + analys, value.var = \"value\")\nd_tbl &lt;- d_tbl[order(or_tru, parname)]\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"parname\") |&gt;\n  fmt_number(\n    columns = everything(),\n    decimals = 2,\n    use_seps = FALSE\n  ) |&gt; \n  tab_spanner(\n    label = html(\"Superiority\"),\n    columns = paste0(\"sup_\", 1:5)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility (sup)\"),\n    columns = c(paste0(\"fut_sup_\", 1:5))\n  ) |&gt;\n  tab_spanner(\n    label = html(\"NI (trt ni ref)\"),\n    columns = paste0(\"ni_\", 1:5)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility (ni)\"),\n    columns = c(paste0(\"fut_ni_\", 1:5))\n  ) |&gt;\n  cols_label(\n    or_tru = html(\"OR (true)\"),\n    sup_1 = html(\"500\"),\n    sup_2 = html(\"1000\"),\n    sup_3 = html(\"1500\"),\n    sup_4 = html(\"2000\"),\n    sup_5 = html(\"2500\"),\n    fut_sup_1 = html(\"500\"),\n    fut_sup_2 = html(\"1000\"),\n    fut_sup_3 = html(\"1500\"),\n    fut_sup_4 = html(\"2000\"),\n    fut_sup_5 = html(\"2500\"),\n    ni_1 = html(\"500\"),\n    ni_2 = html(\"1000\"),\n    ni_3 = html(\"1500\"),\n    ni_4 = html(\"2000\"),\n    ni_5 = html(\"2500\"),\n    fut_ni_1 = html(\"500\"),\n    fut_ni_2 = html(\"1000\"),\n    fut_ni_3 = html(\"1500\"),\n    fut_ni_4 = html(\"2000\"),\n    fut_ni_5 = html(\"2500\")\n  ) |&gt;\n  tab_style(\n    style = cell_borders(\n      sides = c(\"left\"),\n      weight = px(1)),\n    locations = cells_body(\n      # columns = c(sup_1, fut_sup_1, inf_1, fut_inf_1, ni_1, fut_ni_1)\n      columns = c(sup_1, fut_sup_1, ni_1, fut_ni_1)\n      )\n    ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or_tru == \"OR 1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR (true)\nSuperiority\nFutility (sup)\nNI (trt ni ref)\nFutility (ni)\n\n\n500\n1000\n1500\n2000\n2500\n500\n1000\n1500\n2000\n2500\n500\n1000\n1500\n2000\n2500\n500\n1000\n1500\n2000\n2500\n\n\n\n\nb_r\n\n\nOR 1/2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.93\n1.00\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.5\n0.00\n0.00\n0.00\n0.00\n0.00\n0.68\n0.93\n0.99\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.35\n0.63\n0.80\n0.90\n0.95\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1\n0.01\n0.01\n0.02\n0.02\n0.03\n0.15\n0.28\n0.39\n0.48\n0.56\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.2\n0.04\n0.09\n0.14\n0.19\n0.25\n0.04\n0.07\n0.09\n0.11\n0.12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.5\n0.15\n0.38\n0.59\n0.76\n0.86\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 2\n0.45\n0.86\n0.98\n1.00\n1.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_r1d\n\n\nOR 1/2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.00\n0.00\n0.00\n0.00\n0.00\n0.40\n0.75\n0.90\n0.96\n0.99\n\n\nOR 1/1.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.00\n0.00\n0.00\n0.00\n0.00\n0.19\n0.40\n0.57\n0.69\n0.78\n\n\nOR 1/1.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.00\n0.01\n0.01\n0.02\n0.02\n0.07\n0.16\n0.23\n0.30\n0.35\n\n\nOR 1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.02\n0.04\n0.06\n0.10\n0.12\n0.03\n0.06\n0.08\n0.10\n0.11\n\n\nOR 1.2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.04\n0.12\n0.20\n0.28\n0.36\n0.01\n0.01\n0.02\n0.02\n0.02\n\n\nOR 1.5\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.12\n0.29\n0.47\n0.63\n0.76\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\nOR 2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0.22\n0.60\n0.84\n0.95\n0.98\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\nb_r2d\n\n\nOR 1/2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.83\n0.99\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.5\n0.00\n0.00\n0.00\n0.00\n0.00\n0.57\n0.88\n0.97\n0.99\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.30\n0.56\n0.72\n0.83\n0.90\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1\n0.01\n0.02\n0.02\n0.03\n0.03\n0.13\n0.24\n0.33\n0.42\n0.49\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.2\n0.03\n0.07\n0.12\n0.16\n0.20\n0.04\n0.07\n0.09\n0.11\n0.12\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.5\n0.10\n0.28\n0.47\n0.62\n0.75\n0.01\n0.01\n0.01\n0.01\n0.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 2\n0.28\n0.69\n0.92\n0.98\n1.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_f\n\n\nOR 1/2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.98\n1.00\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.5\n0.00\n0.00\n0.00\n0.00\n0.00\n0.80\n0.97\n1.00\n1.00\n1.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1/1.2\n0.00\n0.00\n0.00\n0.00\n0.00\n0.46\n0.75\n0.89\n0.95\n0.98\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1\n0.01\n0.02\n0.02\n0.03\n0.03\n0.18\n0.33\n0.45\n0.55\n0.63\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.2\n0.06\n0.13\n0.21\n0.28\n0.35\n0.04\n0.07\n0.09\n0.10\n0.11\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 1.5\n0.25\n0.52\n0.73\n0.85\n0.93\n0.00\n0.01\n0.01\n0.01\n0.01\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOR 2\n0.62\n0.93\n0.99\n1.00\n1.00\n0.00\n0.00\n0.00\n0.00\n0.00\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTable 2: Cumulative probability of decision\n\n\n\n\nFigure 2 shows the distribution of estimated posterior means by simulated effect size, parameter and sample size.\n\n\n\n\n\n\n\n\nFigure 2: Distribution of posterior means (true log OR shown in red).",
    "crumbs": [
      "Simulations",
      "Simulation results 3"
    ]
  },
  {
    "objectID": "notebooks/trial-data.html",
    "href": "notebooks/trial-data.html",
    "title": "Simulated trial data",
    "section": "",
    "text": "The following give a sense of the number of participants contributing to each treatment arm and cell. The data are simulated under the model specification with a total sample size of 2500.\nCode\nset.seed(1)\nll &lt;- get_trial_data(N = 2500)\n\nd &lt;- copy(ll$d)",
    "crumbs": [
      "Assumptions and setup",
      "Simulated trial data"
    ]
  },
  {
    "objectID": "notebooks/trial-data.html#surgical-domain",
    "href": "notebooks/trial-data.html#surgical-domain",
    "title": "Simulated trial data",
    "section": "Surgical domain",
    "text": "Surgical domain\nOnly patients in the late silo receive randomised surgical treatment (dair vs revision) with the type of revision selected by the clinician. Table 1 shows the allocation to dair vs rev for this cohort and the balance across the remaining group levels in the data.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[l1 == 1 & er == 1, .(er, r, ed, srp, d)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(r, ed, srp, d)]\nd_B &lt;- dcast(d_tmp2, ed + d + srp ~ r, value.var = \"N\")\nd_B[, domain := \"Duration\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", \"surgery\", \"dair\", \"rev\", \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[l1 == 1 & er == 1, .(er, r, ef, srp, f)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(r, ef, srp, f)]\nd_C &lt;- dcast(d_tmp2, ef + f + srp ~ r, value.var = \"N\")\nd_C[, domain := \"Choice\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", \"surgery\", \"dair\", \"rev\", \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C, fill = TRUE)\n# d_tbl[, group := factor(group, levels = c(\"w12\",\"w12p1\", \"w06p1\", \"w12p2\", \"d07p2\", \"other\", \"norif\", \"rif\"))]\nd_tbl &lt;- d_tbl[order(domain, rand, surgery, group)]\n\nd_tbl[, total := rowSums(d_tbl[, .(dair, rev)], na.rm = T)]\nd_tbl[domain == \"Choice\" & rand == 0, group := NA]\nd_tbl[domain == \"Duration\" & rand == 0, group := NA]\n\ncols &lt;- c(\"Domain\", \"Revealed\", \"Treatment\", \"Surgery recvd\", \"DAIR\", \"Revision\", \"Total\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  )  |&gt;\n  tab_spanner(\n    label = html(\"Domain A (late silo)\"),\n    columns = c(dair, rev),\n    id = \"da\"\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols) |&gt; \n  summary_rows(\n    columns = c(\"dair\", \"rev\", \"total\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )  |&gt;\n  tab_footnote(\n    footnote = \"Revealed indicates whether units were randomised into choice/duration domain (0: No, 1: Yes)\",\n    locations = cells_column_labels(columns = rand)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Surgery recvd indicates surgery type actually perfromed (0: dair, 1: one-stage, 2: two-stage). Surgery recvd may deviate from original randomisation/plan.\",\n    locations = cells_column_labels(columns = surgery)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Treatment indicates which treatment assigned within domain. For choice (0: no-rif, 1: rif). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the choice/duration domain have undefined randomised treatment status.\",\n    locations = cells_column_labels(columns = group)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Only units randomised to surgery domain reported.\",\n    locations = cells_column_spanners(spanners = \"da\")\n  )\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRevealed2\nTreatment3\nSurgery recvd4\nDomain A (late silo)1\nTotal\n\n\nDAIR\nRevision\n\n\n\n\nChoice\n\n\n\n0\n-\n0\n253\n-\n253\n\n\n\n0\n-\n1\n-\n77\n77\n\n\n\n0\n-\n2\n-\n178\n178\n\n\n\n1\n0\n0\n198\n-\n198\n\n\n\n1\n1\n0\n182\n-\n182\n\n\n\n1\n0\n1\n-\n68\n68\n\n\n\n1\n1\n1\n-\n56\n56\n\n\n\n1\n0\n2\n-\n121\n121\n\n\n\n1\n1\n2\n-\n142\n142\n\n\nsubtotal\n—\n—\n—\n633\n642\n1275\n\n\nDuration\n\n\n\n0\n-\n0\n633\n-\n633\n\n\n\n1\n0\n1\n-\n91\n91\n\n\n\n1\n1\n1\n-\n110\n110\n\n\n\n1\n0\n2\n-\n224\n224\n\n\n\n1\n1\n2\n-\n217\n217\n\n\nsubtotal\n—\n—\n—\n633\n642\n1275\n\n\n\n1 Only units randomised to surgery domain reported.\n\n\n2 Revealed indicates whether units were randomised into choice/duration domain (0: No, 1: Yes)\n\n\n3 Treatment indicates which treatment assigned within domain. For choice (0: no-rif, 1: rif). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the choice/duration domain have undefined randomised treatment status.\n\n\n4 Surgery recvd indicates surgery type actually perfromed (0: dair, 1: one-stage, 2: two-stage). Surgery recvd may deviate from original randomisation/plan.\n\n\n\n\n\n\n\n\n\nTable 1: Simulated trial data for (late silo) surgical domain - covariate balance across other groups",
    "crumbs": [
      "Assumptions and setup",
      "Simulated trial data"
    ]
  },
  {
    "objectID": "notebooks/trial-data.html#duration-domain",
    "href": "notebooks/trial-data.html#duration-domain",
    "title": "Simulated trial data",
    "section": "Duration domain",
    "text": "Duration domain\nTable 2 shows the allocation to the duration domain conditional on surgery type actually received and the balance across the remaining group levels in the data. Only units randomised within the duration domain are reported.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[ed == 1, .(ed, d, er, r, srp)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(d, er, r,srp)]\n# d_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_B &lt;- dcast(d_tmp2, er + r ~ srp + d, value.var = \"N\")\nd_B[, domain := \"Surgery\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", c(\"long_1\", \"short_1\", \"long_2\", \"short_2\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[ed == 1, .(ed, d, ef, f, srp)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(d, ef, f, srp)]\n# d_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_C &lt;- dcast(d_tmp2, ef + f ~ srp + d, value.var = \"N\")\nd_C[, domain := \"Choice\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", c(\"long_1\", \"short_1\", \"long_2\", \"short_2\"), \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C, fill = T)\n\nd_tbl[, total := rowSums(d_tbl[, .(long_1, short_1, long_2, short_2)], na.rm = T)]\nd_tbl[domain == \"Surgery\" & rand == 0, group := NA]\nd_tbl[domain == \"Choice\" & rand == 0, group := NA]\n\ncols &lt;- c(\"Domain\", \"Revealed\", \"Treatment\", c(\"long\", \"short\", \"long\", \"short\"), \"Total\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt; \n  summary_rows(\n    columns = c(\"long_1\", \"short_1\", \"long_2\", \"short_2\", \"total\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )   |&gt;\n  tab_spanner(\n    label = html(\"AB Duration &lt;br&gt;(one-stage)\"),\n    columns = c(\"long_1\", \"short_1\"),\n    id = \"d1\"\n  ) |&gt;\n  tab_spanner(\n    label = html(\"AB Duration &lt;br&gt;(two-stage)\"),\n    columns = c(\"long_2\", \"short_2\"),\n    id = \"d2\"\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)  |&gt;\n  tab_footnote(\n    footnote = \"Revealed indicates whether units were randomised into surgery/duration domain (0: No, 1: Yes)\",\n    locations = cells_column_labels(columns = rand)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Treatment indicates which treatment assigned within domain. For choice (0: no-rif, 1: rif). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the surgery/choice domain have undefined randomised treatment status.\",\n    locations = cells_column_labels(columns = group)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Only units randomised to interventions in the surgery domain reported. One-stage/two-stage is by clinician selection\",\n    locations = cells_column_spanners(spanners = c(\"d1\", \"d2\"))\n  )\n\n\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRevealed2\nTreatment3\nAB Duration\n(one-stage)1\nAB Duration\n(two-stage)1\nTotal\n\n\nlong\nshort\nlong\nshort\n\n\n\n\nSurgery\n\n\n\n0\n-\n88\n88\n159\n147\n482\n\n\n\n1\n1\n91\n110\n224\n217\n642\n\n\nsubtotal\n—\n—\n179\n198\n383\n364\n1124\n\n\nChoice\n\n\n\n0\n-\n71\n83\n151\n151\n456\n\n\n\n1\n0\n56\n60\n100\n105\n321\n\n\n\n1\n1\n52\n55\n132\n108\n347\n\n\nsubtotal\n—\n—\n179\n198\n383\n364\n1124\n\n\n\n1 Only units randomised to interventions in the surgery domain reported. One-stage/two-stage is by clinician selection\n\n\n2 Revealed indicates whether units were randomised into surgery/duration domain (0: No, 1: Yes)\n\n\n3 Treatment indicates which treatment assigned within domain. For choice (0: no-rif, 1: rif). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the surgery/choice domain have undefined randomised treatment status.\n\n\n\n\n\n\n\n\n\nTable 2: Simulated trial data for AB duration domain - covariate balance across other groups",
    "crumbs": [
      "Assumptions and setup",
      "Simulated trial data"
    ]
  },
  {
    "objectID": "notebooks/trial-data.html#choice-domain",
    "href": "notebooks/trial-data.html#choice-domain",
    "title": "Simulated trial data",
    "section": "Choice domain",
    "text": "Choice domain\nTable 3 shows the allocation to the choice domain and the balance across the remaining group levels in the data. Only units randomised within the antibiotic choice domain are reported.\n\n\nCode\n# domain \nd_tmp1 &lt;- d[ef == 1, .(f, er, r, srp)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(f, er, r, srp)]\n# d_tmp2[, a := factor(a, levels = c(\"dair\", \"rev\", \"one\", \"two\"))]\n# d_tmp2[, qa := factor(qa, levels = c(\"dair\", \"one\", \"two\"))]\n# d_tmp2[, c := factor(c, levels = c(\"other\", \"norif\", \"rif\"))]\nd_A &lt;- dcast(d_tmp2, er + srp + r ~ f, value.var = \"N\")\nd_A[, domain := \"Surgery\"]\ncolnames(d_A) &lt;- c(\"rand\", \"surgery\",\"group\",  c(\"norif\", \"rif\"), \"domain\")\nsetcolorder(d_A, \"domain\")\n# domain\nd_tmp1 &lt;- d[ef == 1, .(f, ed, d, srp)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(f, ed, d, srp)]\n# d_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\n# d_tmp2[, c := factor(c, levels = c(\"other\", \"norif\", \"rif\"))]\nd_B &lt;- dcast(d_tmp2, ed + srp + d ~ f, value.var = \"N\")\nd_B[, domain := \"Duration\"]\ncolnames(d_B) &lt;- c(\"rand\", \"surgery\", \"group\", c(\"norif\", \"rif\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n\nd_tbl &lt;- rbind(d_A, d_B, fill = T)\n\nd_tbl[, total := rowSums(d_tbl[, .(norif, rif)], na.rm = T)]\n\nd_tbl[domain == \"Surgery\" & rand == 0, group := NA]\nd_tbl[domain == \"Duration\" & rand == 0, group := NA]\n\n\n\ncols &lt;- c(\"Domain\", \"Revealed\", \"Surgery recvd\", \"Treatment\", c(\"norif\", \"rif\"), \"Total\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt; \n  summary_rows(\n    columns = c(\"norif\", \"rif\", \"total\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  ) |&gt;\n  tab_spanner(\n    label = html(\"AB Choice\"),\n    columns = c(\"norif\", \"rif\"),\n    id = \"c1\"\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)|&gt;\n  tab_footnote(\n    footnote = \"Revealed indicates whether units were randomised into surgery/choice domain (0: No, 1: Yes)\",\n    locations = cells_column_labels(columns = rand)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Treatment indicates which treatment assigned within domain. For surgery (0: dair, 1: rev). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the surgery/duration domain have undefined randomised treatment status.\",\n    locations = cells_column_labels(columns = group)\n  ) |&gt;\n  tab_footnote(\n    footnote = \"Only units randomised to interventions in the antibiotic choice domain reported.\",\n    locations = cells_column_spanners(spanners = c(\"c1\"))\n  )\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRevealed2\nSurgery recvd\nTreatment3\nAB Choice1\nTotal\n\n\nnorif\nrif\n\n\n\n\nSurgery\n\n\n\n0\n0\n-\n229\n232\n461\n\n\n\n0\n1\n-\n48\n51\n99\n\n\n\n0\n2\n-\n84\n98\n182\n\n\n\n1\n0\n0\n198\n182\n380\n\n\n\n1\n1\n1\n68\n56\n124\n\n\n\n1\n2\n1\n121\n142\n263\n\n\nsubtotal\n—\n—\n—\n748\n761\n1509\n\n\nDuration\n\n\n\n0\n0\n-\n427\n414\n841\n\n\n\n1\n1\n0\n56\n52\n108\n\n\n\n1\n1\n1\n60\n55\n115\n\n\n\n1\n2\n0\n100\n132\n232\n\n\n\n1\n2\n1\n105\n108\n213\n\n\nsubtotal\n—\n—\n—\n748\n761\n1509\n\n\n\n1 Only units randomised to interventions in the antibiotic choice domain reported.\n\n\n2 Revealed indicates whether units were randomised into surgery/choice domain (0: No, 1: Yes)\n\n\n3 Treatment indicates which treatment assigned within domain. For surgery (0: dair, 1: rev). For duration is specific to surgery type received (0: long, 1: short). Units that were not randomised within the surgery/duration domain have undefined randomised treatment status.\n\n\n\n\n\n\n\n\n\nTable 3: Simulated trial data for AB choice domain - covariate balance across other groups",
    "crumbs": [
      "Assumptions and setup",
      "Simulated trial data"
    ]
  },
  {
    "objectID": "notebooks/design-notes-09.html",
    "href": "notebooks/design-notes-09.html",
    "title": "Orthonormal contrasts",
    "section": "",
    "text": "Consider the standard one factor factorial setup where we have a grand mean (as in the mean of the factor level means) and deviations for main effects:\n\\[\n\\begin{aligned}\n\\eta = 1^\\top \\mu + X_a \\alpha + X_b \\alpha + X_c \\gamma\n\\end{aligned}\n\\]\nwhere \\(X_a\\) is the design matrix.\nIt might be tempting setup a design matrix with a column for every parameter, but the OLS solution involves inverting \\(X^\\top X\\) which you cannot do as the rank of \\(X\\) is less than the number of columns in \\(X\\):\nX &lt;- cbind(1, diag(3))\n# in ols, the estimator involves inverting the design matrix\ntryCatch(\n  {\n    solve(t(X)%*%X)\n  } ,\n  error = function(z){\n    message(z, \"\\n\")\n  }\n  \n)\n\nError in solve.default(t(X) %*% X): system is computationally singular: reciprocal condition number = 1.38778e-17\nhowever, if we use the intercept as the reference group (or introduce a sum to zero constraint) then we are fine\nX &lt;- cbind(1, diag(3)[,2:3])\n# in ols, the estimator involves inverting the design matrix\nsolve(t(X)%*%X)\n\n     [,1] [,2] [,3]\n[1,]    1   -1   -1\n[2,]   -1    2    1\n[3,]   -1    1    2\nContrasts define a specific linear combination of parameters and affect their interpretation. When treatment contrasts are adopted with a design matrix that includes main and interaction effects for \\(a\\) with 3 levels and \\(b\\) with 2 levels we have\na &lt;- factor(1:3)\nb &lt;- factor(1:2)\nd &lt;- CJ(a, b)\nX &lt;- model.matrix(~a * b, data = d)\nX\n\n  (Intercept) a2 a3 b2 a2:b2 a3:b2\n1           1  0  0  0     0     0\n2           1  0  0  1     0     0\n3           1  1  0  0     0     0\n4           1  1  0  1     1     0\n5           1  0  1  0     0     0\n6           1  0  1  1     0     1\nattr(,\"assign\")\n[1] 0 1 1 2 3 3\nattr(,\"contrasts\")\nattr(,\"contrasts\")$a\n[1] \"contr.treatment\"\n\nattr(,\"contrasts\")$b\n[1] \"contr.treatment\"\nand for deviation (sum to zero) contrasts, which is what would be used for the anova setup, it would look like\na &lt;- factor(1:3)\nb &lt;- factor(1:2)\nd &lt;- CJ(a, b)\ncontrasts(d$a) &lt;- contr.sum(3)\ncontrasts(d$b) &lt;- contr.sum(2)\nX &lt;- model.matrix(~a * b, data = d)\nX\n\n  (Intercept) a1 a2 b1 a1:b1 a2:b1\n1           1  1  0  1     1     0\n2           1  1  0 -1    -1     0\n3           1  0  1  1     0     1\n4           1  0  1 -1     0    -1\n5           1 -1 -1  1    -1    -1\n6           1 -1 -1 -1     1     1\nattr(,\"assign\")\n[1] 0 1 1 2 3 3\nattr(,\"contrasts\")\nattr(,\"contrasts\")$a\n  [,1] [,2]\n1    1    0\n2    0    1\n3   -1   -1\n\nattr(,\"contrasts\")$b\n  [,1]\n1    1\n2   -1\nFor treatment contrasts, the intercept represents the mean of the reference group, taken to be when \\(a\\) and \\(b\\) are both at their first level. For deviation contrasts the intercept becomes the grand mean, equating to the mean of the group means, not the mean value of the outcome in the dataset.\nWith classic ANOVA, a sum to zero constraint allows us to overcome the rank deficient nature of the design matrix.\nWhen using the treatment contrasts, the second and third levels of \\(a\\) are explicit in the design matrix whereas for the deviation contrasts, the first and second levels appear. For example, with a single factor model:\nK_a &lt;- 4\n# means at levels of a\nb_a &lt;- c(-1, 3, 2, 1)\nN &lt;- 1e6\na &lt;- sample(1:K_a, size = N, replace = T, prob = c(0.3, 0.2, 0.4, 0.1))\nd &lt;- data.table(a = factor(a))\nd[, mu := b_a[a]]\nd[, y := rnorm(.N, mu, 1)]\n\n# sum to zero/deviation contrasts as used for anova\ncontrasts(d$a) &lt;- contr.sum(K_a)\nf1 &lt;- lm(y ~ a, data = d)\nThe coefficients include an intercept and deviations for the first three levels of \\(a\\)\ncoef(f1)\n\n(Intercept)          a1          a2          a3 \n  1.2516178  -2.2501422   1.7469334   0.7508964\nFor the deviation contrasts, the mean for the first level of \\(a\\) is computed as the grand mean, plus the first parameter estimate and similarly for the second and third. The mean for the last level of \\(a\\) is implied as the grand mean minus the sum of the first three terms, hence sum to zero.\nd_new &lt;- CJ(a = factor(1:K_a))\ncontrasts(d_new$a) &lt;-  contr.sum(K_a)\nX &lt;- model.matrix(~a, data = d_new)\nX\n\n  (Intercept) a1 a2 a3\n1           1  1  0  0\n2           1  0  1  0\n3           1  0  0  1\n4           1 -1 -1 -1\nattr(,\"assign\")\n[1] 0 1 1 1\nattr(,\"contrasts\")\nattr(,\"contrasts\")$a\n  [,1] [,2] [,3]\n1    1    0    0\n2    0    1    0\n3    0    0    1\n4   -1   -1   -1\nand \\(\\sum_{i=1}^{K_a} \\alpha_i = 0\\) which we can derive empirically by calculating the all K_a group means, subtracting the grand mean from each and taking the sum:\n(mu_a_hat &lt;- t(model.matrix(~a, data = d_new) %*% coef(f1)))\n\n              1        2        3       4\n[1,] -0.9985244 2.998551 2.002514 1.00393\n\nrbind(\n  tru = b_a,\n  estimate = as.numeric(round(mu_a_hat, 3))\n)\n\n           [,1]  [,2]  [,3]  [,4]\ntru      -1.000 3.000 2.000 1.000\nestimate -0.999 2.999 2.003 1.004\nwhich sum to zero:\nCode\nround(sum(mu_a_hat - coef(f1)[1]), 3)  \n\n\n[1] 0\nThe above creates an inconvenience for the Bayesian who would like to (i) play frequentist in their insistence with differentiating fixed from random effects and (ii) place equal prior weights to each group of parameters. We could (and often do) respond to this by fixing the reference parameter at zero to overcome the identification issue, but that also puts a different prior weight on this reference parameter in relation to the other parameters within the group. An alternative to arbitrarily fixing one of the factor level parameters to zero is to project the \\(K_a\\) dimension parameter space associated with the first factor into a \\(K_a - 1\\) dimensional space in a way that will enforce the same marginal prior on all \\(K_a\\) terms.\nThe way that the sum-to-zero constraint is achieved is by placing a prior that has a negative correlation across the effects:\n\\[\n\\begin{aligned}\n\\Sigma_a = \\mathbb{I}_a - J_a / K_a\n\\end{aligned}\n\\]\nwhere \\(J_a\\) is a matrix of ones of dimension \\(K_a \\times K_a\\), leading to, for example, a covariance matrix such as the following:\n# group levels\nK_a &lt;- 3\nJ &lt;- matrix(1, K_a, K_a)\nS_a &lt;- diag(K_a) - J / K_a\n# cov2cor(S_a)\nS_a\n\n           [,1]       [,2]       [,3]\n[1,]  0.6666667 -0.3333333 -0.3333333\n[2,] -0.3333333  0.6666667 -0.3333333\n[3,] -0.3333333 -0.3333333  0.6666667\nwhere again we are just considering a single factor at the moment. As a test, we can generate draws from a multivariate normal distribution using this covariance matrix and observe that they will sum to zero:\nu &lt;- mvtnorm::rmvnorm(3, rep(0, K_a), S_a)\n# final column is the sum of the draws:\nround(cbind(u, rowSums(u)), 3)\n\n       [,1]  [,2]   [,3] [,4]\n[1,] -0.277 0.944 -0.667    0\n[2,] -0.748 0.464  0.284    0\n[3,]  0.631 0.450 -1.082    0\n\\(\\Sigma_a\\) is not full rank, but it can be decomposed using its set of the eigenvectors. Since \\(\\Sigma_a\\) is rank \\(K_a - 1 = 2\\), there will only be two non-zero eigenvalues. Both of the eigenvalues are equal to 1. Below, we construct \\(\\Sigma_a\\) as the product of \\(Q_a\\) and \\(\\Lambda\\) where \\(Q_a\\) is a matrix formed from \\(K_a - 1\\) eigenvectors that correspond to the non-zero eigenvalues of \\(\\Sigma_a\\). In this setting, \\(\\Lambda = \\mathbb{I}_{K_a - 1}\\).\n# for symmetric matrices, svd equiv to eigen\n# eigen values are sorted in decreasing order so we drop the last one\nsvd_S_a &lt;- svd(S_a)\n# eigenvectors\nQ_a &lt;- svd_S_a$v\nQ_a &lt;- Q_a[, 1:(K_a - 1)]\n# original setup for S_a\nQ_a %*% diag(K_a - 1) %*% t(Q_a)\n\n           [,1]       [,2]       [,3]\n[1,]  0.6666667 -0.3333333 -0.3333333\n[2,] -0.3333333  0.6666667 -0.3333333\n[3,] -0.3333333 -0.3333333  0.6666667\nThis allows us to define a new vector of \\(K_a - 1\\) parameters \\(\\alpha^*\\):\n\\[\n\\begin{aligned}\n\\alpha^* = Q_a^\\top \\alpha\n\\end{aligned}\n\\]\nthat sum to zero due to \\(Q_a\\):\nround(t(Q_a), 3)\n\n       [,1]   [,2]  [,3]\n[1,] -0.816  0.408 0.408\n[2,]  0.000 -0.707 0.707\nThe \\(Q_a\\) defines the contrasts that are orthonormal and allow us to identify the \\(K_a - 1\\) parameters.\nArmed with the above, we can now take our original tempting setup for the design matrix (i.e. with a column for every parameter) and convert it to a new design matrix that maps \\(\\alpha^*\\) into the observations:\n(X &lt;- diag(K_a) )\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n\n(X_star &lt;- cbind(X %*% Q_a))\n\n           [,1]          [,2]\n[1,] -0.8164966  4.108230e-17\n[2,]  0.4082483 -7.071068e-01\n[3,]  0.4082483  7.071068e-01\nTo go from the parameters in their original space to the parameters in the reduced dimensional space and back again:\nCode\n# original parameters constrained to sum to zero\nb_a &lt;- c(-1, 0.75, 0.25)\n# representation in lower dimensional space\nb_a_star &lt;- t(Q_a) %*% b_a\n\n# transformed back to b_a\nX_star %*% b_a_star \n\n\n      [,1]\n[1,] -1.00\n[2,]  0.75\n[3,]  0.25\nAn implementation for the single factor case follows:\nget_data &lt;- function(\n    N = 100,\n    K_a = 3,\n    mu = 1,\n    b_a = c(-1, 0.25, 0.75)\n    ){\n  \n  a = sample(1:K_a, size = N, replace = T)\n  d &lt;- data.table(a)\n  d[, eta := mu + b_a[a]]\n  d[, y := rbinom(N, 1, plogis(eta))]\n  \n  # saturated design matrix\n  X_a &lt;- diag(K_a)\n  \n  # correlation matrix to enforce sum to zero\n  J &lt;- matrix(1, K_a, K_a)\n  S_a &lt;- diag(K_a) - J / K_a \n  \n  # decomposition\n  # eigen vectors\n  Q_a &lt;- eigen(S_a)$vector[, 1:(K_a - 1)]\n\n  # full rank design\n  X_a_s &lt;- X_a %*% Q_a\n  \n  list(\n    d = d, K_a = K_a, \n    mu = mu, b_a = b_a,\n    X_a = X_a, X_a_s = X_a_s,\n    S_a = S_a, Q_a = Q_a\n  )\n}\nLogistic regression\n// Model for:\n// independent estimates of treatment arm by subgroup means\ndata {\n  int N;\n  array[N] int y;\n  // arm index\n  array[N] int x1trt;\n  // dimension of design matrix\n  int ncX1des;\n  int nrX1des;\n  matrix[nrX1des, ncX1des] X1des;\n  vector[ncX1des] sx1;\n  int prior_only;\n}\ntransformed data {\n  // build full design matrices\n  matrix[N, ncX1des] X1 = X1des[x1trt];\n}\nparameters{\n  real mu;\n  vector[ncX1des] bx1;\n}\ntransformed parameters{ \n  vector[N] eta = mu + X1*bx1;\n}\nmodel{\n  target += logistic_lpdf(mu | 0, 1);\n  target += normal_lpdf(bx1 | 0, sx1);\n  \n  if(!prior_only){\n    target += bernoulli_logit_lpmf(y | eta);  \n  }\n}\ngenerated quantities{\n}\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/note-09-logistic.stan\")\n\nl1 &lt;- get_data(\n  N = 1e4, K_a = 5, mu = 0.5, \n  b_a = c(-2, -1, 0, 1, 2)\n  )\n\n# would be more efficient to transform into a binomial likelihood\n# but keeping bernoulli for now since it allows me to think about\n# unit level data (not sure if that will be necessary though)\nld &lt;- list(\n  N = length(l1$d$y),\n  y = l1$d$y,\n  # \n  x1trt = l1$d$a,\n  nrX1des = nrow(l1$X_a_s), ncX1des = ncol(l1$X_a_s),\n  X1des = l1$X_a_s,\n  sx1 = rep(1, ncol(l1$X_a_s)),\n  prior_only = 1\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 7.4 seconds.\nChain 2 finished in 7.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 7.4 seconds.\nTotal execution time: 7.6 seconds.\n\n\nCode\nf1$summary(variables = c(\"mu\", \"bx1\"))\n\n\n# A tibble: 5 × 10\n  variable     mean  median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;       &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 mu        0.0259   0.0287 1.85  1.66  -3.01  2.98  1.00    6461.    3808.\n2 bx1[1]   -0.0156  -0.0168 0.987 0.974 -1.65  1.60  1.00    7850.    4549.\n3 bx1[2]    0.00187 -0.0102 0.997 1.00  -1.64  1.67  1.00    7005.    4648.\n4 bx1[3]    0.0188   0.0365 1.01  1.00  -1.64  1.67  1.00    7067.    4657.\n5 bx1[4]    0.00256  0.0142 0.997 0.995 -1.65  1.59  1.00    6849.    4678.\nTo transform the parameter estimates back to the group means that we are interested in, we need to compute the product of the parameters and the unique entries from the design matrix.\nIn theory, these should all have the same prior weight, which appears to be the case as shown below, Figure 1:\nPriors on group offsets\nm_post_s &lt;- f1$draws(variables = c(\"bx1\"), format = \"matrix\")\npost_mu &lt;- m_post_s %*% t(cbind(l1$X_a_s))\n\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a)))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  facet_wrap(~variable, ncol = 1) \n\n\n\n\n\n\n\n\nFigure 1: Priors on group means\nRun the model to see if we get close to the known (true) parameters although they won’t be immediately apparent from the summary:\nCode\nld$prior_only &lt;- 0\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 7.9 seconds.\nChain 2 finished in 7.9 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 7.9 seconds.\nTotal execution time: 8.0 seconds.\n\n\nCode\n# these are the parameters in the reduced dimensional space\nf1$summary(variables = c(\"mu\", \"bx1\"))\n\n\n# A tibble: 5 × 10\n  variable   mean median     sd    mad     q5    q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 mu        0.499  0.499 0.0270 0.0270  0.454  0.542  1.00    3864.    3119.\n2 bx1[1]   -0.844 -0.843 0.0482 0.0482 -0.923 -0.765  1.00    4362.    3147.\n3 bx1[2]    1.26   1.26  0.0757 0.0756  1.14   1.39   1.00    2991.    2834.\n4 bx1[3]   -2.28  -2.28  0.0597 0.0596 -2.38  -2.18   1.00    4214.    3002.\n5 bx1[4]   -1.66  -1.66  0.0554 0.0550 -1.75  -1.57   1.00    3849.    3379.\nObviously, the results won’t align exactly with the true values, but they should be somewhere close, see Figure 2:\nParameter posterior density\nm_post_s &lt;- f1$draws(variables = c(\"mu\", \"bx1\"), format = \"matrix\")\npost_mu &lt;- m_post_s %*% t(cbind(1, l1$X_a_s))\n\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a)))]\n\nd_tru &lt;- data.table(\n  a = 1:l1$K_a\n)\nd_tru[, eta := l1$mu + l1$b_a[a]]\nd_tru[, variable := factor(paste0(\"V\", a))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru, \n              aes(xintercept = eta), col = 2,\n              lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(breaks = seq(-3, 3, by = 0.5))\n\n\n\n\n\n\n\n\nFigure 2: Parameter estimates for group level means\nParameter posterior density\nm_post_s &lt;- f1$draws(variables = c(\"bx1\"), format = \"matrix\")\npost_mu &lt;- m_post_s %*% t(cbind(l1$X_a_s))\n\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a)))]\n\nd_tru &lt;- data.table(\n  a = 1:l1$K_a\n)\nd_tru[, eta := l1$b_a[a]]\nd_tru[, variable := factor(paste0(\"V\", a))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru, \n              aes(xintercept = eta), col = 2,\n              lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1) +\n  scale_x_continuous(breaks = seq(-3, 3, by = 0.5))\n\n\n\n\n\n\n\n\nFigure 3: Parameter estimates for group level offsets",
    "crumbs": [
      "Design notes",
      "Orthonormal contrasts"
    ]
  },
  {
    "objectID": "notebooks/design-notes-09.html#two-factor-setup",
    "href": "notebooks/design-notes-09.html#two-factor-setup",
    "title": "Orthonormal contrasts",
    "section": "Two-factor setup",
    "text": "Two-factor setup\nHere we have two main effects and their associated interactions. I have kept this first implementation as a record of my initial mistake on columnwise vs rowwise specification of the interaction parameters. The implementation in the final section is the correct approach.\n\n\nRevised data generation function\nN = 100\nK_a = 3\nK_b = 2\nb0 = 1\n# effects are sum to zero\nb_a = c(0, -1, 1)\nb_b = c(-0.6, 0.6)\nb_ab = c(-0.05, 0.15, -0.1, 0.05, -0.15,  0.1)\n# b_ab = c(-0.05, 0.05, 0.15, -0.15,  0.1, -0.1)\n\nget_data &lt;- function(\n    N = 100,\n    K_a = 3,\n    K_b = 2,\n    b0 = 1,\n    # effects are sum to zero\n    b_a = c(0, -1, 1),\n    b_b = c(-0.6, 0.6),\n    b_ab = c(-0.05, 0.15, -0.1, 0.05, -0.15,  0.1)\n    # b_ab = c(-0.05, 0.05, 0.15, -0.15,  0.1, -0.1)\n    ){\n  \n  stopifnot(all.equal(0, sum(b_a), \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(0, sum(b_b), \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(0, sum(b_ab), \n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  # cols and rows should sum to zero otherwise following will not work\n  b_ab_matrix &lt;- matrix(b_ab, nrow = K_a, ncol = K_b)\n  stopifnot(all.equal(colSums(b_ab_matrix), rep(0, K_b),\n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(rowSums(b_ab_matrix), rep(0, K_a),\n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  # we could go down this avenue but the original parameters would never be \n  # recovered.\n  # b_ab_centered &lt;- b_ab_matrix -\n  #   rowMeans(b_ab_matrix) -\n  #   rep(colMeans(b_ab_matrix), each = K_a) +\n  #   mean(b_ab_matrix)\n  # b_ab_centered &lt;- as.vector(b_ab_centered)\n  \n  a = sample(1:K_a, size = N, replace = T)\n  b = sample(1:K_b, size = N, replace = T)\n  d &lt;- data.table(a, b)\n  \n  d[, b0 := b0]\n  d[, b_a := b_a[a]]\n  d[, b_b := b_b[b]]\n  d[, ix_b_ab := a + (K_a * (b - 1))]\n  d[, b_ab := b_ab[ix_b_ab]]\n  d[, eta := b0 + b_a + b_b + b_ab]\n\n  # e.g.  \n#   &gt; unique(d[order(b, a)])\n#        a     b    b0   b_a   b_b  b_ab   eta\n#    &lt;int&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n# 1:     1     1     1     0  -0.6  -0.2   0.2\n# 2:     2     1     1    -1  -0.6   0.0  -0.6\n# 3:     3     1     1     1  -0.6   0.6   2.0\n# 4:     1     2     1     0   0.4  -0.4   1.0\n# 5:     2     2     1    -1   0.4   0.2   0.6\n# 6:     3     2     1     1   0.4  -0.2   2.2\n  \n  cols_a &lt;- paste0(\"a\", 1:K_a)\n  cols_b &lt;- paste0(\"a\", 1:K_b)\n  cols_c &lt;- unique(d[order(b, a), paste0(\"a\",a,\"b\",b)])\n  \n  d[, y := rbinom(N, 1, plogis(eta))]\n  \n  # saturated design matrix\n  X_a &lt;- diag(K_a)\n  colnames(X_a) &lt;- cols_a\n  X_b &lt;- diag(K_b)\n  colnames(X_b) &lt;- cols_b\n  X_ab &lt;- diag(K_a * K_b)\n  colnames(X_ab) &lt;- cols_c\n\n  # correlation matrix to enforce sum to zero\n  S_a &lt;- diag(K_a) - (1 / K_a )\n  S_b &lt;- diag(K_b) - (1 / K_b )\n  S_ab &lt;- kronecker(S_a, S_b)\n  # should be rank 2 for a 1:3, b 1:2\n  # pracma::Rank(S_ab)\n  \n  # decomposition eigen vectors\n  Q_a &lt;- eigen(S_a)$vector[, 1:(K_a - 1)]\n  Q_b &lt;- eigen(S_b)$vector[, 1:(K_b - 1)]\n  # Q_ab &lt;- kronecker(Q_a, Q_b)\n  \n  # Ok, Q_ab as defined above will not allow me to recover the original\n  # paramters. Why this is I do not know. The following is a workaround.\n  \n  # All we are doing is building a matrix that will sum up the \n  # columns and the rows of the interaction parameters.\n  # We will then set that to zero and solve (i.e. compute the\n  # null space).\n  C_ab &lt;- construct_C_ab(K_a, K_b)\n\n  # Calculate the null space of C_ab\n  # Nullspace of C_ab gives the set of vectors st each vector\n  # in Q_ab results in C_ab v = 0\n  Q_ab &lt;- pracma::nullspace(C_ab)\n  \n  # transformed pars\n  b_a_s &lt;- t(Q_a) %*% b_a\n  b_b_s &lt;- t(Q_b) %*% b_b\n  b_ab_s &lt;- t(Q_ab) %*% b_ab\n\n  # full rank design\n  X_a_s &lt;- X_a %*% Q_a\n  X_b_s &lt;- X_b %*% Q_b\n  X_ab_s &lt;- X_ab %*% Q_ab\n\n  X_full_s &lt;- create_full_design(X_a_s, X_b_s, X_ab_s)\n  # round(X_full_s, 3)\n   \n  # Check\n  stopifnot(all.equal(as.numeric(X_a_s %*% b_a_s), b_a, \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(as.numeric(X_b_s %*% b_b_s), b_b, \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(as.numeric(X_ab_s %*% b_ab_s), b_ab, \n                      tolerance = sqrt(.Machine$double.eps)))\n  \n\n  list(\n    d = d, b0 = b0, \n    b_a = b_a, b_b = b_b, b_ab = b_ab, \n    b_a_s = b_a_s, b_b_s = b_b_s, b_ab_s = b_ab_s, \n    \n    K_a = K_a, K_b = K_b, \n    X_a = X_a, X_a_s = X_a_s, \n    X_b = X_b, X_b_s = X_b_s, \n    X_ab = X_ab, X_ab_s = X_ab_s, \n    X_full_s = X_full_s,\n    \n    S_a = S_a, S_b = S_b, S_ab = S_ab, \n    C_ab = C_ab, Q_a = Q_a, Q_b = Q_b, Q_ab = Q_ab \n  )\n}\n\n\nWe need some utility functions to stop this getting too messy.\n\n\nUtility functions\n# Utility function to create combinations of parameters (all columns and \n# all rows) that should sum to zero.\nconstruct_C_ab &lt;- function(K_a, K_b) {\n  # Total number of interaction parameters\n  n_params &lt;- K_a * K_b\n  \n  # Number of constraints\n  n_constraints &lt;- K_a + K_b\n  \n  # Initialize C_ab matrix\n  C_ab &lt;- matrix(0, nrow = n_constraints, ncol = n_params)\n  \n  # Constraints for factor b (columns)\n  for (j in 1:K_b) {\n    col_indices &lt;- ((j - 1) * K_a + 1):(j * K_a)\n    C_ab[j, col_indices] &lt;- 1\n  }\n\n  # Constraints for factor a (rows)\n  for (i in 1:K_a) {\n    row_indices &lt;- seq(i, n_params, by = K_a)\n    C_ab[K_b + i, row_indices] &lt;- 1\n  }\n  return(C_ab)\n}\n\n# Utility function to create full design matrix from constrained space.\ncreate_full_design &lt;- function(X_a_s, X_b_s, X_ab_s) {\n  \n  K_a &lt;- nrow(X_a_s)\n  K_b &lt;- nrow(X_b_s)\n  n_a &lt;- ncol(X_a_s)\n  n_b &lt;- ncol(X_b_s)\n  n_ab &lt;- ncol(X_ab_s)\n\n  # Create all combinations\n  design &lt;- expand.grid(a = 1:K_a, b = 1:K_b)\n  \n  # Add intercept and main effects\n  X_main &lt;- cbind(1, \n                  X_a_s[design$a, ],\n                  X_b_s[design$b, ])\n  \n  # Create interaction effects\n  X_int &lt;- X_ab_s[(design$b - 1) * K_a + design$a, , drop = FALSE]\n  \n  # it looks like we can just zero out interaction when main effect is zero\n  # so that we have a logical design matrix, i.e. if some of the main factors \n  # are set to zero then the interaction should also be.\n  # for (i in 1:n_a) {\n  #   for (j in 1:n_b) {\n  #     int_col &lt;- (i - 1) * n_b + j\n  #     X_int[X_main[, 1 + i] == 0 | X_main[, 1 + n_a + j] == 0, int_col] &lt;- 0\n  #   }\n  # }\n  \n  # Combine all effects\n  X_full &lt;- cbind(X_main, X_int)\n  \n  return(X_full)\n}\n\n# Utility to create random parameter values that sum to zero\ncreate_sum_zero_matrix &lt;- function(n_rows, n_cols, sd = 1, seed = 1) {\n  \n  set.seed(seed)\n  # Step 1: Generate random values\n  mat &lt;- matrix(rnorm(n_rows * n_cols, sd = sd), nrow = n_rows, ncol = n_cols)\n  \n  # Step 2: Center columns\n  mat &lt;- scale(mat, center = TRUE, scale = FALSE)\n  \n  # Step 3: Center rows\n  mat &lt;- t(scale(t(mat), center = TRUE, scale = FALSE))\n  \n  # Step 4: Final adjustment to ensure exact zero sums\n  col_adj &lt;- colSums(mat) / n_rows\n  row_adj &lt;- rowSums(mat) / n_cols\n  \n  for (i in 1:n_rows) {\n    for (j in 1:n_cols) {\n      mat[i,j] &lt;- mat[i,j] - col_adj[j] - row_adj[i] + mean(col_adj)\n    }\n  }\n  \n  return(mat)\n}\n\n\n# Utility to create random parameter values that sum to zero\ncreate_sum_zero_vec &lt;- function(n = 3, sd = 1, seed = 1) {\n  \n  set.seed(seed)\n  \n  v &lt;- scale(rnorm(n, 0, sd), center = TRUE, scale = FALSE)\n  \n  return(as.numeric(v))\n}\n\n\nDo some tests to see if the data generation process makes sense.\nNot sure that these matrices are logical in terms of the products of the various factors…\n\n\n2x2 constrained design matrix\nK_a = 2\nK_b = 2\nb0 = 1\nb_a = create_sum_zero_vec(n = K_a, seed = 1)\nb_b = create_sum_zero_vec(n = K_b, seed = 2)\nb_ab = as.numeric(create_sum_zero_matrix(K_a, K_b, seed = 3))\n\nl1 &lt;- get_data(\n  N = 100, K_a = K_a, K_b = K_b, \n  b0 = b0, b_a = b_a, b_b = b_b, b_ab = b_ab\n)\n# 2 x 2\nround(l1$X_full_s, 2)\n\n\n     [,1]  [,2]  [,3] [,4]\n[1,]    1 -0.71 -0.71  0.5\n[2,]    1  0.71 -0.71 -0.5\n[3,]    1 -0.71  0.71 -0.5\n[4,]    1  0.71  0.71  0.5\n\n\n\n\n4x2 constrained design matrix\nK_a = 4\nK_b = 2\nb0 = 1\nb_a = create_sum_zero_vec(n = K_a, seed = 4)\nb_b = create_sum_zero_vec(n = K_b, seed = 5)\nb_ab = as.numeric(create_sum_zero_matrix(K_a, K_b, seed = 6))\n\nl1 &lt;- get_data(\n  N = 100, K_a = K_a, K_b = K_b, \n  b0 = b0, b_a = b_a, b_b = b_b, b_ab = b_ab\n)\n# 4 x 2\nround(l1$X_full_s, 2)\n\n\n     [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]\n[1,]    1  0.00  0.00  0.87 -0.71  0.17  0.51  0.29\n[2,]    1 -0.58 -0.58 -0.29 -0.71 -0.61  0.00 -0.07\n[3,]    1 -0.21  0.79 -0.29 -0.71  0.17 -0.49  0.32\n[4,]    1  0.79 -0.21 -0.29 -0.71  0.27 -0.02 -0.55\n[5,]    1  0.00  0.00  0.87  0.71 -0.17 -0.51 -0.29\n[6,]    1 -0.58 -0.58 -0.29  0.71  0.61  0.00  0.07\n[7,]    1 -0.21  0.79 -0.29  0.71 -0.17  0.49 -0.32\n[8,]    1  0.79 -0.21 -0.29  0.71 -0.27  0.02  0.55\n\n\n\n\n3x5 constrained design matrix\nK_a = 3\nK_b = 4\nb0 = 1\nb_a = create_sum_zero_vec(n = K_a, seed = 6)\nb_b = create_sum_zero_vec(n = K_b, seed = 7)\nb_ab = as.numeric(create_sum_zero_matrix(K_a, K_b, seed = 8))\n\nl1 &lt;- get_data(\n  N = 100, K_a = K_a, K_b = K_b, \n  b0 = b0, b_a = b_a, b_b = b_b, b_ab = b_ab\n)\n# 4 x 2\nround(l1$X_full_s, 2)\n\n\n      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11] [,12]\n [1,]    1  0.00  0.82  0.00  0.00  0.87 -0.10  0.45  0.30 -0.21  0.34  0.19\n [2,]    1 -0.71 -0.41  0.00  0.00  0.87  0.47 -0.17  0.20  0.24 -0.39 -0.03\n [3,]    1  0.71 -0.41  0.00  0.00  0.87 -0.37 -0.29 -0.50 -0.03  0.05 -0.16\n [4,]    1  0.00  0.82 -0.58 -0.58 -0.29 -0.07 -0.12  0.03 -0.41 -0.46 -0.31\n [5,]    1 -0.71 -0.41 -0.58 -0.58 -0.29 -0.33 -0.25  0.07  0.12  0.21  0.52\n [6,]    1  0.71 -0.41 -0.58 -0.58 -0.29  0.40  0.37 -0.10  0.29  0.26 -0.21\n [7,]    1  0.00  0.82 -0.21  0.79 -0.29  0.42 -0.33 -0.33 -0.02  0.23  0.23\n [8,]    1 -0.71 -0.41 -0.21  0.79 -0.29 -0.23  0.54 -0.30 -0.01 -0.24 -0.08\n [9,]    1  0.71 -0.41 -0.21  0.79 -0.29 -0.18 -0.21  0.63  0.04  0.01 -0.15\n[10,]    1  0.00  0.82  0.79 -0.21 -0.29 -0.25  0.00  0.00  0.64 -0.11 -0.11\n[11,]    1 -0.71 -0.41  0.79 -0.21 -0.29  0.10 -0.13  0.03 -0.35  0.43 -0.41\n[12,]    1  0.71 -0.41  0.79 -0.21 -0.29  0.15  0.13 -0.03 -0.30 -0.32  0.52\n\n\nThe model now splits up the design into three separate matrices so that we can look to recover each grouping of parameters. Also, I convert to a binomial likelihood to speed things up.\n\n\nLogistic regression\n// Model for:\n// independent estimates of treatment arm by subgroup means\ndata {\n  int N;\n  array[N] int y;\n  array[N] int n;\n  // arm index\n  array[N, 3] int trt;\n  // factor 1 design matrix\n  int ncXades;\n  int nrXades;\n  matrix[nrXades, ncXades] Xades;\n  vector[ncXades] sa;\n  // factor 2 design matrix\n  int ncXbdes;\n  int nrXbdes;\n  matrix[nrXbdes, ncXbdes] Xbdes;\n  vector[ncXbdes] sb;\n  // factor 1/2 interaction design matrix\n  int ncXabdes;\n  int nrXabdes;\n  matrix[nrXabdes, ncXabdes] Xabdes;\n  vector[ncXabdes] sab;\n  \n  int prior_only;\n}\ntransformed data {\n  // build full design matrices\n  matrix[N, ncXades] Xa = Xades[trt[,1]];\n  matrix[N, ncXbdes] Xb = Xbdes[trt[,2]];\n  // indexes the relevant col in the design matrix\n  matrix[N, ncXabdes] Xab = Xabdes[trt[,3]];\n}\nparameters{\n  real mu;\n  vector[ncXades] ba;  \n  vector[ncXbdes] bb;\n  vector[ncXabdes] bab;\n}\ntransformed parameters{ \n  vector[N] eta = mu + Xa*ba + Xb*bb + Xab*bab;\n}\nmodel{\n  target += logistic_lpdf(mu | 0, 1);\n  target += normal_lpdf(ba | 0, sa);\n  target += normal_lpdf(bb | 0, sb);\n  target += normal_lpdf(bab | 0, sab);\n  \n  if(!prior_only){\n    // target += bernoulli_logit_lpmf(y | eta);  \n    target += binomial_logit_lpmf(y | n, eta);  \n  }\n}\ngenerated quantities{\n}\n\n\n\nTwo-factor (3 x 2)\nFit the model without the likelihood involved to examine the implied priors.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/note-09-logistic-2.stan\")\n\nl1 &lt;- get_data(\n  N = 1e6, K_a = 3, K_b = 2, \n  b0 = 1,   b_a = c(0, -1, 1), b_b = c(-0.4, 0.4),\n  # has to have all rows, all cols sum to zero if you \n  # want to target recovering parameters.\n  b_ab = c(-0.05, 0.15, -0.1, 0.05, -0.15,  0.1)\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 1\n)\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.1 seconds.\n\n\nCode\nf1$summary(variables = c(\"mu\", \"ba\", \"bb\", \"bab\"))\n\n\n# A tibble: 6 × 10\n  variable     mean   median    sd   mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 mu       -0.00680  0.00949 1.83  1.59  -3.07  3.06  1.00    8006.    4149.\n2 ba[1]    -0.0157  -0.0173  1.00  0.998 -1.65  1.62  1.00    8398.    4477.\n3 ba[2]    -0.00834 -0.0232  0.976 0.977 -1.62  1.63  1.00    8236.    4753.\n4 bb[1]    -0.00215  0.0134  1.00  1.01  -1.66  1.66  1.00    8462.    4937.\n5 bab[1]   -0.0149  -0.0111  1.01  1.00  -1.66  1.68  1.00    9257.    4619.\n6 bab[2]    0.00843  0.0218  1.03  1.02  -1.71  1.67  1.00    7462.    4568.\n\n\n\n\nPriors on group means\nm_post_s &lt;- f1$draws(variables = c(\"mu\", \"ba\", \"bb\", \"bab\"), format = \"matrix\")\n\n\nX_s &lt;- cbind(l1$X_a_s[rep(1:l1$K_a, each = 2),], \n             l1$X_b_s[rep(1:l1$K_b, len = l1$K_a * l1$K_b),], \n             l1$X_ab_s)\npost_mu &lt;- m_post_s %*% t(cbind(1, X_s))\n\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a * l1$K_b)))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  facet_wrap(~variable, ncol = 1) \n\n\n\n\n\n\n\n\nFigure 4: Priors on group means for all cells\n\n\n\n\n\nAnd now look at the parameter estimates.\n\n\nCode\nld$prior_only &lt;- 0\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.1 seconds.\n\n\n\n\nCode\nf1$summary(variables = c(\"mu\", \"ba\", \"bb\", \"bab\"))\n\n\n# A tibble: 6 × 10\n  variable     mean   median      sd     mad       q5      q95  rhat ess_bulk\n  &lt;chr&gt;       &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 mu        1.00     1.00    0.00251 0.00255  0.996    1.00     1.00    4747.\n2 ba[1]     1.42     1.42    0.00451 0.00446  1.41     1.42     1.00    3642.\n3 ba[2]    -0.00149 -0.00150 0.00433 0.00435 -0.00865  0.00560  1.00    4175.\n4 bb[1]     0.559    0.559   0.00358 0.00363  0.553    0.565    1.00    4302.\n5 bab[1]   -0.260   -0.260   0.00548 0.00548 -0.269   -0.251    1.00    4082.\n6 bab[2]    0.0598   0.0599  0.00684 0.00688  0.0484   0.0709   1.00    3558.\n# ℹ 1 more variable: ess_tail &lt;dbl&gt;\n\n\nChecking the recovery of the original parameters, it looks like we got somewhere near to the original values we used.\n\n\nParameter posterior density for first factor\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_mu &lt;- m_post_s %*% t(l1$X_a_s)\n\n# colMeans(post_mu)\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:l1$K_a))]\n\nd_tru &lt;- data.table(b_a = l1$b_a)\nd_tru[, variable := paste0(\"V\", 1:l1$K_a)]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru,\n             aes(xintercept = b_a), col = 2,\n             lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 5: Parameter posterior density for first factor\n\n\n\n\n\n\n\nParameter posterior density for second factor\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_mu &lt;- m_post_s %*% t(l1$X_b_s)\n\n# colMeans(post_mu)\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:l1$K_b))]\n\nd_tru &lt;- data.table(b_a = l1$b_b)\nd_tru[, variable := paste0(\"V\", 1:l1$K_b)]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru,\n             aes(xintercept = b_a), col = 2,\n             lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 6: Parameter posterior density for second factor\n\n\n\n\n\n\n\nParameter posterior density for interaction\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_mu &lt;- m_post_s %*% t(l1$X_ab_s)\n\n# colMeans(post_mu)\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a * l1$K_b)))]\n\nd_tru &lt;- data.table(b_ab = l1$b_ab)\nd_tru[, variable := paste0(\"V\", 1:(l1$K_a * l1$K_b))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru,\n             aes(xintercept = b_ab), col = 2,\n             lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 7: Parameter posterior density for interaction\n\n\n\n\n\n\n\nParameter posterior density group means\nm_post_s &lt;- f1$draws(variables = c(\"mu\", \"ba\", \"bb\", \"bab\"), format = \"matrix\") \npost_mu &lt;- m_post_s %*% t(l1$X_full_s)\n\n# colMeans(post_mu)\nd_fig &lt;- data.table(post_mu)\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\nd_fig[, variable := factor(\n  variable, \n  levels = paste0(\"V\", 1:(l1$K_a * l1$K_b)))]\n\nd_tru &lt;- unique(l1$d[order(b, a), .(a, b, eta)])\nd_tru[, variable := paste0(\"V\", 1:(l1$K_a * l1$K_b))]\n\nggplot(d_fig, aes(x = value, group = variable)) +\n  geom_density(lwd = 0.2) +\n  geom_vline(data = d_tru,\n             aes(xintercept = eta), col = 2,\n             lwd = 0.3) +\n  facet_wrap(~variable, ncol = 1)\n\n\n\n\n\n\n\n\nFigure 8: Parameter posterior density group means\n\n\n\n\n\n\n\nTwo-factor (2 x 2)\n\n\nCode\nl1 &lt;- get_data(\n  N = 1e6, K_a = 2, K_b = 2, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(2, seed = 22),\n  b_b = create_sum_zero_vec(2, seed = 23),\n  b_ab = as.numeric(create_sum_zero_matrix(2, 2, seed = 24))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.499\n1.499\n\n\nposterior_mean\n-1.504\n1.504\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n0.314\n-0.314\n\n\nposterior_mean\n0.314\n-0.314\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\nb_ab\n-0.521\n0.521\n0.521\n-0.521\n\n\nposterior_mean\n-0.521\n0.521\n0.521\n-0.521\n\n\n\nCompare true parameters with posterior means (interaction)\n\n\n\nTwo-factor (3 x 3)\n\n\nCode\nl1 &lt;- get_data(\n  N = 1e6, K_a = 3, K_b = 3, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(3, seed = 22),\n  b_b = create_sum_zero_vec(3, seed = 23),\n  b_ab = as.numeric(create_sum_zero_matrix(3, 3, seed = 24))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.506\n1.492\n0.014\n\n\nposterior_mean\n-1.508\n1.494\n0.014\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n-0.031\n-0.659\n0.689\n\n\nposterior_mean\n-0.032\n-0.668\n0.700\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_ab\n-0.447\n0.102\n0.345\n-0.524\n0.373\n0.151\n0.971\n-0.474\n-0.496\n\n\nposterior_mean\n-0.444\n0.096\n0.347\n-0.524\n0.368\n0.156\n0.967\n-0.464\n-0.503\n\n\n\nCompare true parameters with posterior means (interaction)\n\n\n\nTwo-factor (2 x 4)\n\n\nCode\nl1 &lt;- get_data(\n  N = 1e6, K_a = 2, K_b = 4, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(2, seed = 22),\n  b_b = create_sum_zero_vec(4, seed = 23),\n  b_ab = as.numeric(create_sum_zero_matrix(2, 4, seed = 24))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.499\n1.499\n\n\nposterior_mean\n-1.501\n1.501\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n-0.423\n-1.051\n0.297\n1.177\n\n\nposterior_mean\n-0.423\n-1.050\n0.296\n1.177\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_ab\n-0.718\n0.718\n0.325\n-0.325\n0.114\n-0.114\n0.279\n-0.279\n\n\nposterior_mean\n-0.717\n0.717\n0.319\n-0.319\n0.113\n-0.113\n0.285\n-0.285\n\n\n\nCompare true parameters with posterior means (interaction)\n\n\n\nTwo-factor (5 x 2)\n\n\nCode\nl1 &lt;- get_data(\n  N = 1e6, K_a = 5, K_b = 2, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(5, seed = 22),\n  b_b = create_sum_zero_vec(2, seed = 23),\n  b_ab = as.numeric(create_sum_zero_matrix(5, 2, seed = 24))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.125\n1.872\n0.395\n-0.32\n-0.822\n\n\nposterior_mean\n-1.120\n1.880\n0.383\n-0.32\n-0.822\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n0.314\n-0.314\n\n\nposterior_mean\n0.313\n-0.313\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nb_ab\n-0.534\n-0.082\n0.315\n0.005\n0.295\n0.534\n0.082\n-0.315\n-0.005\n-0.295\n\n\nposterior_mean\n-0.532\n-0.083\n0.312\n0.004\n0.300\n0.532\n0.083\n-0.312\n-0.004\n-0.300\n\n\n\nCompare true parameters with posterior means (interaction)",
    "crumbs": [
      "Design notes",
      "Orthonormal contrasts"
    ]
  },
  {
    "objectID": "notebooks/design-notes-09.html#what-is-it-with-kroneckerq_a-q_b",
    "href": "notebooks/design-notes-09.html#what-is-it-with-kroneckerq_a-q_b",
    "title": "Orthonormal contrasts",
    "section": "What is it with kronecker(Q_a, Q_b)?",
    "text": "What is it with kronecker(Q_a, Q_b)?\nThe problem with kronecker(Q_a, Q_b) was that I was using a column wise definition for the interaction parameters. However, kronecker(Q_a, Q_b) varies b first rather than a which is incompatible with the specification of the interaction parameters.\n\n\nRevised data generation function\nget_data_alt &lt;- function(\n    N = 100,\n    K_a = 3,\n    K_b = 2,\n    b0 = 1,\n    # effects are sum to zero\n    b_a = c(0, -1, 1),\n    b_b = c(-0.6, 0.6),\n    # rowwise\n    b_ab = c(-0.05, 0.05, 0.15, -0.15, -0.1, 0.1)\n    ){\n  \n  stopifnot(all.equal(0, sum(b_a), \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(0, sum(b_b), \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(0, sum(b_ab), \n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  # cols and rows should sum to zero otherwise following will not work\n  b_ab_matrix &lt;- matrix(b_ab, nrow = K_a, ncol = K_b, byrow = T)\n  stopifnot(all.equal(colSums(b_ab_matrix), rep(0, K_b),\n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(rowSums(b_ab_matrix), rep(0, K_a),\n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  a = sample(1:K_a, size = N, replace = T)\n  b = sample(1:K_b, size = N, replace = T)\n  d &lt;- data.table(a, b)\n  \n  d[, b0 := b0]\n  d[, b_a := b_a[a]]\n  d[, b_b := b_b[b]]\n  # column wise indexing into b_ab\n  # d[, ix_b_ab := a + (K_a * (b - 1))]\n  # rowwise indexing into b_ab\n  d[, ix_b_ab := ((a - 1) * K_b) + b]\n  d[, b_ab := b_ab[ix_b_ab]]\n  d[, eta := b0 + b_a + b_b + b_ab]\n\n  # e.g.  \n  unique(d[order(b, a)])\n#        a     b    b0   b_a   b_b  b_ab   eta\n#    &lt;int&gt; &lt;int&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n# 1:     1     1     1     0  -0.6  -0.2   0.2\n# 2:     2     1     1    -1  -0.6   0.0  -0.6\n# 3:     3     1     1     1  -0.6   0.6   2.0\n# 4:     1     2     1     0   0.4  -0.4   1.0\n# 5:     2     2     1    -1   0.4   0.2   0.6\n# 6:     3     2     1     1   0.4  -0.2   2.2\n  \n  cols_a &lt;- paste0(\"a\", 1:K_a)\n  cols_b &lt;- paste0(\"a\", 1:K_b)\n  cols_c &lt;- unique(d[order(b, a), paste0(\"a\",a,\"b\",b)])\n  \n  d[, y := rbinom(N, 1, plogis(eta))]\n  \n  # saturated design matrix\n  X_a &lt;- diag(K_a)\n  colnames(X_a) &lt;- cols_a\n  X_b &lt;- diag(K_b)\n  colnames(X_b) &lt;- cols_b\n  X_ab &lt;- diag(K_a * K_b)\n  colnames(X_ab) &lt;- cols_c\n\n  # correlation matrix to enforce sum to zero\n  S_a &lt;- diag(K_a) - (1 / K_a )\n  S_b &lt;- diag(K_b) - (1 / K_b )\n  S_ab &lt;- kronecker(S_a, S_b)\n  # should be rank 2 for a 1:3, b 1:2\n  # pracma::Rank(S_ab)\n  \n  # decomposition eigen vectors\n  Q_a &lt;- eigen(S_a)$vector[, 1:(K_a - 1)]\n  Q_b &lt;- eigen(S_b)$vector[, 1:(K_b - 1)]\n  Q_ab &lt;- kronecker(Q_a, Q_b)\n  \n  # transformed pars\n  b_a_s &lt;- t(Q_a) %*% b_a\n  b_b_s &lt;- t(Q_b) %*% b_b\n  b_ab_s &lt;- t(Q_ab) %*% b_ab\n\n  # full rank design\n  X_a_s &lt;- X_a %*% Q_a\n  X_b_s &lt;- X_b %*% Q_b\n  X_ab_s &lt;- X_ab %*% Q_ab\n  \n \n  # Check\n  stopifnot(all.equal(as.numeric(X_a_s %*% b_a_s), b_a, \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(as.numeric(X_b_s %*% b_b_s), b_b, \n                      tolerance = sqrt(.Machine$double.eps)))\n  stopifnot(all.equal(as.numeric(X_ab_s %*% b_ab_s), b_ab, \n                      tolerance = sqrt(.Machine$double.eps)))\n  \n  \n  \n  # build the design matrix up incrementally\n  X_full_s &lt;- cbind(\n    X_a_s[rep(1:K_a, length = K_a * K_b), ],\n    X_b_s[rep(1:K_b, each = K_a), ]\n  )\n  for(j in 1:(K_b-1)){\n    for(i in 1:(K_a-1)){\n      X_full_s &lt;- cbind(X_full_s,\n                        X_full_s[, i]  * X_full_s[, ((K_a - 1) + j)])\n    }\n  }\n  X_full_s\n  # round(X_full_s, 3)\n  \n  list(\n    d = d, b0 = b0, \n    b_a = b_a, b_b = b_b, b_ab = b_ab, \n    b_a_s = b_a_s, b_b_s = b_b_s, b_ab_s = b_ab_s, \n    \n    K_a = K_a, K_b = K_b, \n    X_a = X_a, X_a_s = X_a_s, \n    X_b = X_b, X_b_s = X_b_s, \n    X_ab = X_ab, X_ab_s = X_ab_s, \n    X_full_s = X_full_s,\n    \n    S_a = S_a, S_b = S_b, S_ab = S_ab, \n    Q_a = Q_a, Q_b = Q_b, Q_ab = Q_ab \n  )\n}\n\n\n\n\nCode\nl1 &lt;- get_data_alt(\n  N = 1e6, K_a = 3, K_b = 2, \n  b0 = 1,   \n  b_a = create_sum_zero_vec(3, seed = 22),\n  b_b = create_sum_zero_vec(2, seed = 23),\n  b_ab = as.numeric(c(t(create_sum_zero_matrix(3, 2, seed = 24))))\n)\n\nd_smry &lt;- l1$d[, .(y = sum(y), n = .N), keyby = .(b, a)]\n\n\nld &lt;- list(\n  N = nrow(d_smry), y = d_smry$y, n = d_smry$n, \n  # columnwise\n  # trt = cbind(d_smry$a, d_smry$b, d_smry$a + (l1$K_a * (d_smry$b - 1))),\n  \n  # rowwise\n  trt = cbind(d_smry$a, d_smry$b, ((d_smry$a - 1) * l1$K_b) + d_smry$b),\n  \n  nrXades = nrow(l1$X_a_s), ncXades = ncol(l1$X_a_s), \n  Xades = l1$X_a_s, sa = rep(1, ncol(l1$X_a_s)),\n  \n  nrXbdes = nrow(l1$X_b_s), ncXbdes = ncol(l1$X_b_s), \n  Xbdes = l1$X_b_s, sb = rep(1, ncol(l1$X_b_s)),\n  \n  nrXabdes = nrow(l1$X_ab_s), ncXabdes = ncol(l1$X_ab_s), \n  Xabdes = l1$X_ab_s, sab = rep(1, ncol(l1$X_ab_s)),\n  \n  prior_only = 0\n)\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 3000,\n    parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F,\n    max_treedepth = 10)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.1 seconds.\nChain 2 finished in 0.1 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.1 seconds.\nTotal execution time: 0.2 seconds.\n\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"ba\"), format = \"matrix\") \npost_ba &lt;- m_post_s %*% t(l1$X_a_s)\n\nknitr::kable(rbind(\n  b_a = l1$b_a,\n  posterior_mean = colMeans(post_ba)\n), digits = 3, caption = \"Compare true parameters with posterior means (a factor)\")\n\n\n\n\n\n\nb_a\n-1.506\n1.492\n0.014\n\n\nposterior_mean\n-1.507\n1.486\n0.021\n\n\n\nCompare true parameters with posterior means (a factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bb\"), format = \"matrix\") \npost_bb &lt;- m_post_s %*% t(l1$X_b_s)\n\nknitr::kable(rbind(\n  b_b = l1$b_b,\n  posterior_mean = colMeans(post_bb)\n), digits = 3, caption = \"Compare true parameters with posterior means (b factor)\")\n\n\n\n\n\n\nb_b\n0.314\n-0.314\n\n\nposterior_mean\n0.311\n-0.311\n\n\n\nCompare true parameters with posterior means (b factor)\n\n\n\nCode\nm_post_s &lt;- f1$draws(variables = c(\"bab\"), format = \"matrix\") \npost_bab &lt;- m_post_s %*% t(l1$X_ab_s)\n\nknitr::kable(rbind(\n  b_ab = l1$b_ab,\n  posterior_mean = colMeans(post_bab)\n), digits = 3, caption = \"Compare true parameters with posterior means (interaction)\")\n\n\n\n\n\n\nb_ab\n0.039\n-0.039\n-0.136\n0.136\n0.097\n-0.097\n\n\nposterior_mean\n0.041\n-0.041\n-0.134\n0.134\n0.093\n-0.093\n\n\n\nCompare true parameters with posterior means (interaction)",
    "crumbs": [
      "Design notes",
      "Orthonormal contrasts"
    ]
  }
]