[
  {
    "objectID": "notebooks/simulation-pars.html#baseline-response",
    "href": "notebooks/simulation-pars.html#baseline-response",
    "title": "Simulation setup",
    "section": "Baseline response",
    "text": "Baseline response\nThe baseline probability/log-odds of treatment success is assumed to vary by silo and site of infection as detailed below.\n\n\nBaseline probability of treatment success by silo and site of infection\n\n\nSilo\nJoint\nPr(trt success)\nlog-odds\n\n\n\n\nearly\nknee\n0.65\n0.62\n\n\nearly\nhip\n0.75\n1.10\n\n\nlate\nknee\n0.55\n0.20\n\n\nlate\nhip\n0.6\n0.41\n\n\nchronic\nknee\n0.6\n0.41\n\n\nchronic\nhip\n0.65\n0.62",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#accrual",
    "href": "notebooks/simulation-pars.html#accrual",
    "title": "Simulation setup",
    "section": "Accrual",
    "text": "Accrual\nAccrual is assumed to follow a non-homogeneous Poisson process event times with ramp up over the first 12 months of enrolment and then enrolment of around 1.5 per day.\n\n\nCode\n# events per day\nlambda = 1.52\n# ramp up over 12 months \nrho = function(t) pmin(t/360, 1)\n\nd_fig &lt;- data.table(\n  t = 0:(5 * 365),\n  # expected number enrolled\n  n = c(0, nhpp.mean(lambda, rho, t1 = 5 * 365, num.points = 5 * 365))\n)\n\nggplot(d_fig, aes(x = t/365, y = n)) +\n  geom_line() +\n  scale_x_continuous(\"Year\") +\n  scale_y_continuous(\"E[Accrual]\", breaks = seq(0, 2500, by = 500))\n\n\n\n\n\n\n\n\nFigure 1: Expected accrual",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#domain-non-membership-effects",
    "href": "notebooks/simulation-pars.html#domain-non-membership-effects",
    "title": "Simulation setup",
    "section": "Domain non-membership effects",
    "text": "Domain non-membership effects\nWe assume a small effects for not being randomised to a domain for all domains.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#missingness",
    "href": "notebooks/simulation-pars.html#missingness",
    "title": "Simulation setup",
    "section": "Missingness",
    "text": "Missingness\nMissingness is not implemented.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#non-differential-follow-up",
    "href": "notebooks/simulation-pars.html#non-differential-follow-up",
    "title": "Simulation setup",
    "section": "Non-differential follow-up",
    "text": "Non-differential follow-up\nTo avoid artifacts associated with non-differential follow-up (e.g. early vs late deaths), participants will be included in the analyses only when they reach the primary endpoints (12 months) irrespective of whether they experienced treatment failure before that time.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#simulation-scenarios",
    "href": "notebooks/simulation-pars.html#simulation-scenarios",
    "title": "Simulation setup",
    "section": "Simulation scenarios",
    "text": "Simulation scenarios\nWe consider a range of simulation settings:\n\nNull scenario - no effect of any randomised treatment in any cell (OR = 1) for all domains and silos\nAll effective - all randomised treatments in all cells effective (OR = 1.5) for all domains and silos\nSingle effective - single cell effective (OR = 1.5) for single domain and silo\nSingle harmful - single cell harmful (OR = 1/1.5) for single domain and silo",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#statistical-quantities",
    "href": "notebooks/simulation-pars.html#statistical-quantities",
    "title": "Simulation setup",
    "section": "Statistical quantities",
    "text": "Statistical quantities\nWe consider treatment superiority, inferiority and futility.\nAs a set, whatever quantities are used, need to be mutually exclusive. For example, with the current set of quantities, if a parameter is superior, then it cannot be either inferior and futile.\n\nSuperiority\n\\[\\begin{aligned}\n\\phi_{sup} = Pr(OR &gt; 1)\n\\end{aligned}\\]\nand conclude superiority if \\(\\phi_{sup} &gt; \\delta_{sup}\\).\n\n\nInferiority\n\\[\\begin{aligned}\n\\phi_{inf} = 1 - \\phi_{sup}\n\\end{aligned}\\]\nand conclude inferiority if \\(\\phi_{inf} &gt; \\delta_{inf}\\).\n\n\nFutility\nIs simply defined in relation to superiority with futility concluded if \\(\\phi_{sup} &lt; \\delta_{fut}\\).",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#decision-thresholds",
    "href": "notebooks/simulation-pars.html#decision-thresholds",
    "title": "Simulation setup",
    "section": "Decision thresholds",
    "text": "Decision thresholds\nDecision thresholds are documented with the simulation results.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/adaptations.html#interim-analyses",
    "href": "notebooks/adaptations.html#interim-analyses",
    "title": "Adaptations",
    "section": "Interim analyses",
    "text": "Interim analyses\nInterim analyses start at"
  },
  {
    "objectID": "notebooks/about.html#repository-status",
    "href": "notebooks/about.html#repository-status",
    "title": "About",
    "section": "Repository status",
    "text": "Repository status\nDetails on GitHub repository files, tags, commits follow:\n\n\nCode\nrepo &lt;- git2r::repository(path = \".\")\nsummary(repo)\n\n\nLocal:    main /Users/mark/Documents/project/roadmap/src/roadmap-sim\nRemote:   main @ origin (https://github.com/maj-biostat/roadmap-sim.git)\nHead:     [353b786] 2024-02-18: Add rand reveal notes\n\nBranches:         2\nTags:             0\nCommits:         77\nContributors:     2\nStashes:          0\nIgnored files:   53\nUntracked files: 23\nUnstaged files:   0\nStaged files:     0\n\nLatest commits:\n[353b786] 2024-02-18: Add rand reveal notes\n[378a8c2] 2024-02-16: add draft for rand reveal\n[74f5dd5] 2024-02-16: wip\n[030be66] 2024-02-15: wip\n[80cae58] 2024-02-15: WIP",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html",
    "href": "notebooks/design-notes.html",
    "title": "Design Notes",
    "section": "",
    "text": "Setup\nsource(\"./R/init.R\")\nlog_info(\"Called design-notes notebook\")\nStart by saying we were doing a trial in just the late acute patients. We are interested in surgery (DAIR/revision) and antibiotic duration (long/short), but we are limited in that, for whatever reason, we can not ethically randomise the type of revision surgery, only revision surgery itself.\nChoice of antibiotic duration is conditional on the type of revision surgery used, so surgery type needs to be considered in any joint analysis (alternatively, analyse separately).\nI just want to work through from a basic scenario to more involved ones to check understanding of potential issues. The following will ignore much of the complexity, but just want to get some basics down as a reference.",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#surgery",
    "href": "notebooks/design-notes.html#surgery",
    "title": "Design Notes",
    "section": "Surgery",
    "text": "Surgery\nAs a starting point, consider the following:\n\nR: randomised surgery - 0: DAIR, 1: revision\nS: preferred revision - 0: one-stage, 1: two-stage\nA: allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\nY: treatment success - 0: no, 1: yes\n\nPatients are randomised to a surgery type, \\(R\\): DAIR or revision. For every patient, if they were to have been allocated to revision, there is some preference/plan for one/two stage, \\(S\\). The value of \\(S\\) is determined by the surgeon/patient and I’m considering it here as just an attribute of the patient.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe above determination is actually dependent on the surgeon’s position as well as patient characteristics. In fact, one may dominate the other. For example, would a surgeon choose two-stage for all their patients simply because they have more experience or sucess with that approach, whereas another might choose one-stage for all theirs?\nNote to self - in practice, I actually think that what matters is that we know what selection is rather than what process occurs to decide. Additionally, later we see that this consideration becomes redundant.\n\n\n\nThe actual allocated treatment is a deterministic function of \\(R\\) and \\(S\\), i.e. \\(A = R \\times (S + 1)\\). Note that I’m assuming that \\(S\\) is known for every patient before \\(R\\) is revealed to the surgeon, irrespective of whether they are eventually assigned to DAIR or revision (if that it isn’t the case then perhaps some issues might arise, but I don’t think that it matters too much for what’s being considered here given randomisation).\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A \n  S --&gt; Y\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 1: Scenario 1, the \\(U\\) denote independent exogenous variables\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nThere are no back-door paths for the above, hence no open back-door paths\n\\(Y\\) is caused by/depends on some function of \\(R\\) and \\(S\\): \\(Y = f(R,S)\\)\nAssuming \\(S\\) causes \\(Y\\) a weaker/safer assumption than excluding that link.\nMaybe there should be some shared \\(U\\) that influences both \\(S\\) and \\(Y\\) rather than assuming \\(S\\) causes \\(Y\\)?\nThe graph implies:\n\n\\(S\\) and \\(R\\) are independent; \\(S \\mathrel{\\unicode{x2AEB}} R\\)\n\\(Y\\) is conditionally independent of \\(R\\) given \\(A\\) and \\(S\\); \\(Y \\mathrel{\\unicode{x2AEB}} R | A, S\\)\n\nWe can estimate the total effect of \\(R\\) on \\(Y\\) where \\(R = 1\\) is loosely defined as revision with expert selection of one-stage or two-stage procedure (or something along those lines)\nThink planned/intended procedure should be recorded prior to any elements of randomisation being revealed.\nNo adjustment is required to estimate the total effect of \\(R\\) on \\(Y\\)\n\n\n\n\nOur intervention is on \\(R\\), everything down stream from that (revision type, antibiotic use, physiotherapy, complications) is a consequence of the intervention. It’s the overall effect of allocation to \\(R=0\\) or \\(R=1\\) that we are trying to (the only thing we can, not necessarily want to) compare.\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nIsn’t revision-type independent of intervention? I don’t think I understand why it is downstream.\nNot really sure what is meant by the statement the only thing we can, not necessarily want to compare\n\n\n\n\nIf \\(Y(a)\\) is the potential outcome of a patient under surgery of type \\(a\\) (dair, one-stage, two-stage), then:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y(a)] &= \\mathbb{E}[Y(a)|R=0] \\\\\n&= \\mathbb{E}[Y(a) | R=1] \\\\\n&= \\mathbb{E}[Y(a) | A = 0] \\\\\n&= \\mathbb{E}[Y(a) | A \\in \\{1,2\\}] \\\\\n&\\ne \\mathbb{E}[Y(a) | A = j], \\quad j\\in\\{1,2\\} \\\\\n\\end{aligned}\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\n\nAbove we establish exchangeability assumptions, which are a partial requirement for identifying causal effects, i.e. it gets you to \\(\\mathbb{E}[Y(1)] = \\mathbb{E}[Y|A=1]\\) and \\(\\mathbb{E}[Y(0)] = \\mathbb{E}[Y|A=0]\\) whereby you are learning about the potential outcomes from the observed data.\nAll come about due to randomisation of \\(R\\).\nWhere independence holds (as above for the majority of the cases) knowing the conditioning variable tells you nothing about \\(Y(a)\\) (the term on the LHS of the conditioning).\nFor example \\(\\mathbb{E}[Y(a)] = \\mathbb{E}[Y(a)|R=0]\\) tells us that the potential outcomes of \\(Y(a)\\) in those receive dair have the same distribution as those that do not.\nFor \\(\\mathbb{E}[Y(a)] \\ne \\mathbb{E}[Y(a) | A = 1]\\) and \\(\\mathbb{E}[Y(a)] \\ne \\mathbb{E}[Y(a) | A = 2]\\) we are saying that the distribution of potential outcomes in those for whom one-stage is planned do not share the same distribtion as for those for whom one-stage is not planned. And this is by virtue of the fact that revision type is selected rather than randomised.\n\n\n\n\nThe only randomised comparison we can make is \\(R=1\\) vs \\(R=0\\), but, given we want to eventually condition on which revision type is selected, we want to include terms for preferred revision type in the model. Assume logistic regression is the true model and specify\n\\[\n\\begin{align}\n\\mathbb{E}[Y | R] &= Pr(Y = 1 | R) = \\text{expit}(\\alpha_0 + \\alpha_1R) \\\\\n\\end{align}\n\\tag{1}\\]\n\\[\n\\begin{align}\n\\mathbb{E}[Y | A] &= Pr(Y = 1 | A) = \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(A=1) + \\beta_2\\mathbb{I}(A=2)) \\\\\n\\end{align}\n\\tag{2}\\]\nEquivalently, state in terms of \\(R\\) and \\(S\\).\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS) \\\\\n\\tag{3}\\]\nEquation 1 targets the thing we actually want to compare, the log-odds ratio of revision versus DAIR. Equation 3 splits this out into one and two stage which we would need to combine to get the overall revision effect. In Equation 3, the \\(\\beta_1\\) gives the effect of revision under a one-stage procedure and the \\(\\beta_2\\) gives the increment on that term when a two-stage procedure is undertaken. Some weighted combination of these terms will give us a view of the aggregated effect of revision.\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhat isn’t directly stated above is that the (primary?) reason we need to split \\(R\\) into one-stage and two-stage effects is so that we can incorporate the duration domain within a single model. The randomised interventions for duration are 12 weeks vs 6 weeks antibiotics for those receiving one-stage surgery and 12 weeks vs 7 days for those receiving two-stage surgery. If a patient received one-stage, the duration intervention parameters associated with two-stage are mostly irrelevant to estimating the log-odds of treatment success for this patient. Moreover, the response for the one-stage patient does not inform the two-stage duration intervention effects. To accommodate this, the one-stage and two-stage duration parameters enter the model independently, e.g.\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1 \\mathbb{I}(R = \\text{one-stage} \\land D = short) + \\beta_2 \\mathbb{I}(R = \\text{two-stage} \\land D = short)) \\\\\n\\]\nHowever, this means that the duration domain reference group for the one-stage and two-stage duration effects have the same log-odds of treatment success and this is very unlikely to be the case. Thus, by splitting \\(R\\) into one-stage and two-stage effects we allow the reference groups for the one-stage and two-stage duration effects to vary.\n\n\n\nThese models could also adjust for \\(S\\), i.e. in addition to any actual effect of one/two stage revision, the patients for whom a two-stage would be preferred may differ from those for who a one-stage is the preference. Interpretation of model parameters then changes of course.\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3S) \\\\\n\\tag{4}\\]\nWe don’t really care about the difference due to \\(S\\), as the revision type effects may still be confounded by other factors anyway. Due to the randomisation, I think that both the version with and without \\(S\\) are targeting the same estimand for revision vs. DAIR (the distribution of \\(S\\) is the same (in expectation) amongst DAIR and revision patients, so is not a confounder, but obviously, \\(S\\) is known exactly to be \\(A-1\\) when \\(R=1\\)).\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think what you are proposing for the \\(\\beta_3\\) term (the effect of \\(S\\)) boils down to the following:\n\nthe effect of \\(S\\), clinical selection of one-stage vs two-stage may be confounded and we can probably do very little about that\nhowever, the estimate we obtain for \\(\\beta_3\\) would be the same in the group that received revision as the group that did not due to the fact that dair vs revision was randomised\n\nProbably incorrectly, I think the selection effect is meaningless in the sense that receiving dair contradicts the possibility of a selection. It is analogous to a model for number of children whereby you make an adjustment for (randomised) marriage and (self-selected) age of marriage. The main effect of age of marriage is excluded, on the basis that it has no counterpart in reality and therefore no way to inform the effect.\nWhat is the counter-argument? Perhaps something along the lines of:\nTo justify the inclusion of \\(\\beta_3\\) we argue that the married and the non-married groups are balanced across age (and all other characteristics). Therefore, the married and unmarried groups are similar and the effect for age of married in the group is portable to the group that were not randomised to marriage, in the counterfactual world where they had been.\nOk, think I have convinced myself (if perhaps no-one else) that it makes sense.\n\n\n\nFor the second model above, in terms of \\(R\\) and \\(S\\), without adjustment for \\(S\\)\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | R] &= \\mathbb{E}[\\mathbb{E}[Y | S, R] | R] \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs)\\mathbb{P}(S = s | R) \\\\\n\\mathbb{E}[Y|R =0] &= \\text{expit}(\\beta_0) \\\\\n\\mathbb{E}[Y|R = 1] &=  \\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(S=0|R=1) \\\\\n& \\quad \\ + \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2)\\mathbb{P}(S=1|R=1)\n\\end{aligned}\n\\]\nso the log-odds ratio for the marginal success probability for revision vs. DAIR is\n\\[\n\\begin{aligned}\n\\ln\\frac{\\text{odds}(Y|R=1)}{\\text{odds}(Y|R=0)} &= \\text{logit}[\\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(S=0|R=1) + \\\\  \n& \\quad \\quad \\ \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2)\\mathbb{P}(S=1|R=1)] -  \\beta_0\n\\end{aligned}\n\\tag{5}\\]\nWe don’t know \\(\\mathbb{P}(S=s|R)\\) so estimate it from the sample. Due to randomisation \\(\\mathbb{P}(S=s|R) = \\mathbb{P}(S=s)\\).\n\n\n\n\n\n\nNote\n\n\n\n\n\nWhich is just creating a standardised probability of treatment success under revision based on a weighted version of the probability of treatment success for each of the selection groups (one-stage and two-stage) where the weights are formed from the (unknown) distribution of \\(S\\) (estimated from the sample). The standardised probability of treatment success under revision is then converted to the log odds of treatment success and the reference group (DAIR) log-odds of treatment success is subtracted to come up with the log-OR.\nThe final line in the above derivation is just saying that we can assume that the probability distribution of \\(S\\) is independent to treatment group membership and so can be estimated from the full sample rather than condition on \\(R\\). Note that \\(\\mathbb{P}(S=s)\\) is not necessarily indicative of the probability distribution of \\(S\\) in the population because of our convenience sample, but this is true for all inference here and in the majority of trials.\n\n\n\nAn alternative to the above is to consider the “average” conditional log-odds ratio rather than the odds ratio of the marginal probabilities.\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S)}{\\text{odds}(Y|R=0,S)}\\right] = \\mathbb{E}[\\beta_1 + \\beta_2S] = \\beta_1 + \\beta_2\\mathbb{E}[S]\n\\tag{6}\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe expectation of \\(S\\) above is across the sample, but below the weighting is taken from the revision group. Would it not be preferable to use the mean derived from the full sample or am I thinking about it incorrectly?\n\n\n\nIf the model also adjusts for \\(S\\), then\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | R] &= \\mathbb{E}[\\mathbb{E}[Y | S, R] | R] \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs + \\beta_3s)\\mathbb{P}(S = s | R) \\\\\n\\mathbb{E}[Y|R = 0] &= \\text{expit}(\\beta_0)\\mathbb{P}(S = 0 | R=0) + \\text{expit}(\\beta_0 + \\beta_3)\\mathbb{P}(S=1|R=0)\\\\\n\\mathbb{E}[Y|R = 1] &= \\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(S = 0 | R = 1) + \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3)\\mathbb{P}(S=1 | R = 1) \\\\\n\\ln\\frac{\\text{odds}(Y|R=1)}{\\text{odds}(Y|R=0)} &= \\text{logit}(\\mathbb{E}[Y|R = 1]) - \\text{logit}(\\mathbb{E}[Y|R = 0])\n\\end{aligned}\n\\]\nWith the introduction of a main effect for \\(S\\) we can still report on the average conditional log-odds ratio in the same form as previously:\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S)}{\\text{odds}(Y|R=0,S)}\\right] = \\mathbb{E}[\\beta_1 + \\beta_2S] = \\beta_1 + \\beta_2\\mathbb{E}[S]\n\\]\ni.e. with the same terms as without adjustment for \\(S\\). However, the treatment effect parameter estimates produced from the model that includes the main effect for \\(S\\) (and the interaction term) and the model that only has the interaction term, are likely be different.\n\nExample\nHerein I am just assuming \\(n\\approx \\infty\\), i.e. checking consistency.\n\n\n\n\n\n\nNote\n\n\n\n\n\nConsistency is simply about whether the estimator produces an estimate that gets closer towards the true value as the sample size gets bigger; a consistent estimator does not negate the possibility of bias. For example, \\(\\frac{1}{N-1}\\sum_i (x_i)\\) is a consistent but biased estimator of the mean for a random vector, \\(x\\).\nThe default parameterisation for the data generating mechanism is to adopt the functional form from Equation 4, which includes terms for \\(R\\), \\(S\\) and an interaction between \\(R\\) and \\(S\\).\n\n\n\n\n\nGenerate data scenario 1\n# Assume ~ infinite population as just checking consistency\n# Precision will of course vary by approach at small sample sizes\ngenerate_data_1 &lt;- function(\n    n = 1000000,\n    f = function(r, s, x){-1 + s + 0.25 * r + 0.25 * r * s}) {\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  x &lt;- rbinom(n, 1, 0.25)\n  a &lt;- r * (s + 1)\n  y0 &lt;- rbinom(n, 1, plogis(f(0, s, x)))\n  y1 &lt;- rbinom(n, 1, plogis(f(1, s, x)))\n  y &lt;- (1 - r) * y0 + r * y1\n  w &lt;- mean(s) # Selection probability\n  D &lt;- data.table(r = r, x = x, s = s, a = a, y0 = y0, y1 = y1, y = y)[\n    ,\n    `:=`(\n      r_fac = factor(r),\n      a_fac = factor(a),\n      s_fac = factor(s),\n      a_cen = r * (a - 1 - mean(a[r == 1] - 1)),\n      s_cen = s - mean(s)\n    )\n  ]\n}\n\n\n\n\nSimulate null effect\nset.seed(123)\nD &lt;- generate_data_1(f = function(r, s, x){-1 + s})\n\n# Eqn 1\nfit1 &lt;- glm(y ~ r, data = D, family = binomial())\n\n# Eqn 3\nfit2 &lt;- glm(y ~ r + r:s, data = D, family = binomial())\n\n# Eqn 6?\nfit1s &lt;- glm(y ~ r + s, data = D, family = binomial())\n\n# Eqn 4\nfit2s &lt;- glm(y ~ r + r:s + s, data = D, family = binomial())\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nIn the use of “true” below, what is meant is the empirical log-odds ratios in the population (approximated by a very large sample) that we observe. We estimate the effects directly from the data by calculating the difference in the log-odds of treatment success in the strata of interest for those in the treated vs control groups.\nThe table just tries to line up the quantities, like with like as there were some minor differences in the naming.\n\n\n\n\n\nNull effect quantities\nw &lt;- mean(D$a == 2) / mean(D$a %in% c(1, 2))\nw_s1 &lt;- mean(D[r == 0]$s == 1)\nw_s2 &lt;- mean(D[r == 1]$s == 1)\n\nb1 &lt;- unname(coef(fit1))\nb2 &lt;- unname(coef(fit2))\nb1s &lt;- unname(coef(fit1s))\nb2s &lt;- unname(coef(fit2s))\n\nEY_R0_2 &lt;- expit(b2[1])\nEY_R1_2 &lt;- (1 - w) * expit(b2[1] + b2[2]) + w * expit(b2[1] + b2[2] + b2[3])\n\nEY_R0_1_S0 &lt;- expit(b1s[1])\nEY_R0_1_S1 &lt;- expit(b1s[1] + b1s[3])\nEY_R1_1_S0 &lt;- expit(b1s[1] + b1s[2])\nEY_R1_1_S1 &lt;- expit(b1s[1] + b1s[2] + b1s[3])\nEY_R0_1 &lt;- (1 - w_s1) * EY_R0_1_S0 + w_s1 * EY_R0_1_S1\nEY_R1_1 &lt;- (1 - w_s2) * EY_R1_1_S0 + w_s2 * EY_R1_1_S1\n\nEY_R0_2s_S0 &lt;- expit(b2s[1])\nEY_R0_2s_S1 &lt;- expit(b2s[1] + b2s[3])\nEY_R1_2s_S0 &lt;- expit(b2s[1] + b2s[2]) # Pr(A = 2 | S = 0) = 0\nEY_R1_2s_S1 &lt;- expit(b2s[1] + b2s[2] + b2s[3] + b2s[4]) # Pr(A = 2 | S = 1) = 1\nEY_R0_2s &lt;- (1 - w_s1) * EY_R0_2s_S0 + w_s1 * EY_R0_2s_S1\nEY_R1_2s &lt;- (1 - w_s2) * EY_R1_2s_S0 + w_s2 * EY_R1_2s_S1\n\nrbind(\n  \"True conditional (S = 0) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n  \"True conditional (S = 1) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n  \"True marginal log-odds ratio\" = qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  \"True weighted log-odds ratio\" =\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n  \"True average weighted log-odds ratio\" =\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y))),\n  \"fit1 marginal log-odds ratio\" = b1[2],\n  \"fit2 marginal log-odds ratio\" = qlogis(EY_R1_2) - qlogis(EY_R0_2),\n  \"fit2 conditional (weighted) log-odds ratio\" = b2[2] + w * b2[3],\n  \"fit1s conditional log-odds ratio\" = b1s[2], # Don't know what this targets\n  \"fit1s marginal log-odds ratio\" = qlogis(EY_R1_1) - qlogis(EY_R0_1),\n  \"fit2s conditional (S = 0) log-odds ratio\" = qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0),\n  \"fit2s conditional (S = 1) log-odds ratio\" = qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1),\n  \"fit2s marginal log-odds ratio\" = qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n  \"fit2s average (weighted) log-odds ratio\" = b2s[2] + w * b2s[4]\n)\n\n\n                                                   [,1]\nTrue conditional (S = 0) log-odds ratio    -0.003882742\nTrue conditional (S = 1) log-odds ratio     0.003222299\nTrue marginal log-odds ratio                0.002568068\nTrue weighted log-odds ratio               -0.018727631\nTrue average weighted log-odds ratio        0.001097800\nfit1 marginal log-odds ratio                0.002568068\nfit2 marginal log-odds ratio                0.002568068\nfit2 conditional (weighted) log-odds ratio -0.018727631\nfit1s conditional log-odds ratio            0.001436139\nfit1s marginal log-odds ratio               0.002568068\nfit2s conditional (S = 0) log-odds ratio   -0.003882742\nfit2s conditional (S = 1) log-odds ratio    0.003222299\nfit2s marginal log-odds ratio               0.002568068\nfit2s average (weighted) log-odds ratio     0.001097800\n\n\nNull effect quantities\nd_out &lt;- data.table(\n  desc = c(\n    \"conditional (S = 0) log-OR\",\n    \"conditional (S = 1) log-OR\",\n    \"conditional log-OR (?)\",\n    \"conditional (weighted) log-OR\",\n    \"marginal log-OR\",\n    \"weighted log-OR\",\n    \"average (weighted) log-OR\"\n  ),\n  true = c(\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n    NA,  \n    NA,\n    qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)))\n  ),\n  fit_1 = c(\n    NA, \n    NA,  \n    NA,\n    NA, \n    b1[2], \n    NA, \n    NA\n  ),\n  fit_2 = c(\n    NA, \n    NA,\n    NA, \n    b2[2] + w * b2[3], \n    qlogis(EY_R1_2) - qlogis(EY_R0_2), \n    NA,\n    NA\n  ),\n  fit_1s = c(\n    NA, \n    NA, \n    b1s[2],\n    NA,\n    qlogis(EY_R1_1) - qlogis(EY_R0_1), \n    NA,\n    NA\n  ),\n  fit_2s = c(\n    qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0), \n    qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1), \n    NA, \n    NA,\n    qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n    NA,\n    b2s[2] + w * b2s[4]\n  )\n)\n\n\n\n\nTabulate effect quantities\ngt_tbl &lt;- d_out |&gt; \n  gt(rowname_col = c(\"desc\")) |&gt; \n  cols_align(align = \"right\", columns = 2:6) |&gt;  \n  fmt_number(columns = everything(), decimals = 3) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") |&gt;\n  tab_options(table.font.size = \"80%\") |&gt;\n  tab_footnote(\n    footnote = \"y ~ r\",\n    locations = cells_column_labels(columns = fit_1)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s\",\n    locations = cells_column_labels(columns = fit_2)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + s\",\n    locations = cells_column_labels(columns = fit_1s)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + s\",\n    locations = cells_column_labels(columns = fit_2s)\n    ) |&gt;\n  tab_footnote(\n    footnote = md(\"Should be labelled *conditional (weighted) log-OR*?\"),\n    locations = cells_stub(rows = c(\n      \"weighted log-OR\"\n    ))\n  ) |&gt;\n  tab_footnote(\n    footnote = md(\"log-OR for R term in model, but interpretation unclear\"),\n    locations = cells_stub(rows = c(\n      \"conditional log-OR (?)\"))\n  )\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrue\nfit_11\nfit_22\nfit_1s3\nfit_2s4\n\n\n\n\nconditional (S = 0) log-OR\n−0.004\n\n\n\n\n\n\n−0.004\n\n\nconditional (S = 1) log-OR\n0.003\n\n\n\n\n\n\n0.003\n\n\nconditional log-OR (?)5\n\n\n\n\n\n\n0.001\n\n\n\n\nconditional (weighted) log-OR\n\n\n\n\n−0.019\n\n\n\n\n\n\nmarginal log-OR\n0.003\n0.003\n0.003\n0.003\n0.003\n\n\nweighted log-OR6\n−0.019\n\n\n\n\n\n\n\n\n\n\naverage (weighted) log-OR\n0.001\n\n\n\n\n\n\n0.001\n\n\n\n1 y ~ r\n\n\n2 y ~ r + r:s\n\n\n3 y ~ r + s\n\n\n4 y ~ r + r:s + s\n\n\n5 log-OR for R term in model, but interpretation unclear\n\n\n6 Should be labelled conditional (weighted) log-OR?\n\n\n\n\n\n\n\n\n\nTable 1: Null effects\n\n\n\n\n\n\nSimulate effect\nset.seed(123)\nD &lt;- generate_data_1()\nfit1 &lt;- glm(y ~ r, data = D, family = binomial())\nfit2 &lt;- glm(y ~ r + r:s, data = D, family = binomial())\nfit1s &lt;- glm(y ~ r + s, data = D, family = binomial())\nfit2s &lt;- glm(y ~ r + r:s + s, data = D, family = binomial())\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nSimulate from Equation 4 with a baseline probability of treatment success equal to 0.27 together with \\(\\beta_1 = 0.25\\), \\(\\beta_2 = 0.25\\) and \\(\\beta_3 = 1\\) for the log-ORs associated with treatment, the interaction between treatment and selection and selection, respectively.\n\n\n\n\n\nEffect quantities\nw &lt;- mean(D$a == 2) / mean(D$a %in% c(1, 2))\nw_s1 &lt;- mean(D[r == 0]$s == 1)\nw_s2 &lt;- mean(D[r == 1]$s == 1)\n\nb1 &lt;- unname(coef(fit1))\nb2 &lt;- unname(coef(fit2))\nb1s &lt;- unname(coef(fit1s))\nb2s &lt;- unname(coef(fit2s))\n\nEY_R0_2 &lt;- expit(b2[1])\nEY_R1_2 &lt;- (1 - w) * expit(b2[1] + b2[2]) + w * expit(b2[1] + b2[2] + b2[3])\n\nEY_R0_1_S0 &lt;- expit(b1s[1])\nEY_R0_1_S1 &lt;- expit(b1s[1] + b1s[3])\nEY_R1_1_S0 &lt;- expit(b1s[1] + b1s[2])\nEY_R1_1_S1 &lt;- expit(b1s[1] + b1s[2] + b1s[3])\nEY_R0_1 &lt;- (1 - w_s1) * EY_R0_1_S0 + w_s1 * EY_R0_1_S1\nEY_R1_1 &lt;- (1 - w_s2) * EY_R1_1_S0 + w_s2 * EY_R1_1_S1\n\nEY_R0_2s_S0 &lt;- expit(b2s[1])\nEY_R0_2s_S1 &lt;- expit(b2s[1] + b2s[3])\nEY_R1_2s_S0 &lt;- expit(b2s[1] + b2s[2]) # Pr(A = 2 | S = 0) = 0\nEY_R1_2s_S1 &lt;- expit(b2s[1] + b2s[2] + b2s[3] + b2s[4]) # Pr(A = 2 | S = 1) = 1\nEY_R0_2s &lt;- (1 - w_s1) * EY_R0_2s_S0 + w_s1 * EY_R0_2s_S1\nEY_R1_2s &lt;- (1 - w_s2) * EY_R1_2s_S0 + w_s2 * EY_R1_2s_S1\n\nrbind(\n  \"True conditional (S = 0) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n  \"True conditional (S = 1) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n  \"True marginal log-odds ratio\" = qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  \"True weighted log-odds ratio\" =\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n  \"True average (weighted) log-odds ratio\" =\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y))),\n  \"fit1 marginal log-odds ratio\" = b1[2],\n  \"fit2 marginal log-odds ratio\" = qlogis(EY_R1_2) - qlogis(EY_R0_2),\n  \"fit2 conditional (weighted) log-odds ratio\" = b2[2] + w * b2[3],\n  \"fit1s conditional log-odds ratio\" = b1s[2], # Don't know what this targets\n  \"fit1s marginal log-odds ratio\" = qlogis(EY_R1_1) - qlogis(EY_R0_1),\n  \"fit2s conditional (S = 0) log-odds ratio\" = qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0),\n  \"fit2s conditional (S = 1) log-odds ratio\" = qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1),\n  \"fit2s marginal log-odds ratio\" = qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n  \"fit2s average (weighted) log-odds ratio\" = b2s[2] + w * b2s[4]\n)\n\n\n                                                [,1]\nTrue conditional (S = 0) log-odds ratio    0.2462550\nTrue conditional (S = 1) log-odds ratio    0.4944007\nTrue marginal log-odds ratio               0.4038167\nTrue weighted log-odds ratio               0.4003765\nTrue average (weighted) log-odds ratio     0.4202020\nfit1 marginal log-odds ratio               0.4038167\nfit2 marginal log-odds ratio               0.4038167\nfit2 conditional (weighted) log-odds ratio 0.4003765\nfit1s conditional log-odds ratio           0.4285063\nfit1s marginal log-odds ratio              0.4038167\nfit2s conditional (S = 0) log-odds ratio   0.2462550\nfit2s conditional (S = 1) log-odds ratio   0.4944007\nfit2s marginal log-odds ratio              0.4038167\nfit2s average (weighted) log-odds ratio    0.4202020\n\n\nEffect quantities\nd_out &lt;- data.table(\n  desc = c(\n    \"conditional (S = 0) log-OR\",\n    \"conditional (S = 1) log-OR\",\n    \"conditional log-OR (?)\",\n    \"conditional (weighted) log-OR\",\n    \"marginal log-OR\",\n    \"weighted log-OR\",\n    \"average (weighted) log-OR\"\n  ),\n  true = c(\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n    NA,  \n    NA,\n    qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)))\n  ),\n  fit_1 = c(\n    NA, \n    NA,   \n    NA,\n    NA, \n    b1[2], \n    NA, \n    NA\n  ),\n  fit_2 = c(\n    NA, \n    NA, \n    NA, \n    b2[2] + w * b2[3], \n    qlogis(EY_R1_2) - qlogis(EY_R0_2), \n    NA,\n    NA\n  ),\n  fit_1s = c(\n    NA, \n    NA, \n    b1s[2],\n    NA,\n    qlogis(EY_R1_1) - qlogis(EY_R0_1), \n    NA,\n    NA\n  ),\n  fit_2s = c(\n    qlogis(EY_R1_2s_S0) - qlogis(EY_R0_2s_S0), \n    qlogis(EY_R1_2s_S1) - qlogis(EY_R0_2s_S1),  \n    NA, \n    NA,\n    qlogis(EY_R1_2s) - qlogis(EY_R0_2s),\n    NA,\n    b2s[2] + w * b2s[4]\n  )\n)\n\n\n\n\nTabulate effect quantities\ngt_tbl &lt;- d_out |&gt; \n  gt(rowname_col = c(\"desc\")) |&gt; \n  cols_align(align = \"right\", columns = 2:6) |&gt;  \n  fmt_number(columns = everything(), decimals = 3) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") |&gt;\n  tab_options(table.font.size = \"80%\") |&gt;\n  tab_footnote(\n    footnote = \"y ~ r\",\n    locations = cells_column_labels(columns = fit_1)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s\",\n    locations = cells_column_labels(columns = fit_2)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + s\",\n    locations = cells_column_labels(columns = fit_1s)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + s\",\n    locations = cells_column_labels(columns = fit_2s)\n    ) |&gt;\n  tab_footnote(\n    footnote = md(\"Should be labelled *conditional (weighted) log-OR*?\"),\n    locations = cells_stub(rows = c(\n      \"weighted log-OR\"))) |&gt;\n  tab_footnote(\n    footnote = md(\"log-OR for R term in model, but interpretation unclear\"),\n    locations = cells_stub(rows = c(\n      \"conditional log-OR (?)\"))\n  )\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntrue\nfit_11\nfit_22\nfit_1s3\nfit_2s4\n\n\n\n\nconditional (S = 0) log-OR\n0.246\n\n\n\n\n\n\n0.246\n\n\nconditional (S = 1) log-OR\n0.494\n\n\n\n\n\n\n0.494\n\n\nconditional log-OR (?)5\n\n\n\n\n\n\n0.429\n\n\n\n\nconditional (weighted) log-OR\n\n\n\n\n0.400\n\n\n\n\n\n\nmarginal log-OR\n0.404\n0.404\n0.404\n0.404\n0.404\n\n\nweighted log-OR6\n0.400\n\n\n\n\n\n\n\n\n\n\naverage (weighted) log-OR\n0.420\n\n\n\n\n\n\n0.420\n\n\n\n1 y ~ r\n\n\n2 y ~ r + r:s\n\n\n3 y ~ r + s\n\n\n4 y ~ r + r:s + s\n\n\n5 log-OR for R term in model, but interpretation unclear\n\n\n6 Should be labelled conditional (weighted) log-OR?\n\n\n\n\n\n\n\n\n\nTable 2: Effects\n\n\n\n\nSo in the basic case, as \\(n\\to\\infty\\), these models are all in a sense equivalent, in that they are consistent for the treatment effects of interest.\nMore generally, can just use g-computation rather than analytic expressions\n\n\nCode\nm &lt;- rbind(\n  \"G-comp marginal mean\" =\n    c(avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\")$estimate, NA_real_),\n  \"G-comp marginal mean (adjust s)\" =\n    c(avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")$estimate, NA_real_),\n  \"G-comp average log-odds\" =\n    c(avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\")$estimate, NA_real_),\n  \"G-comp average log-odds (adjust s)\" = \n    c(avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\")$estimate, NA_real_),\n  \"G-comp conditional (S) average log-odds\" =\n    avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\", by = \"s\")$estimate,\n  \"G-comp conditional (S) average log-odds (adjust s)\" =\n    avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\", by = \"s\")$estimate\n)\ncolnames(m) &lt;- c(\"S = 0\", \"S = 1\")\nm\n\n\n                                                        S = 0     S = 1\nG-comp marginal mean                                0.4030520        NA\nG-comp marginal mean (adjust s)                     0.4024538        NA\nG-comp average log-odds                             0.3995870        NA\nG-comp average log-odds (adjust s)                  0.4200453        NA\nG-comp conditional (S) average log-odds            -0.4764725 0.7744050\nG-comp conditional (S) average log-odds (adjust s)  0.2462550 0.4944007\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think that the above are basically making predictions for the comparison of interest at each of the rows in the data set and then averaging to give a marginalised view.\nThe definitional differences between lnoravg and lnor amount to:\nlnor   \\(hi, lo) log((hi/(1 - hi))/(lo/(1 - lo)))\nvs.\nlnoravg    \\(hi, lo) log((mean(hi)/(1 - mean(hi)))/(mean(lo)/(1 - mean(lo)))\nso (I think but need to confirm) one is doing the calculation on every row and then averaging whereas the other averages first.",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#covariate",
    "href": "notebooks/design-notes.html#covariate",
    "title": "Design Notes",
    "section": "Covariate",
    "text": "Covariate\nSuppose we introduce a covariate \\(X\\) because it’s predictive of the outcome, e.g. sex. Our model, which does not adjust for \\(S\\), is\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R,S,X] &= \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3X) \\\\\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|R,S,X]|R,X] \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs + \\beta_3X)\\mathbb{P}(S=s|R,X) \\\\\n\\mathbb{E}[Y|R=0,X] &= \\text{expit}(\\beta_0 + \\beta_3X) \\\\\n\\mathbb{E}[Y|R=1,X] &= \\text{expit}(\\beta_0 + \\beta_1 + \\beta_3X)\\mathbb{P}(S=0|R=1,X)  \\\\\n&\\quad \\ + \\text{expit}(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3X)\\mathbb{P}(S=1|R=1,X)\n\\end{aligned}\n\\]\nThe conditional (on \\(X\\)) log-odds ratio of marginal success probability for revision versus DAIR depends on the value of \\(X\\) (i.e. is not the same effect for every \\(X=x\\)) and cannot be simplified. It is\n\\[\n\\text{logit}(\\mathbb{E}[Y|R=1,X]) - (\\beta_0 + \\beta_3X).\n\\]\nBy marginalising over type of revision type (which is necessary for the comparison we want), we lose our one number summary. No way to avoid that other than perhaps considering fitting separate models for surgery and duration.\nTo maintain a one-number-summary, again an alternative is to consider the average conditional log-odds\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1|S,X)}{\\text{odds}(Y|R=0|S,X)}\\right] = \\beta_1 + \\beta_2\\mathbb{E}[S].\n\\]\nIf \\(S\\) has an effect, say in truth,\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|S,R,X] &= \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3S + \\beta_4X) \\\\\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|S,R,X]|R,X] \\\\\n&= \\sum_{s=0}^1 \\mathbb{E}[Y|S=s,R,X]\\mathbb{P}(S=s|R,X)\n\\end{aligned}\n\\]\nThen if our model does condition on \\(S\\),\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|R,X,S]|R,X] \\\\\n&= \\sum_{s=0}^1\n\\text{expit}(\\beta_0 + \\beta_1R + \\beta_2Rs + \\beta_3s+\\beta_4X)\n\\mathbb{P}(S=s|R,X) \\\\\n\\mathbb{E}[Y|R=0,X] &= \\text{expit}(\\beta_0 + \\beta_4X)\\mathbb{P}(S=0|R=0,X) +\n\\text{expit}(\\beta_0 + \\beta_3 + \\beta_4X)\\mathbb{P}(S=1|R=0,X) \\\\\n\\mathbb{E}[Y|R=1,X] &= \\text{expit}(\\beta_0 + \\beta_1 + \\beta_4X)\\mathbb{P}(S=0|R=0,X) +\n\\text{expit}(\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3 + \\beta_4X)\\mathbb{P}(S=1|R=0,X) \\\\\n\\ln\\frac{\\text{odds}(Y|R=1,X)}{\\text{odds}(Y|R=0,X)} &= \\text{logit}(\\mathbb{E}[Y|R=1,X]) - \\text{logit}(\\mathbb{E}[Y|R=0,X])\n\\end{aligned}\n\\]\nDue to randomisation, \\(\\mathbb{P}(S=s|R,X) = \\mathbb{P}(S=s|X)\\).\nThe model without adjustment for \\(S\\) assumes\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R,S,X] &= \\text{expit}(\\alpha_0 + \\alpha_1R + \\alpha_2RS + \\alpha_3X) \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3X + \\beta_4s)\\mathbb{P}(S=s|R,X)\n\\end{aligned}\n\\]\n\nExample\n\n\n\n\n\n\nNote\n\n\n\n\n\nBy definition, \\(x\\) has a 25% chance of occurrence in the sample data.\n\n\n\n\n\nGenerate data with covariate\nset.seed(6124)\nD &lt;- generate_data_1(\n  f = function(r, s, x){ -1 + s + x + 0.25 * r + 0.25 * r * s}\n)\nfit1 &lt;- glm(y ~ r + x, data = D, family = binomial())\nfit2 &lt;- glm(y ~ r + r:s + x, data = D, family = binomial())\nfit1s &lt;- glm(y ~ r + s + x, data = D, family = binomial())\nfit2s &lt;- glm(y ~ r + s + r:s + x, data = D, family = binomial())\n\n\nUsing G-computation to marginalise over \\(S\\) and \\(X\\).\n\n\nEffect quantities\ntt &lt;- cbind(\n  qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  NA,\n  qlogis(mean(D[r == 1 & x == 0]$y)) - qlogis(mean(D[r == 0 & x == 0]$y)),\n  qlogis(mean(D[r == 1 & x == 1]$y)) - qlogis(mean(D[r == 0 & x == 1]$y))\n)\nrownames(tt) &lt;- \"True\"\nm1 &lt;- rbind(\n  avg_comparisons(fit1, variables = \"r\", comparison = \"lnoravg\")$estimate,\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\")$estimate,\n  avg_comparisons(fit1s, variables = \"r\", comparison = \"lnoravg\")$estimate,\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")$estimate\n)\nm2 &lt;- rbind(\n  avg_comparisons(fit1, variables = \"r\", comparison = \"lnor\")$estimate,\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\")$estimate,\n  avg_comparisons(fit1s, variables = \"r\", comparison = \"lnor\")$estimate,\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\")$estimate\n)\nm3 &lt;- rbind(\n  avg_comparisons(fit1, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate,\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate,\n  avg_comparisons(fit1s, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate,\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\", by = \"x\")$estimate\n)\nm &lt;- cbind(m1, m2, m3)\ncols &lt;- c(\"Marginal log-odds ratio\", \"Average log-odds ratio\", \"Conditional (X = 0)\", \"Conditional (X = 1)\")\ncolnames(m) &lt;- cols\nrownames(m) &lt;- c(\"fit1\", \"fit2\", \"fit1s\", \"fit2s\")\nround(rbind(tt, m), 3)\n\n\n      Marginal log-odds ratio Average log-odds ratio Conditional (X = 0)\nTrue                    0.376                     NA               0.397\nfit1                    0.377                  0.391               0.391\nfit2                    0.378                  0.405               0.408\nfit1s                   0.378                  0.418               0.393\nfit2s                   0.378                  0.416               0.398\n      Conditional (X = 1)\nTrue                0.367\nfit1                0.391\nfit2                0.334\nfit1s               0.392\nfit2s               0.371\n\n\n\n\nTabulate effect quantities\nd_out &lt;- data.table(t(round(rbind(tt, m), 3)))\nd_out[, desc := cols]\nsetcolorder(d_out, \"desc\")\n\n\n\ngt_tbl &lt;- d_out |&gt; \n  gt(rowname_col = c(\"desc\")) |&gt; \n  cols_align(align = \"right\", columns = 2:6) |&gt;  \n  fmt_number(columns = everything(), decimals = 3) |&gt;\n  sub_missing(columns = everything(), missing_text = \"\") |&gt;\n  tab_options(table.font.size = \"80%\") |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + x\",\n    locations = cells_column_labels(columns = fit1)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + x\",\n    locations = cells_column_labels(columns = fit2)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + s + x\",\n    locations = cells_column_labels(columns = fit1s)\n    ) |&gt;\n  tab_footnote(\n    footnote = \"y ~ r + r:s + s + x\",\n    locations = cells_column_labels(columns = fit2s)\n    ) \n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTrue\nfit11\nfit22\nfit1s3\nfit2s4\n\n\n\n\nMarginal log-odds ratio\n0.376\n0.377\n0.378\n0.378\n0.378\n\n\nAverage log-odds ratio\n\n\n0.391\n0.405\n0.418\n0.416\n\n\nConditional (X = 0)\n0.397\n0.391\n0.408\n0.393\n0.398\n\n\nConditional (X = 1)\n0.367\n0.391\n0.334\n0.392\n0.371\n\n\n\n1 y ~ r + x\n\n\n2 y ~ r + r:s + x\n\n\n3 y ~ r + s + x\n\n\n4 y ~ r + r:s + s + x\n\n\n\n\n\n\n\n\n\nTable 3: G-computation estimates in presence of prognostic covariate",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#unmeasured-confounder",
    "href": "notebooks/design-notes.html#unmeasured-confounder",
    "title": "Design Notes",
    "section": "Unmeasured Confounder",
    "text": "Unmeasured Confounder\nThe above hides some complexity because we assume everything is correctly specified. Suppose we introduce some unmeasured factor which influences which patients are preferred for a given revision type. Consider the following:\n\nR: randomised surgery - 0: DAIR, 1: revision\nS: preferred revision - 0: one-stage, 1: two-stage\nA: allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\nY: treatment success - 0: no, 1: yes\nZ: unmeasured factor, patient attributes/type - continuous\n\nWe assume \\(Z\\) is some immeasurable combination of factors which partly determines a patients risk of failure. We also think that this \\(Z\\) partly determines the surgeons choice of one/two stage. Say patients with higher values of \\(Z\\) are less likely to have successful treatment. However, the surgeon has some knowledge/experience/expertise/intuition which means that they are more likely to prefer a two-stage revision for patients with higher values of \\(Z\\), as they expect those types of patients will have better outcomes under two-stage. The allocated treatment and the underlying patient risk determines the patients outcome, \\(Y\\).\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A\n  Z(Z) --&gt; S & A & Y\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 2: Scenario 2, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\nGiven the randomisation, this does not really change anything, except making explicit that differences between one/two stage may just be due to confounding rather than effect of treatment. We can’t tell which without adjusting for all confounders.",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#checkpoint",
    "href": "notebooks/design-notes.html#checkpoint",
    "title": "Design Notes",
    "section": "Checkpoint",
    "text": "Checkpoint\nSo, perhaps the easiest quantity to consider is the average conditional log-odds, i.e.\n\\[\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S,X,...)}{\\text{odds}(Y|R=0,S,X,...)}\\right] = \\beta_1 + \\beta_2\\mathbb{E}[S].\n\\]\nIs this sufficiently meaningful?\n\n\n\n\n\n\nNote\n\n\n\n\n\nI think what you are saying is to adopt Equation 4 and then report our effect estimate for revision at the sample mean of observed selection, which is this case fully characterises the distribution anyway.\nThe terminology used for effects seems to vary a bit throughout, but my label would probably be more explicit conditional log-OR evaluated at the mean selection or something like that, whereas I think it has been previously referred to as conditional (weighted) log-OR earlier and average (weighted) log-OR earlier, probably because that is how they have been computed.",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#duration",
    "href": "notebooks/design-notes.html#duration",
    "title": "Design Notes",
    "section": "Duration",
    "text": "Duration\nDuration, \\(D\\), is randomised, however, the duration options depends upon assignment to revision \\(R\\), and the chosen revision type, \\(S\\). So it is random conditional on \\(R\\) and \\(S\\). Nothing else alters the distribution of \\(D\\). We expect that duration has an effect on the outcome.\nBelow we just use \\(D=0\\) for long and \\(D=1\\) for short, but note that the meaning of these is conditional on \\(R/S\\) (i.e. short for one-stage different to short for two-stage and only applies to revision)\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A & D\n  R --&gt; D\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 3: Scenario 3, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThere might be alternative representations of the above and also the potential for direct and indirect effects of \\(S\\), see below:\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A\n  S --&gt; Y\n  A --&gt; D\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; D\n  S --&gt; D\n  S --&gt; Y\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 4\n\nFigure 5\nNow there are two interventions: \\(R\\) which has downstream unknown effects partly due to the unknown revision type, \\(S\\), which is selected, and \\(D\\) which is randomised.\nThe simplest approach is to analyse these separately. First, restrict the analysis to those patients who were assigned to one-stage and have an RCT for duration in embedded in that subset. Then, restrict analysis to only those assigned to two-stage and have an RCT for duration in that subset. However, we would like to have a joint model so that other effects can be shared (other domains/site/surgeon/age/whatever else). In the joint model, duration effect needs to be conditional on revision type.\nSay the true model were something like\n\\[\n\\mathbb{E}[Y|R,S,D] = \\text{expit}(\\beta_0 + \\beta_1S + \\beta_2R + \\beta_3RS + \\beta_4RD + \\beta_5RDS)\n\\tag{7}\\]\nso\n\n\\(\\beta_2\\) is the shift associated with revision and long duration (assuming long-duration is the refrence group)\n\\(\\beta_3\\) the additional shift associated with two-stage long duration,\n\\(\\beta_4\\) the relative shift for short duration given revision,\n\\(\\beta_5\\) the relative shift for short duration given two-stage.\n\nWe might choose to setup the design matrix so that it is orthonormal so that a-priori we don’t assign more uncertainty to a specific revision type. E.g.\n\\[\n\\mathbb{E}[Y|R,S] = \\text{expit}(\\beta_0 + \\beta_1(S - 0.5) + \\beta_2R + \\beta_3R(S-0.5) + \\beta_4R(D-0.5) + \\beta_5R(D-0.5)(S-0.5)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\nIs the above missing a \\(D\\) from the conditioning?\n\n\n\nbut for simplicity, not doing this here.\nFrom the above, and with a focus on the surgical domain, we could compare (randomised comparison) any of:\n\nrevision long vs. DAIR\nrevision short vs. DAIR, but no other combinations of revision.\none-stage short + two-stage long vs. DAIR\ntwo-stage short + one-stage long vs. DAIR\n\nWhere (1) and (2) are the likely the most relevant comparisons of interest, but nothing precludes the comparisons stated in (3) and (4). The key point is the explicit statement of the duration type at which the comparison is made, which again is averaged over the empircal distribution of surgical procedure type (one-stage/two-stage).\nHowever, we always needs to marginalise over \\(S\\) (selection/plan):\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|R=0] &= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1s)\\mathbb{P}(S=s|R=0) \\\\\n\\mathbb{E}[Y|R=1,D=0] &= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1s + \\beta_2 + \\beta_3s)\\mathbb{P}(S=s|R=1,D=0) \\\\\n\\mathbb{E}[Y|R=1,D=1] &= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1s + \\beta_2 + \\beta_3s + \\beta_4 + \\beta_5s)\\mathbb{P}(S=s|R=1,D=1)\n\\end{aligned}\n\\]\nAgain, can alternatively consider the average conditional log-odds ratio\n\\[\n\\begin{aligned}\n\\mathbb{E}\\left[\\ln\\frac{\\text{odds}(Y|R=1,S,D)}{\\text{odds}(Y|R=0,S,D)}|D_0,D_1\\right] &= \\beta_2+\\beta_3\\mathbb{E}[S] + \\beta_4D_0 + \\beta_5D_1\\mathbb{E}[S]\n\\end{aligned}\n\\]\nwhere I’ve made it explicit that \\(D_0\\) (one-stage short) and \\(D_1\\) (two-stage short) may differ. However, in practice, these would likely be set to the same level.\nThe default data generating mechanism has the functional form:\n\\[\n\\mathbb{E}[Y|R,S,D] = \\text{expit}(\\beta_0 + \\beta_1X + \\beta_1S + \\beta_2R + \\beta_3RS + \\beta_4RD + \\beta_5RSD)\n\\]\nspecified with non-zero effects on all terms.\n\n\nGenerate duration data\ngenerate_data_2 &lt;- function(\n    n = 1000000,\n    f = function(x, r, s, d){ -1 + x + s + r + 0.5 * r * s - 0.5 * r * d - 0.25 * r * s * d}) {\n  x &lt;- rbinom(n, 1, 0.25)\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  a &lt;- r * (s + 1)\n  d &lt;- as.numeric((a &gt; 0) * rbinom(n, 1, 0.5))\n  y0 &lt;- rbinom(n, 1, plogis(f(x, 0, s, 0)))\n  y10 &lt;- rbinom(n, 1, plogis(f(x, 1, s, 0)))\n  y11 &lt;- rbinom(n, 1, plogis(f(x, 1, s, 1)))\n  y &lt;- (1 - r) * y0 + r * ((1 - d) * y10 + d * y11)\n  D &lt;- data.table(x = x, r = r, s = s, a = a, d = d, y0 = y0, y10 = y10, y11 = y11, y = y)[\n    ,\n    `:=`(\n      a1d1 = as.numeric(a == 1 & d == 1),\n      a2d1 = as.numeric(a == 2 & d == 1),\n      r_fac = factor(r),\n      a_fac = factor(a),\n      s_fac = factor(s),\n      a_cen = r * (a - 1 - mean(a[r == 1] - 1)),\n      s_cen = s - mean(s),\n      s_ort = s - 0.5\n    )\n  ]\n}\nset.seed(1246)\nD &lt;- generate_data_2(f = function(x, r, s, d){ -1 + s + x})\nfit2 &lt;- glm(y ~ x + r + r:s + r:d + r:s:d, data = D, family = binomial())\nfit2s &lt;- glm(y ~ x + s + r + r:s + r:d + r:s:d, data = D, family = binomial())\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nIn the following examples estimation under null effects is considered wherein the true data generation mechanism was \\(\\mathbb{E}[Y|S,X] = \\text{expit}(-1 + S + X)\\). That is, where there are no treatment effects in either the surgical or duration domains.\nThe estimates use G-computation. Specifically, all of the following average over all terms bar the comparison of interest.\n\n\n\n\n\nRevision vs. DAIR\n# Revision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %\n    r ln(odds(1) / odds(0)) -0.00856    0.00410 -2.09   0.0370 4.8 -0.0166\n    r ln(odds(1) / odds(0)) -0.00836    0.00406 -2.06   0.0396 4.7 -0.0163\n    97.5 %\n -0.000515\n -0.000400\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\nRevision (long) vs. DAIR and Revision (short) vs. DAIR\n# Revision (long) vs. DAIR and Revision (short) vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = \"d\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = \"d\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d Estimate Std. Error     z Pr(&gt;|z|)   S   2.5 %\n    r ln(odds(1) / odds(0)) 0 -0.00864    0.00473 -1.83   0.0676 3.9 -0.0179\n    r ln(odds(1) / odds(0)) 1 -0.00832    0.00473 -1.76   0.0785 3.7 -0.0176\n    r ln(odds(1) / odds(0)) 0 -0.00863    0.00469 -1.84   0.0658 3.9 -0.0178\n    r ln(odds(1) / odds(0)) 1 -0.00755    0.00469 -1.61   0.1074 3.2 -0.0167\n   97.5 %\n 0.000627\n 0.000949\n 0.000562\n 0.001641\n\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nConditional on X\n# Conditional on X\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d x Estimate Std. Error      z Pr(&gt;|z|)    S\n    r ln(odds(1) / odds(0)) 0 0  0.00267    0.00493  0.541   0.5884  0.8\n    r ln(odds(1) / odds(0)) 0 1 -0.04726    0.00496 -9.525   &lt;0.001 69.0\n    r ln(odds(1) / odds(0)) 1 0  0.00270    0.00493  0.547   0.5842  0.8\n    r ln(odds(1) / odds(0)) 1 1 -0.04602    0.00496 -9.277   &lt;0.001 65.6\n    r ln(odds(1) / odds(0)) 0 0 -0.00895    0.00490 -1.829   0.0675  3.9\n    r ln(odds(1) / odds(0)) 0 1 -0.00909    0.00494 -1.841   0.0656  3.9\n    r ln(odds(1) / odds(0)) 1 0 -0.00822    0.00489 -1.680   0.0930  3.4\n    r ln(odds(1) / odds(0)) 1 1 -0.00667    0.00494 -1.350   0.1771  2.5\n    2.5 %    97.5 %\n -0.00700  0.012332\n -0.05699 -0.037538\n -0.00696  0.012360\n -0.05575 -0.036301\n -0.01855  0.000643\n -0.01878  0.000588\n -0.01782  0.001370\n -0.01635  0.003014\n\nColumns: term, contrast, d, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs Long (one-stage) and short vs. long (two-stage)\n# Short vs Long (one-stage) and short vs. long (two-stage)\nrbind(\n  avg_comparisons(fit2, variables = \"d\", by = \"s\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"d\", by = \"s\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast s Estimate Std. Error      z Pr(&gt;|z|)   S    2.5 %\n    d ln(odds(1) / odds(0)) 0  0.00603    0.00491  1.228    0.220 2.2 -0.00359\n    d ln(odds(1) / odds(0)) 1 -0.00174    0.00330 -0.528    0.597 0.7 -0.00821\n    d ln(odds(1) / odds(0)) 0  0.00664    0.00538  1.234    0.217 2.2 -0.00390\n    d ln(odds(1) / odds(0)) 1 -0.00176    0.00333 -0.527    0.598 0.7 -0.00829\n  97.5 %\n 0.01565\n 0.00472\n 0.01718\n 0.00478\n\nColumns: term, contrast, s, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs long conditional on x\n# Short vs long conditional on x\navg_comparisons(fit2, variables = \"d\", by = c(\"s\", \"x\"), comparison = \"lnoravg\")\n\n\n\n Term              Contrast s x Estimate Std. Error      z Pr(&gt;|z|)   S\n    d ln(odds(1) / odds(0)) 0 0  0.00599    0.00488  1.228    0.220 2.2\n    d ln(odds(1) / odds(0)) 0 1  0.00712    0.00580  1.228    0.220 2.2\n    d ln(odds(1) / odds(0)) 1 0 -0.00184    0.00349 -0.528    0.597 0.7\n    d ln(odds(1) / odds(0)) 1 1 -0.00172    0.00326 -0.528    0.597 0.7\n    2.5 %  97.5 %\n -0.00357 0.01555\n -0.00425 0.01850\n -0.00868 0.00499\n -0.00812 0.00467\n\nColumns: term, contrast, s, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nAnd now consider estimation under effects for all surgery and duration.\n\n\n\n\n\nData generation assuming effects in both domains\nD &lt;- generate_data_2()\nfit2 &lt;- glm(y ~ x + r + r:s + r:d + r:s:d, data = D, family = binomial())\nfit2s &lt;- glm(y ~ x + s + r + r:s + r:d + r:s:d, data = D, family = binomial())\n\n\n\n\nRevision vs. DAIR\n# Revision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))     1.03    0.00427 240   &lt;0.001 Inf  1.02   1.03\n    r ln(odds(1) / odds(0))     1.03    0.00423 243   &lt;0.001 Inf  1.02   1.03\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\nRevision (long) vs. DAIR and Revision (short) vs. DAIR\n# Revision (long) vs. DAIR and Revision (short) vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = \"d\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = \"d\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0)) 0    1.184    0.00518 228   &lt;0.001 Inf 1.174  1.194\n    r ln(odds(1) / odds(0)) 1    0.607    0.00482 126   &lt;0.001 Inf 0.598  0.617\n    r ln(odds(1) / odds(0)) 0    1.184    0.00515 230   &lt;0.001 Inf 1.174  1.194\n    r ln(odds(1) / odds(0)) 1    0.607    0.00478 127   &lt;0.001 Inf 0.598  0.616\n\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nConditional on X\n# Conditional on X\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = c(\"d\", \"x\"), comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d x Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 %\n    r ln(odds(1) / odds(0)) 0 0    1.239    0.00532 233   &lt;0.001 Inf 1.228\n    r ln(odds(1) / odds(0)) 0 1    1.153    0.00554 208   &lt;0.001 Inf 1.142\n    r ln(odds(1) / odds(0)) 1 0    0.645    0.00499 129   &lt;0.001 Inf 0.635\n    r ln(odds(1) / odds(0)) 1 1    0.573    0.00510 112   &lt;0.001 Inf 0.563\n    r ln(odds(1) / odds(0)) 0 0    1.230    0.00528 233   &lt;0.001 Inf 1.219\n    r ln(odds(1) / odds(0)) 0 1    1.191    0.00554 215   &lt;0.001 Inf 1.180\n    r ln(odds(1) / odds(0)) 1 0    0.635    0.00495 128   &lt;0.001 Inf 0.625\n    r ln(odds(1) / odds(0)) 1 1    0.610    0.00509 120   &lt;0.001 Inf 0.600\n 97.5 %\n  1.249\n  1.163\n  0.655\n  0.583\n  1.240\n  1.202\n  0.645\n  0.620\n\nColumns: term, contrast, d, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs Long (one-stage) and short vs. long (two-stage)\n# Short vs Long (one-stage) and short vs. long (two-stage)\nrbind(\n  avg_comparisons(fit2, variables = \"d\", by = \"s\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"d\", by = \"s\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast s Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %\n    d ln(odds(1) / odds(0)) 0   -0.235    0.00504 -46.6   &lt;0.001 Inf -0.245\n    d ln(odds(1) / odds(0)) 1   -0.264    0.00295 -89.7   &lt;0.001 Inf -0.270\n    d ln(odds(1) / odds(0)) 0   -0.242    0.00520 -46.6   &lt;0.001 Inf -0.252\n    d ln(odds(1) / odds(0)) 1   -0.277    0.00309 -89.7   &lt;0.001 Inf -0.283\n 97.5 %\n -0.225\n -0.258\n -0.232\n -0.271\n\nColumns: term, contrast, s, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs long conditional on x\n# Short vs long conditional on x\navg_comparisons(fit2, variables = \"d\", by = c(\"s\", \"x\"), comparison = \"lnoravg\")\n\n\n\n Term              Contrast s x Estimate Std. Error     z Pr(&gt;|z|)   S  2.5 %\n    d ln(odds(1) / odds(0)) 0 0   -0.246    0.00527 -46.6   &lt;0.001 Inf -0.256\n    d ln(odds(1) / odds(0)) 0 1   -0.243    0.00523 -46.5   &lt;0.001 Inf -0.253\n    d ln(odds(1) / odds(0)) 1 0   -0.286    0.00319 -89.7   &lt;0.001 Inf -0.292\n    d ln(odds(1) / odds(0)) 1 1   -0.212    0.00241 -87.9   &lt;0.001 Inf -0.217\n 97.5 %\n -0.235\n -0.233\n -0.280\n -0.207\n\nColumns: term, contrast, s, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#other-domains",
    "href": "notebooks/design-notes.html#other-domains",
    "title": "Design Notes",
    "section": "Other Domains",
    "text": "Other Domains\nThe desire for a single model is incorporation of multiple silos and domains. Suppose we introduce the antibiotic type (rifampicin) domain, which is denoted by \\(F\\). Assume everyone were eligible. Our base model would be\n\\[\n\\mathbb{E}[Y|R,S,D,F] = \\text{expit}(\\beta_0 + \\beta_1S + \\beta_2R + \\beta_3RS + \\beta_4RD + \\beta_5RDS + \\beta_6F)\n\\]\n\n\n\n\n\n\nNote\n\n\n\n\n\n\\(\\beta_2\\) is now the shift for revision (under long duration irrespective of surgical type)\n\n\n\n\n\nGenerate rifampicin data\ngenerate_data_3 &lt;- function(\n    n = 1000000,\n    g = function(x, r, s, d, f){ -1 + x + s + r + 0.5 * r * s - 0.25 * r * d - 0.15 * r * s * d + 0.2 * f}) {\n  x &lt;- rbinom(n, 1, 0.25)\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  f &lt;- rbinom(n, 1, 0.5)\n  a &lt;- r * (s + 1)\n  d &lt;- as.numeric((a &gt; 0) * rbinom(n, 1, 0.5))\n  y &lt;- rbinom(n, 1, plogis(g(x, r, s, d, f)))\n  D &lt;- data.table(x = x, r = r, s = s, a = a, d = d, f = f, y = y)\n}\nset.seed(1246)\nD &lt;- generate_data_3()\nfit2 &lt;- glm(y ~ x + r + f + r:s + r:d + r:s:d, data = D, family = binomial())\nfit2s &lt;- glm(y ~ x + s + r + f + r:s + r:d + r:s:d, data = D, family = binomial())\n\n\n\n\nRevision vs. DAIR\n# Revision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))      1.1    0.00441 250   &lt;0.001 Inf   1.1   1.11\n    r ln(odds(1) / odds(0))      1.1    0.00437 253   &lt;0.001 Inf   1.1   1.11\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nRevision vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\"),\n  avg_comparisons(fit2s, variables = \"r\", comparison = \"lnor\")\n)\n\n\n\n Term              Contrast Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))     1.25    0.00508 247   &lt;0.001 Inf  1.24   1.26\n    r ln(odds(1) / odds(0))     1.26    0.00512 246   &lt;0.001 Inf  1.25   1.27\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nRevision vs. DAIR conditional\n# Revision vs. DAIR conditional\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = c(\"f\", \"x\", \"d\"), comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = c(\"f\", \"x\", \"d\"), comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast f x d Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 %\n    r ln(odds(1) / odds(0)) 0 0 0    1.245    0.00542 230   &lt;0.001 Inf 1.234\n    r ln(odds(1) / odds(0)) 0 0 1    0.945    0.00519 182   &lt;0.001 Inf 0.935\n    r ln(odds(1) / odds(0)) 0 1 0    1.159    0.00561 206   &lt;0.001 Inf 1.148\n    r ln(odds(1) / odds(0)) 0 1 1    0.861    0.00532 162   &lt;0.001 Inf 0.850\n    r ln(odds(1) / odds(0)) 1 0 0    1.225    0.00543 226   &lt;0.001 Inf 1.215\n    r ln(odds(1) / odds(0)) 1 0 1    0.926    0.00518 179   &lt;0.001 Inf 0.916\n    r ln(odds(1) / odds(0)) 1 1 0    1.145    0.00567 202   &lt;0.001 Inf 1.134\n    r ln(odds(1) / odds(0)) 1 1 1    0.852    0.00537 158   &lt;0.001 Inf 0.841\n    r ln(odds(1) / odds(0)) 0 0 0    1.232    0.00538 229   &lt;0.001 Inf 1.222\n    r ln(odds(1) / odds(0)) 0 0 1    0.931    0.00515 181   &lt;0.001 Inf 0.921\n    r ln(odds(1) / odds(0)) 0 1 0    1.192    0.00560 213   &lt;0.001 Inf 1.181\n    r ln(odds(1) / odds(0)) 0 1 1    0.896    0.00531 169   &lt;0.001 Inf 0.886\n    r ln(odds(1) / odds(0)) 1 0 0    1.221    0.00539 227   &lt;0.001 Inf 1.210\n    r ln(odds(1) / odds(0)) 1 0 1    0.922    0.00514 179   &lt;0.001 Inf 0.912\n    r ln(odds(1) / odds(0)) 1 1 0    1.188    0.00569 209   &lt;0.001 Inf 1.177\n    r ln(odds(1) / odds(0)) 1 1 1    0.894    0.00538 166   &lt;0.001 Inf 0.883\n 97.5 %\n  1.256\n  0.955\n  1.170\n  0.871\n  1.236\n  0.936\n  1.156\n  0.862\n  1.243\n  0.941\n  1.203\n  0.907\n  1.231\n  0.932\n  1.200\n  0.905\n\nColumns: term, contrast, f, x, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nRevision (long) vs. DAIR and Revision (short) vs. DAIR\n# Revision (long) vs. DAIR and Revision (short) vs. DAIR\nrbind(\n  avg_comparisons(fit2, variables = \"r\", by = \"d\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"r\", by = \"d\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast d Estimate Std. Error   z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0)) 0    1.182    0.00528 224   &lt;0.001 Inf 1.171  1.192\n    r ln(odds(1) / odds(0)) 1    0.889    0.00502 177   &lt;0.001 Inf 0.879  0.899\n    r ln(odds(1) / odds(0)) 0    1.182    0.00525 225   &lt;0.001 Inf 1.171  1.192\n    r ln(odds(1) / odds(0)) 1    0.890    0.00499 178   &lt;0.001 Inf 0.880  0.899\n\nColumns: term, contrast, d, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nRifampicin vs not\n# Rifampicin vs not\nrbind(\n  avg_comparisons(fit2, variables = \"f\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"f\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    f ln(odds(1) / odds(0))    0.168    0.00387 43.4   &lt;0.001 Inf 0.161  0.176\n    f ln(odds(1) / odds(0))    0.168    0.00382 44.0   &lt;0.001 Inf 0.160  0.175\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\n\n\nShort vs Long (one-stage) and short vs. long (two-stage)\n# Short vs Long (one-stage) and short vs. long (two-stage)\nrbind(\n  avg_comparisons(fit2, variables = \"d\", by = \"s\", comparison = \"lnoravg\"),\n  avg_comparisons(fit2s, variables = \"d\", by = \"s\", comparison = \"lnoravg\")\n)\n\n\n\n Term              Contrast s Estimate Std. Error     z Pr(&gt;|z|)     S  2.5 %\n    d ln(odds(1) / odds(0)) 0   -0.119    0.00505 -23.6   &lt;0.001 406.7 -0.129\n    d ln(odds(1) / odds(0)) 1   -0.121    0.00284 -42.6   &lt;0.001   Inf -0.127\n    d ln(odds(1) / odds(0)) 0   -0.120    0.00508 -23.6   &lt;0.001 407.5 -0.130\n    d ln(odds(1) / odds(0)) 1   -0.129    0.00302 -42.6   &lt;0.001   Inf -0.134\n 97.5 %\n -0.109\n -0.115\n -0.110\n -0.123\n\nColumns: term, contrast, s, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nShort vs long conditional on x\n# Short vs long conditional on x\navg_comparisons(fit2, variables = \"d\", by = c(\"s\", \"x\"), comparison = \"lnoravg\")\n\n\n\n Term              Contrast s x Estimate Std. Error     z Pr(&gt;|z|)     S\n    d ln(odds(1) / odds(0)) 0 0  -0.1250    0.00530 -23.6   &lt;0.001 406.9\n    d ln(odds(1) / odds(0)) 0 1  -0.1210    0.00513 -23.6   &lt;0.001 406.4\n    d ln(odds(1) / odds(0)) 1 0  -0.1309    0.00307 -42.6   &lt;0.001   Inf\n    d ln(odds(1) / odds(0)) 1 1  -0.0946    0.00223 -42.4   &lt;0.001   Inf\n   2.5 %  97.5 %\n -0.1354 -0.1146\n -0.1310 -0.1109\n -0.1370 -0.1249\n -0.0989 -0.0902\n\nColumns: term, contrast, s, x, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#silos",
    "href": "notebooks/design-notes.html#silos",
    "title": "Design Notes",
    "section": "Silos",
    "text": "Silos\nThe above has considered the late-acute silo in isolation. Suppose we also had a chronic silo with the same limitations: randomise to DAIR vs. revision, then revision type is determined by the surgeon/patient, duration is randomised. In the new setting, nothing really changes, we can just introduce silo-specific parameters. For lack of letters, let \\(G\\) denote group (silo). Then\n\\[\n\\mathbb{E}[Y|G=g,R,S,D] = \\text{expit}(\\beta_{0,g} + \\beta_{1,g}R + \\beta_{2,g}S + \\beta_{3,g}RS + \\beta_{4,g}RD + \\beta_{5,g}RSD + \\gamma_g^\\mathsf{T}X)\n\\]\nWe might choose to assume that some of the conditional effects are equal across groups. E.g. \\(\\gamma_g=\\gamma\\) for all \\(g\\). Or \\(\\beta_{4,g} = \\beta_4\\) and \\(\\beta_{5,g}=\\beta_5\\). Depends how realistic we think these assumptions may be and whether we have sufficient data to meaningfully estimate silo-specific effects.\nPerhaps the only new issue is that now \\(\\mathbb{P}(S=s|G=1)\\ne\\mathbb{P}(S=s|G=2)\\), so need to weight things within silo.\n\n\n\n\n\n\nNote\n\n\n\n\n\nThe other thing to consider here is that in the early silo, there is no information contributed to parameters characterising the surgical intervention effects. I am not sure that the above model addresses this in that \\(\\beta_{1,g}\\) for \\(g = early\\) would not be defined.",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#revision-type",
    "href": "notebooks/design-notes.html#revision-type",
    "title": "Design Notes",
    "section": "Revision Type",
    "text": "Revision Type\nIn all the above I’ve been assuming that the revision type, \\(S\\), is an attribute of the patient. E.g. all surgeons would choose the same \\(S\\) for the same patient. More realistically, \\(S\\) might also partly depend on the surgeon (e.g. say a surgeon would choose \\(S=1\\) for all patients, but another would choose \\(S=0\\) for all patients, now \\(S\\) is conditional on the surgeon rather than the patient). Assume \\(S\\) is an attribute of the patient/surgeon combination rather than either alone. Do we need to change anything? How to interpret “revision effect”? An average effect over patients and surgeons?\nAlready expect that we should at least condition on the site/surgeon, but do we need anything extra to account for \\(S\\)? Distribution of \\(S\\) conditional on surgeon?",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#randomisation-reveal",
    "href": "notebooks/design-notes.html#randomisation-reveal",
    "title": "Design Notes",
    "section": "Randomisation reveal",
    "text": "Randomisation reveal\nA number of simplifying assumptions have been made that result in an incomplete representation of the design. For example, at the start of the discussion on the duration domain, we assumed that duration is randomised, but depends on both \\(R\\) and \\(S\\). However, note:\n\n\\(R\\) presupposes eligibility and reveal for the surgical domain, which is not the general case, e.g. early stage infection silo.\nPatients may enter into the study without having being entered for a randomised comparison in the surgical domain (e.g. patients with early stage infection) in which case the allocated surgery (\\(R_A\\)) would have been determined entirely by clinician selection.\nPatients enter into the duration domain based on the surgical procedure that occurred. This is expected to usually align with the allocated procedure \\(R_A\\), but may deviate from that.\n\\(D\\) is random, conditional solely on \\(R_P\\) rather than both \\(R\\) and \\(S_{R_A}\\) (as stated in the duration section).\n\\(D\\) exists only for \\(R_P \\in \\{\\text{one-stage}, \\text{two-stage}\\}\\) otherwise reveal never occurs and duration allocated \\(D_A\\) is determined by clinician selection\nWhile the duration domain for one-stage and two-stage both contain long (reference) vs short levels for duration of antibiotic, the levels are distinct for each procedure.\n\nTo incorporate some of these ideas, start with the following definitions:\n\n\\(E_R\\) reveal for surgical domain - 0: no, 1: yes\n\\(E_D\\) reveal for duration domain - 0: no, 1: yes\n\\(E_F\\) reveal for choice domain - 0: no, 1: yes\n\\(R\\) randomised surgery - 0: DAIR, 1: revision\n\\(S_R\\) revision type preference (pre-randomisation) - 0: DAIR, 1: one-stage, 2: two-stage\n\\(R_A\\) allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\n\\(R_P\\) performed surgery - 0: DAIR, 1: revision\n\\(S_{R_P}\\) revision type performed (post-randomisation) - 0: one-stage, 1: two-stage\n\\(D\\) randomised duration - 0: long, 1: short\n\\(D_A\\) allocated duration - 0: long, 1: short, 2: other\n\\(S_D\\) selected duration - 0: long, 1: short, 2: other\n\\(F\\) randomised choice - 0: norif, 1: rif\n\\(F_A\\) allocated choice - 0: norif, 1: rif, 2: other\n\\(S_F\\) selected choice - 0: norif, 1: rif, 2: other\n\\(Y\\) treatment success - 0: no, 1: yes\n\nIn practice, we expect the allocated \\(R_A\\) and actual \\(R_P\\) surgical procedure performed will align, but in some cases they may not.\nContrived) example one: revision was randomised and the original surgeon only performs two-stage revision. The original surgeon becomes unavailable to do the procedure and another surgeon (who only performs one-stage revision) takes over the case. The patient enters into the duration domain for comparisons within the setting of one-stage revision.\nContrived) example two: revision was randomised and the surgeon intends to perform a two-stage revision. On the operating table, the surgeon switches to dair, for unknown reasons and the patient will no longer enter into randomised comparisons for the duration domain.\n\\(R_A\\) (allocation) is now determined by additional variables:\n\\[\nR_A = (1-E_R) S_R + E_R R S_R\n\\]\nso that when we have no revealed randomisation for the surgical domain, \\(R_A\\) aligns with the preferred procedure out of all those possible (dair, one-stage, two-stage). When randomisation revealed for the surgical domain, the first term disappears and for \\(R = 0\\), the allocation is dair, irrespective of preferred surgery, whereas when \\(R = 1\\) we get whatever one of one-stage (\\(S_R = 1\\)) or two-stage (\\(S_R = 2\\)) is preferred.\nFor duration allocated \\(D_A\\):\n\\[\nD_A = (1-E_D) S_D + E_D D\n\\]\nwhen no reveal, \\(E_D = 1\\) and \\(D_A = S_D\\) (long/short/other duration) and when revealed, \\(D_A = D\\) (long/short duration).\nFor choice allocated \\(F_A\\):\n\\[\nF_A = (1 - E_F) S_F + E_F F\n\\]\nwhen no reveal, \\(F_A = S_F\\) (norif/rif/other) and when revealed, \\(F_A = F\\) (norif/rif).\n\n\n\n\n\n\nNote\n\n\n\n\n\nAbove, I am assuming that you can randomise someone within a domain without first assessing their eligibility status or knowing anything about them other than they want to enter the platform, which I believe is the intention. Randomisation is only revealed if eligibility is confirmed and this process is independent to the randomisation process.\n\n\n\nThe edited DAG is shown below, which still has a number of simplications relative to the intended approach but is intended to represent a generalised silo and site of infection, implicitly acknowledging that the outcome will be dependent on both these factors. Patients may contribute to some or all domains, which influences the treatment regimen (combination of treatments across the domains) they receive and which suggests the various causal effects that are identifiable.\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  ER(E&lt;sub&gt;R) --&gt; RA(R&lt;sub&gt;A) \n  ER --&gt; SR(S&lt;sub&gt;R)\n  ED(E&lt;sub&gt;D) --&gt; DA(D&lt;sub&gt;A) \n  SR --&gt; RA \n  SD(S&lt;sub&gt;D) --&gt; DA \n  R --&gt; RA\n  RA --&gt; RP(R&lt;sub&gt;P) \n  SRP(S&lt;sub&gt;R&lt;sub&gt;P) --&gt; RP\n  RA --&gt; Y\n  RP --&gt; ED\n  D --&gt; DA(D&lt;sub&gt;A)\n  DA --&gt; Y\n  F --&gt; FA(F&lt;sub&gt;A)\n  EF(E&lt;sub&gt;F) --&gt; FA\n  SF(S&lt;sub&gt;F) --&gt; FA \n  FA --&gt; Y\n  UER((U&lt;sub&gt;E&lt;sub&gt;R)) -.-&gt; ER\n  UED((U&lt;sub&gt;E&lt;sub&gt;D)) -.-&gt; ED\n  UEF((U&lt;sub&gt;E&lt;sub&gt;F)) -.-&gt; EF\n  UF((U&lt;sub&gt;F)) -.-&gt; F\n  URP((U&lt;sub&gt;R&lt;sub&gt;P)) -.-&gt; SRP\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  USR((U&lt;sub&gt;S&lt;sub&gt;R)) -.-&gt; SR\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  USD((U&lt;sub&gt;S&lt;sub&gt;D)) -.-&gt; SD\n  USF((U&lt;sub&gt;S&lt;sub&gt;F)) -.-&gt; SF\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 6: Scenario 4, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nThere is potentially a direct as well as the indirect effect of both \\(S_R\\) on \\(Y\\) and \\(S_{R_P}\\) on \\(Y\\) but these have been left out of the DAG for now. \\(S_R\\) is actually representing multiple ideas:\n\nwhen the surgical domain is not applicable (randomisation never revealed) e.g. for the chronic patients, then \\(S_R\\) is the selection from dair, one-stage, two-stage\nwhen surgical domain is applicable (randomisation is revealed) then \\(S_R\\) is the option between one-stage and two-stage that is most prefered.\n\nIn essence, \\(S_R\\) involves a conditional ranking of which surgical procedure is prefered.\nFor example, say the selection is: dair, two-stage, one-stage in order of preference. If randomisation is not reveal, dair is would be the selection. If randomisation is revealed, two-stage would be as it is the most prefered surgical procedure applicable to revision.\nOriginally, \\(D\\) was said to depend on some of the selection elements. However, subsequently it was decided that \\(D\\) (long/short) should be viewed like all other randomisation processes, i.e. independent of all other nodes, but is only manifest through \\(D_A\\) for certain surgery types.\n\n\n\nAgain consider intervening on surgical procedure whereby we are interested in the effect of dair vs revision on treatment success. There are no open backdoor paths apparent and therefore no adjustment is required to identify the total effect of \\(R\\) on \\(Y\\). Similarly, neither \\(D\\) nor \\(F\\) have backdoor paths.\nPostulate the following model:\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|L; \\beta] &=  \\text{expit}( \\beta_0 + \\\\\n  &\\quad \\beta_1 \\mathbb{I}[G = 1] + \\beta_2 \\mathbb{I}[G = 2] + \\beta_3 J + \\\\\n  &\\quad \\beta_4 J \\mathbb{I}[G = 1] + \\beta_5 J \\mathbb{I}[G = 2] + \\\\\n  &\\quad \\beta_6 \\mathbb{I}(1-E_R) + ([\\beta_7 R + \\beta_8 R \\mathbb{I}(S_{R_P} = 2) ])\\mathbb{I}(E_R) + \\\\\n  &\\quad \\beta_9 \\mathbb{I}(1-E_D) + ([\\beta_{10} R_P D + \\beta_{11} R_P D \\mathbb{I}(S_{R_P} = 2)])\\mathbb{I}(E_D) + \\\\\n  &\\quad \\beta_{12} \\mathbb{I}(1-E_F) + \\beta_{13} F E_F )\n\\end{aligned}\n\\]\nwhere the \\(L\\) stands for the set of model variables and \\(\\beta\\) the vector of parameters. The following describe the reference/movements in the log-odds of treatment success:\n\n\\(\\beta_{0}\\) baseline log-odds of treatment success in the early silo / knee site\n\\(\\beta_{1}\\) shift for late-silo membership relative to early\n\\(\\beta_{2}\\) shift for chronic-silo membership relative to early\n\\(\\beta_{3}\\) shift for hip\n\\(\\beta_{4}\\) relative shift for late-silo membership with hip\n\\(\\beta_{5}\\) relative shift for chronic-silo membership with hip\n\\(\\beta_{6}\\) shift under non-reveal (surgery1)\n\\(\\beta_{7}\\) shift under revision that was performed with one-stage procedure for long duration and no-rif\n\\(\\beta_{8}\\) relative shift under revision that was performed with two-stage procedure for long duration and no-rif\n\\(\\beta_{9}\\) shift under non-reveal (duration) with no differentiation for surgical nor duration preference\n\\(\\beta_{10}\\) shift for short duration when one-stage was actually performed\n\\(\\beta_{11}\\) shift for short duration when two-stage was actually performed\n\\(\\beta_{12}\\) shift under non-reveal (choice) with no differentiation for choice preference\n\\(\\beta_{13}\\) shift for rif\n\nWith the complicating factor being that the surgical allocation may inform the type of surgery that the patient gets (but may deviate) and the randomisation that the patient is revealed to in the duration domain is determined by what surgical intervention the patient actually got.\nWe replace pre-randomised preference for surgical type with post-randomised surgical type performed and marginalise out this term.\n\n\n\n\n\n\nNote\n\n\n\n\n\nFull disclosure, I am not entirely sure as to whether the above addresses the full impacts of deviations between allocated and performed surgery or whether the DAG is sufficiently complete representation of the dependencies.\n\n\n\nAs previously, for the surgical domain, we are interested the effect of intervening on \\(R\\). For the duration domain, we are interested in the effect of intervening on \\(D|R_P\\). For the choice domain, we are interested in the effect of intervening on \\(F\\).\n\n\n\n\n\n\nNote\n\n\n\n\n\nNote that for the following specification, the design matrix can become singular (linear dependence between some of the variables) e.g. if surgical reveal is equivalent to silo membership. I am assuming some small amount of noise in reveal such that this isn’t a problem.\n\n\n\n\n\nGenerate complete data\ngenerate_data_4 &lt;- function(\n    n = 1e6,\n    g = function(p_a, l1, l2, j, er, ed, ef, r, rp, d, srp, f){ \n      -1 + -0.04 * l1 - 0.07 * l2 - 0.02 * j - 0.01 * l1 * j - 0.06 * l2 * j +\n        -0.1*(1-er) + (0.2*r + 0.4*r*(srp==2))*(er) +\n        -0.05*(1-ed) + (0.4*rp*d + 0.1*rp*d*(srp==2))*(ed) +\n        -0.25*(1-ef) + 0.15*f*(ef) \n      }\n    ) {\n  \n  p_a = array(\n    c(0.65, 0.55, 0.6, 0.75, 0.6, 0.65),\n    dim = c(3, 2), dimnames = list(c(\"early\", \"late\", \"chronic\"),c(\"knee\", \"hip\")))\n  \n  # silo (l) and joint (j)\n  l &lt;- sample(0:2, n, replace = T, prob = c(0.3, 0.5, 0.2)) \n  l1 = as.numeric(l == 1)\n  l2 = as.numeric(l == 2)\n  \n  p_j &lt;- array(c(0.4,0.7,0.5,0.6,0.3,0.5), dim = c(3, 2), \n               dimnames = list(c(\"early\", \"late\", \"chronic\"), c(\"knee\", \"hip\")))\n  j &lt;- rbinom(n, 1, p_j[l+1, 2])\n  # reveal for late only, with a small number who never get revealed even if they\n  # were in late. you can leave this out but the model spec will need to be updated\n  # because there will be linearly depenedent cols in the design matrix\n  er &lt;- as.numeric(l == 1)\n  er[l==1][as.logical(rbinom(er[l==1], 1, 0.05))] &lt;- 0\n  # randomise dair vs rev\n  r &lt;- rbinom(n, 1, 0.5)\n  # (approx) 70% chance of clinician choosing two-stage if pt is rand to revision \n  sr &lt;- numeric(n)\n  sr[r == 0] &lt;- sample(0:2, sum(r == 0), replace = T, prob = c(0.2, 0.2, 0.6))\n  sr[r == 1] &lt;- sample(1:2, sum(r == 1), replace = T, prob = c(0.3, 0.7))\n  # pref towards two-stage, assuming revision\n  sra &lt;- as.numeric(sr == 2)\n  # determine allocation of surgery type\n  ra &lt;- er * sr + (1-er) * r * (sr) \n  \n  # 10% of the allocated treatments may have switch to a different surg type\n  srp &lt;- ra\n  ic &lt;- rbinom(n, 1, 0.1)\n  srp[as.logical(ic)] &lt;- sample(0:2, sum(ic), replace = T, prob = c(0.2, 0.2, 0.6))\n  # was the procedure type dair or revision?\n  rp &lt;- as.numeric(srp %in% 1:2)\n  \n  # non-reveal of duration if rp is dair (0)\n  ed &lt;- as.numeric(rp == 1)\n  # rand to long (0), short (1) based on surgery received\n  d &lt;- as.numeric((rp &gt; 0) * rbinom(n, 1, 0.5))\n  # 60% reveal ab choice\n  ef &lt;- rbinom(n, 1, 0.6)\n  f &lt;- as.numeric((ef == 1) * rbinom(n, 1, 0.5))\n  \n  y &lt;- rbinom(n, 1, plogis(g(p_a, l1, l2, j, er, ed, ef, r, rp, d, srp, f)))\n  # table(y, useNA = \"always\")\n  \n  D &lt;- data.table(\n    l1, l2, j, \n    er, ed, ef,\n    erx = 1-er, edx = 1-ed, efx=1-ef,\n    r, sr, sra, ra, \n    ic, rp, srp, srp2 = as.numeric(srp == 2), d,\n    f, y\n  )\n}\nset.seed(102)\nD &lt;- generate_data_4()\n\n# early silo, should be non-reveal with no r options (default to 0)\n# D[, .N, keyby = .(l, j, er, r)]\n# those who received rev are revealed for d (ed = 0) and are 0:1 conditional on revision type (srp)\n# D[, .N, keyby = .(rp, ed, srp, d)]\n# those entering ab choice should come from all strata, infec site\n# D[ef == 0, .N, keyby = .(l, j, f)]\n# those that dont should also be dist across sample\n# D[ef == 1, .N, keyby = .(l, j, f)]\n\nfit2 &lt;- glm(y ~ l1 + l2 + j + l1:j + l2:j +\n              erx + er:r + er:r:srp2 +\n              edx + ed:rp:d + ed:d:rp:srp2 +\n              efx + ef:f, \n            data = D, family = binomial())\nsummary(fit2)\n\n\n\nCall:\nglm(formula = y ~ l1 + l2 + j + l1:j + l2:j + erx + er:r + er:r:srp2 + \n    edx + ed:rp:d + ed:d:rp:srp2 + efx + ef:f, family = binomial(), \n    data = D)\n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -0.992730   0.017361 -57.182  &lt; 2e-16 ***\nl1           -0.036997   0.016251  -2.277  0.02281 *  \nl2           -0.081398   0.009886  -8.234  &lt; 2e-16 ***\nj            -0.028103   0.008548  -3.288  0.00101 ** \nerx          -0.101703   0.015480  -6.570 5.04e-11 ***\nedx          -0.045398   0.006282  -7.227 4.94e-13 ***\nefx          -0.251435   0.005446 -46.167  &lt; 2e-16 ***\nl1:j         -0.022724   0.010840  -2.096  0.03605 *  \nl2:j         -0.052919   0.013561  -3.902 9.53e-05 ***\ner:r          0.187560   0.009727  19.283  &lt; 2e-16 ***\nef:f          0.147332   0.005624  26.198  &lt; 2e-16 ***\ner:r:srp2     0.407762   0.010375  39.302  &lt; 2e-16 ***\ned:rp:d       0.414709   0.008222  50.439  &lt; 2e-16 ***\nsrp2:ed:rp:d  0.085740   0.008749   9.800  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 1216852  on 999999  degrees of freedom\nResidual deviance: 1179406  on 999986  degrees of freedom\nAIC: 1179434\n\nNumber of Fisher Scoring iterations: 4\n\n\nGenerate complete data\n# linearly_dep_cols(fit2)\n\n\n\n\n\n\n\n\nNote\n\n\n\n\n\nUsing g-computation to determine the marginal effects. lnor and lnoravg are used as the comparisons.\nThe first (lnor) approach (average log odds?)\n\npredicts the log-odds of treatment success for all units with the surgical approach set to revision.\npredicts the log-odds of treatment success for all units with the surgical approach set to dair.\ncomputes the difference between the response on the log odds scale and takes the mean\n\nAlso can be derived from a weigted combination of the parameters from the regression model. What is an accurate interpretation of this parameter? How would you explain it to a non-statistician?\nThe second (lnoravg) approach (marginal mean?)\n\npredicts the probability of treatment success for all units with the surgical approach set to revision and computes the mean\npredicts the probability of treatment success for all units with the surgical approach set to dair and computes the mean\nconverts the mean probability of treatment success to the log-odds scale and takes the difference\n\n\n\n\n\n\nCode\n# Revision vs. DAIR\ncmp &lt;- avg_comparisons(fit2, variables = \"r\", comparison = \"lnor\")\n\nd_new &lt;- copy(D)\n\n# equivalent to using lnor\nd_new[, r := 1]\nlo1 &lt;- predict(fit2, newdata = d_new)\nd_new[, r := 0]\nlo0 &lt;- predict(fit2, newdata = d_new)\n\n# equivalent to weighted combination of parameters\nb &lt;- coef(fit2)\n\nw_srp &lt;- D[er == 1, mean(srp2)]\nw_er &lt;- D[, mean(er)]\n\nrbind(\n  \"predict at r = 0/1\" = mean(lo1 - lo0),\n  \"weighting coef by er and srp (condit on reveal)\" = w_er * b[\"er:r\"] + w_er * w_srp * b[\"er:r:srp2\"] , \n  \"avg_comparisons (lnor)\" = cmp$estimate\n)\n\n\n                                                     er:r\npredict at r = 0/1                              0.2136018\nweighting coef by er and srp (condit on reveal) 0.2136018\navg_comparisons (lnor)                          0.2136018\n\n\nCode\ncmp\n\n\n\n Term              Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))    0.214    0.00301 70.9   &lt;0.001 Inf 0.208   0.22\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\n\n\nCode\n# using lnoravg\navg_comparisons(fit2, variables = \"r\", comparison = \"lnoravg\")\n\n\n\n Term              Contrast Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    r ln(odds(1) / odds(0))    0.229    0.00314 73.1   &lt;0.001 Inf 0.223  0.235\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response \n\n\nCode\nd_new[, r := 1]\np1 &lt;- predict(fit2, newdata = d_new, type = \"response\")\nd_new[, r := 0]\np0 &lt;- predict(fit2, newdata = d_new, type = \"response\")\nqlogis(mean(p1)) - qlogis(mean(p0))\n\n\n[1] 0.2292898\n\n\nAnd for duration and choice.\n\n\nCode\n# Short vs Long (one-stage) and short vs. long (two-stage)\navg_comparisons(fit2, variables = \"d\", by = \"srp2\", comparison = \"lnoravg\")\n\n\n\n Term              Contrast srp2 Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 %\n    d ln(odds(1) / odds(0))    0    0.179    0.00361 49.8   &lt;0.001 Inf 0.172\n    d ln(odds(1) / odds(0))    1    0.486    0.00558 87.1   &lt;0.001 Inf 0.475\n 97.5 %\n  0.187\n  0.497\n\nColumns: term, contrast, srp2, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nCode\n# Rifampicin vs not\navg_comparisons(fit2, variables = \"f\", comparison = \"lnoravg\")\n\n\n\n Term              Contrast Estimate Std. Error    z Pr(&gt;|z|)     S  2.5 %\n    f ln(odds(1) / odds(0))   0.0894    0.00341 26.2   &lt;0.001 500.7 0.0827\n 97.5 %\n  0.096\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high, predicted_lo, predicted_hi, predicted \nType:  response",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#footnotes",
    "href": "notebooks/design-notes.html#footnotes",
    "title": "Design Notes",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe parameter ignores potential differentiation for surgical type.↩︎",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/model-implementation.html",
    "href": "notebooks/model-implementation.html",
    "title": "Model implementation",
    "section": "",
    "text": "The simplest implementation I could think of split the data into silo-specific chunks, mimicking the formulation in the model specification earlier.\n\n\ndata {\n  // early\n  int N_e;\n  array[N_e] int e_su;\n  array[N_e] int e_y;\n  array[N_e] int e_n;\n  vector[N_e] e_ec; // membership\n  vector[N_e] e_ecp; // non-membership, ie 1 - e_ec\n  array[N_e] int e_c;\n  \n  int N_l;\n  array[N_l] int l_su;\n  array[N_l] int l_y;\n  array[N_l] int l_n;\n  vector[N_l] l_ec;\n  vector[N_l] l_ecp; // 1 - l_ec\n  array[N_l] int l_c;\n  vector[N_l] l_ea;\n  vector[N_l] l_eap;\n  array[N_l] int l_a;\n  vector[N_l] l_eb1;\n  vector[N_l] l_eb2;\n  vector[N_l] l_ebp;\n  array[N_l] int l_b;\n  \n  int N_c;\n  array[N_c] int c_su;\n  array[N_c] int c_y;\n  array[N_c] int c_n;\n  vector[N_c] c_ec;\n  vector[N_c] c_ecp; // 1 - c_ec\n  array[N_c] int c_c;\n  vector[N_c] c_ea;\n  vector[N_c] c_eap;\n  array[N_c] int c_a;\n  vector[N_c] c_eb1;\n  vector[N_c] c_eb2;\n  vector[N_c] c_ebp;\n  array[N_c] int c_b;\n  \n  // priors\n  real pri_sig_b_c;\n  real pri_sig_a_l;\n  real pri_sig_b1_l;\n  real pri_sig_b2_l;\n  real pri_sig_a_c;\n  real pri_sig_b1_c;\n  real pri_sig_b2_c;\n  \n}\ntransformed data {\n  int N = N_e + N_l + N_c;\n}\nparameters {\n  vector[6] alpha;\n  // real gamma_b;\n  real gamma_c;\n  real b_a_l_raw;\n  real b_b1_l_raw;\n  real b_b2_l_raw;\n  real b_a_c_raw;\n  real b_b1_c_raw;\n  real b_b2_c_raw;\n  real b_c_raw;\n}\ntransformed parameters{\n  // Include non-randomised items in parameter vector but set to zero \n  // see b_c[3] below. Gives a simpler way to build up model without index\n  // overrun or conditionals for building linear predictor.\n  \n  vector[2] b_a_l; // dair vs revision (late silo)\n  vector[3] b_b1_l; // note length - dair vs revision (late silo, recvd one-stage)\n  vector[3] b_b2_l; // note length - dair vs revision (late silo, recvd two-stage)\n  \n  vector[2] b_a_c; // dair vs revision (chronic silo)\n  vector[2] b_b1_c; // dair vs revision (chronic silo, recvd one-stage)\n  vector[2] b_b2_c; // dair vs revision (chronic silo, recvd two-stage)\n  \n  vector[3] b_c; // note length\n\n  b_a_l[1] = 0.0;\n  b_a_l[2] = b_a_l_raw;\n\n  b_b1_l[1] = 0.0;\n  b_b1_l[2] = b_b1_l_raw;\n  b_b1_l[3] = 0.0;\n   \n  b_b2_l[1] = 0.0;\n  b_b2_l[2] = b_b2_l_raw;\n  b_b2_l[3] = 0.0;\n  \n  b_a_c[1] = 0.0;\n  b_a_c[2] = b_a_c_raw;\n\n  b_b1_c[1] = 0.0;\n  b_b1_c[2] = b_b1_c_raw;\n\n  b_b2_c[1] = 0.0;\n  b_b2_c[2] = b_b2_c_raw;\n   \n  b_c[1] = 0.0;\n  b_c[2] = b_c_raw;\n  // handles other, but this can be ignored in post-processing\n  b_c[3] = 0.0;\n}\nmodel{\n  target += normal_lpdf(alpha | 0, 1.5);\n  \n  // target += std_normal_lpdf(gamma_b);\n  target += std_normal_lpdf(gamma_c);\n  // all silos\n  target += normal_lpdf(b_c_raw | 0, pri_sig_b_c);\n  // late silo\n  target += normal_lpdf(b_a_l_raw | 0, pri_sig_a_l);\n  target += normal_lpdf(b_b1_l_raw | 0, pri_sig_b1_l);\n  target += normal_lpdf(b_b2_l_raw | 0, pri_sig_b2_l);\n  // chronic silo\n  target += normal_lpdf(b_a_c_raw | 0, pri_sig_a_c);\n  target += normal_lpdf(b_b1_c_raw | 0, pri_sig_b1_c);\n  target += normal_lpdf(b_b2_c_raw | 0, pri_sig_b2_c);\n  \n  // likelihood chunks pertaining to each silo\n  target += binomial_logit_lpmf(e_y | e_n, alpha[e_su] +\n                                      e_ecp * gamma_c + \n                                      e_ec .* b_c[e_c]) ;      \n                                    \n  target += binomial_logit_lpmf(l_y | l_n, alpha[l_su] + \n                                    l_ecp * gamma_c +\n                                    l_ea .* b_a_l[l_a] +\n                                    l_eb1 .* b_b1_l[l_b] +  \n                                    l_eb2 .* b_b2_l[l_b] +\n                                    l_ec .* b_c[l_c]\n                                    ) ;    \n                                    \n  target += binomial_logit_lpmf(c_y | c_n, alpha[c_su] +\n                                      c_ecp * gamma_c +\n                                      c_ea .* b_a_c[c_a] +\n                                      c_eb1 .* b_b1_c[c_b] + \n                                      c_eb2 .* b_b2_c[c_b] +\n                                      c_ec .* b_c[c_c]) ; \n}\ngenerated quantities{\n  vector[N_e] eta_e ;\n  vector[N_l] eta_l ;\n  vector[N_c] eta_c ;\n  vector[N] eta;\n  \n  eta_e = alpha[e_su] + e_ecp * gamma_c + e_ec .* b_c[e_c];\n  eta_l = alpha[l_su] + l_ecp * gamma_c +\n    l_ea .* b_a_l[l_a] + \n    l_eb1 .* b_b1_l[l_b] + l_eb2 .* b_b2_l[l_b] +\n    l_ec .* b_c[l_c];\n  eta_c = alpha[c_su] + c_ecp * gamma_c +\n    c_ea .* b_a_c[c_a] +\n    c_eb1 .* b_b1_c[c_b] + c_eb2 .* b_b2_c[c_b] +\n    c_ec .* b_c[c_c];\n    \n  eta = append_row(eta_e, append_row(eta_l, eta_c));\n\n}\n\n\nBelow I create a data set with a million patients (orders of magnitude more than we will have available) to see if we can get anywhere close to recovering the parameters - if we cannot recover the parameters with this many records, we are certainly not going to be able to do so with 2500 patients.\nThen I fit the stan model and extract and summarise the posterior.\n\n\nCode\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-02.stan\")\n\nset.seed(1)\nll &lt;- get_trial_data(N = 1e6)\nlsd &lt;- get_stan_data(ll$d_i)\nld &lt;- lsd$ld\n# cbind(ld$l_su, ld$l_y, ld$l_n, ld$l_ea, ld$l_eap, ld$l_a)\nd_b &lt;- copy(lsd$d_b)\n\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.6 seconds.\n\n\nCode\npost &lt;- data.table(f2$draws(variables = c(\n  \"eta\"\n), format = \"matrix\"))\n\n# create index field\npost &lt;- melt(post, measure.vars = names(post))\npost[, idx := gsub(\".*\\\\[\", \"\", variable)]\npost[, idx := gsub(\"\\\\]\", \"\", idx)]\npost[, idx := as.integer(idx)]\n\nd_fig &lt;- cbind(d_b, post[, .(eta_med = median(value), \n         eta_q025 = quantile(value, prob = 0.025),\n         eta_q975 = quantile(value, prob = 0.975)), keyby = idx])\n\n\nFigure 1 shows a comparison between the true log-odds of treatment success with the 95% credible interval obtained from the model. It suggests a strong association between the true and estimated log-odds of treatment success for this particular dataset.\n\n\nCode\nggplot(d_fig, aes(x = eta, y = eta_med)) +\n  # geom_point() +\n  geom_linerange(aes(ymin = eta_q025, ymax = eta_q975)) +\n  geom_abline(intercept = 0, slope = 1, lwd = 0.1) +\n  scale_x_continuous(\"True log-odds success\") +\n  scale_y_continuous(\"Posterior log-odds success (95% credible interval)\") +\n  facet_grid(silo ~ joint) +\n  ggtitle(\"True log-odds success vs 95% credible interval\")\n\n\n\n\n\n\n\n\nFigure 1: Scatter plot comparing true vs estimated 95% credible interval for log-odds treatment success.\n\n\n\n\n\n\n\nCode\npost &lt;- data.table(f2$draws(variables = c(\n    \"alpha\", \"gamma_c\", \n    \"b_a_l\", \n    \"b_b1_l\", \n    \"b_b2_l\",\n    \"b_a_c\",\n    \"b_b1_c\", \n    \"b_b2_c\",\n    \"b_c\"\n  ), format = \"matrix\"))\n  \n\n# test outcome\ncols &lt;- names(post)\ncols &lt;- gsub(\"[\",\"_\",cols,fixed = T)\ncols &lt;- gsub(\"]\",\"\",cols,fixed = T)\nnames(post) &lt;- cols\n  \n# effects\neffs &lt;- c(\n  # domain a, late (revision) and chronic (two-stage)\n  \"b_a_l_2\", \"b_a_c_2\", \n  # domain b, (late/revision one stage pts)\n  # wk12p1 (ref is wk6p1)\n  \"b_b1_l_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_l_2\", \n  # wk12p1 (ref is wk6p1)\n  \"b_b1_c_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_c_2\",\n  # rif (ref is no-rif)\n  \"b_c_2\")\n  \nd_beta &lt;- post[, .SD, .SDcols = effs]\nd_beta &lt;- melt(d_beta, measure.vars = names(d_beta))\n# unique(d_beta$variable)\n\n\nparname_map &lt;- roadmap.data::get_par_effects_mapping()\nd_beta[, parname := parname_map[variable]]\nd_beta[, parname := factor(parname, levels = roadmap.data::get_par_effects_mapping())]\n\nd_fig &lt;- d_beta[, .(\n  lor_med = median(value), \n  lor_q025 = quantile(value, prob = 0.025),\n  lor_q975 = quantile(value, prob = 0.975)), keyby = parname]\n\nd_effects &lt;- roadmap.data::get_sim_spec_effects(roadmap.data::get_sim_spec())\nd_effects &lt;- melt(d_effects, measure.vars = names(d_effects), value.name = \"lor\")\n\nd_fig &lt;- merge(d_fig, d_effects, by.x = \"parname\", by.y = \"variable\")\n\n\nFigure 1 shows a comparison between the true log-odds of treatment success with the 95% credible interval obtained from the model. It suggests a strong association between the true and estimated log-odds of treatment success for this particular dataset.\n\n\nCode\nggplot(d_fig, aes(x = parname, y = lor_med)) +\n  geom_point() +\n  geom_point(data = d_fig, aes(x = parname, y = lor), pch = 2) +\n  geom_linerange(aes(ymin = lor_q025, ymax = lor_q975))  +\n  scale_x_discrete(\"\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Posterior log-odds-ratio (95% credible interval)\") \n\n\n\n\n\n\n\n\nFigure 2: Posterior estimates for log-odds-ratios (true values shown as triangles).\n\n\n\n\n\n\n\nCode\npost &lt;- data.table(f2$draws(variables = c(\n    \"alpha\", \"gamma_c\", \n    \"b_a_l\", \n    \"b_b1_l\", \n    \"b_b2_l\",\n    \"b_a_c\",\n    \"b_b1_c\", \n    \"b_b2_c\",\n    \"b_c\"\n  ), format = \"matrix\"))\n  \n\n# test outcome\ncols &lt;- names(post)\ncols &lt;- gsub(\"[\",\"_\",cols,fixed = T)\ncols &lt;- gsub(\"]\",\"\",cols,fixed = T)\nnames(post) &lt;- cols\n  \n# effects\npars &lt;- c(\n  \"alpha\", \"gamma_c\", \n  # domain a, late (revision) and chronic (two-stage)\n  \"b_a_l_2\", \"b_a_c_2\", \n  # domain b, (late/revision one stage pts)\n  # wk12p1 (ref is wk6p1)\n  \"b_b1_l_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_l_2\", \n  # wk12p1 (ref is wk6p1)\n  \"b_b1_c_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_c_2\",\n  # rif (ref is no-rif)\n  \"b_c_2\")\n  \nd_pars &lt;- post[, .SD, .SDcols = effs]\nm_cor &lt;- d_pars[, cor(.SD)]\nd_cor &lt;- data.table(cbind(var1 = rownames(m_cor), m_cor))\nd_cor &lt;- melt(d_cor, id.vars = \"var1\", variable.name = \"var2\")\nd_cor[, value := as.numeric(value)]\n\nd_cor[, `:=`(\n  var1 = factor(var1, levels = c(pars[length(pars):1])),\n  var2 = factor(var2, levels = c(pars[length(pars):1]))\n)]\n\n\nFigure 3 shows the correlation between parameters estimated from the model.\n\n\nCode\nggplot(d_cor, aes(x = var1, y = var2, fill = value)) +\n  geom_tile(color = \"white\",\n            lwd = 1.5,\n            linetype = 1) +\n  geom_text(aes(label = round(value, 2)), color = \"white\", size = 4) +\n  scale_x_discrete(\"\",position = \"top\", limits=rev) +\n  scale_y_discrete(\"\") + \n  scale_fill_gradient2(\"Pearson correlation\") +\n  coord_fixed()\n\n\n\n\n\n\n\n\nFigure 3: Parameter correlation (white indicates zero correlation)",
    "crumbs": [
      "Design",
      "Model implementation"
    ]
  },
  {
    "objectID": "notebooks/misc-notes.html#thought-1",
    "href": "notebooks/misc-notes.html#thought-1",
    "title": "Misc notes",
    "section": "Thought 1",
    "text": "Thought 1\nWhat is the effect of treating a patient with joint infection with a revision surgical procedure compared to a less invasive procedure, known as dair? What about the effect of treating with long relative to short duration antibiotic where the definition (and action) of long vs short duration are different within each level (i.e. a nested design rather than crossed). The usual experimental approach here is to apply random assignment of all possible treatment combinations, which with two levels\nImagine a situation where we have a nested factorial design with factors A (control vs active) and B (control vs active). Contrary to the usual situation, we assume that active for A comes in two flavours, active-1 and active-2. Usually, we assume that the control vs active for B are different under each level of A. Here, we assume that control vs active for B are different under each of the possibilities for A.\ntrial with control vs treatment with a single dichotomous covariate in the model (X) and where the outcome is death by day 30. We specify a conditional logistic regression model with linear predictor \\(\\eta = \\beta_0 + \\beta_1 I(trt_i == 1) + \\beta_2 I(sex = male)\\). By chance, all the control group are male and all the treatment group are female. Logically, we would not be able to separate the effect of treatment from sex, but model it anyway.\n\n\nCode\nN &lt;- 10000\nd &lt;- data.table(id = 1:N)\nd[, trt := rbinom(.N, 1, 0.5)]\nd[trt == 0, sex := 1]\nd[trt == 1, sex := 0]\nbeta_0 &lt;- qlogis(0.7)\nbeta_trt &lt;- log(2)\nbeta_sex &lt;- log(0.2)\nd[, eta := beta_0 + beta_trt * trt + beta_sex * sex]\nd[, y := rbinom(.N, 1, prob = plogis(eta))]\nhead(d)\n\n\nBasic logistic regression.\n\n\n\nFit the model and extract posterior.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-01.stan\")\n\nd_grp &lt;- d[, .(y = sum(y), n = length(y)), keyby = .(trt, sex)]\nld &lt;- list(\n  N = nrow(d_grp), \n  y = d_grp$y, n = d_grp$n, trt = d_grp$trt, sex = d_grp$sex\n)\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\npost &lt;- data.table(f1$draws(variables = c(\n  \"b0\", \"b_trt\", \"b_sex\"\n), format = \"matrix\"))\n\n\nSummarise the posterior draws:\n\n\nCode\nd_tbl &lt;- melt(post[, 2:3], measure.vars = names(post)[2:3])\nd_tbl &lt;- d_tbl[, .(mu = mean(value), \n          sd = sd(value),\n          q_025 = quantile(value, prob = 0.025), \n          q_975 = quantile(value, prob = 0.975)), by = variable]\n\nb_tru &lt;- c(beta_trt, beta_sex)\nnames(b_tru) &lt;- c(\"b_trt\", \"b_sex\")\nd_tbl[, b_tru := b_tru[variable]]\nd_tbl\n\n\nSo, the posterior mean is nowhere near our known true value that we simulated the data with."
  },
  {
    "objectID": "notebooks/model-spec.html",
    "href": "notebooks/model-spec.html",
    "title": "Model specification",
    "section": "",
    "text": "The primary outcome is treatment success at 12 months post platform entry, defined as all of:\nhereafter referred to as ‘treatment success’.\nFor each silo and site of infectioin we model the probability of treatment success as follows:\nwhere",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#interpretation",
    "href": "notebooks/model-spec.html#interpretation",
    "title": "Model specification",
    "section": "Interpretation",
    "text": "Interpretation\nSome additional more detailed and narrative is perhaps useful on the interpretation of parameters.\nAs noted previously, the baseline reference groups are defined as follows:\n\n\nGroups corresponding to baseline log-odds of treatment success\n\n\nSilo\nA\nB\nC\n\n\n\n\nearly\n-\n-\nno-rif\n\n\nlate\ndair\n-\nno-rif\n\n\nchronic\none\n6wk\nno-rif\n\n\n\n\nAs such, we have:\n\n\\(\\alpha_{[early, \\cdot]} \\quad\\) - this parameter describes the log-odds of treatment success for the sample members with early infection who are randomised within Domain C (that is, were not part of the 40% Domain C exclusion set) to no-rif and had no randomisation options for domains A and B. The parameter makes no adjustment for what surgery a patient received, nor how long their duration of antibiotic was.\n\\(\\alpha_{[late, \\cdot]} \\quad\\) - this parameter describes the log-odds of treatment success for the sample members with late infection who were randomised to dair in Domain A, had no randomisation options for Domain B, which is a deterministic consequence of being randomised to dair in Domain A, and were randomised to no-rif in Domain C.\n\\(\\alpha_{[chronic, \\cdot]} \\quad\\) - this parameter describes the log-odds of treatment success for the sample members with chronic infection who were randomised to one-stage in Domain A, were randomised to 6wksp1 in Domain B and were randomised to no-rif in Domain C.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe following are incomplete:\n\n\n\nLate infection\nIn the surgical domain, we consider the effect (log-odds-ratio) of revision relative to dair. Within revision, patients may receive one or two-stage procedures. The log-odds of treatment success for those receiving a one-stage procedure, are randomised to 6wk duration and receive no-rif is \\(\\alpha_{late,\\cdot}\\). Similarly, this is true for those receiving a (non-randomised) two-stage procedure, are randomised to 7day duration and receive no-rif.\nThe effect of revision relative to dair is thus in the context of some weighted average of the response under the one-stage and two-stage procedures.\nThe model characterises associations between the log-odds of treatment success and each of the parameters. The effect of each term is considered while holding all others constant.\n\n\n\n\n\n\nNote\n\n\n\nIs overlap and extrapolation an issue here???\n\n\n\n\nChronic infection\nTODO",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#priors",
    "href": "notebooks/model-spec.html#priors",
    "title": "Model specification",
    "section": "Priors",
    "text": "Priors\nAs with the linear predictor, the priors are currently targeted towards the simulation work but may be appropriate for the final model.\n\nIntercepts\nThe silo and infection site specific intercepts are given independent normal priors\n\\[\\begin{aligned}\n\\alpha_{s(i),u(i)} \\sim \\mathcal{N}(0, 1.5^2)\n\\end{aligned}\\]\nOn the probability scale, these concentrate on 0.5 with 95% of the density between 0.04 and 0.96, approximately uniform across this interval.\nWhile the intercept priors are currently independent, consideration should be given to partial pooling across site of infection. However, the concept of exchangeability is perhaps dubious for this set of parameters due to the fact that the baseline log-odds of success must be interpreted based on the domain level options available to each group.\nFor example, there are no randomisation options for early stage infection in domains A and B and therefore the baseline log-odds (intercept) refers to the cohort of patients that were not randomised within A nor B and randomised to the reference group for domain C. In contrast, for the late stage patients, the baseline log-odds of treatment success is interpreted contextually for the cohort of patients that were randomised to the reference level of domains A, B and C, see below.\n\n\nGroups corresponding to baseline log-odds of treatment success\n\n\nSilo\nA\nB\nC\n\n\n\n\nearly\n-\n-\nno-rif\n\n\nlate\ndair\n-\nno-rif\n\n\nchronic\none\n6wk\nno-rif\n\n\n\n\n\n\nDomain non-membership\nThe domain non-membership parameters are given standard normal independent priors. These parameters are pooled across all silos.\n\\[\\begin{aligned}\n\\gamma_\\mathcal{D} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\n\n\nInterventions\nA hierarchical prior structure may be appropriate for some of the intervention effects dependent on what can be assumed regarding exchangeability.\n\nSurgical domain\nSilo-specific, independent normal priors are assumed for the surgical domain. There is no pooling, we simply compare dair vs revision in the late stage patients and one vs two stage in the chronic stage patients.\n\\[\\begin{aligned}\n\\beta_{A,s,d_{A,j}} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\nThe reference level is set to 0.\n\n\nAntibiotic duration domain\nWhile a hierarchical structure could be considered for this domain, independent normal priors are currenlty assumed for the duration domain. Currently, there is no pooling. We compare 6 vs 12 weeks for late stage patients having a one stage procedure and 7 days vs 12 wks for those having a two stage procedure. Independently, we compare 6 vs 12 weeks for chronic stage patients having a one stage procedure and 7 days vs 12 wks for those having a two stage procedure.\n\\[\\begin{aligned}\n\\beta_{B_k,s,d_{B,j}} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\nThe reference level is set to 0.\nTheoretically, partial pooling could be implemented across the late and chronic silos.\n\n\nAntibiotic type domain\nA hierarchical structure could also be considered for this domain. The ‘average’ across silos could be obtained by sampling from the posterior assuming normality based on the parameter for the group variance. With three groups the extent of the partial pooling is going to be heavily influenced by the prior rather than the data.\nCurrently we adopt a standard normal prior for the treatment effects in this domain, which are completely pooled across silos.\n\\[\\begin{aligned}\n\\beta_{C,d_{C,j}} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\nThe reference level is set to 0.",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#footnotes",
    "href": "notebooks/model-spec.html#footnotes",
    "title": "Model specification",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn practice, it may be the case that non-membership for domain \\(B\\) is relevant. For example, if an early stage patient receives a one or two-stage surgical procedure.↩︎\nAs such, silo-specific decisions on antibiotic type are not possible.↩︎",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "etc/readme.html",
    "href": "etc/readme.html",
    "title": "readme",
    "section": "",
    "text": "readme\nfile name format is\ncfg-sim&lt;sim-id&gt;-&lt;scenario-id&gt;-&lt;variant-id&gt;\nuse sed for efficient updating, e.g. \n\nChange number of simulations from 10 to 500:\n\ngsed -i 's/nsim:\\ 10/nsim:\\ 500/' cfg-sim01-sc01-0*.yml\n\nUpdate scenario label:\n\ngsed -i 's/sc01/sc02/' cfg-sim01-sc02-0*.yml"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "This site contains notes, data summaries and simulation results for the ROADMAP study.\nAll the code can be found on github, just use the icon to the top right. The functionality herein has a dependency on the roadmap.data R package, which can also be found via the above link (see the readme for this repo). If you find any issues, let me know and I will prioritise accordingly.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#notes",
    "href": "index.html#notes",
    "title": "Overview",
    "section": "Notes",
    "text": "Notes\n\nDoes not explore impact of effect heterogeneity on \\(C\\)",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html",
    "href": "notebooks/population-structure.html",
    "title": "Population structure",
    "section": "",
    "text": "The following specification is for the partially factorial structure of the study. The outcome model is specified separately.",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#silo",
    "href": "notebooks/population-structure.html#silo",
    "title": "Population structure",
    "section": "Silo",
    "text": "Silo\nThe total sample size is divided across the silos in proportion to the values described in the table below. These proportions are expectations. Each simulated dataset will vary somewhat from these proportions due to the stochastic nature of the generation process.\n\n\nSilo categories (\\(\\pi\\) denotes probability of membership)\n\n\nSilo\n\\(\\pi\\)\n\n\n\n\nearly\n0.3\n\n\nlate\n0.5\n\n\nchronic\n0.2",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#site-of-infection-joint",
    "href": "notebooks/population-structure.html#site-of-infection-joint",
    "title": "Population structure",
    "section": "Site of infection (joint)",
    "text": "Site of infection (joint)\nEach silo comprises patients assumed to have primary infection in either knee or hip (not both). The proportion of infections associated with each joint for each silo are shown below. As previously, these proportions are expectations and the empirical proportions observed in simulated datasets will vary from these.\n\n\nSite of infection (\\(\\pi\\) denotes probability of site infection conditional on silo membership)\n\n\nSilo\nJoint\n\\(\\pi\\)\n\n\n\n\n\nearly\nknee\n0.4\n\n\n\nearly\nhip\n0.6\n\n\n\nlate\nknee\n0.7\n\n\n\nlate\nhip\n0.3\n\n\n\nchronic\nknee\n0.5\n\n\n\nchronic\nhip\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-surgery-domain-a",
    "href": "notebooks/population-structure.html#randomisation-into-surgery-domain-a",
    "title": "Population structure",
    "section": "Randomisation into surgery domain (A)",
    "text": "Randomisation into surgery domain (A)\nRandomisation into domain A is conditional on silo membership as detailed below.\n\n\nRandomisation within domain A\n\n\nSilo\nRandomised (\\(e_a\\))\n\n\n\n\nearly\nN\n\n\nlate\nY\n\n\nchronic\nN",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#surgery-domain-a",
    "href": "notebooks/population-structure.html#surgery-domain-a",
    "title": "Population structure",
    "section": "Surgery domain (A)",
    "text": "Surgery domain (A)\nAllocation probabilities (conditional on entry into domain A) are shown below. Early stage patients do not receive randomisation and are assumed to receive DAIR. Chronic stage patients do not receive randomisation and are assumed to receive DAIR, one-stage and two-stage based on clinician assessment.\n\n\nAllocation within domain A (\\(\\pi\\) denotes probability allocation to surgery type conditional on silo membership)\n\n\nSilo\nSurgery type (\\(a\\))\n\\(\\pi\\)\n\n\n\n\n\nearly\ndair\n-\n\n\n\nlate\ndair\n0.5\n\n\n\nlate\nrevision\n0.5\n\n\n\nchronic\ndair\n-\n\n\n\nchronic\none-stage\n-\n\n\n\nchronic\ntwo-stage\n-",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#intended-surgery",
    "href": "notebooks/population-structure.html#intended-surgery",
    "title": "Population structure",
    "section": "Intended surgery",
    "text": "Intended surgery\nLate stage infections will be randomised to DAIR vs revision where revision would be planned as one or two-stage, determined by the treating clinician, i.e. not randomised.\nWe do not know the assignment mechanism for one vs two-stage for the late-stage infection patients. We do the same for chronic stage patients.\nIn all other cases, the intended surgery is set to allocated surgery.\n\n\nIndended surgical approach (\\(\\pi\\) denotes probability allocation to surgery type conditional on silo membership)\n\n\nSilo\nAllocation (\\(a\\))\nIntended surgery (\\(q\\))\n\\(\\pi\\)\n\n\n\n\n\nearly\ndair\ndair\n-\n\n\n\nlate\ndair\ndair\n-\n\n\n\nlate\nrevision\none-stage\n0.3\n\n\n\nlate\nrevision\ntwo-stage\n0.7\n\n\n\nchronic\ndair\ndair\n0.2\n\n\n\nchronic\none-stage\none-stage\n0.2\n\n\n\nchronic\ntwo-stage\ntwo-stage\n0.6",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-duration-domain-b",
    "href": "notebooks/population-structure.html#randomisation-into-duration-domain-b",
    "title": "Population structure",
    "section": "Randomisation into duration domain (B)",
    "text": "Randomisation into duration domain (B)\nEntry into domain B is dependent on the domain A entry and allocation and is detailed below.\n\n\nRandomisation within domain B\n\n\nIntended surgery (\\(q\\))\nRandomised (\\(e_b\\))\n\n\n\n\n\ndair\nN\n\n\n\nrevision\nY\n\n\n\none-stage\nY\n\n\n\ntwo-stage\nY",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#duration-domain-b",
    "href": "notebooks/population-structure.html#duration-domain-b",
    "title": "Population structure",
    "section": "Duration domain (B)",
    "text": "Duration domain (B)\nThe treatment options and allocation probabilities for domain B are detailed below. Duration of antibiotic is conditional on allocated (intended) surgery type, see above. Patients receiving DAIR are assumed to have 12 wk duration (not randomised).\n\n\nAllocation within duration domain (\\(\\pi\\) denotes probability allocation to surgery type conditional on allocated/intended surgery)\n\n\nSilo\nAllocation/Intended surgery (\\(q\\))\nAllocation (\\(b\\))\n\\(\\pi\\)\n\n\n\n\nearly\ndair\n12 wk\n-\n\n\nlate\none-stage\n6 wk\n0.5\n\n\nlate\none-stage\n12 wk\n0.5\n\n\nlate\ntwo-stage\n7 day post 2\n0.5\n\n\nlate\ntwo-stage\n12 wk post 2\n0.5\n\n\nchronic\none-stage\n6 wk\n0.5\n\n\nchronic\none-stage\n12 wk\n0.5\n\n\nchronic\ntwo-stage\n7 day post 2\n0.5\n\n\nchronic\ntwo-stage\n12 wk post 2\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-antibiotic-choice-domain-c",
    "href": "notebooks/population-structure.html#randomisation-into-antibiotic-choice-domain-c",
    "title": "Population structure",
    "section": "Randomisation into antibiotic choice domain (C)",
    "text": "Randomisation into antibiotic choice domain (C)\nThe data generating process assume that 60% of the cohort enter into this domain at random, unrelated to risk factors. The remainder are held out so that we do not over-estimate the operating characteristics, such as power.\n\n\nRandomisation within domain C (\\(\\pi\\) denotes probability patient is indicated as eligible for domain)\n\n\nSilo\nRandomised (\\(e_c\\))\n\\(\\pi\\)\n\n\n\n\nearly\nY\n0.6\n\n\nlate\nY\n0.6\n\n\nchronic\nY\n0.6",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#antibiotic-choice-domain-c",
    "href": "notebooks/population-structure.html#antibiotic-choice-domain-c",
    "title": "Population structure",
    "section": "Antibiotic choice domain (C)",
    "text": "Antibiotic choice domain (C)\nThe treatment options and allocation probabilities for domain C are detailed below.\n\n\nAllocation within antibiotic choice domain (\\(\\pi\\) denotes probability that an eligible patient is allocated to no rif vs rif)\n\n\nAllocation (\\(c\\))\n\\(\\pi\\)\n\n\n\n\nno rif\n0.5\n\n\nrif\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#encoded-specification",
    "href": "notebooks/population-structure.html#encoded-specification",
    "title": "Population structure",
    "section": "Encoded specification",
    "text": "Encoded specification\nThe above specification is bundled into an R package (roadmap.data) for consistent data generation for ROADMAP.\n\n\nCode\nroadmap.data::get_pop_spec()\n\n\n$r_silo\n      silo   p\n1:   early 0.3\n2:    late 0.5\n3: chronic 0.2\n\n$r_joint\n      silo joint   p\n1:   early  knee 0.4\n2:   early   hip 0.6\n3:    late  knee 0.7\n4:    late   hip 0.3\n5: chronic  knee 0.5\n6: chronic   hip 0.5\n\n$r_ea\n      silo rand\n1:   early    N\n2:    late    Y\n3: chronic    Y\n\n$r_a\n      silo    a   p\n1:   early dair  NA\n2:    late dair 0.5\n3:    late  rev 0.5\n4: chronic  one 0.5\n5: chronic  two 0.5\n\n$r_a_q\n      silo    a   qa   p\n1:   early dair dair  NA\n2:    late dair dair  NA\n3:    late  rev  one 0.3\n4:    late  rev  two 0.7\n5: chronic  one  one  NA\n6: chronic  two  two  NA\n\n$r_eb\n     qa rand\n1: dair    N\n2:  rev    Y\n3:  one    Y\n4:  two    Y\n\n$r_b\n      silo   qa     b   p\n1:   early dair   w12 1.0\n2:    late  one w06p1 0.5\n3:    late  one w12p1 0.5\n4:    late  two d07p2 0.5\n5:    late  two w12p2 0.5\n6: chronic  one w06p1 0.5\n7: chronic  one w12p1 0.5\n8: chronic  two d07p2 0.5\n9: chronic  two w12p2 0.5\n\n$r_ec\n      silo rand   p\n1:   early    Y 0.6\n2:    late    Y 0.6\n3: chronic    Y 0.6\n\n$r_c\n       c   p\n1: norif 0.5\n2:   rif 0.5\n\n\nThe following function simulates the design matrix.\n\n\nCode\nroadmap.data::get_design\n\n\nfunction (N = 1e+05, pop_spec = NULL, idx_s = 1) \n{\n    if (is.null(pop_spec)) {\n        pop_spec &lt;- get_pop_spec()\n    }\n    d &lt;- data.table()\n    d[, `:=`(id, idx_s:(N + idx_s - 1))]\n    d[, `:=`(silo, sample(pop_spec$r_silo$silo, size = N, replace = T, \n        prob = pop_spec$r_silo$p))]\n    setkey(d, silo)\n    setkey(pop_spec$r_joint, silo)\n    setkey(pop_spec$r_ea, silo)\n    for (z in pop_spec$r_silo$silo) {\n        d[z, `:=`(joint, sample(pop_spec$r_joint[z, joint], size = .N, \n            replace = T, prob = pop_spec$r_joint[z, p]))]\n        d[z, `:=`(ea, pop_spec$r_ea[z, rand])]\n    }\n    setkey(pop_spec$r_a, silo)\n    d[\"early\", `:=`(a, \"dair\")]\n    z &lt;- \"late\"\n    d[z, `:=`(a, sample(pop_spec$r_a[z, a], size = .N, replace = T, \n        prob = pop_spec$r_a[z, p]))]\n    z &lt;- \"chronic\"\n    d[z, `:=`(a, sample(pop_spec$r_a[z, a], size = .N, replace = T, \n        prob = pop_spec$r_a[z, p]))]\n    setkey(d, silo, a)\n    setkey(pop_spec$r_a_q, silo, a)\n    d[.(\"late\", \"rev\"), `:=`(qa, sample(pop_spec$r_a_q[.(\"late\", \n        \"rev\"), qa], size = .N, replace = T, prob = pop_spec$r_a_q[.(\"late\", \n        \"rev\"), p]))]\n    d[is.na(qa), `:=`(qa, copy(a))]\n    d &lt;- merge(d, pop_spec$r_eb[, .(qa, eb = rand)], by = c(\"qa\"), \n        all.x = T)\n    setcolorder(d, c(\"id\", \"silo\", \"joint\", \"ea\", \"a\", \"qa\", \n        \"eb\"))\n    setkey(d, id)\n    setkey(d, qa)\n    setkey(pop_spec$r_b, qa)\n    d[\"dair\", `:=`(b, pop_spec$r_b[\"dair\", unique(b)])]\n    setkey(d, silo, qa)\n    setkey(pop_spec$r_b, silo, qa)\n    d[.(\"late\", \"one\"), `:=`(b, sample(pop_spec$r_b[.(\"late\", \n        \"one\"), b], size = .N, replace = T, prob = pop_spec$r_b[.(\"late\", \n        \"one\"), p]))]\n    d[.(\"late\", \"two\"), `:=`(b, sample(pop_spec$r_b[.(\"late\", \n        \"two\"), b], size = .N, replace = T, prob = pop_spec$r_b[.(\"late\", \n        \"two\"), p]))]\n    d[.(\"chronic\", \"one\"), `:=`(b, sample(pop_spec$r_b[.(\"chronic\", \n        \"one\"), b], size = .N, replace = T, prob = pop_spec$r_b[.(\"chronic\", \n        \"one\"), p]))]\n    d[.(\"chronic\", \"two\"), `:=`(b, sample(pop_spec$r_b[.(\"chronic\", \n        \"two\"), b], size = .N, replace = T, prob = pop_spec$r_b[.(\"chronic\", \n        \"two\"), p]))]\n    setkey(d, id)\n    setkey(d, silo)\n    setkey(pop_spec$r_ec, silo)\n    for (z in pop_spec$r_ec$silo) {\n        d[z, `:=`(ec, sample(c(\"Y\", \"N\"), size = .N, replace = T, \n            prob = c(pop_spec$r_ec[z, p], 1 - pop_spec$r_ec[z, \n                p])))]\n    }\n    d[ec == \"Y\", `:=`(c, sample(pop_spec$r_c[, c], size = .N, \n        replace = T, prob = pop_spec$r_c[, p]))]\n    d[ec == \"N\", `:=`(c, \"other\")]\n    setkey(d, id)\n    d\n}\n&lt;bytecode: 0x112e40ac8&gt;\n&lt;environment: namespace:roadmap.data&gt;\n\n\nThe data generation assumptions imply unique patients groups on which we would observe the outcome. The outcome is known to be heterogenous across these groups and yet the stated goal is to aggregate measures of effect (odds ratios) across all these groups, e.g. no rif vs rif. However, the effect of interest is assumed to be obtained from the model parameter that characterises the effect of antibiotic type conditional on the other covariates in the model.\n\n\nCode\nd &lt;- roadmap.data::get_design()\nunique(d[order(silo, joint, ea, a, qa, eb, b, ec, c), .SD, .SDcols = !c(\"id\")])\n\n\n       silo joint ea    a   qa eb     b ec     c\n 1: chronic   hip  Y  one  one  Y w06p1  N other\n 2: chronic   hip  Y  one  one  Y w06p1  Y norif\n 3: chronic   hip  Y  one  one  Y w06p1  Y   rif\n 4: chronic   hip  Y  one  one  Y w12p1  N other\n 5: chronic   hip  Y  one  one  Y w12p1  Y norif\n 6: chronic   hip  Y  one  one  Y w12p1  Y   rif\n 7: chronic   hip  Y  two  two  Y d07p2  N other\n 8: chronic   hip  Y  two  two  Y d07p2  Y norif\n 9: chronic   hip  Y  two  two  Y d07p2  Y   rif\n10: chronic   hip  Y  two  two  Y w12p2  N other\n11: chronic   hip  Y  two  two  Y w12p2  Y norif\n12: chronic   hip  Y  two  two  Y w12p2  Y   rif\n13: chronic  knee  Y  one  one  Y w06p1  N other\n14: chronic  knee  Y  one  one  Y w06p1  Y norif\n15: chronic  knee  Y  one  one  Y w06p1  Y   rif\n16: chronic  knee  Y  one  one  Y w12p1  N other\n17: chronic  knee  Y  one  one  Y w12p1  Y norif\n18: chronic  knee  Y  one  one  Y w12p1  Y   rif\n19: chronic  knee  Y  two  two  Y d07p2  N other\n20: chronic  knee  Y  two  two  Y d07p2  Y norif\n21: chronic  knee  Y  two  two  Y d07p2  Y   rif\n22: chronic  knee  Y  two  two  Y w12p2  N other\n23: chronic  knee  Y  two  two  Y w12p2  Y norif\n24: chronic  knee  Y  two  two  Y w12p2  Y   rif\n25:   early   hip  N dair dair  N   w12  N other\n26:   early   hip  N dair dair  N   w12  Y norif\n27:   early   hip  N dair dair  N   w12  Y   rif\n28:   early  knee  N dair dair  N   w12  N other\n29:   early  knee  N dair dair  N   w12  Y norif\n30:   early  knee  N dair dair  N   w12  Y   rif\n31:    late   hip  Y dair dair  N   w12  N other\n32:    late   hip  Y dair dair  N   w12  Y norif\n33:    late   hip  Y dair dair  N   w12  Y   rif\n34:    late   hip  Y  rev  one  Y w06p1  N other\n35:    late   hip  Y  rev  one  Y w06p1  Y norif\n36:    late   hip  Y  rev  one  Y w06p1  Y   rif\n37:    late   hip  Y  rev  one  Y w12p1  N other\n38:    late   hip  Y  rev  one  Y w12p1  Y norif\n39:    late   hip  Y  rev  one  Y w12p1  Y   rif\n40:    late   hip  Y  rev  two  Y d07p2  N other\n41:    late   hip  Y  rev  two  Y d07p2  Y norif\n42:    late   hip  Y  rev  two  Y d07p2  Y   rif\n43:    late   hip  Y  rev  two  Y w12p2  N other\n44:    late   hip  Y  rev  two  Y w12p2  Y norif\n45:    late   hip  Y  rev  two  Y w12p2  Y   rif\n46:    late  knee  Y dair dair  N   w12  N other\n47:    late  knee  Y dair dair  N   w12  Y norif\n48:    late  knee  Y dair dair  N   w12  Y   rif\n49:    late  knee  Y  rev  one  Y w06p1  N other\n50:    late  knee  Y  rev  one  Y w06p1  Y norif\n51:    late  knee  Y  rev  one  Y w06p1  Y   rif\n52:    late  knee  Y  rev  one  Y w12p1  N other\n53:    late  knee  Y  rev  one  Y w12p1  Y norif\n54:    late  knee  Y  rev  one  Y w12p1  Y   rif\n55:    late  knee  Y  rev  two  Y d07p2  N other\n56:    late  knee  Y  rev  two  Y d07p2  Y norif\n57:    late  knee  Y  rev  two  Y d07p2  Y   rif\n58:    late  knee  Y  rev  two  Y w12p2  N other\n59:    late  knee  Y  rev  two  Y w12p2  Y norif\n60:    late  knee  Y  rev  two  Y w12p2  Y   rif\n       silo joint ea    a   qa eb     b ec     c",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/simulation-results.html#all-treatments-effective",
    "href": "notebooks/simulation-results.html#all-treatments-effective",
    "title": "Simulation results 1",
    "section": "All treatments effective",
    "text": "All treatments effective\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc01\")\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n}\n\nd_sup &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"pr_sup\")\n\nd_inf &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_inf[, lapply(.SD, mean)])\n}))\nd_inf &lt;- melt(d_inf, id.vars = c(\"sc\", \"v\"), value.name = \"pr_inf\")\n\nd_fut &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_fut[, lapply(.SD, mean)])\n}))\nd_fut &lt;- melt(d_fut, id.vars = c(\"sc\", \"v\"), value.name = \"pr_fut\")\n\nd_cfg &lt;- rbindlist(lapply(l, function(z){\n  data.table(do.call(cbind, z$cfg)) \n}))\n# urgh - conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  mc_cores = as.numeric(mc_cores),\n  b_a_l_2 = as.numeric(b_a_l_2),\n  b_a_c_2 = as.numeric(b_a_c_2),\n  b_b1_l_2 = as.numeric(b_b1_l_2),\n  b_b2_l_2 = as.numeric(b_b2_l_2),\n  b_b1_c_2 = as.numeric(b_b1_c_2),\n  b_b2_c_2 = as.numeric(b_b2_c_2),\n  b_c_2 = as.numeric(b_c_2),\n  d_sup = as.numeric(d_sup),\n  d_inf = as.numeric(d_inf),\n  d_fut = as.numeric(d_fut)\n  )]\n\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\nd_pars &lt;- melt(d_cfg[\n  , .SD, .SDcols = c(\"sc\", \"v\", \n                     \"b_a_l_2\", \"b_a_c_2\", \n                     \"b_b1_l_2\", \"b_b2_l_2\", \"b_b1_c_2\", \"b_b2_c_2\", \n                     \"b_c_2\")], \n  id.vars = c(\"sc\", \"v\"), value.name = \"lor_tru\")\n\n\nd_sup &lt;- add_effect_field(d_sup, d_pars)\nd_inf &lt;- add_effect_field(d_inf, d_pars)\nd_fut &lt;- add_effect_field(d_fut, d_pars)\n\n\nd_fig &lt;- merge(d_sup, d_inf, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- merge(d_fig, d_fut, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- melt(d_fig, measure.vars = c(\"pr_sup\", \"pr_inf\", \"pr_fut\"), variable.name = \"decision_type\")\nd_fig[decision_type == \"pr_sup\", decision_type := \"Superiority\"]\nd_fig[decision_type == \"pr_inf\", decision_type := \"Inferiority\"]\nd_fig[decision_type == \"pr_fut\", decision_type := \"Futility\"]\n\n\nTable 1 summarises the setup for the simulated effect sizes (from \\(\\log(1/1.4)\\) to \\(\\log(2)\\)). All parameters are simulated to have the same effect size such that all parameters are effective, show no effect or are harmful.\nResults based on 500 simulations for a cohort sample size of 2500.\n\n\nCode\nd_tbl &lt;- d_cfg[, .SD, .SDcols = !c(\"sc\",\"nsim\", \"mc_cores\")]\nd_tbl &lt;- cbind(\n  effect = c(\n    \"null\", rep(\"superior\", 5), rep(\"inferior\", 2)\n  ), d_tbl\n)\n\n\ng_tbl &lt;- d_tbl |&gt; gt(rowname_col = \"effect\") |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = everything(),\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_a_l_2, b_a_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_b1_l_2, b_b2_l_2, b_b1_c_2, b_b2_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision thresholds\"),\n    columns = c(d_sup, d_inf, d_fut)\n  ) |&gt;\n  cols_label(\n    b_a_l_2 = html(\"revision\"),\n    b_a_c_2 = html(\"two-stage\"),\n    b_b1_l_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_l_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_b1_c_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_c_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_c_2 = html(\"rif\"),\n    d_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    d_inf = html(\"delta&lt;sub&gt;inf&lt;/sub&gt;\"),\n    d_fut = html(\"delta&lt;sub&gt;fut&lt;/sub&gt;\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nv\nN_pt\nSurgical (Da)\nDuration (Db)\nType (Dc)\nDecision thresholds\n\n\nrevision\ntwo-stage\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nrif\ndeltasup\ndeltainf\ndeltafut\n\n\n\n\nnull\nv01\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.050\n\n\nsuperior\nv02\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.050\n\n\nsuperior\nv03\n2500\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.050\n\n\nsuperior\nv04\n2500\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.050\n\n\nsuperior\nv05\n2500\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.050\n\n\nsuperior\nv06\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.050\n\n\ninferior\nv07\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.050\n\n\ninferior\nv08\n2500\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.050\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 summarises the variation in the probability of declaring each decision type on each parameter with increasing effects size (odds ratios). All domains are set so that the treatment effects are all equal, e.g. all set to \\(\\log(2)\\) etc. The parameters are log-odds-ratios relative to the relevant reference values.\nFor example, b_a_late_rev is the effect revision relative to dair specific to the late silo. Similarly, b_a_chronic_two is the effect of two-stage procedure relative to the one-stage specific to the chronic silo.\n\n\nCode\nggplot(d_fig, aes(x = exp(lor_tru), y = value, group = decision_type, col = decision_type)) +\n  geom_point(size = 0.5) +\n  geom_line() +\n  scale_color_discrete(\"\") +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Pr(decide superior)\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~parname, ncol = 3)\n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc02\")\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n}\n\nd_sup &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"pr_sup\")\n\nd_inf &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_inf[, lapply(.SD, mean)])\n}))\nd_inf &lt;- melt(d_inf, id.vars = c(\"sc\", \"v\"), value.name = \"pr_inf\")\n\nd_fut &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_fut[, lapply(.SD, mean)])\n}))\nd_fut &lt;- melt(d_fut, id.vars = c(\"sc\", \"v\"), value.name = \"pr_fut\")\n\nd_cfg &lt;- rbindlist(lapply(l, function(z){\n  data.table(do.call(cbind, z$cfg)) \n}))\n# urgh - conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  mc_cores = as.numeric(mc_cores),\n  b_a_l_2 = as.numeric(b_a_l_2),\n  b_a_c_2 = as.numeric(b_a_c_2),\n  b_b1_l_2 = as.numeric(b_b1_l_2),\n  b_b2_l_2 = as.numeric(b_b2_l_2),\n  b_b1_c_2 = as.numeric(b_b1_c_2),\n  b_b2_c_2 = as.numeric(b_b2_c_2),\n  b_c_2 = as.numeric(b_c_2),\n  d_sup = as.numeric(d_sup),\n  d_inf = as.numeric(d_inf),\n  d_fut = as.numeric(d_fut)\n  )]\n\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\nd_pars &lt;- melt(d_cfg[\n  , .SD, .SDcols = c(\"sc\", \"v\", \n                     \"b_a_l_2\", \"b_a_c_2\", \n                     \"b_b1_l_2\", \"b_b2_l_2\", \"b_b1_c_2\", \"b_b2_c_2\", \n                     \"b_c_2\")], \n  id.vars = c(\"sc\", \"v\"), value.name = \"lor_tru\")\n\n\nd_sup &lt;- add_effect_field(d_sup, d_pars)\nd_inf &lt;- add_effect_field(d_inf, d_pars)\nd_fut &lt;- add_effect_field(d_fut, d_pars)\n\n\nd_fig &lt;- merge(d_sup, d_inf, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- merge(d_fig, d_fut, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- melt(d_fig, measure.vars = c(\"pr_sup\", \"pr_inf\", \"pr_fut\"), variable.name = \"decision_type\")\nd_fig[decision_type == \"pr_sup\", decision_type := \"Superiority\"]\nd_fig[decision_type == \"pr_inf\", decision_type := \"Inferiority\"]\nd_fig[decision_type == \"pr_fut\", decision_type := \"Futility\"]\n\n\nRepeating the simulations (500 iterations) based on a total cohort size of 1000.\n\n\nCode\nggplot(d_fig, aes(x = exp(lor_tru), y = value, group = decision_type, col = decision_type)) +\n  geom_point(size = 0.5) +\n  geom_line() +\n  scale_color_discrete(\"\") +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Pr(decide superior)\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~parname, ncol = 3)\n\n\n\n\n\n\n\n\nFigure 2: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc03\")\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n}\n\nd_sup &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"pr_sup\")\n\nd_inf &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_inf[, lapply(.SD, mean)])\n}))\nd_inf &lt;- melt(d_inf, id.vars = c(\"sc\", \"v\"), value.name = \"pr_inf\")\n\nd_fut &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_fut[, lapply(.SD, mean)])\n}))\nd_fut &lt;- melt(d_fut, id.vars = c(\"sc\", \"v\"), value.name = \"pr_fut\")\n\nd_cfg &lt;- rbindlist(lapply(l, function(z){\n  data.table(do.call(cbind, z$cfg)) \n}))\n# urgh - conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  mc_cores = as.numeric(mc_cores),\n  b_a_l_2 = as.numeric(b_a_l_2),\n  b_a_c_2 = as.numeric(b_a_c_2),\n  b_b1_l_2 = as.numeric(b_b1_l_2),\n  b_b2_l_2 = as.numeric(b_b2_l_2),\n  b_b1_c_2 = as.numeric(b_b1_c_2),\n  b_b2_c_2 = as.numeric(b_b2_c_2),\n  b_c_2 = as.numeric(b_c_2),\n  d_sup = as.numeric(d_sup),\n  d_inf = as.numeric(d_inf),\n  d_fut = as.numeric(d_fut)\n  )]\n\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\nd_pars &lt;- melt(d_cfg[\n  , .SD, .SDcols = c(\"sc\", \"v\", \n                     \"b_a_l_2\", \"b_a_c_2\", \n                     \"b_b1_l_2\", \"b_b2_l_2\", \"b_b1_c_2\", \"b_b2_c_2\", \n                     \"b_c_2\")], \n  id.vars = c(\"sc\", \"v\"), value.name = \"lor_tru\")\n\n\nd_sup &lt;- add_effect_field(d_sup, d_pars)\nd_inf &lt;- add_effect_field(d_inf, d_pars)\nd_fut &lt;- add_effect_field(d_fut, d_pars)\n\n\nd_fig &lt;- merge(d_sup, d_inf, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- merge(d_fig, d_fut, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- melt(d_fig, measure.vars = c(\"pr_sup\", \"pr_inf\", \"pr_fut\"), variable.name = \"decision_type\")\nd_fig[decision_type == \"pr_sup\", decision_type := \"Superiority\"]\nd_fig[decision_type == \"pr_inf\", decision_type := \"Inferiority\"]\nd_fig[decision_type == \"pr_fut\", decision_type := \"Futility\"]\n\n\nRepeating the simulations (500 iterations) based on a total cohort size of 500.\n\n\nCode\nggplot(d_fig, aes(x = exp(lor_tru), y = value, group = decision_type, col = decision_type)) +\n  geom_point(size = 0.5) +\n  geom_line() +\n  scale_color_discrete(\"\") +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Pr(decide superior)\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~parname, ncol = 3)\n\n\n\n\n\n\n\n\nFigure 3: Probability of declaring decision by parameter by effect size (all pars set with same OR).",
    "crumbs": [
      "Design",
      "Simulation results 1"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html",
    "href": "notebooks/sim-design2-results.html",
    "title": "Simulation results 2",
    "section": "",
    "text": "The trial is performed sequentially. Entry into silo-specific (plus surgery specific) parameters is coordinated by triggers for superiority, inferiority and futility, all defined earlier.",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html#all-treatments-effective",
    "href": "notebooks/sim-design2-results.html#all-treatments-effective",
    "title": "Simulation results 2",
    "section": "All treatments effective",
    "text": "All treatments effective\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim02-sc01\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n# cfg - decision thresholds currently static but could be varied over time\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\nd_pars &lt;- melt(d_cfg[, c(\"sc\", \"v\", \"analys\", g_effs), with = F], \n               id.vars = c(\"sc\", \"v\", \"analys\"), \n               value.name = \"lor_tru\", variable.name = \"parname\")\n\n\nd_trig &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  l[[i]]$d_trig\n\n  m &lt;- melt(l[[i]]$d_trig, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"parname\")\n  # Should be right, but just in case...\n  m[is.na(value), value := FALSE]\n  m[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, parname)]\n  m &lt;- m[, .(pr_val = mean(value)), keyby = .(analys, quant, parname)]\n  m &lt;- dcast(m, parname + analys ~ quant, value.var = \"pr_val\")\n\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n\nd_est &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  l[[i]]$d_trig\n  # mean of means\n  # what if analysis not reached....?????\n  m &lt;- l[[i]]$d_par\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\nd_fig &lt;- melt(d_trig, id.vars = c(\"sc\", \"v\", \"analys\", \"parname\"), variable.name = \"quant\")\nd_fig &lt;- merge(d_fig, d_pars, by = c(\"sc\", \"v\", \"analys\", \"parname\"))\nd_fig[, quant := factor(quant, \n                        labels = c(\"superiority\", \"futility\", \"inferiority\"),\n                        levels = c(\"sup\", \"fut\", \"inf\"))]\nd_fig &lt;- merge(d_fig, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig[, or_tru := round(exp(lor_tru), 3)]\n\nd_fig[, or_tru := factor(\n  or_tru, \n  labels = c(\"OR 1/1.4\" ,\"OR 1/1.2\", \"OR 1\", \"OR 1.2\", \"OR 1.4\", \"OR 1.6\", \"OR 1.8\", \"OR 2\"),\n  levels = c(\"0.714\", \"0.833\", \"1\", \"1.2\", \"1.4\", \"1.6\", \"1.8\", \"2\"))]\n\nsetkey(d_fig, sc, v, analys, N_pt)\n\n\nTable 1 summarises the setup for the simulated effect sizes (from \\(\\log(1/1.4)\\) to \\(\\log(2)\\)). All parameters are simulated to have the same effect size such that all parameters are effective, show no effect or are harmful. Decision thresholds remain constant throughout the duration of the study.\n\n\nCode\nd_tbl &lt;- d_cfg[, .SD, .SDcols = !c(\"sc\",\"nsim\", \"mc_cores\", \"t_pri\", \"analys\")]\n\ng_tbl &lt;- d_tbl |&gt; gt(rowname_col = \"effect\") |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = g_effs,\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_a_l_2, b_a_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_b1_l_2, b_b2_l_2, b_b1_c_2, b_b2_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision thresholds\"),\n    columns = c(d_sup, d_inf, d_fut)\n  ) |&gt;\n  cols_label(\n    v = html(\"Configuration\"),\n    b_a_l_2 = html(\"revision\"),\n    b_a_c_2 = html(\"two-stage\"),\n    b_b1_l_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_l_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_b1_c_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_c_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_c_2 = html(\"rif\"),\n    d_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    d_inf = html(\"delta&lt;sub&gt;inf&lt;/sub&gt;\"),\n    d_fut = html(\"delta&lt;sub&gt;fut&lt;/sub&gt;\")\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"bottom\"), color = \"black\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = N_pt == 2500\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration\nN_pt\nSurgical (Da)\nDuration (Db)\nType (Dc)\nDecision thresholds\n\n\nrevision\ntwo-stage\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nrif\ndeltasup\ndeltainf\ndeltafut\n\n\n\n\nv01\n1000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv01\n1500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv01\n2000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv01\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv02\n1000\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv02\n1500\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv02\n2000\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv02\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv03\n1000\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv03\n1500\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv03\n2000\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv03\n2500\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv04\n1000\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv04\n1500\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv04\n2000\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv04\n2500\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv05\n1000\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv05\n1500\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv05\n2000\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv05\n2500\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv06\n1000\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv06\n1500\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv06\n2000\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv06\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv07\n1000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv07\n1500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv07\n2000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv07\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv08\n1000\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\nv08\n1500\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\nv08\n2000\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\nv08\n2500\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 shows the change in the cumulative probability of declaring each of the decision types for each parameter with changing effects size (odds ratios).\n\n\n\n\n\n\nNote\n\n\n\nThe sample size shows number of enrolled patients having reached 12-months post-randomisation.\n\n\nAs noted above, all domains are set so that the treatment effects are all equal, e.g. all set to \\(\\log(2)\\) etc. The facet labels characterise the odds ratios and the parameters reported (Table 2 is a lookup table for translating the parameter names). The interpretation of some of these parameters is quite challenging.\n\n\nCode\nd_tbl &lt;- data.table(\n  parname = as.character(unique(d_fig$parname)),\n  reflab = get_effect_ref_lev(as.character(unique(d_fig$parname))),\n  parlab = get_effect_label(as.character(unique(d_fig$parname)), do_html = F)\n)\n\ng_tbl &lt;- d_tbl |&gt; gt(rowname_col = \"parname\") |&gt; \n  cols_align(\n    columns = c(\"reflab\", \"parlab\"),\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    parname = \"Parameter\",\n    reflab = \"Ref level\",\n    parlab = \"Effect\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRef level\nEffect\n\n\n\n\nb_a_l_2\ndair\nrevision\n\n\nb_a_c_2\none-stage\ntwo-stage\n\n\nb_b1_l_2\nwk6 (post stage 1)\nwk12 (post stage 1)\n\n\nb_b2_l_2\nd7 (post stage 2)\nwk12 (post stage 2)\n\n\nb_b1_c_2\nwk6 (post stage 1)\nwk12 (post stage 1)\n\n\nb_b2_c_2\nd7 (post stage 2)\nwk12 (post stage 2)\n\n\nb_c_2\nnorif\nrif\n\n\n\n\n\n\n\n\nTable 2: Translation from parameter names to effects\n\n\n\n\n\n\nCode\nggplot(d_fig, aes(x = N_pt, y = value, group = quant, col = quant)) +\n  geom_point(size = 0.5) +\n  geom_line(aes(lty = quant), lwd = 0.3) +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  scale_x_continuous(\"Sample size\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Cumulative probability\", breaks = seq(0, 1, by = 0.2)) +\n  facet_grid(parname~or_tru)\n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\nTable 3 provides the same detail as the above figure, but makes it easier to see what the magnitudes of the cumulate probabilities are.\n\n\nCode\nd_tbl &lt;- dcast(d_fig, parname + or_tru ~ quant + analys, value.var = \"value\")\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"inferiority\", \"inf\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility\", \"fut\", names(d_tbl))\nd_tbl &lt;- d_tbl[order(or_tru, parname)]\nd_tbl[, parlab := paste0(parname, \" - \", get_effect_label(as.character(parname), do_html = F))]\nd_tbl[, parname := NULL]\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"parlab\") |&gt; \n  tab_spanner(\n    label = html(\"Superiority\"),\n    columns = c(\"sup_1\", \"sup_2\", \"sup_3\", \"sup_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility\"),\n    columns = c(\"fut_1\", \"fut_2\", \"fut_3\", \"fut_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Inferiority\"),\n    columns = c(\"inf_1\", \"inf_2\", \"inf_3\", \"inf_4\")\n  ) |&gt;\n  cols_label(\n    or_tru = html(\"OR (true)\"),\n    sup_1 = html(\"1000\"),\n    sup_2 = html(\"1500\"),\n    sup_3 = html(\"2000\"),\n    sup_4 = html(\"2500\"),\n    fut_1 = html(\"1000\"),\n    fut_2 = html(\"1500\"),\n    fut_3 = html(\"2000\"),\n    fut_4 = html(\"2500\"),\n    inf_1 = html(\"1000\"),\n    inf_2 = html(\"1500\"),\n    inf_3 = html(\"2000\"),\n    inf_4 = html(\"2500\")\n  ) |&gt;\n  tab_style(\n    style = cell_borders(\n      sides = c(\"left\"),\n      weight = px(1)),\n    locations = cells_body(\n      columns = c(sup_1, fut_1, inf_1)\n      )\n    ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or_tru == \"OR 1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nOR (true)\nSuperiority\nFutility\nInferiority\n\n\n1000\n1500\n2000\n2500\n1000\n1500\n2000\n2500\n1000\n1500\n2000\n2500\n\n\n\n\nb_a_l_2 - revision\n\n\nOR 1/1.4\n0.000\n0.000\n0.000\n0.000\n0.662\n0.852\n0.946\n0.974\n0.398\n0.558\n0.646\n0.718\n\n\nOR 1/1.2\n0.006\n0.006\n0.006\n0.006\n0.342\n0.492\n0.614\n0.694\n0.156\n0.224\n0.278\n0.322\n\n\nOR 1\n0.016\n0.030\n0.042\n0.044\n0.082\n0.128\n0.154\n0.170\n0.010\n0.026\n0.036\n0.038\n\n\nOR 1.2\n0.128\n0.236\n0.292\n0.328\n0.014\n0.020\n0.020\n0.020\n0.000\n0.002\n0.002\n0.002\n\n\nOR 1.4\n0.348\n0.512\n0.604\n0.666\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.624\n0.770\n0.828\n0.862\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.788\n0.880\n0.914\n0.922\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.866\n0.936\n0.954\n0.968\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_a_c_2 - two-stage\n\n\nOR 1/1.4\n0.004\n0.006\n0.006\n0.006\n0.216\n0.390\n0.530\n0.618\n0.074\n0.130\n0.208\n0.286\n\n\nOR 1/1.2\n0.006\n0.006\n0.006\n0.010\n0.164\n0.266\n0.336\n0.400\n0.046\n0.086\n0.118\n0.134\n\n\nOR 1\n0.018\n0.038\n0.058\n0.064\n0.084\n0.120\n0.132\n0.156\n0.028\n0.034\n0.038\n0.044\n\n\nOR 1.2\n0.038\n0.078\n0.108\n0.130\n0.020\n0.030\n0.036\n0.038\n0.004\n0.004\n0.004\n0.008\n\n\nOR 1.4\n0.088\n0.166\n0.236\n0.300\n0.008\n0.010\n0.010\n0.010\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.180\n0.266\n0.328\n0.390\n0.006\n0.006\n0.006\n0.006\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.278\n0.400\n0.472\n0.504\n0.002\n0.004\n0.004\n0.004\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.336\n0.486\n0.570\n0.610\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_b1_l_2 - wk12 (post stage 1)\n\n\nOR 1/1.4\n0.000\n0.000\n0.000\n0.000\n0.384\n0.426\n0.440\n0.442\n0.164\n0.184\n0.186\n0.194\n\n\nOR 1/1.2\n0.006\n0.006\n0.006\n0.006\n0.220\n0.296\n0.348\n0.368\n0.064\n0.084\n0.096\n0.104\n\n\nOR 1\n0.012\n0.024\n0.032\n0.036\n0.060\n0.094\n0.120\n0.152\n0.010\n0.018\n0.022\n0.024\n\n\nOR 1.2\n0.082\n0.142\n0.192\n0.234\n0.028\n0.038\n0.050\n0.052\n0.002\n0.002\n0.002\n0.004\n\n\nOR 1.4\n0.160\n0.302\n0.406\n0.508\n0.008\n0.012\n0.012\n0.012\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.240\n0.452\n0.630\n0.716\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.302\n0.564\n0.738\n0.846\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.322\n0.628\n0.784\n0.878\n0.004\n0.004\n0.004\n0.004\n0.000\n0.000\n0.000\n0.000\n\n\nb_b2_l_2 - wk12 (post stage 2)\n\n\nOR 1/1.4\n0.002\n0.002\n0.002\n0.002\n0.394\n0.448\n0.466\n0.472\n0.166\n0.188\n0.208\n0.218\n\n\nOR 1/1.2\n0.000\n0.000\n0.000\n0.000\n0.216\n0.284\n0.322\n0.336\n0.050\n0.068\n0.086\n0.088\n\n\nOR 1\n0.016\n0.036\n0.046\n0.050\n0.080\n0.118\n0.150\n0.158\n0.026\n0.040\n0.048\n0.056\n\n\nOR 1.2\n0.064\n0.104\n0.144\n0.188\n0.022\n0.036\n0.042\n0.046\n0.000\n0.006\n0.006\n0.010\n\n\nOR 1.4\n0.158\n0.276\n0.380\n0.496\n0.010\n0.014\n0.016\n0.016\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.258\n0.434\n0.614\n0.740\n0.004\n0.006\n0.006\n0.006\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.300\n0.536\n0.748\n0.848\n0.002\n0.002\n0.002\n0.002\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.388\n0.662\n0.816\n0.908\n0.002\n0.002\n0.002\n0.002\n0.002\n0.002\n0.002\n0.002\n\n\nb_b1_c_2 - wk12 (post stage 1)\n\n\nOR 1/1.4\n0.004\n0.006\n0.006\n0.006\n0.226\n0.374\n0.486\n0.592\n0.060\n0.122\n0.200\n0.266\n\n\nOR 1/1.2\n0.000\n0.000\n0.004\n0.006\n0.154\n0.230\n0.312\n0.364\n0.050\n0.088\n0.118\n0.140\n\n\nOR 1\n0.024\n0.034\n0.052\n0.066\n0.080\n0.122\n0.144\n0.172\n0.018\n0.026\n0.040\n0.044\n\n\nOR 1.2\n0.054\n0.098\n0.134\n0.158\n0.032\n0.042\n0.052\n0.056\n0.002\n0.010\n0.012\n0.012\n\n\nOR 1.4\n0.104\n0.154\n0.204\n0.252\n0.016\n0.016\n0.018\n0.020\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.150\n0.222\n0.296\n0.344\n0.006\n0.006\n0.008\n0.008\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.224\n0.300\n0.366\n0.424\n0.004\n0.004\n0.004\n0.004\n0.002\n0.002\n0.002\n0.002\n\n\nOR 2\n0.246\n0.360\n0.448\n0.500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_b2_c_2 - wk12 (post stage 2)\n\n\nOR 1/1.4\n0.002\n0.002\n0.002\n0.002\n0.306\n0.420\n0.480\n0.514\n0.114\n0.162\n0.180\n0.196\n\n\nOR 1/1.2\n0.010\n0.016\n0.016\n0.016\n0.200\n0.284\n0.370\n0.428\n0.064\n0.098\n0.134\n0.150\n\n\nOR 1\n0.022\n0.036\n0.046\n0.048\n0.088\n0.126\n0.148\n0.174\n0.014\n0.022\n0.032\n0.038\n\n\nOR 1.2\n0.040\n0.070\n0.102\n0.126\n0.028\n0.038\n0.054\n0.062\n0.002\n0.002\n0.004\n0.006\n\n\nOR 1.4\n0.100\n0.164\n0.230\n0.282\n0.014\n0.022\n0.028\n0.030\n0.000\n0.000\n0.000\n0.002\n\n\nOR 1.6\n0.152\n0.238\n0.374\n0.456\n0.000\n0.004\n0.004\n0.006\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.192\n0.334\n0.494\n0.596\n0.000\n0.002\n0.002\n0.002\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.190\n0.350\n0.530\n0.678\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_c_2 - rif\n\n\nOR 1/1.4\n0.000\n0.000\n0.000\n0.000\n0.732\n0.874\n0.938\n0.964\n0.460\n0.624\n0.716\n0.792\n\n\nOR 1/1.2\n0.002\n0.002\n0.002\n0.002\n0.364\n0.524\n0.618\n0.686\n0.174\n0.262\n0.324\n0.382\n\n\nOR 1\n0.026\n0.044\n0.058\n0.064\n0.056\n0.112\n0.140\n0.154\n0.018\n0.030\n0.040\n0.040\n\n\nOR 1.2\n0.204\n0.300\n0.380\n0.472\n0.002\n0.004\n0.008\n0.008\n0.000\n0.000\n0.002\n0.002\n\n\nOR 1.4\n0.522\n0.676\n0.806\n0.880\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.756\n0.894\n0.950\n0.978\n0.002\n0.002\n0.002\n0.002\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.862\n0.964\n0.994\n0.996\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.966\n0.994\n0.998\n1.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\n\n\n\n\n\n\nTable 3: Cumulative probability of decision\n\n\n\n\nFigure 2 shows the distribution of estimated posterior means by simulated effect size, parameter and sample size.\n\n\nCode\nd_fig &lt;- d_est[, .(sc, v, sim, parname = par, analys, mu)]\nd_fig &lt;- merge(d_fig, d_pars, by = c(\"sc\", \"v\", \"analys\", \"parname\"))\nd_fig &lt;- merge(d_fig, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig[, analys := factor(analys)]\nd_fig[, N_pt := factor(N_pt)]\n\nd_fig[, or_tru := factor(\n  round(exp(lor_tru), 3), \n  labels = c(\"OR 1/1.4\" ,\"OR 1/1.2\", \"OR 1\", \"OR 1.2\", \"OR 1.4\", \"OR 1.6\", \"OR 1.8\", \"OR 2\"),\n  levels = c(\"0.714\", \"0.833\", \"1\", \"1.2\", \"1.4\", \"1.6\", \"1.8\", \"2\"))]\n\nd_fig_2 &lt;- unique(d_fig[, .(sc, or_tru, parname, lor_tru)])\n\np &lt;- ggplot(d_fig, aes(x = N_pt, y = mu)) +\n  geom_hline(data = d_fig_2, aes(yintercept = lor_tru, group = parname), col = 2) +\n  geom_boxplot() +\n  scale_x_discrete(\"\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Distribution of posterior mean\") +\n  facet_grid(parname~or_tru)\n\nsuppressWarnings(print(p))\n\n\n\n\n\n\n\n\nFigure 2: Distribution of posterior means (true log OR shown in red).",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html#single-effective-treatment",
    "href": "notebooks/sim-design2-results.html#single-effective-treatment",
    "title": "Simulation results 2",
    "section": "Single effective treatment",
    "text": "Single effective treatment\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim02-sc02\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n# cfg - decision thresholds currently static but could be varied over time\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\nd_pars &lt;- melt(d_cfg[, c(\"sc\", \"v\", \"analys\", g_effs), with = F], \n               id.vars = c(\"sc\", \"v\", \"analys\"), \n               value.name = \"lor_tru\", variable.name = \"parname\")\n\n\nd_trig &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  l[[i]]$d_trig\n\n  m &lt;- melt(l[[i]]$d_trig, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"parname\")\n  # Should be right, but just in case...\n  m[is.na(value), value := FALSE]\n  m[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, parname)]\n  m &lt;- m[, .(pr_val = mean(value)), keyby = .(analys, quant, parname)]\n  m &lt;- dcast(m, parname + analys ~ quant, value.var = \"pr_val\")\n\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\nd_fig &lt;- melt(d_trig, id.vars = c(\"sc\", \"v\", \"analys\", \"parname\"), variable.name = \"quant\")\nd_fig &lt;- merge(d_fig, d_pars, by = c(\"sc\", \"v\", \"analys\", \"parname\"))\nd_fig[, quant := factor(quant, \n                        labels = c(\"superiority\", \"futility\", \"inferiority\"),\n                        levels = c(\"sup\", \"fut\", \"inf\"))]\nd_fig &lt;- merge(d_fig, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig[, or_tru := round(exp(lor_tru), 3)]\n\nd_fig[, or_tru := factor(\n  or_tru, \n  labels = c(\"OR 1/1.4\" ,\"OR 1/1.2\", \"OR 1\", \"OR 1.2\", \"OR 1.4\", \"OR 1.6\", \"OR 1.8\", \"OR 2\"),\n  levels = c(\"0.714\", \"0.833\", \"1\", \"1.2\", \"1.4\", \"1.6\", \"1.8\", \"2\"))]\n\nsetkey(d_fig, sc, v, analys, N_pt)\n\n\n\n\nCode\nggplot(d_fig, aes(x = N_pt, y = value, group = quant, col = quant)) +\n  geom_point(size = 0.5) +\n  geom_line(aes(lty = quant), lwd = 0.3) +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  scale_x_continuous(\"Sample size\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Cumulative probability\", breaks = seq(0, 1, by = 0.2)) +\n  facet_grid(parname~or_tru)\n\n\nTable 4 provides the same detail as the above figure, but makes it easier to see what the magnitudes of the cumulate probabilities are.\n\n\n\n\nCode\nd_tbl &lt;- dcast(d_fig, parname + or_tru ~ quant + analys, value.var = \"value\")\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"inferiority\", \"inf\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility\", \"fut\", names(d_tbl))\nd_tbl &lt;- d_tbl[order(or_tru, parname)]\nd_tbl[, parlab := paste0(parname, \" - \", get_effect_label(as.character(parname), do_html = F))]\nd_tbl[, parname := NULL]\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"parlab\") |&gt; \n  tab_spanner(\n    label = html(\"Superiority\"),\n    columns = c(\"sup_1\", \"sup_2\", \"sup_3\", \"sup_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility\"),\n    columns = c(\"fut_1\", \"fut_2\", \"fut_3\", \"fut_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Inferiority\"),\n    columns = c(\"inf_1\", \"inf_2\", \"inf_3\", \"inf_4\")\n  ) |&gt;\n  cols_label(\n    or_tru = html(\"OR (true)\"),\n    sup_1 = html(\"1000\"),\n    sup_2 = html(\"1500\"),\n    sup_3 = html(\"2000\"),\n    sup_4 = html(\"2500\"),\n    fut_1 = html(\"1000\"),\n    fut_2 = html(\"1500\"),\n    fut_3 = html(\"2000\"),\n    fut_4 = html(\"2500\"),\n    inf_1 = html(\"1000\"),\n    inf_2 = html(\"1500\"),\n    inf_3 = html(\"2000\"),\n    inf_4 = html(\"2500\")\n  ) |&gt;\n  tab_style(\n    style = cell_borders(\n      sides = c(\"left\"),\n      weight = px(1)),\n    locations = cells_body(\n      columns = c(sup_1, fut_1, inf_1)\n      )\n    ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or_tru == \"OR 1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\nTable 4: Cumulative probability of decision",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html",
    "href": "notebooks/example-trials.html",
    "title": "Example trials",
    "section": "",
    "text": "Example trials are provided to give insight into the cell sizes as well as the level of uncertainty associated with the parameter estimation process. Examples are from trials at their maximum sample size with all follow up completed. Sequential variants with adaptations will be added later.",
    "crumbs": [
      "Design",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html#null-scenario",
    "href": "notebooks/example-trials.html#null-scenario",
    "title": "Example trials",
    "section": "Null scenario",
    "text": "Null scenario\nTable 1 shows a summary of the treatment sucesses based on the \\(n\\) patients associated with each combination of design variables when no treatment effects (non-membership effects still retained) in the simulated data of 2500 patients. Given that this is a summary of a single data set, some variation from the underlying simulation parameters is to be expected.\n\n\nCode\nsim_spec &lt;- get_sim_spec()\nsim_spec$b_a_late[\"rev\"] &lt;- 0\nsim_spec$b_a_chronic[\"two\"] &lt;- 0\nsim_spec$b_b1_late_one[\"w12p1\"] &lt;- 0\nsim_spec$b_b2_late_two[\"w12p2\"] &lt;- 0\nsim_spec$b_b1_chronic_one[\"w12p1\"] &lt;- 0\nsim_spec$b_b2_chronic_two[\"w12p2\"] &lt;- 0\nsim_spec$b_c[\"rif\"] &lt;- 0\n\nset.seed(15)\nll &lt;- get_trial_data(N = 2500, pop_spec = NULL, sim_spec = sim_spec)\n\ngt_tbl &lt;- tbl_ex_trial(ll$d)\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSurgical Da\nDuration Db\nType Dc\nResponse\n\n\nmember\nassigned\nplan\nmember\nassigned1\nmember\nassigned\ny\nn\nMLE (py)\nTRUE (py)2\n\n\n\n\nearly - knee\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n77\n122\n0.63\n0.63\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n62\n93\n0.67\n0.65\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n60\n93\n0.65\n0.65\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n199\n308\n0.65\n—\n\n\nearly - hip\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n147\n199\n0.74\n0.73\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n108\n137\n0.79\n0.75\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n85\n123\n0.69\n0.75\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n340\n459\n0.74\n—\n\n\nlate - knee\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n84\n170\n0.49\n0.52\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n73\n120\n0.61\n0.55\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n78\n127\n0.61\n0.55\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n14\n23\n0.61\n0.52\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n7\n17\n0.41\n0.55\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n12\n21\n0.57\n0.55\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n13\n28\n0.46\n0.52\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n4\n10\n0.40\n0.55\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n8\n20\n0.40\n0.55\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n31\n62\n0.50\n0.52\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n25\n53\n0.47\n0.55\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n24\n37\n0.65\n0.55\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n29\n57\n0.51\n0.52\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n20\n36\n0.56\n0.55\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n26\n46\n0.57\n0.55\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n448\n827\n0.54\n—\n\n\nlate - hip\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n33\n58\n0.57\n0.57\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n27\n55\n0.49\n0.60\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n34\n47\n0.72\n0.60\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n9\n13\n0.69\n0.57\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n4\n7\n0.57\n0.60\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n3\n7\n0.43\n0.60\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n11\n19\n0.58\n0.57\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n1\n3\n0.33\n0.60\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n6\n9\n0.67\n0.60\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n24\n36\n0.67\n0.57\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n10\n21\n0.48\n0.60\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n9\n18\n0.50\n0.60\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n17\n30\n0.57\n0.57\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n11\n14\n0.79\n0.60\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n16\n21\n0.76\n0.60\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n215\n358\n0.60\n—\n\n\nchronic - knee\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n15\n27\n0.56\n0.57\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n11\n25\n0.44\n0.60\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n11\n16\n0.69\n0.60\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n14\n20\n0.70\n0.57\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n15\n22\n0.68\n0.60\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n16\n26\n0.62\n0.60\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n22\n34\n0.65\n0.57\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n13\n22\n0.59\n0.60\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n9\n24\n0.38\n0.60\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n14\n28\n0.50\n0.57\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n5\n15\n0.33\n0.60\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n13\n23\n0.57\n0.60\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n158\n282\n0.56\n—\n\n\nchronic - hip\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n19\n27\n0.70\n0.63\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n14\n24\n0.58\n0.65\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n13\n17\n0.76\n0.65\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n8\n19\n0.42\n0.63\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n15\n24\n0.62\n0.65\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n17\n22\n0.77\n0.65\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n10\n22\n0.45\n0.63\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n16\n27\n0.59\n0.65\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n10\n19\n0.53\n0.65\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n21\n29\n0.72\n0.63\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n13\n23\n0.57\n0.65\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n7\n13\n0.54\n0.65\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n163\n266\n0.61\n—\n\n\ntotal\n—\n—\n—\n—\n—\n—\n—\n1523\n2500\n0.61\n—\n\n\n\n1 w06p1 = 6 weeks following one-stage procedure, w12p1 = 12 weeks following one-stage procedure etc\n\n\n2 Transformed from the log-odds of response as used in the linear predictor to simulate data.\n\n\n\n\n\n\n\n\n\nTable 1: Summary of simulated trial data when no treatment effects present\n\n\n\n\nModel the simulated data first using standard normal priors on the domain level treatment effects, then increasing the prior standard deviation to ten in order to see if there is any movement in the posterior summary.\n\n\nCode\nlsd &lt;- get_stan_data(ll$d_i)\nld &lt;- lsd$ld\nd_b &lt;- copy(lsd$d_b)\n\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-02.stan\")\n\nf_null_1 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.5 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.6 seconds.\n\n\nCode\npost_1 &lt;- data.table(f_null_1$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n# compare when prior sd is set to 10 for trt effects\n\npri_sd &lt;- 10\nld$pri_sig_b_c &lt;- pri_sd\nld$pri_sig_a_l &lt;- pri_sd\nld$pri_sig_b1_l &lt;- pri_sd\nld$pri_sig_b2_l &lt;- pri_sd\nld$pri_sig_a_c &lt;- pri_sd\nld$pri_sig_b1_c &lt;- pri_sd\nld$pri_sig_b2_c &lt;- pri_sd\n\nf_null_2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.5 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.5 seconds.\n\n\nCode\npost_2 &lt;- data.table(f_null_2$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n\n\n\nCode\nd_fig1 &lt;- post_alpha(post_1)\nd_fig2 &lt;- post_alpha(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = grp, y = a, group = prior_sd, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-odds treatment success\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = grp, y = a_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = a_q025, ymax = a_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = grp, y = a), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 1: Posterior median and 95% CI for baseline log-odds of treatment success (triangles show true values).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_a(post_1)\nd_fig2 &lt;- post_dom_a(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 2: Posterior median and 95% CI for baseline log-odds of treatment success domain A (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_b(post_1)\nd_fig2 &lt;- post_dom_b(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(paste0(\"Planned/assigned surgery: \", qa, \"-stage\")~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 3: Posterior median and 95% CI for baseline log-odds of treatment success domain B (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_c(post_1)\nd_fig2 &lt;- post_dom_c(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 4: Posterior median and 95% CI for baseline log-odds of treatment success in domain C (effect is pooled across all silos).",
    "crumbs": [
      "Design",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html#all-domains-effective-scenario",
    "href": "notebooks/example-trials.html#all-domains-effective-scenario",
    "title": "Example trials",
    "section": "All domains effective scenario",
    "text": "All domains effective scenario\nshows a summary of the treatment sucesses based on the \\(n\\) patients associated with each combination of design variables when all treatment effects set to log(2) (with non-membership effects retained as before) in the simulated data of 2500 patients.\n\n\nCode\nsim_spec &lt;- get_sim_spec()\nsim_spec$b_a_late[\"rev\"] &lt;- log(2)\nsim_spec$b_a_chronic[\"two\"] &lt;- log(2)\nsim_spec$b_b1_late_one[\"w12p1\"] &lt;- log(2)\nsim_spec$b_b2_late_two[\"w12p2\"] &lt;- log(2)\nsim_spec$b_b1_chronic_one[\"w12p1\"] &lt;- log(2)\nsim_spec$b_b2_chronic_two[\"w12p2\"] &lt;- log(2)\nsim_spec$b_c[\"rif\"] &lt;- log(2)\n\nset.seed(222)\nll &lt;- get_trial_data(N = 2500, pop_spec = NULL, sim_spec = sim_spec)\n\n# just wrapped table generation up into a function to save space and min repitition, see util.R\ngt_tbl &lt;- tbl_ex_trial(ll$d)\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSurgical Da\nDuration Db\nType Dc\nResponse\n\n\nmember\nassigned\nplan\nmember\nassigned1\nmember\nassigned\ny\nn\nMLE (py)\nTRUE (py)2\n\n\n\n\nearly - knee\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n99\n137\n0.72\n0.63\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n73\n103\n0.71\n0.65\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n68\n81\n0.84\n0.79\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n240\n321\n0.75\n—\n\n\nearly - hip\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n147\n189\n0.78\n0.73\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n112\n144\n0.78\n0.75\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n117\n135\n0.87\n0.86\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n376\n468\n0.80\n—\n\n\nlate - knee\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n78\n154\n0.51\n0.52\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n62\n114\n0.54\n0.55\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n88\n124\n0.71\n0.71\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n19\n33\n0.58\n0.69\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n20\n26\n0.77\n0.71\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n21\n22\n0.95\n0.83\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n12\n17\n0.71\n0.81\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n19\n22\n0.86\n0.83\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n17\n19\n0.89\n0.91\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n49\n70\n0.70\n0.69\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n41\n50\n0.82\n0.71\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n39\n46\n0.85\n0.83\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n45\n59\n0.76\n0.81\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n51\n59\n0.86\n0.83\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n46\n52\n0.88\n0.91\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n607\n867\n0.70\n—\n\n\nlate - hip\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n50\n80\n0.62\n0.57\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n23\n48\n0.48\n0.60\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n37\n51\n0.73\n0.75\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n5\n8\n0.62\n0.73\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n8\n12\n0.67\n0.75\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n8\n9\n0.89\n0.86\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n8\n11\n0.73\n0.84\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n5\n8\n0.62\n0.86\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n11\n12\n0.92\n0.92\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n18\n21\n0.86\n0.73\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n14\n17\n0.82\n0.75\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n18\n21\n0.86\n0.86\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n29\n33\n0.88\n0.84\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n17\n18\n0.94\n0.86\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n16\n16\n1.00\n0.92\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n267\n365\n0.73\n—\n\n\nchronic - knee\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n16\n25\n0.64\n0.57\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n9\n17\n0.53\n0.60\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n12\n15\n0.80\n0.75\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n17\n22\n0.77\n0.73\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n10\n13\n0.77\n0.75\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n16\n18\n0.89\n0.86\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n14\n23\n0.61\n0.73\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n11\n16\n0.69\n0.75\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n12\n13\n0.92\n0.86\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n21\n24\n0.88\n0.84\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n16\n19\n0.84\n0.86\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n12\n13\n0.92\n0.92\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n166\n218\n0.76\n—\n\n\nchronic - hip\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n12\n19\n0.63\n0.63\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n13\n21\n0.62\n0.65\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n12\n19\n0.63\n0.79\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n25\n30\n0.83\n0.77\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n10\n11\n0.91\n0.79\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n20\n23\n0.87\n0.88\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n21\n26\n0.81\n0.77\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n19\n24\n0.79\n0.79\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n12\n12\n1.00\n0.88\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n28\n31\n0.90\n0.87\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n24\n28\n0.86\n0.88\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n15\n17\n0.88\n0.94\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n211\n261\n0.81\n—\n\n\ntotal\n—\n—\n—\n—\n—\n—\n—\n1867\n2500\n0.75\n—\n\n\n\n1 w06p1 = 6 weeks following one-stage procedure, w12p1 = 12 weeks following one-stage procedure etc\n\n\n2 Transformed from the log-odds of response as used in the linear predictor to simulate data.\n\n\n\n\n\n\n\n\n\nTable 2: Summary of simulated trial data when no treatment effects present\n\n\n\n\n\n\nCode\nlsd &lt;- get_stan_data(ll$d_i)\nld &lt;- lsd$ld\nd_b &lt;- copy(lsd$d_b)\n\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-02.stan\")\n\nf_alleff_1 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.4 seconds.\n\n\nCode\npost_1 &lt;- data.table(f_alleff_1$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n# compare when prior sd is set to 10 for trt effects\n\npri_sd &lt;- 10\nld$pri_sig_b_c &lt;- pri_sd\nld$pri_sig_a_l &lt;- pri_sd\nld$pri_sig_b1_l &lt;- pri_sd\nld$pri_sig_b2_l &lt;- pri_sd\nld$pri_sig_a_c &lt;- pri_sd\nld$pri_sig_b1_c &lt;- pri_sd\nld$pri_sig_b2_c &lt;- pri_sd\n\nf_alleff_2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.5 seconds.\n\n\nCode\npost_2 &lt;- data.table(f_alleff_2$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n\n\n\nCode\nd_fig1 &lt;- post_alpha(post_1)\nd_fig2 &lt;- post_alpha(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = grp, y = a, group = prior_sd, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-odds treatment success\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = grp, y = a_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = a_q025, ymax = a_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = grp, y = a), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 5: Posterior median and 95% CI for baseline log-odds of treatment success (triangles show true values).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_a(post_1)\nd_fig2 &lt;- post_dom_a(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 6: Posterior median and 95% CI for baseline log-odds of treatment success domain A (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_b(post_1)\nd_fig2 &lt;- post_dom_b(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(paste0(\"Planned/assigned surgery: \", qa, \"-stage\")~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 7: Posterior median and 95% CI for baseline log-odds of treatment success domain B (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_c(post_1)\nd_fig2 &lt;- post_dom_c(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 8: Posterior median and 95% CI for baseline log-odds of treatment success in domain C (effect is pooled across all silos).",
    "crumbs": [
      "Design",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/trial-data.html",
    "href": "notebooks/trial-data.html",
    "title": "Simulated trial data",
    "section": "",
    "text": "Trial data is simulated under the model specification, see earlier section. The sub-totals sum to the size of the subset (e.g. patients under late stage infection) and not the size of the total sample. The missingness is a consequence of the partial factorial structure.\n\n\nCode\nset.seed(25)\nll &lt;- get_trial_data(N = 2500)\n\nd &lt;- copy(ll$d)\n\n\nTable 1 shows the allocation to (late stage infection) dair vs rev and the balance across the remaining group levels in the data.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[silo == \"late\", .(ea, a, eb, b)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(a, eb, b)]\nd_B &lt;- dcast(d_tmp2, eb + b ~ a, value.var = \"N\")\nd_B[, domain := \"B\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", \"dair\", \"rev\", \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[silo == \"late\", .(ea, a, ec, c)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(a, ec, c)]\nd_C &lt;- dcast(d_tmp2, ec + c ~ a, value.var = \"N\")\nd_C[, domain := \"C\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", \"dair\", \"rev\", \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C)\nd_tbl[, group := factor(group, levels = c(\"w12\",\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\", \"other\", \"norif\", \"rif\"))]\nd_tbl[domain == \"B\", domain := \"AB Duration\"]\nd_tbl[domain == \"C\", domain := \"AB Type\"]\nd_tbl &lt;- d_tbl[order(domain, rand, group)]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", \"DAIR\", \"Revision\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  )  |&gt;\n  tab_spanner(\n    label = html(\"Domain A (late silo)\"),\n    columns = c(dair, rev)\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols) |&gt; \n  summary_rows(\n    columns = c(\"dair\", \"rev\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  ) \n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nDomain A (late silo)\n\n\nDAIR\nRevision\n\n\n\n\nAB Duration\n\n\n\nN\nw12\n627\n-\n\n\n\nY\nw06p1\n-\n75\n\n\n\nY\nw12p1\n-\n97\n\n\n\nY\nd07p2\n-\n216\n\n\n\nY\nw12p2\n-\n208\n\n\nsubtotal\n—\n—\n627\n596\n\n\nAB Type\n\n\n\nN\nother\n241\n244\n\n\n\nY\nnorif\n195\n184\n\n\n\nY\nrif\n191\n168\n\n\nsubtotal\n—\n—\n627\n596\n\n\n\n\n\n\n\n\nTable 1: Simulated trial data for (late silo) surgical domain - covariate balance across other groups\n\n\n\n\nTable 2 shows the allocation to (chronic stage infection) one vs two-stage and the balance across the remaining group levels in the data.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[silo == \"chronic\", .(ea, a, eb, b)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(a, eb, b)]\nd_B &lt;- dcast(d_tmp2, eb + b ~ a, value.var = \"N\")\nd_B[, domain := \"B\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", \"one\", \"two\", \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[silo == \"chronic\", .(ea, a, ec, c)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(a, ec, c)]\nd_C &lt;- dcast(d_tmp2, ec + c ~ a, value.var = \"N\")\nd_C[, domain := \"C\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", \"one\", \"two\", \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C)\nd_tbl[, group := factor(group, levels = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\", \"other\", \"norif\", \"rif\"))]\nd_tbl &lt;- d_tbl[order(domain, rand, group)]\n\nd_tbl[domain == \"B\", domain := \"AB Duration\"]\nd_tbl[domain == \"C\", domain := \"AB Type\"]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", \"One-stage\", \"Two-stage\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  )  |&gt; \n  summary_rows(\n    columns = c(\"one\", \"two\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )   |&gt;\n  tab_spanner(\n    label = html(\"Domain A (chronic silo)\"),\n    columns = c(one, two)\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nDomain A (chronic silo)\n\n\nOne-stage\nTwo-stage\n\n\n\n\nAB Duration\n\n\n\nY\nw06p1\n132\n-\n\n\n\nY\nw12p1\n135\n-\n\n\n\nY\nd07p2\n-\n124\n\n\n\nY\nw12p2\n-\n131\n\n\nsubtotal\n—\n—\n267\n255\n\n\nAB Type\n\n\n\nN\nother\n103\n95\n\n\n\nY\nnorif\n100\n78\n\n\n\nY\nrif\n64\n82\n\n\nsubtotal\n—\n—\n267\n255\n\n\n\n\n\n\n\n\nTable 2: Simulated trial data for (chronic silo) surgical domain - covariate balance across other groups\n\n\n\n\nTable 3 shows the allocation to (late stage infection) dair vs rev and the balance across the remaining group levels in the data. The subsequent tables show analogous summaries.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[silo == \"late\", .(eb, b, ea, a, qa)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(b, ea, a, qa)]\nd_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_B &lt;- dcast(d_tmp2, ea + a + qa ~ b, value.var = \"N\")\nd_B[, domain := \"A\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", \"plan\", c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[silo == \"late\", .(eb, b, ec, c)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(b, ec, c)]\nd_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_C &lt;- dcast(d_tmp2, ec + c ~ b, value.var = \"N\")\nd_C[, domain := \"C\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"), \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C, fill = T)\nd_tbl[domain == \"A\", domain := \"AB Duration\"]\nd_tbl[domain == \"C\", domain := \"AB Type\"]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", \"Plan\",c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt; \n  summary_rows(\n    columns = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )   |&gt;\n  tab_spanner(\n    label = html(\"Domain B (late silo)\"),\n    columns = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\")\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nPlan\nDomain B (late silo)\n\n\nw12\nw06p1\nw12p1\nd07p2\nw12p2\n\n\n\n\nAB Duration\n\n\n\nY\ndair\ndair\n627\n-\n-\n-\n-\n\n\n\nY\nrev\none\n-\n75\n97\n-\n-\n\n\n\nY\nrev\ntwo\n-\n-\n-\n216\n208\n\n\nsubtotal\n—\n—\n—\n627\n75\n97\n216\n208\n\n\nAB Type\n\n\n\nN\nother\n-\n241\n35\n40\n88\n81\n\n\n\nY\nnorif\n-\n195\n24\n24\n68\n68\n\n\n\nY\nrif\n-\n191\n16\n33\n60\n59\n\n\nsubtotal\n—\n—\n—\n627\n75\n97\n216\n208\n\n\n\n\n\n\n\n\nTable 3: Simulated trial data for (late silo) duration domain - covariate balance across other groups\n\n\n\n\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[silo == \"chronic\", .(eb, b, ea, a)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(b, ea, a)]\nd_tmp2[, b := factor(b, levels = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_B &lt;- dcast(d_tmp2, ea + a ~ b, value.var = \"N\")\nd_B[, domain := \"A\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[silo == \"chronic\", .(eb, b, ec, c)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(b, ec, c)]\nd_tmp2[, b := factor(b, levels = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_C &lt;- dcast(d_tmp2, ec + c ~ b, value.var = \"N\")\nd_C[, domain := \"C\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"), \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C, fill = T)\nd_tbl[domain == \"A\", domain := \"AB Duration\"]\nd_tbl[domain == \"C\", domain := \"AB Type\"]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt;\n  summary_rows(\n    columns = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )   |&gt;\n  tab_spanner(\n    label = html(\"Domain B (chronic silo)\"),\n    columns = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\")\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nDomain B (chronic silo)\n\n\nw06p1\nw12p1\nd07p2\nw12p2\n\n\n\n\nAB Duration\n\n\n\nY\none\n132\n135\n-\n-\n\n\n\nY\ntwo\n-\n-\n124\n131\n\n\nsubtotal\n—\n—\n132\n135\n124\n131\n\n\nAB Type\n\n\n\nN\nother\n54\n49\n42\n53\n\n\n\nY\nnorif\n44\n56\n40\n38\n\n\n\nY\nrif\n34\n30\n42\n40\n\n\nsubtotal\n—\n—\n132\n135\n124\n131\n\n\n\n\n\n\n\n\nTable 4: Simulated trial data for (chronic silo) duration domain - covariate balance across other groups\n\n\n\n\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[, .(c, ea, a, qa)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(c, ea, a, qa)]\nd_tmp2[, a := factor(a, levels = c(\"dair\", \"rev\", \"one\", \"two\"))]\nd_tmp2[, qa := factor(qa, levels = c(\"dair\", \"one\", \"two\"))]\nd_tmp2[, c := factor(c, levels = c(\"other\", \"norif\", \"rif\"))]\nd_A &lt;- dcast(d_tmp2, ea + a + qa ~ c, value.var = \"N\")\nd_A[, domain := \"A\"]\ncolnames(d_A) &lt;- c(\"rand\", \"group\", \"plan\", c(\"other\", \"norif\", \"rif\"), \"domain\")\nsetcolorder(d_A, \"domain\")\n# domain B\nd_tmp1 &lt;- d[, .(c, eb, b)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(c, eb, b)]\nd_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_tmp2[, c := factor(c, levels = c(\"other\", \"norif\", \"rif\"))]\nd_B &lt;- dcast(d_tmp2, eb + b ~ c, value.var = \"N\")\nd_B[, domain := \"B\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", c(\"other\", \"norif\", \"rif\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n\nd_tbl &lt;- rbind(d_A, d_B, fill = T)\nd_tbl[domain == \"A\", domain := \"Surgical\"]\nd_tbl[domain == \"B\", domain := \"AB Duration\"]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", \"Plan\", c(\"other\", \"norif\", \"rif\"))\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt; \n  summary_rows(\n    columns = c(\"other\", \"norif\", \"rif\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Domain C\"),\n    columns = c(\"other\", \"norif\", \"rif\")\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nPlan\nDomain C\n\n\nother\nnorif\nrif\n\n\n\n\nSurgical\n\n\n\nN\ndair\ndair\n295\n237\n223\n\n\n\nY\ndair\ndair\n241\n195\n191\n\n\n\nY\nrev\none\n75\n48\n49\n\n\n\nY\nrev\ntwo\n169\n136\n119\n\n\n\nY\none\none\n103\n100\n64\n\n\n\nY\ntwo\ntwo\n95\n78\n82\n\n\nsubtotal\n—\n—\n—\n978\n794\n728\n\n\nAB Duration\n\n\n\nN\nw12\n-\n536\n432\n414\n\n\n\nY\nw06p1\n-\n89\n68\n50\n\n\n\nY\nw12p1\n-\n89\n80\n63\n\n\n\nY\nd07p2\n-\n130\n108\n102\n\n\n\nY\nw12p2\n-\n134\n106\n99\n\n\nsubtotal\n—\n—\n—\n978\n794\n728\n\n\n\n\n\n\n\n\nTable 5: Simulated trial data for surgical domain - covariate balance across other groups",
    "crumbs": [
      "Design",
      "Simulated trial data"
    ]
  },
  {
    "objectID": "notebooks/estimands.html",
    "href": "notebooks/estimands.html",
    "title": "Estimands in complex designs",
    "section": "",
    "text": "Are designed to permit the evaluation of multiple interventions in a perpetual manner under a single protocol establishing a common infrastructure and analysis plan. Interventions can be added and withdrawn at different times based on need and the control group may be revised as the trial progresses. Platform trials can include adaptive elements (commonly stopping rules and adaptive randomisations) that allow design variations based on accruing evidence."
  },
  {
    "objectID": "notebooks/estimands.html#platform-trials",
    "href": "notebooks/estimands.html#platform-trials",
    "title": "Estimands in complex designs",
    "section": "",
    "text": "Are designed to permit the evaluation of multiple interventions in a perpetual manner under a single protocol establishing a common infrastructure and analysis plan. Interventions can be added and withdrawn at different times based on need and the control group may be revised as the trial progresses. Platform trials can include adaptive elements (commonly stopping rules and adaptive randomisations) that allow design variations based on accruing evidence."
  },
  {
    "objectID": "notebooks/estimands.html#estimands",
    "href": "notebooks/estimands.html#estimands",
    "title": "Estimands in complex designs",
    "section": "Estimands",
    "text": "Estimands\nCausal estimands are population quantities describing causal effects of treatments. The estimand framework facilitates a precise description of the treatment effect of interest in clinical trials. The estimand is the thing targeted for estimation which will address a question of interest intrinsic to the trial. In other words, setting objectives leads to estimands which, once clear, can lead to identifying a suitable method for estimation.\n\n\n\n\n\n\nNote\n\n\n\nIf you do not have a clear definition of an estimand, how do you derive an appropriate estimator?\n\n\nEstimands comprise:\n\na population of interest\na treatment strategy\na variable to be measured for each patient\nstrategies for handing intercurrent events (IE)\na population summary measure\n\nPer FDA, endpoint measures are developed to assess clinical outcomes, but things do seem to get mixed up.\nNevertheless - the endpoint is an outcome obtained for each patient that will be statistically analyzed to address the scientific question; this may include data from multiple variables.\nWhile the usual suspects for defining analysis populations (specifically for dealing with IE) were intention-to-treat ITT and per-protocol, the ICH expanded this set of strategies. Loosely, ITT analyses all patients as randomised, irrespective of what actually happened (e.g. deviations). PP analyses, only those who follow the protocol are used, the otherse are excluded. PP is commonly cited as being subject to bias, ITT less so. ICH defines:\n\nICH treatment strategies\n\n\n\n\n\n\nCommand\nDescription of common use\n\n\n\n\ntreatment policy\nMost common, similar to ITT; data collected is used regardless of whether IE occur. In other words, the IE is not a considered a departure from the treatment regimen of interest. TP preserves the randomisation, hence its attraction. Death can lead to TP being undefineable unless death is the (or a component of the) primary.\n\n\ncomposite policy\nIncorporates the IE as a component of the variable, e.g. alive at 29 days without use of rescue medication.\n\n\nhypothetical\nComplicated - envisages a scenario where the IE does not occur. The observed outcomes of patients without IE correspond to the outcome of interest, but the outcome of patients with IE is considered missing and needs to be imputed.\n\n\nwhile on treatment\nApplicable where there are repeat measures. The data is used up to the point where treatement was ended.\n\n\nprincipal stratum\nInvolves defining sub-populations according to the specific IEs on one or all treatments.\n\n\n\nas analyses strategies with some loose and brief descriptions provided above.\nIntercurrent events are just post-randomisation events that impact our measurements or interpretation of measurements in some way (e.g. intercurrent events arise through discontinuation of medication).\nFor the population-level summary, it is ususally relevant to provide within and between-arm measures, e.g. within-arm being overall survival at 28 days vs between-arm hazard ratio etc.\nPlatform trials introduce complexity into the specification of estimands and is not well considered in the literature. For example, what are the implications of addring treatment arms or modifying the control or implementing further data-driven adaptive features?"
  }
]