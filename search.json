[
  {
    "objectID": "notebooks/simulation-pars.html#baseline-response",
    "href": "notebooks/simulation-pars.html#baseline-response",
    "title": "Simulation setup",
    "section": "Baseline response",
    "text": "Baseline response\nThe baseline probability/log-odds of treatment success is assumed to vary by silo and site of infection as detailed below.\n\n\nBaseline probability of treatment success by silo and site of infection\n\n\nSilo\nJoint\nPr(trt success)\nlog-odds\n\n\n\n\nearly\nknee\n0.65\n0.62\n\n\nearly\nhip\n0.75\n1.10\n\n\nlate\nknee\n0.55\n0.20\n\n\nlate\nhip\n0.6\n0.41\n\n\nchronic\nknee\n0.6\n0.41\n\n\nchronic\nhip\n0.65\n0.62",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#accrual",
    "href": "notebooks/simulation-pars.html#accrual",
    "title": "Simulation setup",
    "section": "Accrual",
    "text": "Accrual\nAccrual is assumed to follow a non-homogeneous Poisson process event times with ramp up over the first 12 months of enrolment and then enrolment of around 1.5 per day.\n\n\nCode\n# events per day\nlambda = 1.52\n# ramp up over 12 months \nrho = function(t) pmin(t/360, 1)\n\nd_fig &lt;- data.table(\n  t = 0:(5 * 365),\n  # expected number enrolled\n  n = c(0, nhpp.mean(lambda, rho, t1 = 5 * 365, num.points = 5 * 365))\n)\n\nggplot(d_fig, aes(x = t/365, y = n)) +\n  geom_line() +\n  scale_x_continuous(\"Year\") +\n  scale_y_continuous(\"E[Accrual]\", breaks = seq(0, 2500, by = 500))\n\n\n\n\n\n\n\n\nFigure 1: Expected accrual",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#domain-non-membership-effects",
    "href": "notebooks/simulation-pars.html#domain-non-membership-effects",
    "title": "Simulation setup",
    "section": "Domain non-membership effects",
    "text": "Domain non-membership effects\nWe assume a small effects for not being randomised to a domain for all domains.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#missingness",
    "href": "notebooks/simulation-pars.html#missingness",
    "title": "Simulation setup",
    "section": "Missingness",
    "text": "Missingness\nMissingness is not implemented.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#non-differential-follow-up",
    "href": "notebooks/simulation-pars.html#non-differential-follow-up",
    "title": "Simulation setup",
    "section": "Non-differential follow-up",
    "text": "Non-differential follow-up\nTo avoid artifacts associated with non-differential follow-up (e.g. early vs late deaths), participants will be included in the analyses only when they reach the primary endpoints (12 months) irrespective of whether they experienced treatment failure before that time.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#simulation-scenarios",
    "href": "notebooks/simulation-pars.html#simulation-scenarios",
    "title": "Simulation setup",
    "section": "Simulation scenarios",
    "text": "Simulation scenarios\nWe consider a range of simulation settings:\n\nNull scenario - no effect of any randomised treatment in any cell (OR = 1) for all domains and silos\nAll effective - all randomised treatments in all cells effective (OR = 1.5) for all domains and silos\nSingle effective - single cell effective (OR = 1.5) for single domain and silo\nSingle harmful - single cell harmful (OR = 1/1.5) for single domain and silo",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#statistical-quantities",
    "href": "notebooks/simulation-pars.html#statistical-quantities",
    "title": "Simulation setup",
    "section": "Statistical quantities",
    "text": "Statistical quantities\nWe consider treatment superiority, inferiority and futility.\nAs a set, whatever quantities are used, need to be mutually exclusive. For example, with the current set of quantities, if a parameter is superior, then it cannot be either inferior and futile.\n\nSuperiority\n\\[\\begin{aligned}\n\\phi_{sup} = Pr(OR &gt; 1)\n\\end{aligned}\\]\nand conclude superiority if \\(\\phi_{sup} &gt; \\delta_{sup}\\).\n\n\nInferiority\n\\[\\begin{aligned}\n\\phi_{inf} = 1 - \\phi_{sup}\n\\end{aligned}\\]\nand conclude inferiority if \\(\\phi_{inf} &gt; \\delta_{inf}\\).\n\n\nFutility\nIs simply defined in relation to superiority with futility concluded if \\(\\phi_{sup} &lt; \\delta_{fut}\\).",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/simulation-pars.html#decision-thresholds",
    "href": "notebooks/simulation-pars.html#decision-thresholds",
    "title": "Simulation setup",
    "section": "Decision thresholds",
    "text": "Decision thresholds\nDecision thresholds are documented with the simulation results.",
    "crumbs": [
      "Design",
      "Simulation setup"
    ]
  },
  {
    "objectID": "notebooks/adaptations.html#interim-analyses",
    "href": "notebooks/adaptations.html#interim-analyses",
    "title": "Adaptations",
    "section": "Interim analyses",
    "text": "Interim analyses\nInterim analyses start at"
  },
  {
    "objectID": "notebooks/about.html#repository-status",
    "href": "notebooks/about.html#repository-status",
    "title": "About",
    "section": "Repository status",
    "text": "Repository status\nDetails on GitHub repository files, tags, commits follow:\n\n\nCode\nrepo &lt;- git2r::repository(path = \".\")\nsummary(repo)\n\n\nLocal:    main /Users/mark/Documents/project/roadmap/src/roadmap-sim\nRemote:   main @ origin (https://github.com/maj-biostat/roadmap-sim.git)\nHead:     [b3e3b27] 2024-02-02: add design notes\n\nBranches:         2\nTags:             0\nCommits:         60\nContributors:     2\nStashes:          0\nIgnored files:   53\nUntracked files: 18\nUnstaged files:   0\nStaged files:     0\n\nLatest commits:\n[b3e3b27] 2024-02-02: add design notes\n[51adf51] 2024-02-02: Merge remote-tracking branch 'refs/remotes/origin/main'\n[56c5ee1] 2024-02-02: temp addition:\n[4f0bada] 2024-02-02: temp addition\n[9b27c8e] 2024-02-02: Fix figure",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html",
    "href": "notebooks/design-notes.html",
    "title": "Design Notes",
    "section": "",
    "text": "Say we were doing a trial in just the late acute patients. We are interested in surgery (DAIR/revision) and antibiotic duration (long/short), but we are limited in that, for whatever reason, we can not ethically randomise the type of revision surgery, only revision surgery itself. However, choice of antibiotic duration is conditional on the type of revision surgery used, so surgery type needs to be considered in any joint analysis (alternatively, analyse separately).\nI just want to work through from a basic scenario to more involved ones to check understanding of potential issues. This will ignore much of the complexity, but just want to get some basics down as a reference.",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#surgery",
    "href": "notebooks/design-notes.html#surgery",
    "title": "Design Notes",
    "section": "Surgery",
    "text": "Surgery\nAs a starting point, consider the following:\n\nR: randomised surgery - 0: DAIR, 1: revision\nS: preferred revision - 0: one-stage, 1: two-stage\nA: allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\nY: treatment success - 0: no, 1: yes\n\nPatients are randomised to a surgery type, \\(R\\): DAIR or revision. For every patient, if they were to have been allocated to revision, there is some preference/plan for one/two stage, \\(S\\). The value of \\(S\\) is determined by the surgeon/patient and I’m considering it here as just an attribute of the patient. The actual allocated treatment is a deterministic function of \\(R\\) and \\(S\\), i.e. \\(A = R \\times (S + 1)\\). Note that I’m assuming that \\(S\\) is known for every patient before \\(R\\) is revealed to the surgeon, irrespective of whether they are eventually assigned to DAIR or revision (if that it isn’t the case then perhaps some issues might arise, but I don’t think that it matters too much for what’s being considered here given randomisation).\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A & Y\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 1: Scenario 1, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\nOur intervention is on \\(R\\), everything down stream from that (revision type, antibiotic use, physiotherapy, complications) is a consequence of the intervention. It’s the overall effect of allocation to \\(R=0\\) or \\(R=1\\) that we are trying to (the only thing we can, not necessarily want to) compare.\nIf \\(Y(a)\\) is the potential outcome of a patient if they were assigned to receive surgery \\(a\\), then\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y(a)] &= \\mathbb{E}[Y(a) | A = 0] \\\\\n&= \\mathbb{E}[Y(a)|R=0] \\\\\n&= \\mathbb{E}[Y(a)|R=1] \\\\\n&= \\mathbb{E}[Y(a) | A \\in \\{1,2\\}] \\\\\n&\\ne \\mathbb{E}[Y(a) | A = j], \\quad j\\in\\{1,2\\} \\\\\n\\end{aligned}\n\\]\nThe only randomised comparison we can make is \\(R=1\\) vs \\(R=0\\), but, given we want to eventually condition on which revision type is selected, we want to include terms for preferred revision type in the model. Say we think logistic regression is the true model. We could specify\n\\[\n\\begin{align}\n\\mathbb{E}[Y | R] &= \\text{expit}(\\alpha_0 + \\alpha_1R) \\\\\n\\mathbb{E}[Y | A] &= \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(A=1) + \\beta_2\\mathbb{I}(A=2)) \\\\\n\\end{align}\n\\]\nI’ve written the above in terms of \\(A\\), but could equivalently state in terms of \\(R\\) and \\(S\\).\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS) \\\\\n\\]\nThe first targets the thing we actually want to compare, the log-odds ratio of revision versus DAIR. The second splits this out into one and two stage which we would need to combine to get the overall revision effect.\nThese models could also adjust for \\(S\\), i.e. in addition to any actual effect of one/two stage revision, the patients for whom a two-stage would be preferred may differ from those for who a one-stage is the preference. Interpretation of model parameters then changes of course.\n\\[\n\\mathbb{E}[Y | R, S] = \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3S) \\\\\n\\]\nWe don’t really care about the difference due to \\(S\\), as the revision type effects may still be confounded by other factors anyway. Due to the randomisation, I think that both the version with and without \\(S\\) are targeting the same estimand for revision vs. DAIR (the distribution of \\(S\\) is the same (in expectation) amongst DAIR and revision patients, so is not be a confounder, but obviously, \\(S\\) is known exactly to be \\(A-1\\) when \\(R=1\\)).\nFor the second model above without \\(S\\)\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | R] &= \\mathbb{E}[\\mathbb{E}[Y | A, R] | R] \\\\\n&= \\sum_{a=0}^2 \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(a=1) + \\beta_2\\mathbb{I}(a=2))\\mathbb{P}(A = a | R) \\\\\n\\mathbb{E}[Y|R =0] &= \\text{expit}(\\beta_0) \\\\\n\\mathbb{E}[Y|R = 1] &=  \\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(A=1|R=1) \\\\\n& \\quad \\ + \\text{expit}(\\beta_0 + \\beta_2)\\mathbb{P}(A=2|R=1)\n\\end{aligned}\n\\]\nso the log-odds ratio for revision vs. DAIR is\n\\[\n\\text{logit}\\left[\\text{expit}(\\beta_0 + \\beta_1)\\mathbb{P}(A=1|R=1) + \\text{expit}(\\beta_0 + \\beta_2)\\mathbb{P}(A=2|R=1)\\right] - \\beta_0.\n\\]\nWe don’t know \\(\\mathbb{P}(A=a|R=1)\\) so estimate it from the sample.\nIf the model also conditions on \\(S\\), then, given that \\(\\mathbb{P}(A=0|R=0,S)=1\\) and \\(\\mathbb{P}(A = S + 1 | R = 1, S) = 1\\).\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y | R, S] &= \\mathbb{E}[\\mathbb{E}[Y | A, S, R] | R, S] \\\\\n&= \\sum_{a=0}^2 \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(a=1) + \\beta_2\\mathbb{I}(a=2) + \\beta_3S)\\mathbb{P}(A = a | R, S) \\\\\n\\mathbb{E}[Y|R = 0, S = 0] &= \\text{expit}(\\beta_0) \\\\\n\\mathbb{E}[Y|R = 0, S = 1] &= \\text{expit}(\\beta_0 + \\beta_3) \\\\\n\\mathbb{E}[Y|R = 1, S = 0] &= \\text{expit}(\\beta_0 + \\beta_1) \\\\\n\\mathbb{E}[Y|R = 1, S = 1] &= \\text{expit}(\\beta_0 + \\beta_2 + \\beta_3) \\\\\n\\mathbb{E}[Y|R] &= \\mathbb{E}[Y|R, S = 0]\\mathbb{P}[S=0|R] + \\mathbb{E}[Y|R, S = 1]\\mathbb{P}[S=1|R] \\\\\n&=   \\mathbb{E}[Y|R, S = 0]\\mathbb{P}[S=0] + \\mathbb{E}[Y|R, S = 1]\\mathbb{P}[S=1]\n\\end{aligned}\n\\]\nso the conditional and marginal log-odds ratio for revision vs. DAIR\n\\[\n\\begin{aligned}\n\\ln\\left(\\text{OR}[S=0]\\right) &= \\beta_1 \\\\\n\\ln\\left(\\text{OR}[S=1]\\right) &= \\beta_3 \\\\\n\\ln\\left(\\text{OR}\\right) &= \\text{logit}(\\mathbb{E}[Y|R=1]) - \\text{logit}(\\mathbb{E}[Y|R=0]).\n\\end{aligned}\n\\]\nCannot separate the effect of \\(A\\) from effect of \\(S\\).\n\nExample\nHerein I am just assuming \\(n\\approx \\infty\\), i.e. checking consistency.\n\n\nSetup\nlibrary(data.table)\n\nodds &lt;- function(p) p / (1 - p)\nexpit &lt;- function(x) plogis(x)\n\n\n\n\nGenerate data scenario 1\n# Assume ~ infinite population as just checking consistency\n# Precision will of course vary by approach at small sample sizes\ngenerate_data_1 &lt;- function(\n    n = 1000000,\n    f = \\(s, a, x) -1 + s + 0.25 * I(a == 1) + 0.75 * I(a == 2)) {\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  x &lt;- rbinom(n, 1, 0.25)\n  a &lt;- r * (s + 1)\n  y0 &lt;- rbinom(n, 1, plogis(f(s, 0, x)))\n  y1 &lt;- rbinom(n, 1, plogis(f(s, s + 1, x)))\n  y &lt;- (1 - r) * y0 + r * y1\n  w &lt;- mean(s) # Selection probability\n  D &lt;- data.table(r = r, x = x, s = s, a = a, y0 = y0, y1 = y1, y = y)[\n    ,\n    `:=`(\n      r_fac = factor(r),\n      a_fac = factor(a),\n      s_fac = factor(s),\n      a_cen = r * (a - 1 - mean(a[r == 1] - 1)),\n      s_cen = s - mean(s)\n    )\n  ]\n}\nset.seed(123)\nD &lt;- generate_data_1()\nfit1 &lt;- glm(y ~ r_fac, data = D, family = binomial())\nfit2 &lt;- glm(y ~ a_fac, data = D, family = binomial())\nfit1s &lt;- glm(y ~ r_fac + s_fac, data = D, family = binomial())\nfit2s &lt;- glm(y ~ a_fac + s_fac, data = D, family = binomial())\n\n\n\n\nEffect quantities\nw &lt;- mean(D$a == 2) / mean(D$a %in% c(1, 2))\nw_s1 &lt;- mean(D[r == 0]$s == 1)\nw_s2 &lt;- mean(D[r == 1]$s == 1)\n\nb1 &lt;- unname(coef(fit1))\nb2 &lt;- unname(coef(fit2))\nb1s &lt;- unname(coef(fit1s))\nb2s &lt;- unname(coef(fit2s))\n\nEY_R0_2 &lt;- expit(b2[1])\nEY_R1_2 &lt;- (1 - w) * expit(b2[1] + b2[2]) + w * expit(b2[1] + b2[3])\n\nEY_R0_1_S0 &lt;- expit(b1s[1])\nEY_R0_1_S1 &lt;- expit(b1s[1] + b1s[3])\nEY_R1_1_S0 &lt;- expit(b1s[1] + b1s[2])\nEY_R1_1_S1 &lt;- expit(b1s[1] + b1s[2] + b1s[3])\nEY_R0_1 &lt;- (1 - w_s1) * EY_R0_1_S0 + w_s1 * EY_R0_1_S1\nEY_R1_1 &lt;- (1 - w_s2) * EY_R1_1_S0 + w_s2 * EY_R1_1_S1\n\nEY_R0_2_S0 &lt;- expit(b2s[1])\nEY_R0_2_S1 &lt;- expit(b2s[1] + b2s[4])\nEY_R1_2_S0 &lt;- expit(b2s[1] + b2s[2]) # Pr(A = 2 | S = 0) = 0\nEY_R1_2_S1 &lt;- expit(b2s[1] + b2s[3] + b2s[4]) # Pr(A = 2 | S = 1) = 1\nEY_R0_2 &lt;- (1 - w_s1) * EY_R0_2_S0 + w_s1 * EY_R0_2_S1\nEY_R1_2 &lt;- (1 - w_s2) * EY_R1_2_S0 + w_s2 * EY_R1_2_S1\n\nEY_R1_2_S0w &lt;- expit(b2s[1] + (1 - w) * b2s[2] + w * b2s[3])\nEY_R1_2_S1w &lt;- expit(b2s[1] + (1 - w) * b2s[2] + w * b2s[3] + b2s[4])\nEY_R1_2w &lt;- (1 - w_s2) * EY_R1_2_S0w + w_s2 * EY_R1_2_S1w\n\nrbind(\n  \"True conditional (S = 0) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y)),\n  \"True conditional (S = 1) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y)),\n  \"True marginal log-odds ratio\" = qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  \"True weighted log-odds ratio\" =\n    (1 - w) * qlogis(mean(D[a == 1]$y)) + w * qlogis(mean(D[a == 2]$y)) -\n      qlogis(mean(D[r == 0]$y)),\n  \"True weighted conditional log-odds ratio\" =\n    (1 - w) * (qlogis(mean(D[r == 1 & s == 0]$y)) - qlogis(mean(D[r == 0 & s == 0]$y))) +\n      w * (qlogis(mean(D[r == 1 & s == 1]$y)) - qlogis(mean(D[r == 0 & s == 1]$y))),\n  \"fit1 marginal log-odds ratio\" = b1[2],\n  \"fit2 marginal log-odds ratio\" = qlogis(EY_R1_2) - qlogis(EY_R0_2),\n  \"fit2 conditional (weighted) log-odds ratio\" = (1 - w) * b2[2] + w * b2[3],\n  \"fit1s conditional log-odds ratio\" = b1s[2], # Don't know what this targets\n  \"fit1s marginal log-odds ratio\" = qlogis(EY_R1_1) - qlogis(EY_R0_1),\n  \"fit2s conditional (S = 0) log-odds ratio\" = qlogis(EY_R1_2_S0) - qlogis(EY_R0_2_S0),\n  \"fit2s conditional (S = 1) log-odds ratio\" = qlogis(EY_R1_2_S1) - qlogis(EY_R0_2_S1),\n  \"fit2s marginal log-odds ratio\" = qlogis(EY_R1_2) - qlogis(EY_R0_2),\n  \"fit2s conditional (weighted) log-odds ratio\" = (1 - w) * b2s[2] + w * b2s[3]\n)\n\n\n                                                 [,1]\nTrue conditional (S = 0) log-odds ratio     0.2462550\nTrue conditional (S = 1) log-odds ratio     0.7430147\nTrue marginal log-odds ratio                0.5639970\nTrue weighted log-odds ratio                0.5746517\nTrue weighted conditional log-odds ratio    0.5944772\nfit1 marginal log-odds ratio                0.5639970\nfit2 marginal log-odds ratio                0.5639970\nfit2 conditional (weighted) log-odds ratio  0.5746517\nfit1s conditional log-odds ratio            0.6084318\nfit1s marginal log-odds ratio               0.5639970\nfit2s conditional (S = 0) log-odds ratio    0.2462550\nfit2s conditional (S = 1) log-odds ratio    0.7430147\nfit2s marginal log-odds ratio               0.5639970\nfit2s conditional (weighted) log-odds ratio 0.5944772\n\n\nSo in the basic case, as \\(n\\to\\infty\\), these models are all in a sense equivalent, in that they are consistent for the treatment efffects of interest.",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#covariate",
    "href": "notebooks/design-notes.html#covariate",
    "title": "Design Notes",
    "section": "Covariate",
    "text": "Covariate\nSuppose we introduce a covariate \\(X\\) because it’s predictive of the outcome, e.g. sex. Our model is\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|A,X] &= \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(A=1) + \\beta_2\\mathbb{I}(A=2) + \\beta_3X) \\\\\n\\mathbb{E}[Y|R,X] &= \\mathbb{E}[\\mathbb{E}[Y|A,X]|R,X] \\\\\n&= \\sum_{a=0}^2 \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(A=1) + \\beta_2\\mathbb{I}(A=2) + \\beta_3X)\\mathbb{P}(A=a|R,X) \\\\\n\\mathbb{E}[Y|R=0,X] &= \\text{expit}(\\beta_0 + \\beta_3X) \\\\\n\\mathbb{E}[Y|R=1,X] &= \\text{expit}(\\beta_0 + \\beta_1 + \\beta_3X)\\mathbb{P}(A=1|R=1,X)  \\\\\n&\\quad \\ + \\text{expit}(\\beta_0 + \\beta_2 + \\beta_3X)\\mathbb{P}(A=2|R=1,X)\n\\end{aligned}\n\\]\nThe conditional (on \\(X\\)) log-odds ratio of revision versus DAIR depends on the value of \\(X\\) (i.e. is not the same effect for every \\(X=x\\)) and cannot be simplified. It is\n\\[\n\\text{logit}(\\mathbb{E}[Y|R=1,X]) - (\\beta_0 + \\beta_3X).\n\\]\nBy marginalising over type of revision surgery (which is necessary), we lose our one number summary. No way to avoid that other than perhaps considering fitting separate models for surgery and duration.\nIf \\(S\\) has an effect, say in truth,\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|S,A,X] &= \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(A=1) + \\beta_2\\mathbb{I}(A=2) + \\beta_3X + \\beta_4S) \\\\\n\\mathbb{E}[Y|A,X] &= \\mathbb{E}[\\mathbb{E}[Y|S,A,X]|A,X] \\\\\n&= \\sum_{s=0}^1 \\mathbb{E}[Y|S=s,A,X]\\mathbb{P}(S=s|A,X)\n\\end{aligned}\n\\]\nthen our model without \\(S\\) assumes\n\\[\n\\begin{aligned}\n\\mathbb{E}[Y|A,X] &= \\text{expit}(\\alpha_0 + \\alpha_1\\mathbb{I}(A=1) + \\alpha_2\\mathbb{I}(A=2) + \\alpha_3X) \\\\\n&= \\sum_{s=0}^1 \\text{expit}(\\beta_0 + \\beta_1\\mathbb{I}(A=1) + \\beta_2\\mathbb{I}(A=2) + \\beta_3X + \\beta_4s)\\mathbb{P}(S=s|A,X)\n\\end{aligned}\n\\]\n\nExample\nForget \\(S\\) for the moment.\n\n\nGenerate data with covariate\nset.seed(8712)\nD &lt;- generate_data_1(\n  f = \\(s, a, x) -1 + s + x + 0.25 * I(a == 1) + 0.75 * I(a == 2)\n)\nfit1 &lt;- glm(y ~ r_fac + x, data = D, family = binomial())\nfit2 &lt;- glm(y ~ a_fac + x, data = D, family = binomial())\nfit1s &lt;- glm(y ~ r_fac + s_fac + x, data = D, family = binomial())\nfit2s &lt;- glm(y ~ a_fac + s_fac + x, data = D, family = binomial())\n\n\n\n\nEffect quantities\nw &lt;- mean(D$a == 2) / mean(D$r == 1)\nw_s &lt;- mean(D$s == 1)\nw_x0 &lt;- mean(D$x == 0)\nw_x1 &lt;- mean(D$x == 1)\nw_a1_x0 &lt;- mean(D[x == 0]$a == 1) / mean(D[x == 0]$r == 1)\nw_a1_x1 &lt;- mean(D[x == 1]$a == 1) / mean(D[x == 1]$r == 1)\nw_a2_x0 &lt;- mean(D[x == 0]$a == 2) / mean(D[x == 0]$r == 1)\nw_a2_x1 &lt;- mean(D[x == 1]$a == 2) / mean(D[x == 1]$r == 1)\n\nb1 &lt;- unname(coef(fit1))\nb2 &lt;- unname(coef(fit2))\nb1s &lt;- unname(coef(fit1s))\n\nEY_R0_1_X0 &lt;- expit(b1[1])\nEY_R0_1_X1 &lt;- expit(b1[1] + b1[3])\nEY_R1_1_X0 &lt;- expit(b1[1] + b1[2])\nEY_R1_1_X1 &lt;- expit(b1[1] + b1[2] + b1[3])\nEY_R0_1 &lt;- w_x0 * EY_R0_1_X0 + w_x1 * EY_R0_1_X1\nEY_R1_1 &lt;- w_x0 * EY_R1_1_X0 + w_x1 * EY_R1_1_X1\n\nEY_R0_2_X0 &lt;- expit(b2[1])\nEY_R0_2_X1 &lt;- expit(b2[1] + b2[4])\nEY_R1_2_X0 &lt;- w_a1_x0 * expit(b2[1] + b2[2]) + w_a2_x0 * expit(b2[1] + b2[3])\nEY_R1_2_X1 &lt;- w_a1_x1 * expit(b2[1] + b2[2] + b2[4]) + w_a2_x1 * expit(b2[1] + b2[3] + b2[4])\nEY_R0_2 &lt;- w_x0 * EY_R0_2_X0 + w_x1 * EY_R0_2_X1\nEY_R1_2 &lt;- w_x0 * EY_R1_2_X0 + w_x1 * EY_R1_2_X1\n\nrbind(\n  \"True conditional (X = 0) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & x == 0]$y)) - qlogis(mean(D[r == 0 & x == 0]$y)),\n  \"True conditional (X = 1) log-odds ratio\" =\n    qlogis(mean(D[r == 1 & x == 1]$y)) - qlogis(mean(D[r == 0 & x == 1]$y)),\n  \"True marginal log-odds ratio\" = qlogis(mean(D[r == 1]$y)) - qlogis(mean(D[r == 0]$y)),\n  \"fit1 conditional log-odds ratio\" = b1[2],\n  \"fit1 marginal log-odds ratio\" = qlogis(EY_R1_1) - qlogis(EY_R0_1),\n  \"fit2 conditional (X = 0) log-odds ratio\" = qlogis(EY_R1_2_X0) - qlogis(EY_R0_2_X0),\n  \"fit2 conditional (X = 1) log-odds ratio\" = qlogis(EY_R1_2_X1) - qlogis(EY_R0_2_X1),\n  \"fit2 marginal log-odds ratio\" = qlogis(EY_R1_2) - qlogis(EY_R0_2),\n  \"fit2 conditional (weighted) log-odds ratio\" = (1 - w) * b2[2] + w * b2[3],\n  \"fit1s conditional log-odds ratio\" = b1s[2]\n)\n\n\n                                                [,1]\nTrue conditional (X = 0) log-odds ratio    0.5689107\nTrue conditional (X = 1) log-odds ratio    0.4895233\nTrue marginal log-odds ratio               0.5326047\nfit1 conditional log-odds ratio            0.5519726\nfit1 marginal log-odds ratio               0.5326778\nfit2 conditional (X = 0) log-odds ratio    0.5737525\nfit2 conditional (X = 1) log-odds ratio    0.4717552\nfit2 marginal log-odds ratio               0.5326777\nfit2 conditional (weighted) log-odds ratio 0.5860597\nfit1s conditional log-odds ratio           0.5979353",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#unmeasured-confounder",
    "href": "notebooks/design-notes.html#unmeasured-confounder",
    "title": "Design Notes",
    "section": "Unmeasured Confounder",
    "text": "Unmeasured Confounder\nThe above hides some complexity because we assume everything is correctly specified. Suppose we introduce some unmeasured factor which influences which patients are preferred for a given revision type. Consider the following:\n\nR: randomised surgery - 0: DAIR, 1: revision\nS: preferred revision - 0: one-stage, 1: two-stage\nA: allocated surgery - 0: DAIR, 1: one-stage, 2: two-stage\nY: treatment success - 0: no, 1: yes\nZ: unmeasured factor, patient attributes/type - continuous\n\nWe assume \\(Z\\) is some immeasurable combination of factors which partly determines a patients risk of failure. We also think that this \\(Z\\) partly determines the surgeons choice of one/two stage. Say patients with higher values of \\(Z\\) are less likely to have successful treatment. However, the surgeon has some knowledge/experience/expertise/intuition which means that they are more likely to prefer a two-stage revision for patients with higher values of \\(Z\\), as they expect those types of patients will have better outcomes under two-stage. The allocated treatment and the underlying patient risk determines the patients outcome, \\(Y\\).\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A\n  Z(Z) --&gt; S & A & Y\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 2: Scenario 2, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\nGiven the randomisation, this does not really change anything, except making explicit that differences between one/two stage may just be due to confounding rather than effect of treatment. We can’t tell which without adjusting for all confounders.",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/design-notes.html#duration",
    "href": "notebooks/design-notes.html#duration",
    "title": "Design Notes",
    "section": "Duration",
    "text": "Duration\nDuration, \\(D\\), is randomised, however, the duration options depends upon the chosen revision type, \\(S\\). So it is random conditional on \\(S\\). Nothing else alters the distribution of \\(D\\). We expect that duration has an effect on the outcome. Below we just use \\(D=0\\) for long and \\(D=1\\) for short, but note that the meaning of these is conditional on \\(S\\)/\\(A\\) (i.e. short for one-stage different to short for two-stage)\n\n\n\n\n\n\n%%{\n  init:{\n    \"flowchart\":{\"htmlLabels\": \"true\"},\n    \"securityLevel\": \"loose\",\n    \"theme\": \"base\"\n}}%%\nflowchart LR\n  R --&gt; A --&gt; Y\n  S --&gt; A & D\n  D --&gt; Y\n  UD((U&lt;sub&gt;D)) -.-&gt; D\n  US((U&lt;sub&gt;S)) -.-&gt; S\n  UR((U&lt;sub&gt;R)) -.-&gt; R\n  UY((U&lt;sub&gt;Y)) -.-&gt; Y\n\n\n\n\nFigure 3: Scenario 3, the \\(U\\) denote independent exogenous variables,\n\n\n\n\n\nNow have two interventions: \\(R\\) which has downstream unknown effects due to revision type assigned, and \\(D\\) which is randomised, but it’s effect is a consequence of revision type.\nThe simplest approach is to analyse these separately. I.e. restrict the analysis to only those patients who were assigned to one-stage, then have an RCT for duration in that subset. Similarly, restrict analysis to only those assigned to two-stage, then have an RCT for duration in that subset. However, we would like to have a joint model so that other effects can be shared (site/surgeon/age/whatever else). In the joint model, duration effect needs to be conditional on revision type.\nSay the true model were something like\n\\[\n\\mathbb{E}[Y|R,S,D] = \\text{expit}(\\beta_0 + \\beta_1R + \\beta_2RS + \\beta_3RD + \\beta_4RDS)\n\\]\nso \\(\\beta_1\\) is the shift associated with one-stage long duration, \\(\\beta_2\\) the shift associated with two-stage long duration, \\(\\beta_3\\) the relative shift for short duration given one-stage, and \\(\\beta_4\\) the relative shift for short duration given two-stage.\nIn this case we could compare (randomised comparison) either: revision long vs. DAIR or revision short vs. DAIR, but no other combinations.\n\n\nGenerate duration data\ngenerate_data_2 &lt;- function(\n    n = 1000000,\n    f = \\(s, a, d) -1 + s + (a == 1) + 0.5 * (a == 2) - 0.5 * (a == 1) * (d == 1) - 0.25 * (a == 2) * (d == 1)) {\n  s &lt;- rbinom(n, 1, 0.7)\n  r &lt;- rbinom(n, 1, 0.5)\n  a &lt;- r * (s + 1)\n  d &lt;- as.numeric((a &gt; 0) * rbinom(n, 1, 0.5))\n  y0 &lt;- rbinom(n, 1, plogis(f(s, 0, 0)))\n  y10 &lt;- rbinom(n, 1, plogis(f(s, s + 1, 0)))\n  y11 &lt;- rbinom(n, 1, plogis(f(s, s + 1, 1)))\n  y &lt;- (1 - r) * y0 + r * ((1 - d) * y10 + d * y11)\n  D &lt;- data.table(r = r, s = s, a = a, d = d, y0 = y0, y10 = y10, y11 = y11, y = y)[\n    ,\n    `:=`(\n      a1d1 = as.numeric(a == 1 & d == 1),\n      a2d1 = as.numeric(a == 2 & d == 1),\n      r_fac = factor(r),\n      a_fac = factor(a),\n      s_fac = factor(s),\n      a_cen = r * (a - 1 - mean(a[r == 1] - 1)),\n      s_cen = s - mean(s)\n    )\n  ]\n}\nset.seed(1246)\nD &lt;- generate_data_2()\nfit1 &lt;- glm(y ~ r_fac + a1d1 + a2d1, data = D, family = binomial())\nfit2 &lt;- glm(y ~ a_fac + a1d1 + a2d1, data = D, family = binomial())\nfit1s &lt;- glm(y ~ r_fac + a1d1 + a2d1 + s_fac, data = D, family = binomial())\nfit2s &lt;- glm(y ~ a_fac + a1d1 + a2d1 + s_fac, data = D, family = binomial())",
    "crumbs": [
      "Design",
      "Design Notes"
    ]
  },
  {
    "objectID": "notebooks/model-implementation.html",
    "href": "notebooks/model-implementation.html",
    "title": "Model implementation",
    "section": "",
    "text": "The simplest implementation I could think of split the data into silo-specific chunks, mimicking the formulation in the model specification earlier.\n\n\ndata {\n  // early\n  int N_e;\n  array[N_e] int e_su;\n  array[N_e] int e_y;\n  array[N_e] int e_n;\n  vector[N_e] e_ec; // membership\n  vector[N_e] e_ecp; // non-membership, ie 1 - e_ec\n  array[N_e] int e_c;\n  \n  int N_l;\n  array[N_l] int l_su;\n  array[N_l] int l_y;\n  array[N_l] int l_n;\n  vector[N_l] l_ec;\n  vector[N_l] l_ecp; // 1 - l_ec\n  array[N_l] int l_c;\n  vector[N_l] l_ea;\n  vector[N_l] l_eap;\n  array[N_l] int l_a;\n  vector[N_l] l_eb1;\n  vector[N_l] l_eb2;\n  vector[N_l] l_ebp;\n  array[N_l] int l_b;\n  \n  int N_c;\n  array[N_c] int c_su;\n  array[N_c] int c_y;\n  array[N_c] int c_n;\n  vector[N_c] c_ec;\n  vector[N_c] c_ecp; // 1 - c_ec\n  array[N_c] int c_c;\n  vector[N_c] c_ea;\n  vector[N_c] c_eap;\n  array[N_c] int c_a;\n  vector[N_c] c_eb1;\n  vector[N_c] c_eb2;\n  vector[N_c] c_ebp;\n  array[N_c] int c_b;\n  \n  // priors\n  real pri_sig_b_c;\n  real pri_sig_a_l;\n  real pri_sig_b1_l;\n  real pri_sig_b2_l;\n  real pri_sig_a_c;\n  real pri_sig_b1_c;\n  real pri_sig_b2_c;\n  \n}\ntransformed data {\n  int N = N_e + N_l + N_c;\n}\nparameters {\n  vector[6] alpha;\n  // real gamma_b;\n  real gamma_c;\n  real b_a_l_raw;\n  real b_b1_l_raw;\n  real b_b2_l_raw;\n  real b_a_c_raw;\n  real b_b1_c_raw;\n  real b_b2_c_raw;\n  real b_c_raw;\n}\ntransformed parameters{\n  // Include non-randomised items in parameter vector but set to zero \n  // see b_c[3] below. Gives a simpler way to build up model without index\n  // overrun or conditionals for building linear predictor.\n  \n  vector[2] b_a_l; // dair vs revision (late silo)\n  vector[3] b_b1_l; // note length - dair vs revision (late silo, recvd one-stage)\n  vector[3] b_b2_l; // note length - dair vs revision (late silo, recvd two-stage)\n  \n  vector[2] b_a_c; // dair vs revision (chronic silo)\n  vector[2] b_b1_c; // dair vs revision (chronic silo, recvd one-stage)\n  vector[2] b_b2_c; // dair vs revision (chronic silo, recvd two-stage)\n  \n  vector[3] b_c; // note length\n\n  b_a_l[1] = 0.0;\n  b_a_l[2] = b_a_l_raw;\n\n  b_b1_l[1] = 0.0;\n  b_b1_l[2] = b_b1_l_raw;\n  b_b1_l[3] = 0.0;\n   \n  b_b2_l[1] = 0.0;\n  b_b2_l[2] = b_b2_l_raw;\n  b_b2_l[3] = 0.0;\n  \n  b_a_c[1] = 0.0;\n  b_a_c[2] = b_a_c_raw;\n\n  b_b1_c[1] = 0.0;\n  b_b1_c[2] = b_b1_c_raw;\n\n  b_b2_c[1] = 0.0;\n  b_b2_c[2] = b_b2_c_raw;\n   \n  b_c[1] = 0.0;\n  b_c[2] = b_c_raw;\n  // handles other, but this can be ignored in post-processing\n  b_c[3] = 0.0;\n}\nmodel{\n  target += normal_lpdf(alpha | 0, 1.5);\n  \n  // target += std_normal_lpdf(gamma_b);\n  target += std_normal_lpdf(gamma_c);\n  // all silos\n  target += normal_lpdf(b_c_raw | 0, pri_sig_b_c);\n  // late silo\n  target += normal_lpdf(b_a_l_raw | 0, pri_sig_a_l);\n  target += normal_lpdf(b_b1_l_raw | 0, pri_sig_b1_l);\n  target += normal_lpdf(b_b2_l_raw | 0, pri_sig_b2_l);\n  // chronic silo\n  target += normal_lpdf(b_a_c_raw | 0, pri_sig_a_c);\n  target += normal_lpdf(b_b1_c_raw | 0, pri_sig_b1_c);\n  target += normal_lpdf(b_b2_c_raw | 0, pri_sig_b2_c);\n  \n  // likelihood chunks pertaining to each silo\n  target += binomial_logit_lpmf(e_y | e_n, alpha[e_su] +\n                                      e_ecp * gamma_c + \n                                      e_ec .* b_c[e_c]) ;      \n                                    \n  target += binomial_logit_lpmf(l_y | l_n, alpha[l_su] + \n                                    l_ecp * gamma_c +\n                                    l_ea .* b_a_l[l_a] +\n                                    l_eb1 .* b_b1_l[l_b] +  \n                                    l_eb2 .* b_b2_l[l_b] +\n                                    l_ec .* b_c[l_c]\n                                    ) ;    \n                                    \n  target += binomial_logit_lpmf(c_y | c_n, alpha[c_su] +\n                                      c_ecp * gamma_c +\n                                      c_ea .* b_a_c[c_a] +\n                                      c_eb1 .* b_b1_c[c_b] + \n                                      c_eb2 .* b_b2_c[c_b] +\n                                      c_ec .* b_c[c_c]) ; \n}\ngenerated quantities{\n  vector[N_e] eta_e ;\n  vector[N_l] eta_l ;\n  vector[N_c] eta_c ;\n  vector[N] eta;\n  \n  eta_e = alpha[e_su] + e_ecp * gamma_c + e_ec .* b_c[e_c];\n  eta_l = alpha[l_su] + l_ecp * gamma_c +\n    l_ea .* b_a_l[l_a] + \n    l_eb1 .* b_b1_l[l_b] + l_eb2 .* b_b2_l[l_b] +\n    l_ec .* b_c[l_c];\n  eta_c = alpha[c_su] + c_ecp * gamma_c +\n    c_ea .* b_a_c[c_a] +\n    c_eb1 .* b_b1_c[c_b] + c_eb2 .* b_b2_c[c_b] +\n    c_ec .* b_c[c_c];\n    \n  eta = append_row(eta_e, append_row(eta_l, eta_c));\n\n}\n\n\nBelow I create a data set with a million patients (orders of magnitude more than we will have available) to see if we can get anywhere close to recovering the parameters - if we cannot recover the parameters with this many records, we are certainly not going to be able to do so with 2500 patients.\nThen I fit the stan model and extract and summarise the posterior.\n\n\nCode\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-02.stan\")\n\nset.seed(1)\nll &lt;- get_trial_data(N = 1e6)\nlsd &lt;- get_stan_data(ll$d_i)\nld &lt;- lsd$ld\n# cbind(ld$l_su, ld$l_y, ld$l_n, ld$l_ea, ld$l_eap, ld$l_a)\nd_b &lt;- copy(lsd$d_b)\n\nf2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.6 seconds.\n\n\nCode\npost &lt;- data.table(f2$draws(variables = c(\n  \"eta\"\n), format = \"matrix\"))\n\n# create index field\npost &lt;- melt(post, measure.vars = names(post))\npost[, idx := gsub(\".*\\\\[\", \"\", variable)]\npost[, idx := gsub(\"\\\\]\", \"\", idx)]\npost[, idx := as.integer(idx)]\n\nd_fig &lt;- cbind(d_b, post[, .(eta_med = median(value), \n         eta_q025 = quantile(value, prob = 0.025),\n         eta_q975 = quantile(value, prob = 0.975)), keyby = idx])\n\n\nFigure 1 shows a comparison between the true log-odds of treatment success with the 95% credible interval obtained from the model. It suggests a strong association between the true and estimated log-odds of treatment success for this particular dataset.\n\n\nCode\nggplot(d_fig, aes(x = eta, y = eta_med)) +\n  # geom_point() +\n  geom_linerange(aes(ymin = eta_q025, ymax = eta_q975)) +\n  geom_abline(intercept = 0, slope = 1, lwd = 0.1) +\n  scale_x_continuous(\"True log-odds success\") +\n  scale_y_continuous(\"Posterior log-odds success (95% credible interval)\") +\n  facet_grid(silo ~ joint) +\n  ggtitle(\"True log-odds success vs 95% credible interval\")\n\n\n\n\n\n\n\n\nFigure 1: Scatter plot comparing true vs estimated 95% credible interval for log-odds treatment success.\n\n\n\n\n\n\n\nCode\npost &lt;- data.table(f2$draws(variables = c(\n    \"alpha\", \"gamma_c\", \n    \"b_a_l\", \n    \"b_b1_l\", \n    \"b_b2_l\",\n    \"b_a_c\",\n    \"b_b1_c\", \n    \"b_b2_c\",\n    \"b_c\"\n  ), format = \"matrix\"))\n  \n\n# test outcome\ncols &lt;- names(post)\ncols &lt;- gsub(\"[\",\"_\",cols,fixed = T)\ncols &lt;- gsub(\"]\",\"\",cols,fixed = T)\nnames(post) &lt;- cols\n  \n# effects\neffs &lt;- c(\n  # domain a, late (revision) and chronic (two-stage)\n  \"b_a_l_2\", \"b_a_c_2\", \n  # domain b, (late/revision one stage pts)\n  # wk12p1 (ref is wk6p1)\n  \"b_b1_l_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_l_2\", \n  # wk12p1 (ref is wk6p1)\n  \"b_b1_c_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_c_2\",\n  # rif (ref is no-rif)\n  \"b_c_2\")\n  \nd_beta &lt;- post[, .SD, .SDcols = effs]\nd_beta &lt;- melt(d_beta, measure.vars = names(d_beta))\n# unique(d_beta$variable)\n\n\nparname_map &lt;- roadmap.data::get_par_effects_mapping()\nd_beta[, parname := parname_map[variable]]\nd_beta[, parname := factor(parname, levels = roadmap.data::get_par_effects_mapping())]\n\nd_fig &lt;- d_beta[, .(\n  lor_med = median(value), \n  lor_q025 = quantile(value, prob = 0.025),\n  lor_q975 = quantile(value, prob = 0.975)), keyby = parname]\n\nd_effects &lt;- roadmap.data::get_sim_spec_effects(roadmap.data::get_sim_spec())\nd_effects &lt;- melt(d_effects, measure.vars = names(d_effects), value.name = \"lor\")\n\nd_fig &lt;- merge(d_fig, d_effects, by.x = \"parname\", by.y = \"variable\")\n\n\nFigure 1 shows a comparison between the true log-odds of treatment success with the 95% credible interval obtained from the model. It suggests a strong association between the true and estimated log-odds of treatment success for this particular dataset.\n\n\nCode\nggplot(d_fig, aes(x = parname, y = lor_med)) +\n  geom_point() +\n  geom_point(data = d_fig, aes(x = parname, y = lor), pch = 2) +\n  geom_linerange(aes(ymin = lor_q025, ymax = lor_q975))  +\n  scale_x_discrete(\"\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Posterior log-odds-ratio (95% credible interval)\") \n\n\n\n\n\n\n\n\nFigure 2: Posterior estimates for log-odds-ratios (true values shown as triangles).\n\n\n\n\n\n\n\nCode\npost &lt;- data.table(f2$draws(variables = c(\n    \"alpha\", \"gamma_c\", \n    \"b_a_l\", \n    \"b_b1_l\", \n    \"b_b2_l\",\n    \"b_a_c\",\n    \"b_b1_c\", \n    \"b_b2_c\",\n    \"b_c\"\n  ), format = \"matrix\"))\n  \n\n# test outcome\ncols &lt;- names(post)\ncols &lt;- gsub(\"[\",\"_\",cols,fixed = T)\ncols &lt;- gsub(\"]\",\"\",cols,fixed = T)\nnames(post) &lt;- cols\n  \n# effects\npars &lt;- c(\n  \"alpha\", \"gamma_c\", \n  # domain a, late (revision) and chronic (two-stage)\n  \"b_a_l_2\", \"b_a_c_2\", \n  # domain b, (late/revision one stage pts)\n  # wk12p1 (ref is wk6p1)\n  \"b_b1_l_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_l_2\", \n  # wk12p1 (ref is wk6p1)\n  \"b_b1_c_2\", \n  # wk12p2 (ref is day7p2)\n  \"b_b2_c_2\",\n  # rif (ref is no-rif)\n  \"b_c_2\")\n  \nd_pars &lt;- post[, .SD, .SDcols = effs]\nm_cor &lt;- d_pars[, cor(.SD)]\nd_cor &lt;- data.table(cbind(var1 = rownames(m_cor), m_cor))\nd_cor &lt;- melt(d_cor, id.vars = \"var1\", variable.name = \"var2\")\nd_cor[, value := as.numeric(value)]\n\nd_cor[, `:=`(\n  var1 = factor(var1, levels = c(pars[length(pars):1])),\n  var2 = factor(var2, levels = c(pars[length(pars):1]))\n)]\n\n\nFigure 3 shows the correlation between parameters estimated from the model.\n\n\nCode\nggplot(d_cor, aes(x = var1, y = var2, fill = value)) +\n  geom_tile(color = \"white\",\n            lwd = 1.5,\n            linetype = 1) +\n  geom_text(aes(label = round(value, 2)), color = \"white\", size = 4) +\n  scale_x_discrete(\"\",position = \"top\", limits=rev) +\n  scale_y_discrete(\"\") + \n  scale_fill_gradient2(\"Pearson correlation\") +\n  coord_fixed()\n\n\n\n\n\n\n\n\nFigure 3: Parameter correlation (white indicates zero correlation)",
    "crumbs": [
      "Design",
      "Model implementation"
    ]
  },
  {
    "objectID": "notebooks/misc-notes.html#thought-1",
    "href": "notebooks/misc-notes.html#thought-1",
    "title": "Misc notes",
    "section": "Thought 1",
    "text": "Thought 1\nWhat is the effect of treating a patient with joint infection with a revision surgical procedure compared to a less invasive procedure, known as dair? What about the effect of treating with long relative to short duration antibiotic where the definition (and action) of long vs short duration are different within each level (i.e. a nested design rather than crossed). The usual experimental approach here is to apply random assignment of all possible treatment combinations, which with two levels\nImagine a situation where we have a nested factorial design with factors A (control vs active) and B (control vs active). Contrary to the usual situation, we assume that active for A comes in two flavours, active-1 and active-2. Usually, we assume that the control vs active for B are different under each level of A. Here, we assume that control vs active for B are different under each of the possibilities for A.\ntrial with control vs treatment with a single dichotomous covariate in the model (X) and where the outcome is death by day 30. We specify a conditional logistic regression model with linear predictor \\(\\eta = \\beta_0 + \\beta_1 I(trt_i == 1) + \\beta_2 I(sex = male)\\). By chance, all the control group are male and all the treatment group are female. Logically, we would not be able to separate the effect of treatment from sex, but model it anyway.\n\n\nCode\nN &lt;- 10000\nd &lt;- data.table(id = 1:N)\nd[, trt := rbinom(.N, 1, 0.5)]\nd[trt == 0, sex := 1]\nd[trt == 1, sex := 0]\nbeta_0 &lt;- qlogis(0.7)\nbeta_trt &lt;- log(2)\nbeta_sex &lt;- log(0.2)\nd[, eta := beta_0 + beta_trt * trt + beta_sex * sex]\nd[, y := rbinom(.N, 1, prob = plogis(eta))]\nhead(d)\n\n\nBasic logistic regression.\n\n\n\nFit the model and extract posterior.\n\n\nCode\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/logistic-demo-01.stan\")\n\nd_grp &lt;- d[, .(y = sum(y), n = length(y)), keyby = .(trt, sex)]\nld &lt;- list(\n  N = nrow(d_grp), \n  y = d_grp$y, n = d_grp$n, trt = d_grp$trt, sex = d_grp$sex\n)\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\npost &lt;- data.table(f1$draws(variables = c(\n  \"b0\", \"b_trt\", \"b_sex\"\n), format = \"matrix\"))\n\n\nSummarise the posterior draws:\n\n\nCode\nd_tbl &lt;- melt(post[, 2:3], measure.vars = names(post)[2:3])\nd_tbl &lt;- d_tbl[, .(mu = mean(value), \n          sd = sd(value),\n          q_025 = quantile(value, prob = 0.025), \n          q_975 = quantile(value, prob = 0.975)), by = variable]\n\nb_tru &lt;- c(beta_trt, beta_sex)\nnames(b_tru) &lt;- c(\"b_trt\", \"b_sex\")\nd_tbl[, b_tru := b_tru[variable]]\nd_tbl\n\n\nSo, the posterior mean is nowhere near our known true value that we simulated the data with."
  },
  {
    "objectID": "notebooks/model-spec.html",
    "href": "notebooks/model-spec.html",
    "title": "Model specification",
    "section": "",
    "text": "The primary outcome is treatment success at 12 months post platform entry, defined as all of:\nhereafter referred to as ‘treatment success’.\nFor each silo and site of infectioin we model the probability of treatment success as follows:\nwhere",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#interpretation",
    "href": "notebooks/model-spec.html#interpretation",
    "title": "Model specification",
    "section": "Interpretation",
    "text": "Interpretation\nSome additional more detailed and narrative is perhaps useful on the interpretation of parameters.\nAs noted previously, the baseline reference groups are defined as follows:\n\n\nGroups corresponding to baseline log-odds of treatment success\n\n\nSilo\nA\nB\nC\n\n\n\n\nearly\n-\n-\nno-rif\n\n\nlate\ndair\n-\nno-rif\n\n\nchronic\none\n6wk\nno-rif\n\n\n\n\nAs such, we have:\n\n\\(\\alpha_{[early, \\cdot]} \\quad\\) - this parameter describes the log-odds of treatment success for the sample members with early infection who are randomised within Domain C (that is, were not part of the 40% Domain C exclusion set) to no-rif and had no randomisation options for domains A and B. The parameter makes no adjustment for what surgery a patient received, nor how long their duration of antibiotic was.\n\\(\\alpha_{[late, \\cdot]} \\quad\\) - this parameter describes the log-odds of treatment success for the sample members with late infection who were randomised to dair in Domain A, had no randomisation options for Domain B, which is a deterministic consequence of being randomised to dair in Domain A, and were randomised to no-rif in Domain C.\n\\(\\alpha_{[chronic, \\cdot]} \\quad\\) - this parameter describes the log-odds of treatment success for the sample members with chronic infection who were randomised to one-stage in Domain A, were randomised to 6wksp1 in Domain B and were randomised to no-rif in Domain C.\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe following are incomplete:\n\n\n\nLate infection\nIn the surgical domain, we consider the effect (log-odds-ratio) of revision relative to dair. Within revision, patients may receive one or two-stage procedures. The log-odds of treatment success for those receiving a one-stage procedure, are randomised to 6wk duration and receive no-rif is \\(\\alpha_{late,\\cdot}\\). Similarly, this is true for those receiving a (non-randomised) two-stage procedure, are randomised to 7day duration and receive no-rif.\nThe effect of revision relative to dair is thus in the context of some weighted average of the response under the one-stage and two-stage procedures.\nThe model characterises associations between the log-odds of treatment success and each of the parameters. The effect of each term is considered while holding all others constant.\n\n\n\n\n\n\nNote\n\n\n\nIs overlap and extrapolation an issue here???\n\n\n\n\nChronic infection\nTODO",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#priors",
    "href": "notebooks/model-spec.html#priors",
    "title": "Model specification",
    "section": "Priors",
    "text": "Priors\nAs with the linear predictor, the priors are currently targeted towards the simulation work but may be appropriate for the final model.\n\nIntercepts\nThe silo and infection site specific intercepts are given independent normal priors\n\\[\\begin{aligned}\n\\alpha_{s(i),u(i)} \\sim \\mathcal{N}(0, 1.5^2)\n\\end{aligned}\\]\nOn the probability scale, these concentrate on 0.5 with 95% of the density between 0.04 and 0.96, approximately uniform across this interval.\nWhile the intercept priors are currently independent, consideration should be given to partial pooling across site of infection. However, the concept of exchangeability is perhaps dubious for this set of parameters due to the fact that the baseline log-odds of success must be interpreted based on the domain level options available to each group.\nFor example, there are no randomisation options for early stage infection in domains A and B and therefore the baseline log-odds (intercept) refers to the cohort of patients that were not randomised within A nor B and randomised to the reference group for domain C. In contrast, for the late stage patients, the baseline log-odds of treatment success is interpreted contextually for the cohort of patients that were randomised to the reference level of domains A, B and C, see below.\n\n\nGroups corresponding to baseline log-odds of treatment success\n\n\nSilo\nA\nB\nC\n\n\n\n\nearly\n-\n-\nno-rif\n\n\nlate\ndair\n-\nno-rif\n\n\nchronic\none\n6wk\nno-rif\n\n\n\n\n\n\nDomain non-membership\nThe domain non-membership parameters are given standard normal independent priors. These parameters are pooled across all silos.\n\\[\\begin{aligned}\n\\gamma_\\mathcal{D} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\n\n\nInterventions\nA hierarchical prior structure may be appropriate for some of the intervention effects dependent on what can be assumed regarding exchangeability.\n\nSurgical domain\nSilo-specific, independent normal priors are assumed for the surgical domain. There is no pooling, we simply compare dair vs revision in the late stage patients and one vs two stage in the chronic stage patients.\n\\[\\begin{aligned}\n\\beta_{A,s,d_{A,j}} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\nThe reference level is set to 0.\n\n\nAntibiotic duration domain\nWhile a hierarchical structure could be considered for this domain, independent normal priors are currenlty assumed for the duration domain. Currently, there is no pooling. We compare 6 vs 12 weeks for late stage patients having a one stage procedure and 7 days vs 12 wks for those having a two stage procedure. Independently, we compare 6 vs 12 weeks for chronic stage patients having a one stage procedure and 7 days vs 12 wks for those having a two stage procedure.\n\\[\\begin{aligned}\n\\beta_{B_k,s,d_{B,j}} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\nThe reference level is set to 0.\nTheoretically, partial pooling could be implemented across the late and chronic silos.\n\n\nAntibiotic type domain\nA hierarchical structure could also be considered for this domain. The ‘average’ across silos could be obtained by sampling from the posterior assuming normality based on the parameter for the group variance. With three groups the extent of the partial pooling is going to be heavily influenced by the prior rather than the data.\nCurrently we adopt a standard normal prior for the treatment effects in this domain, which are completely pooled across silos.\n\\[\\begin{aligned}\n\\beta_{C,d_{C,j}} \\sim \\mathcal{N}(0, 1)\n\\end{aligned}\\]\nThe reference level is set to 0.",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "notebooks/model-spec.html#footnotes",
    "href": "notebooks/model-spec.html#footnotes",
    "title": "Model specification",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn practice, it may be the case that non-membership for domain \\(B\\) is relevant. For example, if an early stage patient receives a one or two-stage surgical procedure.↩︎\nAs such, silo-specific decisions on antibiotic type are not possible.↩︎",
    "crumbs": [
      "Design",
      "Model specification"
    ]
  },
  {
    "objectID": "etc/readme.html",
    "href": "etc/readme.html",
    "title": "readme",
    "section": "",
    "text": "readme\nfile name format is\ncfg-sim&lt;sim-id&gt;-&lt;scenario-id&gt;-&lt;variant-id&gt;\nuse sed for efficient updating, e.g. \n\nChange number of simulations from 10 to 500:\n\ngsed -i 's/nsim:\\ 10/nsim:\\ 500/' cfg-sim01-sc01-0*.yml\n\nUpdate scenario label:\n\ngsed -i 's/sc01/sc02/' cfg-sim01-sc02-0*.yml"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Overview",
    "section": "",
    "text": "This site contains notes, data summaries and simulation results for the ROADMAP study.\nAll the code can be found on github, just use the icon to the top right. The functionality herein has a dependency on the roadmap.data R package, which can also be found via the above link (see the readme for this repo). If you find any issues, let me know and I will prioritise accordingly.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#notes",
    "href": "index.html#notes",
    "title": "Overview",
    "section": "Notes",
    "text": "Notes\n\nDoes not explore impact of effect heterogeneity on \\(C\\)",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html",
    "href": "notebooks/population-structure.html",
    "title": "Population structure",
    "section": "",
    "text": "The following specification is for the partially factorial structure of the study. The outcome model is specified separately.",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#silo",
    "href": "notebooks/population-structure.html#silo",
    "title": "Population structure",
    "section": "Silo",
    "text": "Silo\nThe total sample size is divided across the silos in proportion to the values described in the table below. These proportions are expectations. Each simulated dataset will vary somewhat from these proportions due to the stochastic nature of the generation process.\n\n\nSilo categories (\\(\\pi\\) denotes probability of membership)\n\n\nSilo\n\\(\\pi\\)\n\n\n\n\nearly\n0.3\n\n\nlate\n0.5\n\n\nchronic\n0.2",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#site-of-infection-joint",
    "href": "notebooks/population-structure.html#site-of-infection-joint",
    "title": "Population structure",
    "section": "Site of infection (joint)",
    "text": "Site of infection (joint)\nEach silo comprises patients assumed to have primary infection in either knee or hip (not both). The proportion of infections associated with each joint for each silo are shown below. As previously, these proportions are expectations and the empirical proportions observed in simulated datasets will vary from these.\n\n\nSite of infection (\\(\\pi\\) denotes probability of site infection conditional on silo membership)\n\n\nSilo\nJoint\n\\(\\pi\\)\n\n\n\n\n\nearly\nknee\n0.4\n\n\n\nearly\nhip\n0.6\n\n\n\nlate\nknee\n0.3\n\n\n\nlate\nhip\n0.7\n\n\n\nchronic\nknee\n0.5\n\n\n\nchronic\nhip\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-surgery-domain-a",
    "href": "notebooks/population-structure.html#randomisation-into-surgery-domain-a",
    "title": "Population structure",
    "section": "Randomisation into surgery domain (A)",
    "text": "Randomisation into surgery domain (A)\nRandomisation into domain A is conditional on silo membership as detailed below.\n\n\nRandomisation within domain A\n\n\nSilo\nRandomised (\\(e_a\\))\n\n\n\n\nearly\nN\n\n\nlate\nY\n\n\nchronic\nY",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#surgery-domain-a",
    "href": "notebooks/population-structure.html#surgery-domain-a",
    "title": "Population structure",
    "section": "Surgery domain (A)",
    "text": "Surgery domain (A)\nAllocation probabilities (conditional on entry into domain A) are shown below. Early silo does not receive randomisation and all early stage patients are assumed to receive DAIR.\n\n\nAllocation within domain A (\\(\\pi\\) denotes probability allocation to surgery type conditional on silo membership)\n\n\nSilo\nSurgery type (\\(a\\))\n\\(\\pi\\)\n\n\n\n\n\nearly\ndair\n-\n\n\n\nlate\ndair\n0.5\n\n\n\nlate\nrevision\n0.5\n\n\n\nchronic\none-stage\n0.5\n\n\n\nchronic\ntwo-stage\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#intended-surgery",
    "href": "notebooks/population-structure.html#intended-surgery",
    "title": "Population structure",
    "section": "Intended surgery",
    "text": "Intended surgery\nLate stage infections will be randomised to DAIR vs revision where revision would be planned as one or two-stage, determined by the treating clinician, i.e. not randomised. As we do not know the assignment mechanism for one vs two-stage for the late-stage infection patients allocated to revision, we simply assume an equal chance of receiving one vs two stage1.\nIn all other cases, the intended surgery is set to allocated surgery.\n\n\nIndended surgical approach (\\(\\pi\\) denotes probability allocation to surgery type conditional on silo membership)\n\n\nSilo\nAllocation (\\(a\\))\nIntended surgery (\\(q\\))\n\\(\\pi\\)\n\n\n\n\n\nearly\ndair\ndair\n-\n\n\n\nlate\ndair\ndair\n-\n\n\n\nlate\nrevision\none-stage\n0.5\n\n\n\nlate\nrevision\ntwo-stage\n0.5\n\n\n\nchronic\none-stage\none-stage\n-\n\n\n\nchronic\ntwo-stage\ntwo-stage\n-",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-duration-domain-b",
    "href": "notebooks/population-structure.html#randomisation-into-duration-domain-b",
    "title": "Population structure",
    "section": "Randomisation into duration domain (B)",
    "text": "Randomisation into duration domain (B)\nEntry into domain B is dependent on the domain A entry and allocation and is detailed below.\n\n\nRandomisation within domain B\n\n\nIntended surgery (\\(q\\))\nRandomised (\\(e_b\\))\n\n\n\n\n\ndair\nN\n\n\n\nrevision\nY\n\n\n\none-stage\nY\n\n\n\ntwo-stage\nY",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#duration-domain-b",
    "href": "notebooks/population-structure.html#duration-domain-b",
    "title": "Population structure",
    "section": "Duration domain (B)",
    "text": "Duration domain (B)\nThe treatment options and allocation probabilities for domain B are detailed below. Duration of antibiotic is conditional on allocated (intended) surgery type, see above. Patients receiving DAIR are assumed to have 12 wk duration (not randomised).\n\n\nAllocation within duration domain (\\(\\pi\\) denotes probability allocation to surgery type conditional on allocated/intended surgery)\n\n\nSilo\nAllocation/Intended surgery (\\(q\\))\nAllocation (\\(b\\))\n\\(\\pi\\)\n\n\n\n\nearly\ndair\n12 wk\n-\n\n\nlate\none-stage\n6 wk\n0.5\n\n\nlate\none-stage\n12 wk\n0.5\n\n\nlate\ntwo-stage\n7 day post 2\n0.5\n\n\nlate\ntwo-stage\n12 wk post 2\n0.5\n\n\nchronic\none-stage\n6 wk\n0.5\n\n\nchronic\none-stage\n12 wk\n0.5\n\n\nchronic\ntwo-stage\n7 day post 2\n0.5\n\n\nchronic\ntwo-stage\n12 wk post 2\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#randomisation-into-adjunctive-domain-c",
    "href": "notebooks/population-structure.html#randomisation-into-adjunctive-domain-c",
    "title": "Population structure",
    "section": "Randomisation into adjunctive domain (C)",
    "text": "Randomisation into adjunctive domain (C)\nThe data generating process assume that 60% of the cohort enter into this domain at random, unrelated to risk factors. The remainder are held out so that we do not over-estimate the operating characteristics, such as power.\n\n\nRandomisation within domain C (\\(\\pi\\) denotes probability patient is indicated as eligible for domain)\n\n\nSilo\nRandomised (\\(e_c\\))\n\\(\\pi\\)\n\n\n\n\nearly\nY\n0.6\n\n\nlate\nY\n0.6\n\n\nchronic\nY\n0.6",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#adjunctive-domain-c",
    "href": "notebooks/population-structure.html#adjunctive-domain-c",
    "title": "Population structure",
    "section": "Adjunctive domain (C)",
    "text": "Adjunctive domain (C)\nThe treatment options and allocation probabilities for domain C are detailed below.\n\n\nAllocation within adjunctive domain (\\(\\pi\\) denotes probability that an eligible patient is allocated to no rif vs rif)\n\n\nAllocation (\\(c\\))\n\\(\\pi\\)\n\n\n\n\nno rif\n0.5\n\n\nrif\n0.5",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#encoded-specification",
    "href": "notebooks/population-structure.html#encoded-specification",
    "title": "Population structure",
    "section": "Encoded specification",
    "text": "Encoded specification\nThe above specification is bundled into an R package (roadmap.data) for consistent data generation for ROADMAP.\n\n\nCode\nroadmap.data::get_pop_spec()\n\n\n$r_silo\n      silo   p\n1:   early 0.3\n2:    late 0.5\n3: chronic 0.2\n\n$r_joint\n      silo joint   p\n1:   early  knee 0.4\n2:   early   hip 0.6\n3:    late  knee 0.3\n4:    late   hip 0.7\n5: chronic  knee 0.5\n6: chronic   hip 0.5\n\n$r_ea\n      silo rand\n1:   early    N\n2:    late    Y\n3: chronic    Y\n\n$r_a\n      silo    a   p\n1:   early dair  NA\n2:    late dair 0.5\n3:    late  rev 0.5\n4: chronic  one 0.5\n5: chronic  two 0.5\n\n$r_a_q\n      silo    a   qa   p\n1:   early dair dair  NA\n2:    late dair dair  NA\n3:    late  rev  one 0.5\n4:    late  rev  two 0.5\n5: chronic  one  one  NA\n6: chronic  two  two  NA\n\n$r_eb\n     qa rand\n1: dair    N\n2:  rev    Y\n3:  one    Y\n4:  two    Y\n\n$r_b\n      silo   qa     b   p\n1:   early dair   w12 1.0\n2:    late  one w06p1 0.5\n3:    late  one w12p1 0.5\n4:    late  two d07p2 0.5\n5:    late  two w12p2 0.5\n6: chronic  one w06p1 0.5\n7: chronic  one w12p1 0.5\n8: chronic  two d07p2 0.5\n9: chronic  two w12p2 0.5\n\n$r_ec\n      silo rand   p\n1:   early    Y 0.6\n2:    late    Y 0.6\n3: chronic    Y 0.6\n\n$r_c\n       c   p\n1: norif 0.5\n2:   rif 0.5\n\n\nThe following function simulates the design matrix.\n\n\nCode\nroadmap.data::get_design\n\n\nfunction(N = 100000, pop_spec = NULL, idx_s = 1){\n\n  if(is.null(pop_spec)){\n    pop_spec &lt;- get_pop_spec()\n  }\n\n  d &lt;- data.table()\n  # pt id\n  d[, id := idx_s:(N+idx_s - 1)]\n  d[, silo := sample(pop_spec$r_silo$silo, size = N, replace = T, prob = pop_spec$r_silo$p)]\n  setkey(d, silo)\n  setkey(pop_spec$r_joint, silo)\n  setkey(pop_spec$r_ea, silo)\n  for(z in pop_spec$r_silo$silo){\n    d[z, joint :=\n        sample(pop_spec$r_joint[z, joint], size = .N, replace = T, prob = pop_spec$r_joint[z, p])\n    ]\n\n    # might as well set ea (eligibility for domain a)\n    d[z, ea := pop_spec$r_ea[z, rand]]\n  }\n\n  # Surgery domain (A)\n  setkey(pop_spec$r_a, silo)\n  d[\"early\", a := \"dair\"]\n  z &lt;- \"late\"\n  d[z, a := sample(pop_spec$r_a[z, a], size = .N, replace = T, prob = pop_spec$r_a[z, p])]\n  z &lt;- \"chronic\"\n  d[z, a := sample(pop_spec$r_a[z, a], size = .N, replace = T, prob = pop_spec$r_a[z, p])]\n\n  # introduce the intended surgical approach (for late stage allocated to revision)\n  setkey(d, silo, a)\n  setkey(pop_spec$r_a_q, silo, a)\n  d[.(\"late\", \"rev\"), qa :=\n      sample(pop_spec$r_a_q[.(\"late\", \"rev\"), qa], size = .N, replace = T, prob = pop_spec$r_a_q[.(\"late\", \"rev\"), p])]\n  d[is.na(qa), qa := copy(a)]\n\n  # Duration domain (B)\n  # eligibility based on a\n  d &lt;- merge(d, pop_spec$r_eb[, .(qa, eb = rand)], by = c(\"qa\"), all.x = T)\n  setcolorder(d, c(\"id\", \"silo\", \"joint\", \"ea\", \"a\", \"qa\",\"eb\"))\n  setkey(d, id)\n\n  setkey(d, qa)\n  setkey(pop_spec$r_b, qa)\n  # all dair get 12wk\n  d[\"dair\", b := pop_spec$r_b[\"dair\", unique(b)]]\n\n  setkey(d, silo, qa)\n  setkey(pop_spec$r_b, silo, qa)\n\n  # do these separately so that triggers can coordinate silo specific adaptations\n  d[.(\"late\", \"one\"), b := sample(\n    pop_spec$r_b[.(\"late\", \"one\"), b], size = .N, replace = T,\n    prob = pop_spec$r_b[.(\"late\", \"one\"), p])]\n  d[.(\"late\", \"two\"), b := sample(\n    pop_spec$r_b[.(\"late\", \"two\"), b], size = .N, replace = T,\n    prob = pop_spec$r_b[.(\"late\", \"two\"), p])]\n\n  d[.(\"chronic\", \"one\"), b := sample(\n    pop_spec$r_b[.(\"chronic\", \"one\"), b], size = .N, replace = T,\n    prob = pop_spec$r_b[.(\"chronic\", \"one\"), p])]\n  d[.(\"chronic\", \"two\"), b := sample(\n    pop_spec$r_b[.(\"chronic\", \"two\"), b], size = .N, replace = T,\n    prob = pop_spec$r_b[.(\"chronic\", \"two\"), p])]\n\n  setkey(d, id)\n\n  # Antibiotic type domain (C)\n\n  # Here I make eligibility random to reflect that some of our cohort will not\n  # enter into this domain, irrespective of their randomisation in other domains.\n  # Each silo is allowed to have a different proportion of pts entering into\n  # domain C.\n  setkey(d, silo)\n  setkey(pop_spec$r_ec, silo)\n\n  for(z in pop_spec$r_ec$silo){\n    d[z, ec :=\n        sample(c(\"Y\",\"N\"), size = .N, replace = T, prob = c(pop_spec$r_ec[z, p], 1- pop_spec$r_ec[z, p]))\n    ]\n  }\n\n  d[ec == \"Y\",\n    c := sample(pop_spec$r_c[, c], size = .N, replace = T, prob = pop_spec$r_c[, p])]\n  d[ec == \"N\", c := \"other\"]\n\n  setkey(d, id)\n\n  d\n}\n&lt;bytecode: 0x11cc02400&gt;\n&lt;environment: namespace:roadmap.data&gt;\n\n\nThe data generation assumptions imply unique patients groups on which we would observe the outcome. The outcome is known to be heterogenous across these groups and yet the stated goal is to aggregate measures of effect (odds ratios) across all these groups, e.g. no rif vs rif. However, the effect of interest is assumed to be obtained from the model parameter that characterises the effect of antibiotic type conditional on the other covariates in the model.\n\n\nCode\nd &lt;- roadmap.data::get_design()\nunique(d[order(silo, joint, ea, a, qa, eb, b, ec, c), .SD, .SDcols = !c(\"id\")])\n\n\n       silo joint ea    a   qa eb     b ec     c\n 1: chronic   hip  Y  one  one  Y w06p1  N other\n 2: chronic   hip  Y  one  one  Y w06p1  Y norif\n 3: chronic   hip  Y  one  one  Y w06p1  Y   rif\n 4: chronic   hip  Y  one  one  Y w12p1  N other\n 5: chronic   hip  Y  one  one  Y w12p1  Y norif\n 6: chronic   hip  Y  one  one  Y w12p1  Y   rif\n 7: chronic   hip  Y  two  two  Y d07p2  N other\n 8: chronic   hip  Y  two  two  Y d07p2  Y norif\n 9: chronic   hip  Y  two  two  Y d07p2  Y   rif\n10: chronic   hip  Y  two  two  Y w12p2  N other\n11: chronic   hip  Y  two  two  Y w12p2  Y norif\n12: chronic   hip  Y  two  two  Y w12p2  Y   rif\n13: chronic  knee  Y  one  one  Y w06p1  N other\n14: chronic  knee  Y  one  one  Y w06p1  Y norif\n15: chronic  knee  Y  one  one  Y w06p1  Y   rif\n16: chronic  knee  Y  one  one  Y w12p1  N other\n17: chronic  knee  Y  one  one  Y w12p1  Y norif\n18: chronic  knee  Y  one  one  Y w12p1  Y   rif\n19: chronic  knee  Y  two  two  Y d07p2  N other\n20: chronic  knee  Y  two  two  Y d07p2  Y norif\n21: chronic  knee  Y  two  two  Y d07p2  Y   rif\n22: chronic  knee  Y  two  two  Y w12p2  N other\n23: chronic  knee  Y  two  two  Y w12p2  Y norif\n24: chronic  knee  Y  two  two  Y w12p2  Y   rif\n25:   early   hip  N dair dair  N   w12  N other\n26:   early   hip  N dair dair  N   w12  Y norif\n27:   early   hip  N dair dair  N   w12  Y   rif\n28:   early  knee  N dair dair  N   w12  N other\n29:   early  knee  N dair dair  N   w12  Y norif\n30:   early  knee  N dair dair  N   w12  Y   rif\n31:    late   hip  Y dair dair  N   w12  N other\n32:    late   hip  Y dair dair  N   w12  Y norif\n33:    late   hip  Y dair dair  N   w12  Y   rif\n34:    late   hip  Y  rev  one  Y w06p1  N other\n35:    late   hip  Y  rev  one  Y w06p1  Y norif\n36:    late   hip  Y  rev  one  Y w06p1  Y   rif\n37:    late   hip  Y  rev  one  Y w12p1  N other\n38:    late   hip  Y  rev  one  Y w12p1  Y norif\n39:    late   hip  Y  rev  one  Y w12p1  Y   rif\n40:    late   hip  Y  rev  two  Y d07p2  N other\n41:    late   hip  Y  rev  two  Y d07p2  Y norif\n42:    late   hip  Y  rev  two  Y d07p2  Y   rif\n43:    late   hip  Y  rev  two  Y w12p2  N other\n44:    late   hip  Y  rev  two  Y w12p2  Y norif\n45:    late   hip  Y  rev  two  Y w12p2  Y   rif\n46:    late  knee  Y dair dair  N   w12  N other\n47:    late  knee  Y dair dair  N   w12  Y norif\n48:    late  knee  Y dair dair  N   w12  Y   rif\n49:    late  knee  Y  rev  one  Y w06p1  N other\n50:    late  knee  Y  rev  one  Y w06p1  Y norif\n51:    late  knee  Y  rev  one  Y w06p1  Y   rif\n52:    late  knee  Y  rev  one  Y w12p1  N other\n53:    late  knee  Y  rev  one  Y w12p1  Y norif\n54:    late  knee  Y  rev  one  Y w12p1  Y   rif\n55:    late  knee  Y  rev  two  Y d07p2  N other\n56:    late  knee  Y  rev  two  Y d07p2  Y norif\n57:    late  knee  Y  rev  two  Y d07p2  Y   rif\n58:    late  knee  Y  rev  two  Y w12p2  N other\n59:    late  knee  Y  rev  two  Y w12p2  Y norif\n60:    late  knee  Y  rev  two  Y w12p2  Y   rif\n       silo joint ea    a   qa eb     b ec     c",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/population-structure.html#footnotes",
    "href": "notebooks/population-structure.html#footnotes",
    "title": "Population structure",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThat is, the data generating process assumes the choice of one vs two-stage in the late acute silo is completely random (not at risk of confounding by risk). At some stage we will need to explore the consequences of non-random choice.↩︎",
    "crumbs": [
      "Design",
      "Population structure"
    ]
  },
  {
    "objectID": "notebooks/simulation-results.html#all-treatments-effective",
    "href": "notebooks/simulation-results.html#all-treatments-effective",
    "title": "Simulation results 1",
    "section": "All treatments effective",
    "text": "All treatments effective\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc01\")\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n}\n\nd_sup &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"pr_sup\")\n\nd_inf &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_inf[, lapply(.SD, mean)])\n}))\nd_inf &lt;- melt(d_inf, id.vars = c(\"sc\", \"v\"), value.name = \"pr_inf\")\n\nd_fut &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_fut[, lapply(.SD, mean)])\n}))\nd_fut &lt;- melt(d_fut, id.vars = c(\"sc\", \"v\"), value.name = \"pr_fut\")\n\nd_cfg &lt;- rbindlist(lapply(l, function(z){\n  data.table(do.call(cbind, z$cfg)) \n}))\n# urgh - conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  mc_cores = as.numeric(mc_cores),\n  b_a_l_2 = as.numeric(b_a_l_2),\n  b_a_c_2 = as.numeric(b_a_c_2),\n  b_b1_l_2 = as.numeric(b_b1_l_2),\n  b_b2_l_2 = as.numeric(b_b2_l_2),\n  b_b1_c_2 = as.numeric(b_b1_c_2),\n  b_b2_c_2 = as.numeric(b_b2_c_2),\n  b_c_2 = as.numeric(b_c_2),\n  d_sup = as.numeric(d_sup),\n  d_inf = as.numeric(d_inf),\n  d_fut = as.numeric(d_fut)\n  )]\n\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\nd_pars &lt;- melt(d_cfg[\n  , .SD, .SDcols = c(\"sc\", \"v\", \n                     \"b_a_l_2\", \"b_a_c_2\", \n                     \"b_b1_l_2\", \"b_b2_l_2\", \"b_b1_c_2\", \"b_b2_c_2\", \n                     \"b_c_2\")], \n  id.vars = c(\"sc\", \"v\"), value.name = \"lor_tru\")\n\n\nd_sup &lt;- add_effect_field(d_sup, d_pars)\nd_inf &lt;- add_effect_field(d_inf, d_pars)\nd_fut &lt;- add_effect_field(d_fut, d_pars)\n\n\nd_fig &lt;- merge(d_sup, d_inf, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- merge(d_fig, d_fut, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- melt(d_fig, measure.vars = c(\"pr_sup\", \"pr_inf\", \"pr_fut\"), variable.name = \"decision_type\")\nd_fig[decision_type == \"pr_sup\", decision_type := \"Superiority\"]\nd_fig[decision_type == \"pr_inf\", decision_type := \"Inferiority\"]\nd_fig[decision_type == \"pr_fut\", decision_type := \"Futility\"]\n\n\nTable 1 summarises the setup for the simulated effect sizes (from \\(\\log(1/1.4)\\) to \\(\\log(2)\\)). All parameters are simulated to have the same effect size such that all parameters are effective, show no effect or are harmful.\nResults based on 500 simulations for a cohort sample size of 2500.\n\n\nCode\nd_tbl &lt;- d_cfg[, .SD, .SDcols = !c(\"sc\",\"nsim\", \"mc_cores\")]\nd_tbl &lt;- cbind(\n  effect = c(\n    \"null\", rep(\"superior\", 5), rep(\"inferior\", 2)\n  ), d_tbl\n)\n\n\ng_tbl &lt;- d_tbl |&gt; gt(rowname_col = \"effect\") |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = everything(),\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_a_l_2, b_a_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_b1_l_2, b_b2_l_2, b_b1_c_2, b_b2_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision thresholds\"),\n    columns = c(d_sup, d_inf, d_fut)\n  ) |&gt;\n  cols_label(\n    b_a_l_2 = html(\"revision\"),\n    b_a_c_2 = html(\"two-stage\"),\n    b_b1_l_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_l_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_b1_c_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_c_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_c_2 = html(\"rif\"),\n    d_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    d_inf = html(\"delta&lt;sub&gt;inf&lt;/sub&gt;\"),\n    d_fut = html(\"delta&lt;sub&gt;fut&lt;/sub&gt;\")\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nv\nN_pt\nSurgical (Da)\nDuration (Db)\nType (Dc)\nDecision thresholds\n\n\nrevision\ntwo-stage\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nrif\ndeltasup\ndeltainf\ndeltafut\n\n\n\n\nnull\nv01\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.050\n\n\nsuperior\nv02\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.050\n\n\nsuperior\nv03\n2500\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.050\n\n\nsuperior\nv04\n2500\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.050\n\n\nsuperior\nv05\n2500\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.050\n\n\nsuperior\nv06\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.050\n\n\ninferior\nv07\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.050\n\n\ninferior\nv08\n2500\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.050\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 summarises the variation in the probability of declaring each decision type on each parameter with increasing effects size (odds ratios). All domains are set so that the treatment effects are all equal, e.g. all set to \\(\\log(2)\\) etc. The parameters are log-odds-ratios relative to the relevant reference values.\nFor example, b_a_late_rev is the effect revision relative to dair specific to the late silo. Similarly, b_a_chronic_two is the effect of two-stage procedure relative to the one-stage specific to the chronic silo.\n\n\nCode\nggplot(d_fig, aes(x = exp(lor_tru), y = value, group = decision_type, col = decision_type)) +\n  geom_point(size = 0.5) +\n  geom_line() +\n  scale_color_discrete(\"\") +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Pr(decide superior)\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~parname, ncol = 3)\n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc02\")\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n}\n\nd_sup &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"pr_sup\")\n\nd_inf &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_inf[, lapply(.SD, mean)])\n}))\nd_inf &lt;- melt(d_inf, id.vars = c(\"sc\", \"v\"), value.name = \"pr_inf\")\n\nd_fut &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_fut[, lapply(.SD, mean)])\n}))\nd_fut &lt;- melt(d_fut, id.vars = c(\"sc\", \"v\"), value.name = \"pr_fut\")\n\nd_cfg &lt;- rbindlist(lapply(l, function(z){\n  data.table(do.call(cbind, z$cfg)) \n}))\n# urgh - conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  mc_cores = as.numeric(mc_cores),\n  b_a_l_2 = as.numeric(b_a_l_2),\n  b_a_c_2 = as.numeric(b_a_c_2),\n  b_b1_l_2 = as.numeric(b_b1_l_2),\n  b_b2_l_2 = as.numeric(b_b2_l_2),\n  b_b1_c_2 = as.numeric(b_b1_c_2),\n  b_b2_c_2 = as.numeric(b_b2_c_2),\n  b_c_2 = as.numeric(b_c_2),\n  d_sup = as.numeric(d_sup),\n  d_inf = as.numeric(d_inf),\n  d_fut = as.numeric(d_fut)\n  )]\n\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\nd_pars &lt;- melt(d_cfg[\n  , .SD, .SDcols = c(\"sc\", \"v\", \n                     \"b_a_l_2\", \"b_a_c_2\", \n                     \"b_b1_l_2\", \"b_b2_l_2\", \"b_b1_c_2\", \"b_b2_c_2\", \n                     \"b_c_2\")], \n  id.vars = c(\"sc\", \"v\"), value.name = \"lor_tru\")\n\n\nd_sup &lt;- add_effect_field(d_sup, d_pars)\nd_inf &lt;- add_effect_field(d_inf, d_pars)\nd_fut &lt;- add_effect_field(d_fut, d_pars)\n\n\nd_fig &lt;- merge(d_sup, d_inf, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- merge(d_fig, d_fut, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- melt(d_fig, measure.vars = c(\"pr_sup\", \"pr_inf\", \"pr_fut\"), variable.name = \"decision_type\")\nd_fig[decision_type == \"pr_sup\", decision_type := \"Superiority\"]\nd_fig[decision_type == \"pr_inf\", decision_type := \"Inferiority\"]\nd_fig[decision_type == \"pr_fut\", decision_type := \"Futility\"]\n\n\nRepeating the simulations (500 iterations) based on a total cohort size of 1000.\n\n\nCode\nggplot(d_fig, aes(x = exp(lor_tru), y = value, group = decision_type, col = decision_type)) +\n  geom_point(size = 0.5) +\n  geom_line() +\n  scale_color_discrete(\"\") +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Pr(decide superior)\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~parname, ncol = 3)\n\n\n\n\n\n\n\n\nFigure 2: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim01-sc03\")\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n}\n\nd_sup &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_sup[, lapply(.SD, mean)])\n}))\nd_sup &lt;- melt(d_sup, id.vars = c(\"sc\", \"v\"), value.name = \"pr_sup\")\n\nd_inf &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_inf[, lapply(.SD, mean)])\n}))\nd_inf &lt;- melt(d_inf, id.vars = c(\"sc\", \"v\"), value.name = \"pr_inf\")\n\nd_fut &lt;- rbindlist(lapply(l, function(z){\n  cbind(sc = z$cfg$sc, v = z$cfg$v, z$d_fut[, lapply(.SD, mean)])\n}))\nd_fut &lt;- melt(d_fut, id.vars = c(\"sc\", \"v\"), value.name = \"pr_fut\")\n\nd_cfg &lt;- rbindlist(lapply(l, function(z){\n  data.table(do.call(cbind, z$cfg)) \n}))\n# urgh - conversion to numeric\nd_cfg[, `:=`(\n  nsim = as.numeric(nsim),\n  mc_cores = as.numeric(mc_cores),\n  b_a_l_2 = as.numeric(b_a_l_2),\n  b_a_c_2 = as.numeric(b_a_c_2),\n  b_b1_l_2 = as.numeric(b_b1_l_2),\n  b_b2_l_2 = as.numeric(b_b2_l_2),\n  b_b1_c_2 = as.numeric(b_b1_c_2),\n  b_b2_c_2 = as.numeric(b_b2_c_2),\n  b_c_2 = as.numeric(b_c_2),\n  d_sup = as.numeric(d_sup),\n  d_inf = as.numeric(d_inf),\n  d_fut = as.numeric(d_fut)\n  )]\n\n\nn_sims &lt;- d_cfg$nsim[1]\nN_pt &lt;- d_cfg$N_pt[1]\n\n\nd_pars &lt;- melt(d_cfg[\n  , .SD, .SDcols = c(\"sc\", \"v\", \n                     \"b_a_l_2\", \"b_a_c_2\", \n                     \"b_b1_l_2\", \"b_b2_l_2\", \"b_b1_c_2\", \"b_b2_c_2\", \n                     \"b_c_2\")], \n  id.vars = c(\"sc\", \"v\"), value.name = \"lor_tru\")\n\n\nd_sup &lt;- add_effect_field(d_sup, d_pars)\nd_inf &lt;- add_effect_field(d_inf, d_pars)\nd_fut &lt;- add_effect_field(d_fut, d_pars)\n\n\nd_fig &lt;- merge(d_sup, d_inf, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- merge(d_fig, d_fut, by = c(\"sc\", \"v\", \"variable\", \"lor_tru\", \"parname\"))\nd_fig &lt;- melt(d_fig, measure.vars = c(\"pr_sup\", \"pr_inf\", \"pr_fut\"), variable.name = \"decision_type\")\nd_fig[decision_type == \"pr_sup\", decision_type := \"Superiority\"]\nd_fig[decision_type == \"pr_inf\", decision_type := \"Inferiority\"]\nd_fig[decision_type == \"pr_fut\", decision_type := \"Futility\"]\n\n\nRepeating the simulations (500 iterations) based on a total cohort size of 500.\n\n\nCode\nggplot(d_fig, aes(x = exp(lor_tru), y = value, group = decision_type, col = decision_type)) +\n  geom_point(size = 0.5) +\n  geom_line() +\n  scale_color_discrete(\"\") +\n  scale_x_continuous(\"Odds-ratio\", breaks = seq(0, 2, by = 0.2)) +\n  scale_y_continuous(\"Pr(decide superior)\", breaks = seq(0, 1, by = 0.1)) +\n  facet_wrap(~parname, ncol = 3)\n\n\n\n\n\n\n\n\nFigure 3: Probability of declaring decision by parameter by effect size (all pars set with same OR).",
    "crumbs": [
      "Design",
      "Simulation results 1"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html",
    "href": "notebooks/sim-design2-results.html",
    "title": "Simulation results 2",
    "section": "",
    "text": "The trial is performed sequentially. Entry into silo-specific (plus surgery specific) parameters is coordinated by triggers for superiority, inferiority and futility, all defined earlier.",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html#all-treatments-effective",
    "href": "notebooks/sim-design2-results.html#all-treatments-effective",
    "title": "Simulation results 2",
    "section": "All treatments effective",
    "text": "All treatments effective\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim02-sc01\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n# cfg - decision thresholds currently static but could be varied over time\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\nd_pars &lt;- melt(d_cfg[, c(\"sc\", \"v\", \"analys\", g_effs), with = F], \n               id.vars = c(\"sc\", \"v\", \"analys\"), \n               value.name = \"lor_tru\", variable.name = \"parname\")\n\n\nd_trig &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  l[[i]]$d_trig\n\n  m &lt;- melt(l[[i]]$d_trig, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"parname\")\n  # Should be right, but just in case...\n  m[is.na(value), value := FALSE]\n  m[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, parname)]\n  m &lt;- m[, .(pr_val = mean(value)), keyby = .(analys, quant, parname)]\n  m &lt;- dcast(m, parname + analys ~ quant, value.var = \"pr_val\")\n\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\n\nd_est &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  l[[i]]$d_trig\n  # mean of means\n  # what if analysis not reached....?????\n  m &lt;- l[[i]]$d_par\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\nd_fig &lt;- melt(d_trig, id.vars = c(\"sc\", \"v\", \"analys\", \"parname\"), variable.name = \"quant\")\nd_fig &lt;- merge(d_fig, d_pars, by = c(\"sc\", \"v\", \"analys\", \"parname\"))\nd_fig[, quant := factor(quant, \n                        labels = c(\"superiority\", \"futility\", \"inferiority\"),\n                        levels = c(\"sup\", \"fut\", \"inf\"))]\nd_fig &lt;- merge(d_fig, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig[, or_tru := round(exp(lor_tru), 3)]\n\nd_fig[, or_tru := factor(\n  or_tru, \n  labels = c(\"OR 1/1.4\" ,\"OR 1/1.2\", \"OR 1\", \"OR 1.2\", \"OR 1.4\", \"OR 1.6\", \"OR 1.8\", \"OR 2\"),\n  levels = c(\"0.714\", \"0.833\", \"1\", \"1.2\", \"1.4\", \"1.6\", \"1.8\", \"2\"))]\n\nsetkey(d_fig, sc, v, analys, N_pt)\n\n\nTable 1 summarises the setup for the simulated effect sizes (from \\(\\log(1/1.4)\\) to \\(\\log(2)\\)). All parameters are simulated to have the same effect size such that all parameters are effective, show no effect or are harmful. Decision thresholds remain constant throughout the duration of the study.\n\n\nCode\nd_tbl &lt;- d_cfg[, .SD, .SDcols = !c(\"sc\",\"nsim\", \"mc_cores\", \"t_pri\", \"analys\")]\n\ng_tbl &lt;- d_tbl |&gt; gt(rowname_col = \"effect\") |&gt; \n  cols_align(\n    columns = everything(),\n    align = \"center\"\n  )  |&gt; \n  fmt_number(\n    columns = g_effs,\n    decimals = 3\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Surgical (D&lt;sub&gt;a&lt;/sub&gt;)\"),\n    columns = c(b_a_l_2, b_a_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Duration (D&lt;sub&gt;b&lt;/sub&gt;)\"),\n    columns = c(b_b1_l_2, b_b2_l_2, b_b1_c_2, b_b2_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Type (D&lt;sub&gt;c&lt;/sub&gt;)\"),\n    columns = c(b_c_2)\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Decision thresholds\"),\n    columns = c(d_sup, d_inf, d_fut)\n  ) |&gt;\n  cols_label(\n    v = html(\"Configuration\"),\n    b_a_l_2 = html(\"revision\"),\n    b_a_c_2 = html(\"two-stage\"),\n    b_b1_l_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_l_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_b1_c_2 = html(\"wk12&lt;br&gt;(post stage 1)\"),\n    b_b2_c_2 = html(\"wk12&lt;br&gt;(post stage 2)\"),\n    b_c_2 = html(\"rif\"),\n    d_sup = html(\"delta&lt;sub&gt;sup&lt;/sub&gt;\"),\n    d_inf = html(\"delta&lt;sub&gt;inf&lt;/sub&gt;\"),\n    d_fut = html(\"delta&lt;sub&gt;fut&lt;/sub&gt;\")\n  ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"bottom\"), color = \"black\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = N_pt == 2500\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nConfiguration\nN_pt\nSurgical (Da)\nDuration (Db)\nType (Dc)\nDecision thresholds\n\n\nrevision\ntwo-stage\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nwk12\n(post stage 1)\nwk12\n(post stage 2)\nrif\ndeltasup\ndeltainf\ndeltafut\n\n\n\n\nv01\n1000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv01\n1500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv01\n2000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv01\n2500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.975\n0.975\n0.1\n\n\nv02\n1000\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv02\n1500\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv02\n2000\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv02\n2500\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.182\n0.975\n0.975\n0.1\n\n\nv03\n1000\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv03\n1500\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv03\n2000\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv03\n2500\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.336\n0.975\n0.975\n0.1\n\n\nv04\n1000\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv04\n1500\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv04\n2000\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv04\n2500\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.470\n0.975\n0.975\n0.1\n\n\nv05\n1000\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv05\n1500\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv05\n2000\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv05\n2500\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.588\n0.975\n0.975\n0.1\n\n\nv06\n1000\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv06\n1500\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv06\n2000\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv06\n2500\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.693\n0.975\n0.975\n0.1\n\n\nv07\n1000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv07\n1500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv07\n2000\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv07\n2500\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n−0.182\n0.975\n0.975\n0.1\n\n\nv08\n1000\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\nv08\n1500\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\nv08\n2000\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\nv08\n2500\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n−0.336\n0.975\n0.975\n0.1\n\n\n\n\n\n\n\n\nTable 1: Parameters used to simulate treatment effects and decision thresholds\n\n\n\n\nFigure 1 shows the change in the cumulative probability of declaring each of the decision types for each parameter with changing effects size (odds ratios).\n\n\n\n\n\n\nNote\n\n\n\nThe sample size shows number of enrolled patients having reached 12-months post-randomisation.\n\n\nAs noted above, all domains are set so that the treatment effects are all equal, e.g. all set to \\(\\log(2)\\) etc. The facet labels characterise the odds ratios and the parameters reported (Table 2 is a lookup table for translating the parameter names). The interpretation of some of these parameters is quite challenging.\n\n\nCode\nd_tbl &lt;- data.table(\n  parname = as.character(unique(d_fig$parname)),\n  reflab = get_effect_ref_lev(as.character(unique(d_fig$parname))),\n  parlab = get_effect_label(as.character(unique(d_fig$parname)), do_html = F)\n)\n\ng_tbl &lt;- d_tbl |&gt; gt(rowname_col = \"parname\") |&gt; \n  cols_align(\n    columns = c(\"reflab\", \"parlab\"),\n    align = \"right\"\n  )  |&gt;\n  cols_label(\n    parname = \"Parameter\",\n    reflab = \"Ref level\",\n    parlab = \"Effect\"\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRef level\nEffect\n\n\n\n\nb_a_l_2\ndair\nrevision\n\n\nb_a_c_2\none-stage\ntwo-stage\n\n\nb_b1_l_2\nwk6 (post stage 1)\nwk12 (post stage 1)\n\n\nb_b2_l_2\nd7 (post stage 2)\nwk12 (post stage 2)\n\n\nb_b1_c_2\nwk6 (post stage 1)\nwk12 (post stage 1)\n\n\nb_b2_c_2\nd7 (post stage 2)\nwk12 (post stage 2)\n\n\nb_c_2\nnorif\nrif\n\n\n\n\n\n\n\n\nTable 2: Translation from parameter names to effects\n\n\n\n\n\n\nCode\nggplot(d_fig, aes(x = N_pt, y = value, group = quant, col = quant)) +\n  geom_point(size = 0.5) +\n  geom_line(aes(lty = quant), lwd = 0.3) +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  scale_x_continuous(\"Sample size\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Cumulative probability\", breaks = seq(0, 1, by = 0.2)) +\n  facet_grid(parname~or_tru)\n\n\n\n\n\n\n\n\nFigure 1: Probability of declaring decision by parameter by effect size (all pars set with same OR).\n\n\n\n\n\nTable 3 provides the same detail as the above figure, but makes it easier to see what the magnitudes of the cumulate probabilities are.\n\n\nCode\nd_tbl &lt;- dcast(d_fig, parname + or_tru ~ quant + analys, value.var = \"value\")\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"inferiority\", \"inf\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility\", \"fut\", names(d_tbl))\nd_tbl &lt;- d_tbl[order(or_tru, parname)]\nd_tbl[, parlab := paste0(parname, \" - \", get_effect_label(as.character(parname), do_html = F))]\nd_tbl[, parname := NULL]\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"parlab\") |&gt; \n  tab_spanner(\n    label = html(\"Superiority\"),\n    columns = c(\"sup_1\", \"sup_2\", \"sup_3\", \"sup_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility\"),\n    columns = c(\"fut_1\", \"fut_2\", \"fut_3\", \"fut_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Inferiority\"),\n    columns = c(\"inf_1\", \"inf_2\", \"inf_3\", \"inf_4\")\n  ) |&gt;\n  cols_label(\n    or_tru = html(\"OR (true)\"),\n    sup_1 = html(\"1000\"),\n    sup_2 = html(\"1500\"),\n    sup_3 = html(\"2000\"),\n    sup_4 = html(\"2500\"),\n    fut_1 = html(\"1000\"),\n    fut_2 = html(\"1500\"),\n    fut_3 = html(\"2000\"),\n    fut_4 = html(\"2500\"),\n    inf_1 = html(\"1000\"),\n    inf_2 = html(\"1500\"),\n    inf_3 = html(\"2000\"),\n    inf_4 = html(\"2500\")\n  ) |&gt;\n  tab_style(\n    style = cell_borders(\n      sides = c(\"left\"),\n      weight = px(1)),\n    locations = cells_body(\n      columns = c(sup_1, fut_1, inf_1)\n      )\n    ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or_tru == \"OR 1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\n\n\n\n\n\n\n\n\nOR (true)\nSuperiority\nFutility\nInferiority\n\n\n1000\n1500\n2000\n2500\n1000\n1500\n2000\n2500\n1000\n1500\n2000\n2500\n\n\n\n\nb_a_l_2 - revision\n\n\nOR 1/1.4\n0.000\n0.000\n0.000\n0.000\n0.662\n0.852\n0.946\n0.974\n0.398\n0.558\n0.646\n0.718\n\n\nOR 1/1.2\n0.006\n0.006\n0.006\n0.006\n0.342\n0.492\n0.614\n0.694\n0.156\n0.224\n0.278\n0.322\n\n\nOR 1\n0.016\n0.030\n0.042\n0.044\n0.082\n0.128\n0.154\n0.170\n0.010\n0.026\n0.036\n0.038\n\n\nOR 1.2\n0.128\n0.236\n0.292\n0.328\n0.014\n0.020\n0.020\n0.020\n0.000\n0.002\n0.002\n0.002\n\n\nOR 1.4\n0.348\n0.512\n0.604\n0.666\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.624\n0.770\n0.828\n0.862\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.788\n0.880\n0.914\n0.922\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.866\n0.936\n0.954\n0.968\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_a_c_2 - two-stage\n\n\nOR 1/1.4\n0.004\n0.006\n0.006\n0.006\n0.216\n0.390\n0.530\n0.618\n0.074\n0.130\n0.208\n0.286\n\n\nOR 1/1.2\n0.006\n0.006\n0.006\n0.010\n0.164\n0.266\n0.336\n0.400\n0.046\n0.086\n0.118\n0.134\n\n\nOR 1\n0.018\n0.038\n0.058\n0.064\n0.084\n0.120\n0.132\n0.156\n0.028\n0.034\n0.038\n0.044\n\n\nOR 1.2\n0.038\n0.078\n0.108\n0.130\n0.020\n0.030\n0.036\n0.038\n0.004\n0.004\n0.004\n0.008\n\n\nOR 1.4\n0.088\n0.166\n0.236\n0.300\n0.008\n0.010\n0.010\n0.010\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.180\n0.266\n0.328\n0.390\n0.006\n0.006\n0.006\n0.006\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.278\n0.400\n0.472\n0.504\n0.002\n0.004\n0.004\n0.004\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.336\n0.486\n0.570\n0.610\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_b1_l_2 - wk12 (post stage 1)\n\n\nOR 1/1.4\n0.000\n0.000\n0.000\n0.000\n0.384\n0.426\n0.440\n0.442\n0.164\n0.184\n0.186\n0.194\n\n\nOR 1/1.2\n0.006\n0.006\n0.006\n0.006\n0.220\n0.296\n0.348\n0.368\n0.064\n0.084\n0.096\n0.104\n\n\nOR 1\n0.012\n0.024\n0.032\n0.036\n0.060\n0.094\n0.120\n0.152\n0.010\n0.018\n0.022\n0.024\n\n\nOR 1.2\n0.082\n0.142\n0.192\n0.234\n0.028\n0.038\n0.050\n0.052\n0.002\n0.002\n0.002\n0.004\n\n\nOR 1.4\n0.160\n0.302\n0.406\n0.508\n0.008\n0.012\n0.012\n0.012\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.240\n0.452\n0.630\n0.716\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.302\n0.564\n0.738\n0.846\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.322\n0.628\n0.784\n0.878\n0.004\n0.004\n0.004\n0.004\n0.000\n0.000\n0.000\n0.000\n\n\nb_b2_l_2 - wk12 (post stage 2)\n\n\nOR 1/1.4\n0.002\n0.002\n0.002\n0.002\n0.394\n0.448\n0.466\n0.472\n0.166\n0.188\n0.208\n0.218\n\n\nOR 1/1.2\n0.000\n0.000\n0.000\n0.000\n0.216\n0.284\n0.322\n0.336\n0.050\n0.068\n0.086\n0.088\n\n\nOR 1\n0.016\n0.036\n0.046\n0.050\n0.080\n0.118\n0.150\n0.158\n0.026\n0.040\n0.048\n0.056\n\n\nOR 1.2\n0.064\n0.104\n0.144\n0.188\n0.022\n0.036\n0.042\n0.046\n0.000\n0.006\n0.006\n0.010\n\n\nOR 1.4\n0.158\n0.276\n0.380\n0.496\n0.010\n0.014\n0.016\n0.016\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.258\n0.434\n0.614\n0.740\n0.004\n0.006\n0.006\n0.006\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.300\n0.536\n0.748\n0.848\n0.002\n0.002\n0.002\n0.002\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.388\n0.662\n0.816\n0.908\n0.002\n0.002\n0.002\n0.002\n0.002\n0.002\n0.002\n0.002\n\n\nb_b1_c_2 - wk12 (post stage 1)\n\n\nOR 1/1.4\n0.004\n0.006\n0.006\n0.006\n0.226\n0.374\n0.486\n0.592\n0.060\n0.122\n0.200\n0.266\n\n\nOR 1/1.2\n0.000\n0.000\n0.004\n0.006\n0.154\n0.230\n0.312\n0.364\n0.050\n0.088\n0.118\n0.140\n\n\nOR 1\n0.024\n0.034\n0.052\n0.066\n0.080\n0.122\n0.144\n0.172\n0.018\n0.026\n0.040\n0.044\n\n\nOR 1.2\n0.054\n0.098\n0.134\n0.158\n0.032\n0.042\n0.052\n0.056\n0.002\n0.010\n0.012\n0.012\n\n\nOR 1.4\n0.104\n0.154\n0.204\n0.252\n0.016\n0.016\n0.018\n0.020\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.150\n0.222\n0.296\n0.344\n0.006\n0.006\n0.008\n0.008\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.224\n0.300\n0.366\n0.424\n0.004\n0.004\n0.004\n0.004\n0.002\n0.002\n0.002\n0.002\n\n\nOR 2\n0.246\n0.360\n0.448\n0.500\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_b2_c_2 - wk12 (post stage 2)\n\n\nOR 1/1.4\n0.002\n0.002\n0.002\n0.002\n0.306\n0.420\n0.480\n0.514\n0.114\n0.162\n0.180\n0.196\n\n\nOR 1/1.2\n0.010\n0.016\n0.016\n0.016\n0.200\n0.284\n0.370\n0.428\n0.064\n0.098\n0.134\n0.150\n\n\nOR 1\n0.022\n0.036\n0.046\n0.048\n0.088\n0.126\n0.148\n0.174\n0.014\n0.022\n0.032\n0.038\n\n\nOR 1.2\n0.040\n0.070\n0.102\n0.126\n0.028\n0.038\n0.054\n0.062\n0.002\n0.002\n0.004\n0.006\n\n\nOR 1.4\n0.100\n0.164\n0.230\n0.282\n0.014\n0.022\n0.028\n0.030\n0.000\n0.000\n0.000\n0.002\n\n\nOR 1.6\n0.152\n0.238\n0.374\n0.456\n0.000\n0.004\n0.004\n0.006\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.192\n0.334\n0.494\n0.596\n0.000\n0.002\n0.002\n0.002\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.190\n0.350\n0.530\n0.678\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nb_c_2 - rif\n\n\nOR 1/1.4\n0.000\n0.000\n0.000\n0.000\n0.732\n0.874\n0.938\n0.964\n0.460\n0.624\n0.716\n0.792\n\n\nOR 1/1.2\n0.002\n0.002\n0.002\n0.002\n0.364\n0.524\n0.618\n0.686\n0.174\n0.262\n0.324\n0.382\n\n\nOR 1\n0.026\n0.044\n0.058\n0.064\n0.056\n0.112\n0.140\n0.154\n0.018\n0.030\n0.040\n0.040\n\n\nOR 1.2\n0.204\n0.300\n0.380\n0.472\n0.002\n0.004\n0.008\n0.008\n0.000\n0.000\n0.002\n0.002\n\n\nOR 1.4\n0.522\n0.676\n0.806\n0.880\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.6\n0.756\n0.894\n0.950\n0.978\n0.002\n0.002\n0.002\n0.002\n0.000\n0.000\n0.000\n0.000\n\n\nOR 1.8\n0.862\n0.964\n0.994\n0.996\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\nOR 2\n0.966\n0.994\n0.998\n1.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n0.000\n\n\n\n\n\n\n\n\nTable 3: Cumulative probability of decision\n\n\n\n\nFigure 2 shows the distribution of estimated posterior means by simulated effect size, parameter and sample size.\n\n\nCode\nd_fig &lt;- d_est[, .(sc, v, sim, parname = par, analys, mu)]\nd_fig &lt;- merge(d_fig, d_pars, by = c(\"sc\", \"v\", \"analys\", \"parname\"))\nd_fig &lt;- merge(d_fig, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig[, analys := factor(analys)]\nd_fig[, N_pt := factor(N_pt)]\n\nd_fig[, or_tru := factor(\n  round(exp(lor_tru), 3), \n  labels = c(\"OR 1/1.4\" ,\"OR 1/1.2\", \"OR 1\", \"OR 1.2\", \"OR 1.4\", \"OR 1.6\", \"OR 1.8\", \"OR 2\"),\n  levels = c(\"0.714\", \"0.833\", \"1\", \"1.2\", \"1.4\", \"1.6\", \"1.8\", \"2\"))]\n\nd_fig_2 &lt;- unique(d_fig[, .(sc, or_tru, parname, lor_tru)])\n\np &lt;- ggplot(d_fig, aes(x = N_pt, y = mu)) +\n  geom_hline(data = d_fig_2, aes(yintercept = lor_tru, group = parname), col = 2) +\n  geom_boxplot() +\n  scale_x_discrete(\"\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Distribution of posterior mean\") +\n  facet_grid(parname~or_tru)\n\nsuppressWarnings(print(p))\n\n\n\n\n\n\n\n\nFigure 2: Distribution of posterior means (true log OR shown in red).",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/sim-design2-results.html#single-effective-treatment",
    "href": "notebooks/sim-design2-results.html#single-effective-treatment",
    "title": "Simulation results 2",
    "section": "Single effective treatment",
    "text": "Single effective treatment\n\n\nCode\nflist &lt;- list.files(\"data\", pattern = \"sim02-sc02\")\ntoks &lt;- list()\nl &lt;- list()\nfor(i in 1:length(flist)){\n  l[[i]] &lt;- qs::qread(file.path(\"data\", flist[i]))\n  toks[[i]] &lt;-  unlist(tstrsplit(flist[i], \"[-.]\"))\n}\n\n# cfg - decision thresholds currently static but could be varied over time\nd_cfg &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  m &lt;- data.table(do.call(cbind, l[[i]]$cfg))\n  data.table(cbind(sc = tok[2], v = tok[3], analys = 1:nrow(m), m))\n}))\n\nd_pars &lt;- melt(d_cfg[, c(\"sc\", \"v\", \"analys\", g_effs), with = F], \n               id.vars = c(\"sc\", \"v\", \"analys\"), \n               value.name = \"lor_tru\", variable.name = \"parname\")\n\n\nd_trig &lt;- rbindlist(lapply(seq_along(l), function(i){\n  tok &lt;- toks[[i]]\n  l[[i]]$d_trig\n\n  m &lt;- melt(l[[i]]$d_trig, id.vars = c(\"sim\", \"analys\", \"quant\"), variable.name = \"parname\")\n  # Should be right, but just in case...\n  m[is.na(value), value := FALSE]\n  m[, value := as.logical(cumsum(value)&gt;0), keyby = .(sim, quant, parname)]\n  m &lt;- m[, .(pr_val = mean(value)), keyby = .(analys, quant, parname)]\n  m &lt;- dcast(m, parname + analys ~ quant, value.var = \"pr_val\")\n\n  cbind(sc = tok[2], v = tok[3], m)\n}))\n\nd_fig &lt;- melt(d_trig, id.vars = c(\"sc\", \"v\", \"analys\", \"parname\"), variable.name = \"quant\")\nd_fig &lt;- merge(d_fig, d_pars, by = c(\"sc\", \"v\", \"analys\", \"parname\"))\nd_fig[, quant := factor(quant, \n                        labels = c(\"superiority\", \"futility\", \"inferiority\"),\n                        levels = c(\"sup\", \"fut\", \"inf\"))]\nd_fig &lt;- merge(d_fig, unique(d_cfg[, .(analys, N_pt)]), by = \"analys\")\n\nd_fig[, or_tru := round(exp(lor_tru), 3)]\n\nd_fig[, or_tru := factor(\n  or_tru, \n  labels = c(\"OR 1/1.4\" ,\"OR 1/1.2\", \"OR 1\", \"OR 1.2\", \"OR 1.4\", \"OR 1.6\", \"OR 1.8\", \"OR 2\"),\n  levels = c(\"0.714\", \"0.833\", \"1\", \"1.2\", \"1.4\", \"1.6\", \"1.8\", \"2\"))]\n\nsetkey(d_fig, sc, v, analys, N_pt)\n\n\n\n\nCode\nggplot(d_fig, aes(x = N_pt, y = value, group = quant, col = quant)) +\n  geom_point(size = 0.5) +\n  geom_line(aes(lty = quant), lwd = 0.3) +\n  scale_color_discrete(\"\") +\n  scale_linetype_discrete(\"\") +\n  scale_x_continuous(\"Sample size\", guide = guide_axis(angle = 45)) +\n  scale_y_continuous(\"Cumulative probability\", breaks = seq(0, 1, by = 0.2)) +\n  facet_grid(parname~or_tru)\n\n\nTable 4 provides the same detail as the above figure, but makes it easier to see what the magnitudes of the cumulate probabilities are.\n\n\n\n\nCode\nd_tbl &lt;- dcast(d_fig, parname + or_tru ~ quant + analys, value.var = \"value\")\nnames(d_tbl) &lt;- gsub(\"superiority\", \"sup\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"inferiority\", \"inf\", names(d_tbl))\nnames(d_tbl) &lt;- gsub(\"futility\", \"fut\", names(d_tbl))\nd_tbl &lt;- d_tbl[order(or_tru, parname)]\nd_tbl[, parlab := paste0(parname, \" - \", get_effect_label(as.character(parname), do_html = F))]\nd_tbl[, parname := NULL]\n\ng_tbl &lt;- d_tbl |&gt; gt(groupname_col = \"parlab\") |&gt; \n  tab_spanner(\n    label = html(\"Superiority\"),\n    columns = c(\"sup_1\", \"sup_2\", \"sup_3\", \"sup_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Futility\"),\n    columns = c(\"fut_1\", \"fut_2\", \"fut_3\", \"fut_4\")\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Inferiority\"),\n    columns = c(\"inf_1\", \"inf_2\", \"inf_3\", \"inf_4\")\n  ) |&gt;\n  cols_label(\n    or_tru = html(\"OR (true)\"),\n    sup_1 = html(\"1000\"),\n    sup_2 = html(\"1500\"),\n    sup_3 = html(\"2000\"),\n    sup_4 = html(\"2500\"),\n    fut_1 = html(\"1000\"),\n    fut_2 = html(\"1500\"),\n    fut_3 = html(\"2000\"),\n    fut_4 = html(\"2500\"),\n    inf_1 = html(\"1000\"),\n    inf_2 = html(\"1500\"),\n    inf_3 = html(\"2000\"),\n    inf_4 = html(\"2500\")\n  ) |&gt;\n  tab_style(\n    style = cell_borders(\n      sides = c(\"left\"),\n      weight = px(1)),\n    locations = cells_body(\n      columns = c(sup_1, fut_1, inf_1)\n      )\n    ) |&gt;\n  tab_style(\n    style = list(\n      cell_borders(\n        sides = c(\"top\", \"bottom\"), color = \"red\", weight = px(1), style = \"solid\"\n      )),\n    locations = list(\n      cells_body(\n        columns = everything(),\n        rows = or_tru == \"OR 1\"\n      )\n    )\n  ) |&gt;\n  tab_options(\n    table.font.size = \"80%\"\n  ) \n\ng_tbl\n\n\n\nTable 4: Cumulative probability of decision",
    "crumbs": [
      "Design",
      "Simulation results 2"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html",
    "href": "notebooks/example-trials.html",
    "title": "Example trials",
    "section": "",
    "text": "Example trials are provided to give insight into the cell sizes as well as the level of uncertainty associated with the parameter estimation process. Examples are from trials at their maximum sample size with all follow up completed. Sequential variants with adaptations will be added later.",
    "crumbs": [
      "Design",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html#null-scenario",
    "href": "notebooks/example-trials.html#null-scenario",
    "title": "Example trials",
    "section": "Null scenario",
    "text": "Null scenario\nTable 1 shows a summary of the treatment sucesses based on the \\(n\\) patients associated with each combination of design variables when no treatment effects (non-membership effects still retained) in the simulated data of 2500 patients. Given that this is a summary of a single data set, some variation from the underlying simulation parameters is to be expected.\n\n\nCode\nsim_spec &lt;- get_sim_spec()\nsim_spec$b_a_late[\"rev\"] &lt;- 0\nsim_spec$b_a_chronic[\"two\"] &lt;- 0\nsim_spec$b_b1_late_one[\"w12p1\"] &lt;- 0\nsim_spec$b_b2_late_two[\"w12p2\"] &lt;- 0\nsim_spec$b_b1_chronic_one[\"w12p1\"] &lt;- 0\nsim_spec$b_b2_chronic_two[\"w12p2\"] &lt;- 0\nsim_spec$b_c[\"rif\"] &lt;- 0\n\nset.seed(15)\nll &lt;- get_trial_data(N = 2500, pop_spec = NULL, sim_spec = sim_spec)\n\ngt_tbl &lt;- tbl_ex_trial(ll$d)\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSurgical Da\nDuration Db\nType Dc\nResponse\n\n\nmember\nassigned\nplan\nmember\nassigned1\nmember\nassigned\ny\nn\nMLE (py)\nTRUE (py)2\n\n\n\n\nearly - knee\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n77\n122\n0.63\n0.63\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n62\n93\n0.67\n0.65\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n60\n93\n0.65\n0.65\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n199\n308\n0.65\n—\n\n\nearly - hip\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n147\n199\n0.74\n0.73\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n108\n137\n0.79\n0.75\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n85\n123\n0.69\n0.75\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n340\n459\n0.74\n—\n\n\nlate - knee\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n29\n58\n0.50\n0.52\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n26\n55\n0.47\n0.55\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n32\n47\n0.68\n0.55\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n15\n30\n0.50\n0.52\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n7\n14\n0.50\n0.55\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n9\n17\n0.53\n0.55\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n8\n20\n0.40\n0.52\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n6\n10\n0.60\n0.55\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n6\n12\n0.50\n0.55\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n11\n22\n0.50\n0.52\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n8\n15\n0.53\n0.55\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n10\n18\n0.56\n0.55\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n16\n26\n0.62\n0.52\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n4\n6\n0.67\n0.55\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n5\n8\n0.62\n0.55\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n192\n358\n0.54\n—\n\n\nlate - hip\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n88\n170\n0.52\n0.57\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n76\n120\n0.63\n0.60\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n80\n127\n0.63\n0.60\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n22\n37\n0.59\n0.57\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n16\n26\n0.62\n0.60\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n18\n33\n0.55\n0.60\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n32\n52\n0.62\n0.57\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n13\n28\n0.46\n0.60\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n14\n28\n0.50\n0.60\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n21\n37\n0.57\n0.57\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n17\n33\n0.52\n0.60\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n23\n33\n0.70\n0.60\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n23\n44\n0.52\n0.57\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n18\n29\n0.62\n0.60\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n20\n30\n0.67\n0.60\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n481\n827\n0.58\n—\n\n\nchronic - knee\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n15\n27\n0.56\n0.57\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n11\n25\n0.44\n0.60\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n11\n16\n0.69\n0.60\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n14\n20\n0.70\n0.57\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n15\n22\n0.68\n0.60\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n16\n26\n0.62\n0.60\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n22\n34\n0.65\n0.57\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n13\n22\n0.59\n0.60\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n9\n24\n0.38\n0.60\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n14\n28\n0.50\n0.57\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n5\n15\n0.33\n0.60\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n13\n23\n0.57\n0.60\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n158\n282\n0.56\n—\n\n\nchronic - hip\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n19\n27\n0.70\n0.63\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n14\n24\n0.58\n0.65\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n13\n17\n0.76\n0.65\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n8\n19\n0.42\n0.63\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n15\n24\n0.62\n0.65\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n17\n22\n0.77\n0.65\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n10\n22\n0.45\n0.63\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n16\n27\n0.59\n0.65\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n10\n19\n0.53\n0.65\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n21\n29\n0.72\n0.63\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n13\n23\n0.57\n0.65\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n7\n13\n0.54\n0.65\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n163\n266\n0.61\n—\n\n\ntotal\n—\n—\n—\n—\n—\n—\n—\n1533\n2500\n0.61\n—\n\n\n\n1 w06p1 = 6 weeks following one-stage procedure, w12p1 = 12 weeks following one-stage procedure etc\n\n\n2 Transformed from the log-odds of response as used in the linear predictor to simulate data.\n\n\n\n\n\n\n\n\n\nTable 1: Summary of simulated trial data when no treatment effects present\n\n\n\n\nModel the simulated data first using standard normal priors on the domain level treatment effects, then increasing the prior standard deviation to ten in order to see if there is any movement in the posterior summary.\n\n\nCode\nlsd &lt;- get_stan_data(ll$d_i)\nld &lt;- lsd$ld\nd_b &lt;- copy(lsd$d_b)\n\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-02.stan\")\n\nf_null_1 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.5 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.6 seconds.\n\n\nCode\npost_1 &lt;- data.table(f_null_1$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n# compare when prior sd is set to 10 for trt effects\n\npri_sd &lt;- 10\nld$pri_sig_b_c &lt;- pri_sd\nld$pri_sig_a_l &lt;- pri_sd\nld$pri_sig_b1_l &lt;- pri_sd\nld$pri_sig_b2_l &lt;- pri_sd\nld$pri_sig_a_c &lt;- pri_sd\nld$pri_sig_b1_c &lt;- pri_sd\nld$pri_sig_b2_c &lt;- pri_sd\n\nf_null_2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.5 seconds.\nChain 2 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.5 seconds.\nTotal execution time: 0.5 seconds.\n\n\nCode\npost_2 &lt;- data.table(f_null_2$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n\n\n\nCode\nd_fig1 &lt;- post_alpha(post_1)\nd_fig2 &lt;- post_alpha(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = grp, y = a, group = prior_sd, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-odds treatment success\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = grp, y = a_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = a_q025, ymax = a_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = grp, y = a), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 1: Posterior median and 95% CI for baseline log-odds of treatment success (triangles show true values).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_a(post_1)\nd_fig2 &lt;- post_dom_a(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 2: Posterior median and 95% CI for baseline log-odds of treatment success domain A (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_b(post_1)\nd_fig2 &lt;- post_dom_b(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(paste0(\"Planned/assigned surgery: \", qa, \"-stage\")~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 3: Posterior median and 95% CI for baseline log-odds of treatment success domain B (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_c(post_1)\nd_fig2 &lt;- post_dom_c(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 4: Posterior median and 95% CI for baseline log-odds of treatment success in domain C (effect is pooled across all silos).",
    "crumbs": [
      "Design",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/example-trials.html#all-domains-effective-scenario",
    "href": "notebooks/example-trials.html#all-domains-effective-scenario",
    "title": "Example trials",
    "section": "All domains effective scenario",
    "text": "All domains effective scenario\nshows a summary of the treatment sucesses based on the \\(n\\) patients associated with each combination of design variables when all treatment effects set to log(2) (with non-membership effects retained as before) in the simulated data of 2500 patients.\n\n\nCode\nsim_spec &lt;- get_sim_spec()\nsim_spec$b_a_late[\"rev\"] &lt;- log(2)\nsim_spec$b_a_chronic[\"two\"] &lt;- log(2)\nsim_spec$b_b1_late_one[\"w12p1\"] &lt;- log(2)\nsim_spec$b_b2_late_two[\"w12p2\"] &lt;- log(2)\nsim_spec$b_b1_chronic_one[\"w12p1\"] &lt;- log(2)\nsim_spec$b_b2_chronic_two[\"w12p2\"] &lt;- log(2)\nsim_spec$b_c[\"rif\"] &lt;- log(2)\n\nset.seed(222)\nll &lt;- get_trial_data(N = 2500, pop_spec = NULL, sim_spec = sim_spec)\n\n# just wrapped table generation up into a function to save space and min repitition, see util.R\ngt_tbl &lt;- tbl_ex_trial(ll$d)\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nSurgical Da\nDuration Db\nType Dc\nResponse\n\n\nmember\nassigned\nplan\nmember\nassigned1\nmember\nassigned\ny\nn\nMLE (py)\nTRUE (py)2\n\n\n\n\nearly - knee\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n99\n137\n0.72\n0.63\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n73\n103\n0.71\n0.65\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n68\n81\n0.84\n0.79\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n240\n321\n0.75\n—\n\n\nearly - hip\n\n\n\nN\ndair\ndair\nN\nw12\nN\nother\n147\n189\n0.78\n0.73\n\n\n\nN\ndair\ndair\nN\nw12\nY\nnorif\n112\n144\n0.78\n0.75\n\n\n\nN\ndair\ndair\nN\nw12\nY\nrif\n117\n135\n0.87\n0.86\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n376\n468\n0.80\n—\n\n\nlate - knee\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n48\n80\n0.60\n0.52\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n20\n48\n0.42\n0.55\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n37\n51\n0.73\n0.71\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n13\n25\n0.52\n0.69\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n11\n15\n0.73\n0.71\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n15\n16\n0.94\n0.83\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n10\n11\n0.91\n0.81\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n12\n16\n0.75\n0.83\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n12\n13\n0.92\n0.91\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n8\n16\n0.50\n0.69\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n10\n12\n0.83\n0.71\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n17\n19\n0.89\n0.83\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n18\n21\n0.86\n0.81\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n9\n12\n0.75\n0.83\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n10\n10\n1.00\n0.91\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n250\n365\n0.68\n—\n\n\nlate - hip\n\n\n\nY\ndair\ndair\nN\nw12\nN\nother\n83\n154\n0.54\n0.57\n\n\n\nY\ndair\ndair\nN\nw12\nY\nnorif\n69\n114\n0.61\n0.60\n\n\n\nY\ndair\ndair\nN\nw12\nY\nrif\n91\n124\n0.73\n0.75\n\n\n\nY\nrev\none\nY\nw06p1\nN\nother\n36\n47\n0.77\n0.73\n\n\n\nY\nrev\none\nY\nw06p1\nY\nnorif\n29\n44\n0.66\n0.75\n\n\n\nY\nrev\none\nY\nw06p1\nY\nrif\n40\n42\n0.95\n0.86\n\n\n\nY\nrev\none\nY\nw12p1\nN\nother\n36\n44\n0.82\n0.84\n\n\n\nY\nrev\none\nY\nw12p1\nY\nnorif\n38\n44\n0.86\n0.86\n\n\n\nY\nrev\none\nY\nw12p1\nY\nrif\n23\n25\n0.92\n0.92\n\n\n\nY\nrev\ntwo\nY\nd07p2\nN\nother\n21\n32\n0.66\n0.73\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nnorif\n22\n32\n0.69\n0.75\n\n\n\nY\nrev\ntwo\nY\nd07p2\nY\nrif\n30\n35\n0.86\n0.86\n\n\n\nY\nrev\ntwo\nY\nw12p2\nN\nother\n47\n56\n0.84\n0.84\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nnorif\n34\n37\n0.92\n0.86\n\n\n\nY\nrev\ntwo\nY\nw12p2\nY\nrif\n34\n37\n0.92\n0.92\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n633\n867\n0.73\n—\n\n\nchronic - knee\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n16\n25\n0.64\n0.57\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n9\n17\n0.53\n0.60\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n12\n15\n0.80\n0.75\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n17\n22\n0.77\n0.73\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n10\n13\n0.77\n0.75\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n16\n18\n0.89\n0.86\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n14\n23\n0.61\n0.73\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n11\n16\n0.69\n0.75\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n12\n13\n0.92\n0.86\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n21\n24\n0.88\n0.84\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n16\n19\n0.84\n0.86\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n12\n13\n0.92\n0.92\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n166\n218\n0.76\n—\n\n\nchronic - hip\n\n\n\nY\none\none\nY\nw06p1\nN\nother\n12\n19\n0.63\n0.63\n\n\n\nY\none\none\nY\nw06p1\nY\nnorif\n13\n21\n0.62\n0.65\n\n\n\nY\none\none\nY\nw06p1\nY\nrif\n12\n19\n0.63\n0.79\n\n\n\nY\none\none\nY\nw12p1\nN\nother\n25\n30\n0.83\n0.77\n\n\n\nY\none\none\nY\nw12p1\nY\nnorif\n10\n11\n0.91\n0.79\n\n\n\nY\none\none\nY\nw12p1\nY\nrif\n20\n23\n0.87\n0.88\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nN\nother\n21\n26\n0.81\n0.77\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nnorif\n19\n24\n0.79\n0.79\n\n\n\nY\ntwo\ntwo\nY\nd07p2\nY\nrif\n12\n12\n1.00\n0.88\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nN\nother\n28\n31\n0.90\n0.87\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nnorif\n24\n28\n0.86\n0.88\n\n\n\nY\ntwo\ntwo\nY\nw12p2\nY\nrif\n15\n17\n0.88\n0.94\n\n\nsubtotal\n—\n—\n—\n—\n—\n—\n—\n211\n261\n0.81\n—\n\n\ntotal\n—\n—\n—\n—\n—\n—\n—\n1876\n2500\n0.75\n—\n\n\n\n1 w06p1 = 6 weeks following one-stage procedure, w12p1 = 12 weeks following one-stage procedure etc\n\n\n2 Transformed from the log-odds of response as used in the linear predictor to simulate data.\n\n\n\n\n\n\n\n\n\nTable 2: Summary of simulated trial data when no treatment effects present\n\n\n\n\n\n\nCode\nlsd &lt;- get_stan_data(ll$d_i)\nld &lt;- lsd$ld\nd_b &lt;- copy(lsd$d_b)\n\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/model-sim-02.stan\")\n\nf_alleff_1 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 2 finished in 0.4 seconds.\nChain 1 finished in 0.5 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.5 seconds.\n\n\nCode\npost_1 &lt;- data.table(f_alleff_1$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n# compare when prior sd is set to 10 for trt effects\n\npri_sd &lt;- 10\nld$pri_sig_b_c &lt;- pri_sd\nld$pri_sig_a_l &lt;- pri_sd\nld$pri_sig_b1_l &lt;- pri_sd\nld$pri_sig_b2_l &lt;- pri_sd\nld$pri_sig_a_c &lt;- pri_sd\nld$pri_sig_b1_c &lt;- pri_sd\nld$pri_sig_b2_c &lt;- pri_sd\n\nf_alleff_2 &lt;- m2$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, \n  max_treedepth = 13)\n\n\nRunning MCMC with 2 parallel chains...\n\nChain 1 finished in 0.4 seconds.\nChain 2 finished in 0.4 seconds.\n\nBoth chains finished successfully.\nMean chain execution time: 0.4 seconds.\nTotal execution time: 0.5 seconds.\n\n\nCode\npost_2 &lt;- data.table(f_alleff_2$draws(variables = c(\n  \"alpha\", \"gamma_c\", \n  \"b_a_l\", \n  \"b_b1_l\", \n  \"b_b2_l\",\n  \"b_a_c\",\n  \"b_b1_c\", \n  \"b_b2_c\",\n  \"b_c\"\n), format = \"matrix\"))\n\n\n\n\nCode\nd_fig1 &lt;- post_alpha(post_1)\nd_fig2 &lt;- post_alpha(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = grp, y = a, group = prior_sd, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-odds treatment success\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = grp, y = a_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = a_q025, ymax = a_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = grp, y = a), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 5: Posterior median and 95% CI for baseline log-odds of treatment success (triangles show true values).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_a(post_1)\nd_fig2 &lt;- post_dom_a(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 6: Posterior median and 95% CI for baseline log-odds of treatment success domain A (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_b(post_1)\nd_fig2 &lt;- post_dom_b(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\n# https://www.andrewheiss.com/blog/2022/12/08/log10-natural-log-scales-ggplot/\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2) +\n  facet_grid(paste0(\"Planned/assigned surgery: \", qa, \"-stage\")~silo,scale=\"free_x\",space=\"free_x\")\n\n\n\n\n\n\n\n\nFigure 7: Posterior median and 95% CI for baseline log-odds of treatment success domain B (independent estimates for late and chronic silo).\n\n\n\n\n\n\n\nCode\nd_fig1 &lt;- post_dom_c(post_1)\nd_fig2 &lt;- post_dom_c(post_2)\n\nd_fig &lt;- rbind(\n  cbind(prior_sd = 1, d_fig1),\n  cbind(prior_sd = pri_sd, d_fig2)\n)\nd_fig[, prior_sd := factor(prior_sd, levels = c(1, pri_sd))]\n\nggplot(d_fig, aes(x = trt, y = b, col = prior_sd)) +\n  scale_x_discrete(\"\") +\n  scale_y_continuous(\"log-OR\") + \n  scale_color_discrete(\"Prior sd on log-OR domain trt effects\") +\n  geom_point(data = d_fig, aes(x = trt, y = b_med), position = position_dodge(width = 0.4)) +\n  geom_linerange(aes(ymin = b_q025, ymax = b_q975), position = position_dodge2(width = 0.4)) +\n  geom_point(data = d_fig, aes(x = trt, y = b), col = 1, pch = 2)\n\n\n\n\n\n\n\n\nFigure 8: Posterior median and 95% CI for baseline log-odds of treatment success in domain C (effect is pooled across all silos).",
    "crumbs": [
      "Design",
      "Example trials"
    ]
  },
  {
    "objectID": "notebooks/trial-data.html",
    "href": "notebooks/trial-data.html",
    "title": "Simulated trial data",
    "section": "",
    "text": "Trial data is simulated under the model specification, see earlier section. The sub-totals sum to the size of the subset (e.g. patients under late stage infection) and not the size of the total sample. The missingness is a consequence of the partial factorial structure.\n\n\nCode\nset.seed(25)\nll &lt;- get_trial_data(N = 2500)\n\nd &lt;- copy(ll$d)\n\n\nTable 1 shows the allocation to (late stage infection) dair vs rev and the balance across the remaining group levels in the data.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[silo == \"late\", .(ea, a, eb, b)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(a, eb, b)]\nd_B &lt;- dcast(d_tmp2, eb + b ~ a, value.var = \"N\")\nd_B[, domain := \"B\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", \"dair\", \"rev\", \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[silo == \"late\", .(ea, a, ec, c)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(a, ec, c)]\nd_C &lt;- dcast(d_tmp2, ec + c ~ a, value.var = \"N\")\nd_C[, domain := \"C\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", \"dair\", \"rev\", \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C)\nd_tbl[, group := factor(group, levels = c(\"w12\",\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\", \"other\", \"norif\", \"rif\"))]\nd_tbl[domain == \"B\", domain := \"AB Duration\"]\nd_tbl[domain == \"C\", domain := \"AB Type\"]\nd_tbl &lt;- d_tbl[order(domain, rand, group)]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", \"DAIR\", \"Revision\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  )  |&gt;\n  tab_spanner(\n    label = html(\"Domain A (late silo)\"),\n    columns = c(dair, rev)\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols) |&gt; \n  summary_rows(\n    columns = c(\"dair\", \"rev\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  ) \n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nDomain A (late silo)\n\n\nDAIR\nRevision\n\n\n\n\nAB Duration\n\n\n\nN\nw12\n627\n-\n\n\n\nY\nw06p1\n-\n141\n\n\n\nY\nw12p1\n-\n150\n\n\n\nY\nd07p2\n-\n150\n\n\n\nY\nw12p2\n-\n155\n\n\nsubtotal\n—\n—\n627\n596\n\n\nAB Type\n\n\n\nN\nother\n241\n244\n\n\n\nY\nnorif\n195\n184\n\n\n\nY\nrif\n191\n168\n\n\nsubtotal\n—\n—\n627\n596\n\n\n\n\n\n\n\n\nTable 1: Simulated trial data for (late silo) surgical domain - covariate balance across other groups\n\n\n\n\nTable 2 shows the allocation to (chronic stage infection) one vs two-stage and the balance across the remaining group levels in the data.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[silo == \"chronic\", .(ea, a, eb, b)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(a, eb, b)]\nd_B &lt;- dcast(d_tmp2, eb + b ~ a, value.var = \"N\")\nd_B[, domain := \"B\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", \"one\", \"two\", \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[silo == \"chronic\", .(ea, a, ec, c)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(a, ec, c)]\nd_C &lt;- dcast(d_tmp2, ec + c ~ a, value.var = \"N\")\nd_C[, domain := \"C\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", \"one\", \"two\", \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C)\nd_tbl[, group := factor(group, levels = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\", \"other\", \"norif\", \"rif\"))]\nd_tbl &lt;- d_tbl[order(domain, rand, group)]\n\nd_tbl[domain == \"B\", domain := \"AB Duration\"]\nd_tbl[domain == \"C\", domain := \"AB Type\"]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", \"One-stage\", \"Two-stage\")\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  )  |&gt; \n  summary_rows(\n    columns = c(\"one\", \"two\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )   |&gt;\n  tab_spanner(\n    label = html(\"Domain A (chronic silo)\"),\n    columns = c(one, two)\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nDomain A (chronic silo)\n\n\nOne-stage\nTwo-stage\n\n\n\n\nAB Duration\n\n\n\nY\nw06p1\n132\n-\n\n\n\nY\nw12p1\n135\n-\n\n\n\nY\nd07p2\n-\n124\n\n\n\nY\nw12p2\n-\n131\n\n\nsubtotal\n—\n—\n267\n255\n\n\nAB Type\n\n\n\nN\nother\n103\n95\n\n\n\nY\nnorif\n100\n78\n\n\n\nY\nrif\n64\n82\n\n\nsubtotal\n—\n—\n267\n255\n\n\n\n\n\n\n\n\nTable 2: Simulated trial data for (chronic silo) surgical domain - covariate balance across other groups\n\n\n\n\nTable 3 shows the allocation to (late stage infection) dair vs rev and the balance across the remaining group levels in the data. The subsequent tables show analogous summaries.\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[silo == \"late\", .(eb, b, ea, a, qa)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(b, ea, a, qa)]\nd_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_B &lt;- dcast(d_tmp2, ea + a + qa ~ b, value.var = \"N\")\nd_B[, domain := \"A\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", \"plan\", c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[silo == \"late\", .(eb, b, ec, c)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(b, ec, c)]\nd_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_C &lt;- dcast(d_tmp2, ec + c ~ b, value.var = \"N\")\nd_C[, domain := \"C\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"), \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C, fill = T)\nd_tbl[domain == \"A\", domain := \"AB Duration\"]\nd_tbl[domain == \"C\", domain := \"AB Type\"]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", \"Plan\",c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt; \n  summary_rows(\n    columns = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )   |&gt;\n  tab_spanner(\n    label = html(\"Domain B (late silo)\"),\n    columns = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\")\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nPlan\nDomain B (late silo)\n\n\nw12\nw06p1\nw12p1\nd07p2\nw12p2\n\n\n\n\nAB Duration\n\n\n\nY\ndair\ndair\n627\n-\n-\n-\n-\n\n\n\nY\nrev\none\n-\n141\n150\n-\n-\n\n\n\nY\nrev\ntwo\n-\n-\n-\n150\n155\n\n\nsubtotal\n—\n—\n—\n627\n141\n150\n150\n155\n\n\nAB Type\n\n\n\nN\nother\n-\n241\n63\n58\n62\n61\n\n\n\nY\nnorif\n-\n195\n43\n52\n47\n42\n\n\n\nY\nrif\n-\n191\n35\n40\n41\n52\n\n\nsubtotal\n—\n—\n—\n627\n141\n150\n150\n155\n\n\n\n\n\n\n\n\nTable 3: Simulated trial data for (late silo) duration domain - covariate balance across other groups\n\n\n\n\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[silo == \"chronic\", .(eb, b, ea, a)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(b, ea, a)]\nd_tmp2[, b := factor(b, levels = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_B &lt;- dcast(d_tmp2, ea + a ~ b, value.var = \"N\")\nd_B[, domain := \"A\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n# domain C\nd_tmp1 &lt;- d[silo == \"chronic\", .(eb, b, ec, c)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(b, ec, c)]\nd_tmp2[, b := factor(b, levels = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_C &lt;- dcast(d_tmp2, ec + c ~ b, value.var = \"N\")\nd_C[, domain := \"C\"]\ncolnames(d_C) &lt;- c(\"rand\", \"group\", c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"), \"domain\")\nsetcolorder(d_C, \"domain\")\n\nd_tbl &lt;- rbind(d_B, d_C, fill = T)\nd_tbl[domain == \"A\", domain := \"AB Duration\"]\nd_tbl[domain == \"C\", domain := \"AB Type\"]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt;\n  summary_rows(\n    columns = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  )   |&gt;\n  tab_spanner(\n    label = html(\"Domain B (chronic silo)\"),\n    columns = c(\"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\")\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nDomain B (chronic silo)\n\n\nw06p1\nw12p1\nd07p2\nw12p2\n\n\n\n\nAB Duration\n\n\n\nY\none\n132\n135\n-\n-\n\n\n\nY\ntwo\n-\n-\n124\n131\n\n\nsubtotal\n—\n—\n132\n135\n124\n131\n\n\nAB Type\n\n\n\nN\nother\n54\n49\n42\n53\n\n\n\nY\nnorif\n44\n56\n40\n38\n\n\n\nY\nrif\n34\n30\n42\n40\n\n\nsubtotal\n—\n—\n132\n135\n124\n131\n\n\n\n\n\n\n\n\nTable 4: Simulated trial data for (chronic silo) duration domain - covariate balance across other groups\n\n\n\n\n\n\nCode\n# domain B\nd_tmp1 &lt;- d[, .(c, ea, a, qa)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(c, ea, a, qa)]\nd_tmp2[, a := factor(a, levels = c(\"dair\", \"rev\", \"one\", \"two\"))]\nd_tmp2[, qa := factor(qa, levels = c(\"dair\", \"one\", \"two\"))]\nd_tmp2[, c := factor(c, levels = c(\"other\", \"norif\", \"rif\"))]\nd_A &lt;- dcast(d_tmp2, ea + a + qa ~ c, value.var = \"N\")\nd_A[, domain := \"A\"]\ncolnames(d_A) &lt;- c(\"rand\", \"group\", \"plan\", c(\"other\", \"norif\", \"rif\"), \"domain\")\nsetcolorder(d_A, \"domain\")\n# domain B\nd_tmp1 &lt;- d[, .(c, eb, b)]\nd_tmp2 &lt;- d_tmp1[, .N, keyby = .(c, eb, b)]\nd_tmp2[, b := factor(b, levels = c(\"w12\", \"w06p1\", \"w12p1\", \"d07p2\", \"w12p2\"))]\nd_tmp2[, c := factor(c, levels = c(\"other\", \"norif\", \"rif\"))]\nd_B &lt;- dcast(d_tmp2, eb + b ~ c, value.var = \"N\")\nd_B[, domain := \"B\"]\ncolnames(d_B) &lt;- c(\"rand\", \"group\", c(\"other\", \"norif\", \"rif\"), \"domain\")\nsetcolorder(d_B, \"domain\")\n\nd_tbl &lt;- rbind(d_A, d_B, fill = T)\nd_tbl[domain == \"A\", domain := \"Surgical\"]\nd_tbl[domain == \"B\", domain := \"AB Duration\"]\n\ncols &lt;- c(\"Domain\", \"Randomised\", \"Treatment\", \"Plan\", c(\"other\", \"norif\", \"rif\"))\nnames(cols) &lt;- names(d_tbl)\n\ngt_tbl &lt;- d_tbl |&gt; \n  gt(groupname_col = \"domain\"\n  ) |&gt; \n  summary_rows(\n    columns = c(\"other\", \"norif\", \"rif\"),\n    fns = list(\n      subtotal = ~ sum(., na.rm = TRUE)\n    )\n  ) |&gt;\n  tab_spanner(\n    label = html(\"Domain C\"),\n    columns = c(\"other\", \"norif\", \"rif\")\n  ) |&gt;\n  sub_missing(\n    columns = everything(),\n    missing_text = \"-\"\n  ) |&gt;\n  cols_label(.list = cols)\n\ngt_tbl\n\n\n\n\n\n\n\n\n\n\n\n\nRandomised\nTreatment\nPlan\nDomain C\n\n\nother\nnorif\nrif\n\n\n\n\nSurgical\n\n\n\nN\ndair\ndair\n295\n237\n223\n\n\n\nY\ndair\ndair\n241\n195\n191\n\n\n\nY\nrev\none\n121\n95\n75\n\n\n\nY\nrev\ntwo\n123\n89\n93\n\n\n\nY\none\none\n103\n100\n64\n\n\n\nY\ntwo\ntwo\n95\n78\n82\n\n\nsubtotal\n—\n—\n—\n978\n794\n728\n\n\nAB Duration\n\n\n\nN\nw12\n-\n536\n432\n414\n\n\n\nY\nw06p1\n-\n117\n87\n69\n\n\n\nY\nw12p1\n-\n107\n108\n70\n\n\n\nY\nd07p2\n-\n104\n87\n83\n\n\n\nY\nw12p2\n-\n114\n80\n92\n\n\nsubtotal\n—\n—\n—\n978\n794\n728\n\n\n\n\n\n\n\n\nTable 5: Simulated trial data for surgical domain - covariate balance across other groups",
    "crumbs": [
      "Design",
      "Simulated trial data"
    ]
  },
  {
    "objectID": "notebooks/estimands.html",
    "href": "notebooks/estimands.html",
    "title": "Estimands in complex designs",
    "section": "",
    "text": "Are designed to permit the evaluation of multiple interventions in a perpetual manner under a single protocol establishing a common infrastructure and analysis plan. Interventions can be added and withdrawn at different times based on need and the control group may be revised as the trial progresses. Platform trials can include adaptive elements (commonly stopping rules and adaptive randomisations) that allow design variations based on accruing evidence."
  },
  {
    "objectID": "notebooks/estimands.html#platform-trials",
    "href": "notebooks/estimands.html#platform-trials",
    "title": "Estimands in complex designs",
    "section": "",
    "text": "Are designed to permit the evaluation of multiple interventions in a perpetual manner under a single protocol establishing a common infrastructure and analysis plan. Interventions can be added and withdrawn at different times based on need and the control group may be revised as the trial progresses. Platform trials can include adaptive elements (commonly stopping rules and adaptive randomisations) that allow design variations based on accruing evidence."
  },
  {
    "objectID": "notebooks/estimands.html#estimands",
    "href": "notebooks/estimands.html#estimands",
    "title": "Estimands in complex designs",
    "section": "Estimands",
    "text": "Estimands\nCausal estimands are population quantities describing causal effects of treatments. The estimand framework facilitates a precise description of the treatment effect of interest in clinical trials. The estimand is the thing targeted for estimation which will address a question of interest intrinsic to the trial. In other words, setting objectives leads to estimands which, once clear, can lead to identifying a suitable method for estimation.\n\n\n\n\n\n\nNote\n\n\n\nIf you do not have a clear definition of an estimand, how do you derive an appropriate estimator?\n\n\nEstimands comprise:\n\na population of interest\na treatment strategy\na variable to be measured for each patient\nstrategies for handing intercurrent events (IE)\na population summary measure\n\nPer FDA, endpoint measures are developed to assess clinical outcomes, but things do seem to get mixed up.\nNevertheless - the endpoint is an outcome obtained for each patient that will be statistically analyzed to address the scientific question; this may include data from multiple variables.\nWhile the usual suspects for defining analysis populations (specifically for dealing with IE) were intention-to-treat ITT and per-protocol, the ICH expanded this set of strategies. Loosely, ITT analyses all patients as randomised, irrespective of what actually happened (e.g. deviations). PP analyses, only those who follow the protocol are used, the otherse are excluded. PP is commonly cited as being subject to bias, ITT less so. ICH defines:\n\nICH treatment strategies\n\n\n\n\n\n\nCommand\nDescription of common use\n\n\n\n\ntreatment policy\nMost common, similar to ITT; data collected is used regardless of whether IE occur. In other words, the IE is not a considered a departure from the treatment regimen of interest. TP preserves the randomisation, hence its attraction. Death can lead to TP being undefineable unless death is the (or a component of the) primary.\n\n\ncomposite policy\nIncorporates the IE as a component of the variable, e.g. alive at 29 days without use of rescue medication.\n\n\nhypothetical\nComplicated - envisages a scenario where the IE does not occur. The observed outcomes of patients without IE correspond to the outcome of interest, but the outcome of patients with IE is considered missing and needs to be imputed.\n\n\nwhile on treatment\nApplicable where there are repeat measures. The data is used up to the point where treatement was ended.\n\n\nprincipal stratum\nInvolves defining sub-populations according to the specific IEs on one or all treatments.\n\n\n\nas analyses strategies with some loose and brief descriptions provided above.\nIntercurrent events are just post-randomisation events that impact our measurements or interpretation of measurements in some way (e.g. intercurrent events arise through discontinuation of medication).\nFor the population-level summary, it is ususally relevant to provide within and between-arm measures, e.g. within-arm being overall survival at 28 days vs between-arm hazard ratio etc.\nPlatform trials introduce complexity into the specification of estimands and is not well considered in the literature. For example, what are the implications of addring treatment arms or modifying the control or implementing further data-driven adaptive features?"
  }
]