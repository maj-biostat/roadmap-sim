---
title: "Model implementation"
date: today
date-modified: last-modified
---

```{r, echo = FALSE}
source("./R/init.R")
log_info("Called model-implementation notebook")
```

The model used for the simulations translates the binary outcome into a binomial outcome by aggregating over the unique groups.
For example with the linear predictor:

```{r}
#| code-fold: false

# data generation process
formals(get_trial_data_new)$g
```

I get:

```{r}
#| code-fold: false

# simulate data
set.seed(1)
sim_spec <- get_sim_spec_new()
ll <- get_trial_data_new(N = 2500, sim_spec = sim_spec)
d <- copy(ll$d)
head(d[, .(y = sum(y), n = .N), keyby = .(l, er, ed, ef, r, rp, srp2, d, f)])
```

The model spec can be translated almost verbatim into stan:

```{r}
#| class-output: stan
#| echo: false
cat(readLines("stan/model-sim-04.stan"), sep = "\n")
```

To establish consistency, I create data with a million patients (orders of magnitude more than we will have available) and fit the model in an attempt to recover the simulation parameters.
If this cannot be done with a million records, it cannot be done with 2500.
I fit the stan model and extract and summarise the posterior.

```{r}
m4 <- cmdstanr::cmdstan_model("stan/model-sim-04.stan")

set.seed(1)

ll <- get_trial_data_new(N = 1e6, sim_spec = sim_spec)
d <- copy(ll$d)
d_s <- d[, .(y = sum(y), n = .N), 
         keyby = .(l1, l2, er, ed, ef, r, rp, srp2, d, f)]

ld <- list(
  N = nrow(d_s), y = d_s$y, n = d_s$n, 
  l1 = d_s$l1, l2 = d_s$l2, 
  er = d_s$er, ed = d_s$ed, ef = d_s$ef, 
  r = d_s$r, d = d_s$d, f = d_s$f,
  rp = d_s$rp, srp2 = d_s$srp2
)

f1 <- m4$sample(
  ld, iter_warmup = 1000, iter_sampling = 2000,
  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, 
  max_treedepth = 13)

# frequentist version
f2 <- glm(y ~ l1 + l2 +
              erx + er:r + er:r:srp2 +
              edx + ed:rp:d + ed:d:rp:srp2 +
              efx + ef:f, 
            data = d, family = binomial())



```

Raw parameter estimates align reasonably well to the simulation parameters used in the linear predictor:

```{r}
post1 <- data.table(f1$draws(variables = c(c("a0", "m", "b")), format = "matrix"))
cf <- coef(f2)

round(rbind(
  "Simulation parameters" = c(sim_spec$a0, sim_spec$m, sim_spec$b),
  "Posterior means" = colMeans(post1),
  "Max likelihood" = c(
    cf[1:3], 
    cf["erx"], cf["er:r"], cf["er:r:srp2"] , 
    cf["edx"], cf["ed:rp:d"], cf["srp2:ed:rp:d"],
    cf["efx"], cf["ef:f"]
  )
), 4)
```


```{r}
eta_r_0 <- f1$draws(variables = c("eta_r_0"), format = "matrix")
eta_r_1 <- f1$draws(variables = c("eta_r_1"), format = "matrix")
eta_d_0 <- f1$draws(variables = c("eta_d_0"), format = "matrix")
eta_d_1 <- f1$draws(variables = c("eta_d_1"), format = "matrix")
eta_f_0 <- f1$draws(variables = c("eta_f_0"), format = "matrix")
eta_f_1 <- f1$draws(variables = c("eta_f_1"), format = "matrix")

b_r <- unlist(mclapply(1:(min(nrow(eta_r_0), 1000)), function(ii){
  lo_0 <- eta_r_0[ii, rep(1:nrow(d_s), times = ld$n)]
  lo_1 <- eta_r_1[ii, rep(1:nrow(d_s), times = ld$n)]
  mean(lo_1 - lo_0)
}, mc.cores = 10))

idx_1 <- d_s[l1 == 1, which = T]
idx_2 <- d_s[l2 == 1, which = T]
ii <- 1

b_d <- do.call(rbind, mclapply(1:(min(nrow(eta_d1_0), 1000)), function(ii){
  
  lo_0 <- eta_d_0[ii, rep(1:nrow(d_s), times = ld$n)]
  lo_1 <- eta_d_1[ii, rep(1:nrow(d_s), times = ld$n)]

  lo_0_1 <- eta_d_0[ii, rep(idx_1, times = ld$n[idx_1])]
  lo_1_1 <- eta_d_1[ii, rep(idx_1, times = ld$n[idx_1])]
  
  lo_0_2 <- eta_d_0[ii, rep(idx_2, times = ld$n[idx_2])]
  lo_1_2 <- eta_d_1[ii, rep(idx_2, times = ld$n[idx_2])]
  
  c(mean(lo_1 - lo_0), 
    # you need to base the mean on the n that were used in the strata
    sum(lo_1_1 - lo_0_1)/sum(ld$n[idx_1]),  
    sum(lo_1_2 - lo_0_2)/sum(ld$n[idx_2])
    )
  
}, mc.cores = 10))

b_f <- unlist(mclapply(1:(min(nrow(eta_f_0), 1000)), function(ii){
  lo_0 <- eta_f_0[ii, rep(1:nrow(d_s), times = ld$n)]
  lo_1 <- eta_f_1[ii, rep(1:nrow(d_s), times = ld$n)]
  mean(lo_1 - lo_0)
}, mc.cores = 10))

d_new <- copy(d_s)
d_new[, `:=`(d = 1, erx = 1-er, edx = 1-ed, efx = 1-ef)]
predict(f2, newdata = d_new[1:10])
eta_d_1
d_new[, `:=`(d = 0, erx = 1-er, edx = 1-ed, efx = 1-ef)]
predict(f2, newdata = d_new[1:10])
eta_d_0

# w_eta_r0 <- sweep(eta_r0, 1, ld$n, "*")

d_new <- copy(d)
lo <- copy(d_new[, r := 0])
d_new <- copy(d)
hi <- copy(d_new[, r := 1])
y_lo <- predict(f2, newdata = lo)
y_hi <- predict(f2, newdata = hi)
y_lo[1:3]
y_hi[1:3]


mean(y_hi - y_lo)
mean(y_hi[d$l2 == 1] - y_lo[d$l2 == 1])


avg_comparisons(f2, variables = "r", comparison = "lnor")
avg_comparisons(f2, variables = "f", comparison = "lnor")
apply(cbind(b_r, b_f), 2, mean)

avg_comparisons(f2, variables = "d", comparison = "lnor")
avg_comparisons(f2, variables = "d", comparison = "lnor", by = c("l1", "l2"))
colMeans(b_d)
# comparisons(f2, variables = "d", comparison = "lnor")
#

# post <- data.table(f1$draws(variables = c(c("b_r")), format = "matrix"))
# 
# d_new <- copy(d)
# d_new[, `:=`(r = 1)]
# lo1 <- predict(f2, newdata = d_new)
# dtmp <- cbind(d_new, lo1)
# dtmp[l == 1 & j == 0 & er == 1]
# d_new[, `:=`(r = 0)]
# lo0 <- predict(f2, newdata = d_new)
# mean(lo1 - lo0)
# 
# colMeans(post)

```


```{r}
post <- data.table(f2$draws(variables = c(c("b_r")), format = "matrix"))

round(rbind(
  c(sim_spec$a0, sim_spec$m, sim_spec$b),
  colMeans(post)
), 3)
```



```{r}

```



```{r}
# create index field
# post <- melt(post, measure.vars = names(post))
# post[, idx := gsub(".*\\[", "", variable)]
# post[, idx := gsub("\\]", "", idx)]
# post[, idx := as.integer(idx)]

# d_fig <- cbind(d_b, post[, .(eta_med = median(value), 
#          eta_q025 = quantile(value, prob = 0.025),
#          eta_q975 = quantile(value, prob = 0.975)), keyby = idx])
```

```{r}
set.seed(1)

# effect on f but nothing else
sim_spec$b["f"] <- log(2)
ll <- get_trial_data_new(N = 1e6, sim_spec = sim_spec)
d <- copy(ll$d)

dtmp <- copy(d[ef == 1, .(er, ed, ef, r, d, f, rp, srp2, y, p_y)])
dtmp[, mean(p_y), keyby = f]


d_s <- d[, .(y = sum(y), n = .N), keyby = .(l, j, er, ed, ef, r, rp, srp2, d, f)]

d[ef == 1, .(y = sum(y), n = .N), keyby = f]

ld <- list(
  N = nrow(d_s), y = d_s$y, n = d_s$n, l = d_s$l + 1, j = d_s$j + 1,
  er = d_s$er, ed = d_s$ed, ef = d_s$ef, 
  r = d_s$r, d = d_s$d, f = d_s$f,
  rp = d_s$rp, srp2 = d_s$srp2
)

f2 <- m4$sample(
  ld, iter_warmup = 1000, iter_sampling = 2000,
  parallel_chains = 2, chains = 2, refresh = 0, show_exceptions = F, 
  max_treedepth = 13)

post <- data.table(f2$draws(variables = c(
  c("b_r", "b_d1", "b_d2", "b_f")
), format = "matrix"))

colMeans(post)


```

@fig-post-vs-tru shows a comparison between the true log-odds of treatment success with the 95% credible interval obtained from the model.
It suggests a strong association between the true and estimated log-odds of treatment success for this particular dataset.

```{r, eval = F}
#| label: fig-post-vs-tru
#| fig-cap: 'Scatter plot comparing true vs estimated 95% credible interval for log-odds treatment success.'
#| fig-cap-location: margin
#| fig-height: 6
#| fig-width: 6

ggplot(d_fig, aes(x = eta, y = eta_med)) +
  # geom_point() +
  geom_linerange(aes(ymin = eta_q025, ymax = eta_q975)) +
  geom_abline(intercept = 0, slope = 1, lwd = 0.1) +
  scale_x_continuous("True log-odds success") +
  scale_y_continuous("Posterior log-odds success (95% credible interval)") +
  facet_grid(silo ~ joint) +
  ggtitle("True log-odds success vs 95% credible interval")
```


```{r, eval = F}
post <- data.table(f2$draws(variables = c(
    "alpha", "gamma_c", 
    "b_a_l", 
    "b_b1_l", 
    "b_b2_l",
    "b_a_c",
    "b_b1_c", 
    "b_b2_c",
    "b_c"
  ), format = "matrix"))
  

# test outcome
cols <- names(post)
cols <- gsub("[","_",cols,fixed = T)
cols <- gsub("]","",cols,fixed = T)
names(post) <- cols
  
# effects
effs <- c(
  # domain a, late (revision) and chronic (two-stage)
  "b_a_l_2", "b_a_c_2", 
  # domain b, (late/revision one stage pts)
  # wk12p1 (ref is wk6p1)
  "b_b1_l_2", 
  # wk12p2 (ref is day7p2)
  "b_b2_l_2", 
  # wk12p1 (ref is wk6p1)
  "b_b1_c_2", 
  # wk12p2 (ref is day7p2)
  "b_b2_c_2",
  # rif (ref is no-rif)
  "b_c_2")
  
d_beta <- post[, .SD, .SDcols = effs]
d_beta <- melt(d_beta, measure.vars = names(d_beta))
# unique(d_beta$variable)


parname_map <- roadmap.data::get_par_effects_mapping()
d_beta[, parname := parname_map[variable]]
d_beta[, parname := factor(parname, levels = roadmap.data::get_par_effects_mapping())]

d_fig <- d_beta[, .(
  lor_med = median(value), 
  lor_q025 = quantile(value, prob = 0.025),
  lor_q975 = quantile(value, prob = 0.975)), keyby = parname]

d_effects <- roadmap.data::get_sim_spec_effects(roadmap.data::get_sim_spec())
d_effects <- melt(d_effects, measure.vars = names(d_effects), value.name = "lor")

d_fig <- merge(d_fig, d_effects, by.x = "parname", by.y = "variable")

```

@fig-post-vs-tru shows a comparison between the true log-odds of treatment success with the 95% credible interval obtained from the model.
It suggests a strong association between the true and estimated log-odds of treatment success for this particular dataset.

```{r, eval = F}
#| label: fig-post-lor
#| fig-cap: 'Posterior estimates for log-odds-ratios (true values shown as triangles).'
#| fig-cap-location: margin
#| fig-height: 4
#| fig-width: 5

ggplot(d_fig, aes(x = parname, y = lor_med)) +
  geom_point() +
  geom_point(data = d_fig, aes(x = parname, y = lor), pch = 2) +
  geom_linerange(aes(ymin = lor_q025, ymax = lor_q975))  +
  scale_x_discrete("", guide = guide_axis(angle = 45)) +
  scale_y_continuous("Posterior log-odds-ratio (95% credible interval)") 
```

```{r, eval = F}
post <- data.table(f2$draws(variables = c(
    "alpha", "gamma_c", 
    "b_a_l", 
    "b_b1_l", 
    "b_b2_l",
    "b_a_c",
    "b_b1_c", 
    "b_b2_c",
    "b_c"
  ), format = "matrix"))
  

# test outcome
cols <- names(post)
cols <- gsub("[","_",cols,fixed = T)
cols <- gsub("]","",cols,fixed = T)
names(post) <- cols
  
# effects
pars <- c(
  "alpha", "gamma_c", 
  # domain a, late (revision) and chronic (two-stage)
  "b_a_l_2", "b_a_c_2", 
  # domain b, (late/revision one stage pts)
  # wk12p1 (ref is wk6p1)
  "b_b1_l_2", 
  # wk12p2 (ref is day7p2)
  "b_b2_l_2", 
  # wk12p1 (ref is wk6p1)
  "b_b1_c_2", 
  # wk12p2 (ref is day7p2)
  "b_b2_c_2",
  # rif (ref is no-rif)
  "b_c_2")
  
d_pars <- post[, .SD, .SDcols = effs]
m_cor <- d_pars[, cor(.SD)]
d_cor <- data.table(cbind(var1 = rownames(m_cor), m_cor))
d_cor <- melt(d_cor, id.vars = "var1", variable.name = "var2")
d_cor[, value := as.numeric(value)]

d_cor[, `:=`(
  var1 = factor(var1, levels = c(pars[length(pars):1])),
  var2 = factor(var2, levels = c(pars[length(pars):1]))
)]

```

@fig-post-cor shows the correlation between parameters estimated from the model.

```{r, eval = F}
#| label: fig-post-cor
#| fig-cap: 'Parameter correlation (white indicates zero correlation)'
#| fig-cap-location: margin
#| fig-height: 7
#| fig-width: 7

ggplot(d_cor, aes(x = var1, y = var2, fill = value)) +
  geom_tile(color = "white",
            lwd = 1.5,
            linetype = 1) +
  geom_text(aes(label = round(value, 2)), color = "white", size = 4) +
  scale_x_discrete("",position = "top", limits=rev) +
  scale_y_discrete("") + 
  scale_fill_gradient2("Pearson correlation") +
  coord_fixed()
```
