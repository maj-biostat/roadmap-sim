---
title: "Simulation results 5"
subtitle: "Sequential design with early stopping (restricted action set) - risk based"
date: today
date-modified: last-modified
sidebar: false
navbar: false
theme: cosmo
# this is necessary to remove an unwanted boarder around a tabset
include-in-header:
  - text: |
      <style>
      .panel-tabset > .nav-tabs,
      .panel-tabset > .tab-content {
        border: none;
      }
      </style>
---





```{r, echo = FALSE}
#| label: libs
#| code-summary: Libraries and globals

source("./R/init.R")
source("./R/util.R")
source("./R/data.R")
log_info("Called simulation-results 5 notebook")

toks <- unlist(tstrsplit(getwd(), "/")) 
if(toks[length(toks)] == "roadmap-sim"){
  prefix_cfg <- "./etc/sim05/"
  prefix_stan <- "./stan"
  prefix_fig <- "./fig"
} else {
  prefix_cfg <- "../etc/sim05/"
  prefix_stan <- "../stan"
  prefix_fig <- "../fig"
}

g_cfgsc <- config::get(file = paste0(prefix_cfg, "/cfg-sim05-sc01-v08.yml"))
```



```{r}
#| label: loadfiles
#| code-summary: Load simulation results

# Each input file corresponds to the results from a single simulation
# scenario/configuration.
# Load all the files into a single list.

# files of interest
flist <- list.files("data/sim05-08", pattern = "sim05")
toks <- list()
l <- list()
i <- 1
for(i in 1:length(flist)){
  l[[i]] <- qs::qread(file.path("data/sim05-08", flist[i]))
  toks[[i]] <-  unlist(tstrsplit(flist[i], "[-.]"))
}


```

## Notes 

Updated: 1/Mar/2025 - 10:45

The decision approach now converts the model outputs to a risk (probability) scale and assesses decisions based on risk difference for the intervention comparisons by domain.
Why?
Log-odds scale had limited interpretability for clinical users and is inconsistent in absolute terms across strata with varying baseline rates.
Additionally, it is useful to explore what an absolute perspective on effectiveness translates to in terms of operating characteristics.
Simulation parameters continue to be expressed as log-odds-ratios.
This makes the simulation process simpler.
Results are presented on both the odds and risk scale.
Aim is to give us a better intuition and transparency on the magnitude of effects we are contemplating and determine if these are reasonable assumptions.

We have a single, large, conditional model, which amongst other things includes an effect for clinician preference for revision type in order to achieve conditional exchangeability across groups.
At each interim, we assess the posterior and if a decision threshold is met, we act.
For example, if a superiority decision is reached in one of the domains for which this decision type is relevant, then we consider that domain dealt with and all subsequent participants are assigned to receive the superior intervention.
We can (and presently do) continue to update the posterior inference for the comparison that has stopped in subsequent interim analyses until we get to the point where all questions have been answered in all domains, at which point the trial will stop.

The priors were as follows:

+ Reference log-odds of response: logistic distribution, mean `r l[[1]]$cfg$pri$mu[[1]]` and scale `r l[[1]]$cfg$pri$mu[[2]]`
+ Silo effects: normal distribution, mean `r l[[1]]$cfg$pri$b_silo[[1]]` and scale `r l[[1]]$cfg$pri$b_silo[[2]]`
+ Joint effects: normal distribution, mean `r l[[1]]$cfg$pri$b_jnt[[1]]` and scale `r l[[1]]$cfg$pri$b_jnt[[2]]`
+ Preference effects: normal distribution, mean `r l[[1]]$cfg$pri$b_prf[[1]]` and scale `r l[[1]]$cfg$pri$b_prf[[2]]`
+ Treatment effects: normal distribution, mean `r l[[1]]$cfg$pri$b_trt[[1]]` and scale `r l[[1]]$cfg$pri$b_trt[[2]]`

@fig-priors shows an example of the priors that are induced on the risk differences, by domain, and the inference on treatment effect parameters after 2500 enrolments when moderate treatment effects (OR 1.75) are applied to all domains bar AB duration, which has a null effect.

```{r}
#| label: fig-priors
#| fig-cap: 'Indicative prior vs posterior belief for risk difference treatment effect parameters after 2500 enrolments (null effect in AB duration, non-zero effects in all other domains)'
#| fig-height: 5
#| fig-width: 5



m1 <- cmdstanr::cmdstan_model(paste0(prefix_stan, "/model-sim-05-a.stan"))   
dec_sup = list(surg = NA,
               ext_proph = NA,
               ab_choice = NA)
dec_ni = list(ab_dur = NA)
dec_sup_fut = list(surg = NA,
                   ext_proph = NA,
                   ab_choice = NA)
dec_ni_fut = list(ab_dur = NA)

mu <- g_cfgsc$cov$mu
b_silo <- unlist(g_cfgsc$cov$silo)
b_jnt <- unlist(g_cfgsc$cov$jnt)
b_pref <- unlist(g_cfgsc$cov$pref)
# dair, one, two-stage, we compare avg of one and two stage rev to dair
b_d1 <- unlist(g_cfgsc$d1)
# always ref, 12wk, 6wk as we are assessing if 6wk ni to 12wk
b_d2 <- c(0, 0, 0) # unlist(g_cfgsc$d2)
# always ref, 0, 12wk as we are assessing if 12wk sup to none
b_d3 <- unlist(g_cfgsc$d3)
# always ref, none, rif as we are assessing if rif is sup to none
b_d4 <- unlist(g_cfgsc$d4)

set.seed(123)
my_N <- 2500
l_new <- get_trial_data_int(
  N = my_N,
  
  # reference level log odds of response
  mu = mu,
  # silo effects
  # silo 1 as the one for late acute
  # silo 2 as the one for late acute
  # silo 3 is LATE ACUTE
  b_silo = b_silo,
  b_jnt = b_jnt,
  b_pref = b_pref,
  # dair, one, two-stage
  b_d1 = b_d1,  #c(0, 2, 2), # b_d1,
  b_d2 = b_d2,
  b_d3 = b_d3,
  b_d4 = b_d4,
  
  dec_sup = dec_sup,
  dec_ni = dec_ni,
  dec_sup_fut = dec_sup_fut,
  dec_ni_fut = dec_ni_fut,
  
  idx_s = 1,
  t0 = rep(1, my_N),
  id_analys = 1
)
  
# create stan data format based on the relevant subsets of pt
lsd <- get_stan_data_all_int(l_new$d)
lsd$ld$prior_only <- 1
lsd$ld$pri_mu <- c(0, 0.47)
lsd$ld$pri_b_silo <- c(0, 1)
lsd$ld$pri_b_jnt <- c(0, 1)
lsd$ld$pri_b_prf <- c(0, 1)
lsd$ld$pri_b_trt <- c(0, 1)

snk <- capture.output(
  f_1 <- m1$sample(
    lsd$ld, iter_warmup = 1000, iter_sampling = 5000,
    parallel_chains = 1, chains = 1, refresh = 0, show_exceptions = F,
    max_treedepth = 11)
)


lsd$ld$prior_only <- 0
snk <- capture.output(
  f_2 <- m1$sample(
    lsd$ld, iter_warmup = 1000, iter_sampling = 5000,
    parallel_chains = 1, chains = 1, refresh = 0, show_exceptions = F,
    max_treedepth = 11)
)

snk <- capture.output(
  f_3 <- m1$optimize(data = lsd$ld)
)
d_mle <- data.table(
  f_3$summary(variables = c("rd_d1", "rd_d2", "rd_d3", "rd_d4")))
# extract posterior - marginal probability of outcome by group
# dair vs rev
d_pri <- data.table(f_1$draws(
  variables = c(
    "rd_d1", "rd_d2", "rd_d3", "rd_d4"
  ),   
  format = "matrix"))
d_fig_1 <- melt(d_pri, measure.vars = names(d_pri))
d_fig_1[, desc := "Prior"]

d_post <- data.table(f_2$draws(
  variables = c(
    "rd_d1", "rd_d2", "rd_d3", "rd_d4"
  ),   
  format = "matrix"))
d_fig_2 <- melt(d_post, measure.vars = names(d_post))
d_fig_2[, desc := "Posterior"]
d_fig <- rbind(
  d_fig_1, d_fig_2  
)
d_fig[, desc := factor(desc, levels = c("Posterior", "Prior"))]

d_fig[, variable := factor(
  variable, levels = c("rd_d1", "rd_d2", "rd_d3", "rd_d4"),
  labels = c("Surgical", "AB Duration", "AB Ext-proph", "AB Choice"))]

d_mle[, variable := factor(
  variable, levels = c("rd_d1", "rd_d2", "rd_d3", "rd_d4"),
  labels = c("Surgical", "AB Duration", "AB Ext-proph", "AB Choice"))]

ggplot(d_fig, aes(x = value, group = desc, lty = desc)) +
  geom_density(lwd = 0.3) +
  geom_vline(
    data = d_fig[desc == "Posterior", .(mu = median(value)), keyby = .(variable)],
    aes(xintercept = mu), lwd = 0.3
  ) +
  geom_vline(
    data = d_mle,
    aes(xintercept = estimate), lwd = 0.3, col = 2
  ) +
  geom_vline(
    aes(xintercept = 0), lwd = 0.2, lty = 1
  ) +
  scale_linetype_discrete("") +
  scale_x_continuous("Risk difference", breaks = seq(-0.8, 0.8, by = 0.2)) +
  scale_y_continuous("") +
  facet_wrap(~variable, axes = "all") +
  theme(
    axis.title.y=element_blank(),
    axis.text.y=element_blank(),
    axis.ticks.y=element_blank(),
    axis.text.x = element_text(size = 5), 
    axis.title.x = element_text(size = 5), 
    strip.text.x = element_text(angle = 0, size = 5)
  )
```


For the superiority decision, a reference value of `r l[[1]]$cfg$dec_ref$delta_sup` was used and a probability threshold of `r l[[1]]$cfg$dec_probs$thresh_sup` was required.
For the futility decision (in relation to superiority) a reference value of `r l[[1]]$cfg$dec_ref$delta_sup_fut` was used and a probability threshold of `r l[[1]]$cfg$dec_probs$thresh_fut_sup` was required.
This means that if the probability that the risk difference is greater than `r l[[1]]$cfg$dec_ref$delta_sup_fut` is less than `r l[[1]]$cfg$dec_probs$thresh_fut_sup`, then we say the superiority goal is futile.
@fig-superiority-rule puts this into pictures based on possible scenarios for assessment of the posterior risk difference for an arbitrary domain where superiority is being assessed.
The approach, reference values and thresholds apply to all domains where superiority is assessed.

```{r, echo = F}
#| label: fig-superiority-rule
#| fig-cap: 'Visualisation of decision rule scenarios for superiority'
#| fig-height: 3
#| fig-width: 6
#| column: page-right

# superior as pr(rd > 0) > 0.98
f_mu_sup <- function(x) {
  (qnorm(0.01, x[1], 0.05))^2
}
o_res_1 <- optim(0, f_mu_sup, method = "L-BFGS-B")

# undecided on futility as  !(pr(rd > 0) > 0.98 & pr(rd > 0.05) < 0.25)
f_mu_sup_indet <- function(x) {  
    (qnorm(0.74, x[1], 0.05) - 0.05)^2
}
o_res_2 <- optim(0, f_mu_sup_indet, method = "L-BFGS-B")

# futility as pr(rd > 0.05) < 0.25
f_mu_sup_fut <- function(x) {  
    (qnorm(0.84, x[1], 0.05) - 0.05)^2
}
o_res_3 <- optim(0, f_mu_sup_fut, method = "L-BFGS-B")

mu_sup <- o_res_1$par[1]
mu_sup_indet <- o_res_2$par[1]
mu_sup_fut <- o_res_3$par[1]
sd <- 0.05

x <- seq(-0.3, 0.3, len = 1000)
y <- dnorm(x, mu_sup, sd)
d_fig_1 <- data.table(x, y)
d_fig_1[x >= 0, fill := T]
d_fig_1[x < 0, fill := F]
d_fig_1[, desc := 1]

x <- seq(-0.3, 0.3, len = 1000)
y <- dnorm(x, mu_sup_fut, sd)

d_fig_2 <- data.table(x, y)
d_fig_2[x >= 0.05, fill := T]
d_fig_2[x < 0.05, fill := F]
d_fig_2[, desc := 2]


x <- seq(-0.3, 0.3, len = 1000)
y <- dnorm(x, 0, sd)

d_fig_3 <- data.table(x, y)
d_fig_3[x >= 0.05, fill := T]
d_fig_3[x < 0.05, fill := F]
d_fig_3[, desc := 3]

d_fig <- rbind(
  d_fig_1, d_fig_2, d_fig_3
)

d_vline <- data.table(
  desc = 1:3,
  x = c(0, 0.05, 0.05)
)

d_poly_1 <- d_fig[fill == T & desc == 1]
d_poly_2 <- d_fig[fill == T & desc == 2]
d_poly_3 <- d_fig[fill == T & desc == 3]

# Surely there is a simpler way to put newlines into facet labels other
# than using atop...?
d_fig[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('Superior','Pr(RD > 0) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > 0) > 0.98 & Pr(RD > 0.05) < 0.25)')",   
    "atop('Futile', 'Pr(RD > 0.05) < 0.25')"
  )
)]
d_poly_1[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('Superior','Pr(RD > 0) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > 0) > 0.98 & Pr(RD > 0.05) < 0.25)')", 
    "atop('Futile', 'Pr(RD > 0.05) < 0.25')"
  )
)]
d_poly_2[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('Superior','Pr(RD > 0) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > 0) > 0.98 & Pr(RD > 0.05) < 0.25)')",     
    "atop('Futile', 'Pr(RD > 0.05) < 0.25')"
  )
)]
d_poly_3[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('Superior','Pr(RD > 0) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > 0) > 0.98 & Pr(RD > 0.05) < 0.25)')", 
    "atop('Futile', 'Pr(RD > 0.05) < 0.25')"
  )
)]
d_vline[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('Superior','Pr(RD > 0) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > 0) > 0.98 & Pr(RD > 0.05) < 0.25)')",    
    "atop('Futile', 'Pr(RD > 0.05) < 0.25')"
  )
)]

ggplot(data = d_fig, aes(x = x, y = y, group = desc)) +
  geom_area(data = d_poly_1, 
               aes(x = x, y = y, group = desc), fill = "green") +
  geom_area(data = d_poly_2, 
               aes(x = x, y = y, group = desc), fill = "grey80") +
  geom_area(data = d_poly_3, 
               aes(x = x, y = y, group = desc), fill = "red") +
  geom_vline(data = d_vline, 
               aes(xintercept = x, group = desc), lwd = 0.25, lty = 2) +
  geom_line(lwd = 0.25) +
  scale_x_continuous("Risk difference",
                     breaks = round(seq(-0.3, 0.3, by = 0.1), 2)) +
  facet_grid(~desc, scales = "free",
             labeller = label_parsed) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(size = 5), 
        axis.title.x = element_text(size = 5), 
        strip.text.x = element_text(angle = 0, size = 5))

```

This iteration of the simulations loosens the NI reference value to 0.05 on the risk scale, i.e. interventions are evaluated relative to reducing the probability of a good outcome by 5%.
The change was motivated by the desire to better reflect current perspective on acceptable NI margins (3% was considered overly conservative).
The futility rule has also been updated to use a reference value of zero (previously it was +2%) so we actually a bit less with regards to futility rule for NI in this set of simulations.

For the ni decision, a reference value of `r l[[1]]$cfg$dec_ref$delta_ni` was used and a probability threshold of `r l[[1]]$cfg$dec_probs$thresh_ni` was required.
This means that if the probability that the risk difference is greater than `r l[[1]]$cfg$dec_ref$delta_ni` is greater than `r l[[1]]$cfg$dec_probs$thresh_ni`, we will say the intervention is non-inferior.
The futility decision (in relation to non-inferiority) has a reference value of `r l[[1]]$cfg$dec_ref$delta_ni_fut` and a probability threshold of `r l[[1]]$cfg$dec_probs$thresh_fut_ni`.
This means that if the probability that the risk difference is greater than `r l[[1]]$cfg$dec_ref$delta_ni_fut` is less than `r l[[1]]$cfg$dec_probs$thresh_fut_ni`, then we say the non-inferiority goal is futile.
@fig-ni-rule puts this into pictures based on possible scenarios for assessment of the posterior risk difference for an arbitrary domain where non-inferiority is being assessed.
The approach, reference values and thresholds apply to all domains.

```{r, echo = F}
#| label: fig-ni-rule
#| fig-cap: 'Visualisation of decision rule scenarios for non-inferiority'
#| fig-height: 3
#| fig-width: 6
#| column: page-right

# Compute the mean required to achieve a representation of a non-inferiority
# scenario, i.e. 
f_mu_ni <- function(x) {
  # addition required because we want this function to reach zero
  (qnorm(0.01, x[1], 0.05) + 0.05)^2
}
o_res_1 <- optim(0, f_mu_ni, method = "L-BFGS-B")

# undecided on futility as pr(rd > 0) = 0.26 > 0.25
f_mu_ni_indet <- function(x) {   
    (qnorm(0.74, x[1], 0.05))^2
}
o_res_2 <- optim(0, f_mu_ni_indet, method = "L-BFGS-B")

# futility as pr(rd > 0) = 0.16 < 0.25
f_mu_ni_fut <- function(x) {   
    (qnorm(0.84, x[1], 0.05))^2
}
o_res_3 <- optim(0, f_mu_ni_fut, method = "L-BFGS-B")


mu_ni <- o_res_1$par[1]
mu_ni_indet <- o_res_2$par[1]
mu_ni_fut <- o_res_3$par[1]
sd <- 0.05



x <- seq(-0.3, 0.3, len = 1000)
y <- dnorm(x, mu_ni, sd)
d_fig_1 <- data.table(x, y)
d_fig_1[x >= -0.05, fill := T]
d_fig_1[x < -0.05, fill := F]
d_fig_1[, desc := 1]

x <- seq(-0.3, 0.3, len = 1000)
y <- dnorm(x, mu_ni_indet, sd)

d_fig_2 <- data.table(x, y)
d_fig_2[x >= 0, fill := T]
d_fig_2[x < 0, fill := F]
d_fig_2[, desc := 2]


x <- seq(-0.3, 0.3, len = 1000)
y <- dnorm(x, mu_ni_fut, sd)

d_fig_3 <- data.table(x, y)
d_fig_3[x >= 0, fill := T]
d_fig_3[x < 0, fill := F]
d_fig_3[, desc := 3]

d_fig <- rbind(
  d_fig_1, d_fig_2, d_fig_3
)

d_vline <- data.table(
  desc = 1:3,
  x = c(-0.05, 0, 0)
)

d_poly_1 <- d_fig[fill == T & desc == 1]
d_poly_2 <- d_fig[fill == T & desc == 2]
d_poly_3 <- d_fig[fill == T & desc == 3]



# Surely there is a simpler way to put newlines into facet labels other
# than using atop...?
d_fig[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('NI','Pr(RD > -0.05) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > -0.05) > 0.98 & Pr(RD > 0) < 0.25)')",   
    "atop('Futile', 'Pr(RD > 0) < 0.25')"
  )
)]
d_poly_1[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('NI','Pr(RD > -0.05) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > -0.05) > 0.98 & Pr(RD > 0) < 0.25)')",   
    "atop('Futile', 'Pr(RD > 0) < 0.25')"
  )
)]
d_poly_2[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('NI','Pr(RD > -0.05) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > -0.05) > 0.98 & Pr(RD > 0) < 0.25)')",    
    "atop('Futile', 'Pr(RD > 0) < 0.25')"
  )
)]
d_poly_3[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('NI','Pr(RD > -0.05) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > -0.05) > 0.98 & Pr(RD > 0) < 0.25)')",    
    "atop('Futile', 'Pr(RD > 0) < 0.25')"
  )
)]
d_vline[, desc := factor(
  desc, 
  levels = 1:3,
  labels = c(
    "atop('NI','Pr(RD > -0.05) > 0.98')", 
    "atop('Undecided', '!(Pr(RD > -0.05) > 0.98 & Pr(RD > 0) < 0.25)')",    
    "atop('Futile', 'Pr(RD > 0) < 0.25')"
  )
)]


ggplot(data = d_fig, aes(x = x, y = y, group = desc)) +
  geom_area(data = d_poly_1, 
               aes(x = x, y = y, group = desc), fill = "green") +
  geom_area(data = d_poly_2, 
               aes(x = x, y = y, group = desc), fill = "grey80") +
  geom_area(data = d_poly_3, 
               aes(x = x, y = y, group = desc), fill = "red") +
  geom_vline(data = d_vline, 
               aes(xintercept = x, group = desc), lwd = 0.25, lty = 2) +
  geom_line(lwd = 0.25) +
  scale_x_continuous("Risk difference",
                     breaks = round(seq(-0.3, 0.3, by = 0.1), 2)) +
  facet_grid(~desc, scales = "free",
             labeller = label_parsed) +
  theme(axis.title.y=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        axis.text.x = element_text(size = 5), 
        axis.title.x = element_text(size = 5), 
        strip.text.x = element_text(angle = 0, size = 5))

```

For this set of simulations, the number of simulated trials per scenario was `r l[[1]]$cfg$nsim`.

Todo:

Do we need to think about the hierarchical component for surgical domain to enable, for example, silo specific effects, which would otherwise be problematic for the domains. Revisit interactions silo x surg, pref x surg, joint x surg, etc.

Scenarios for effects in surg (moderate effect) + choice (weak effect) plus other comparisons.

Discuss region of practical equivalence.

## Simulation results

```{r, echo = FALSE}
#| label: cprobdec
#| code-summary: Cumulative probability of each decision type

# Cumulative probability of decisions:

# Traverse the list of simulation results and for each one summarise the 
# cumulative probability of each decision type.

i <- 1
d_tbl_1 <- data.table()

# For each scenario that was simulated
for(i in 1:length(l)){
  
  # extract the decision matrix - sim, analysis, quantity, domain level decision
  d_dec_1 <- copy(l[[i]]$d_decision)
  # config for scenario
  l_cfg <- copy(l[[i]]$cfg)
  
  # number of enrolments at each interim (interim sample size sequence)
  d_N <- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)
  
  # long version of decisions
  d_dec_2 <- melt(d_dec_1, 
                  id.vars = c("sim", "analys", "quant"), 
                  variable.name = "domain")

  # Should be right, but just in case...
  if(any(is.na(d_dec_2$value))){
    message("Some of the decision values are NA in index ", i, " file ", flist[i])
    d_dec_2[is.na(value), value := FALSE]
  }
  d_dec_2[, domain := as.numeric(gsub("d", "", domain))]
  
  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.
  # Domaain 2 will stop for NI or futility for NI.
  # No other stopping rules apply and so we only evaluate the operating 
  # characteristics on these, i.e. we do not care about the results for the 
  # cumualative probability of ni for domain 1, 3 and 4 because we would never
  # stop for this. 
  d_dec_2 <- rbind(
    d_dec_2[domain %in% c(1, 3, 4) & quant %in% c("sup", "fut_sup")],
    d_dec_2[domain %in% c(2) & quant %in% c("ni", "fut_ni")]
  )
  
  
  # compute the cumulative instances of a decision being made by sim, each 
  # decision type and by parameter
  d_dec_2[, value := as.logical(cumsum(value)>0), keyby = .(sim, quant, domain)]
  
  d_dec_2 <- merge(d_dec_2, d_N, by = "analys")
  
  # cumulative proportion for which each decision quantity has been met by 
  # analysis and domain
  d_dec_cumprob <- d_dec_2[, .(pr_val = mean(value)), keyby = .(analys, N, quant, domain)]
  
  
  
  d_tbl_1 <- rbind(
    d_tbl_1,
    cbind(scenario = i, desc = l_cfg$desc, d_dec_cumprob)
  )

}


```


```{r, echo = FALSE}
#| label: esamplesize
#| code-summary: Expected sample size 

# Expected sample size

# Similar to above but focus on expected sample size

# Traverse the list of simulation results and for each one summarise the 
# sample sizes at which stopping for a domain occurs for any reason.

# All we are trying to get to is the expected sample size by domain and 
# are not really interested in what decision was made. The cumulative prob
# of each decision type is computed previously.

i <- 2
d_tbl_2 <- data.table()

for(i in 1:length(l)){
  
  # extract the decision matrix - sim, analysis, quantity, domain level decision
  d_dec_1 <- copy(l[[i]]$d_decision)
  # config for scenario
  l_cfg <- copy(l[[i]]$cfg)
  
  # interim looks
  d_N <- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)
  
  # long version of decision
  d_dec_2 <- melt(d_dec_1, 
                  id.vars = c("sim", "analys", "quant"), 
                  variable.name = "domain")

  # Should be right, but just in case...
  if(any(is.na(d_dec_2$value))){
    message("Some of the decision values are NA in index ", i, " file ", flist[i])
    d_dec_2[is.na(value), value := FALSE]
  }
  d_dec_2[, domain := as.numeric(gsub("d", "", domain))]
  d_dec_2 <- merge(d_dec_2, d_N, by = "analys")
  
  # First instance of any decision rule being hit by sim and domain.
  
  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.
  # Domaain 2 will stop for NI or futility for NI.
  
  # Sometimes a decision rule will not be hit for a domain and it will continue
  # to the max sample size. We will deal with that in a minute.
  d_dec_stop <- rbind(
    d_dec_2[
      domain %in% c(1, 3, 4) & value == T & quant %in% c("sup", "fut_sup"), 
      .SD[1], keyby = .(sim, domain)],
    d_dec_2[
      domain %in% c(2) & value == T & quant %in% c("ni", "fut_ni"), 
      .SD[1], keyby = .(sim, domain)]
  )
  setnames(d_dec_stop, "N", "N_stopped")
  setnames(d_dec_stop, "value", "stopped_early")
  
  
  # Add in any rows for which no early stopping happened
  d_dec_stop <- merge(d_dec_stop[, .SD, .SDcols = !c("analys")], 
                      # all combinations of sim and domain
                      unique(d_dec_2[, .(sim, domain)]),
                      by = c("sim", "domain"), all.y = T)
  
  # If domain or trial not stopped then record as having run to the 
  # maximum sample size with no decision made.
  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]
  d_dec_stop[is.na(stopped_early), stopped_early := F]
  # So now we know where every domain was stopped and the reason for stopping
  # within each sim. Great.
  d_dec_stop[is.na(quant), quant := "null"]
  
  d_tbl_2 <- rbind(
    d_tbl_2,
    cbind(
      scenario = i, 
      desc = l_cfg$desc, 
      d_dec_stop
      )
  )

}

```



```{r, echo = FALSE}
#| label: distpostmeanuncondit
#| code-summary: Distributions of posterior means (unconditional)

# Distribution of posterior means for parameters of interest.

# Some simulated trials will have stopped prior to the maximum sample size and
# these will have NA for their posterior means. If you were to summarise the 
# posterior means, they would thus be conditional on the trial having 'survived' 
# until the relevant interim. This means that you have missing data at later 
# interims, which creates a selection bias in that your selection of sims at any
# given interim are not a random sample, but rather a sample conditioned on the 
# stopping rules. 
# If you do not account for this in some way then a summary can be either 
# optimistic or pessimistic depending on how the stopping rules interact 
# with the data. Here we try to account for this missingness by imputing the 
# missing posterior means with locf within each simulation.
# Note that this is really only a partial 'fix' to get a sense of whether 
# what we estimate is representative of the parameter values we used to simulate
# the data.

i <- 2
d_tbl_3 <- data.table()

for(i in 1:length(l)){
  
  # config for scenario
  l_cfg <- copy(l[[i]]$cfg)
  # params
  d_pars <- copy(l[[i]]$d_post_smry_1)
  d_pars <- d_pars[par %in% c("lor", "rd")]
  
  # interim looks
  d_N <- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)
  
  d_pars <- dcast(d_pars, sim + id_analys + domain ~ par, value.var = c("mu", "se"))
  
  # locf
  d_pars[, `:=`(mu_lor = nafill(mu_lor, type = "locf"),
                mu_rd = nafill(mu_rd, type = "locf"),
                se_lor = nafill(se_lor, type = "locf"),
                se_rd = nafill(se_rd, type = "locf")
                ), 
         keyby = .(sim, domain)]
  setnames(d_pars, "id_analys", "analys")
  #
  
  d_pars <- merge(d_pars, d_N, by = "analys")
  
  d_tbl_3 <- rbind(
    d_tbl_3,
    cbind(
      scenario = i, desc = l_cfg$desc,
      d_pars[, .(analys, sim, domain, N, mu_lor, mu_rd, se_lor, se_rd)]
      )
  )

}

```


```{r, echo = FALSE}
#| label: distpostmeancondit
#| code-summary: Distributions of posterior means (conditional)

# Distribution of posterior means for parameters of interest.

# By way of contrast to the above, here we summarise based on the stopping
# rules. That is, the posterior means that are included in the summary are only
# those that 'survived' until the relevant interim. This is simply to give you 
# a sense of how extreme the selection effects associated with stopping can be.

i <- 6
d_tbl_4 <- data.table()

for(i in 1:length(l)){
  
  # extract the decision matrix - sim, analysis, quantity, domain level decision
  d_dec_1 <- copy(l[[i]]$d_decision)
  # config for scenario
  l_cfg <- copy(l[[i]]$cfg)
  
  bd1 <- unlist(l_cfg$d1)
  bd2 <- unlist(l_cfg$d2)
  bd3 <- unlist(l_cfg$d3)
  bd4 <- unlist(l_cfg$d4)
  
  d_tru <- copy(l[[i]]$d_all)
  setnames(d_tru, "id_analys", "analys")
  
  d_tru <- dcast(
    d_tru[, .(N = sum(N)), keyby = .(sim, analys, pref_rev)],
    sim + analys ~ pref_rev, value.var = "N"
  )
  colnames(d_tru) <- c("sim", "analys", "N1", "N2")
  d_tru[, `:=`(prop_p1 = N1 / (N1 + N2), 
               prop_p2 = N2 / (N1 + N2))]
  d_tru[, db1 := as.numeric(
    (d_tru$prop_p1 * bd1[2] + d_tru$prop_p2 * bd1[3]) - bd1[1])]
  d_tru[, db2 := as.numeric(bd2[3] - bd2[2])]
  d_tru[, db3 := as.numeric(bd3[3] - bd3[2])]
  d_tru[, db4 := as.numeric(bd4[3] - bd4[2])]
  d_tru[, `:=`(
    N1 = NULL, N2 = NULL, prop_p1 = NULL, prop_p2 = NULL
  )]
  d_tru <- melt(
    d_tru,
    measure.vars = c("db1", "db2", "db3", "db4"),
    value.name = "lor_tru", variable.name = "domain"
  )
  d_tru[, domain := as.numeric(gsub("db", "", domain))]

  # params
  d_pars <- copy(l[[i]]$d_post_smry_1)
  d_pars <- d_pars[par %in% c("lor", "rd")]
  
  # interim looks
  d_N <- data.table(analys = seq_along(l_cfg$N_pt), N = l_cfg$N_pt)
  
  # long version of decision - assessment of each quantity by sim, domain and analysis
  d_dec_2 <- melt(d_dec_1, 
                  id.vars = c("sim", "analys", "quant"), 
                  variable.name = "domain")

  # Should be right, but just in case...
  if(any(is.na(d_dec_2$value))){
    message("Some of the decision values are NA in index ", i, " file ", flist[i])
    d_dec_2[is.na(value), value := FALSE]
  }
  d_dec_2[, domain := as.numeric(gsub("d", "", domain))]
  d_dec_2 <- merge(d_dec_2, d_N, by = "analys")
  
  # First instance of any decision rule being hit by sim and domain.
  
  # Domains 1, 3 and 4 will stop for superiority or futility for superiority.
  # Domaain 2 will stop for NI or futility for NI.
  
  # Sometimes a decision rule will not be hit for a domain and it will continue
  # to the max sample size. We will deal with that in a minute.
  d_dec_stop <- rbind(
    # value being set to TRUE indicates we hit a stopping run
    d_dec_2[
      domain %in% c(1, 3, 4) & value == T & quant %in% c("sup", "fut_sup"), 
      .SD[1], keyby = .(sim, domain)],
    d_dec_2[
      domain %in% c(2) & value == T & quant %in% c("ni", "fut_ni"), 
      .SD[1], keyby = .(sim, domain)]
  )
  setnames(d_dec_stop, "N", "N_stopped")
  setnames(d_dec_stop, "value", "stopped_early")
  
  # Add in any the domains where we did not stop early
  d_dec_stop <- merge(d_dec_stop[, .SD, .SDcols = !c("analys")], 
                      # all combinations of sim and domain
                      unique(d_dec_2[, .(sim, domain)]),
                      by = c("sim", "domain"), all.y = T)
  
  # If domain or trial not stopped then record as having run to the 
  # maximum sample size with no decision made.
  d_dec_stop[is.na(N_stopped), N_stopped := max(d_N$N)]
  # get rid of quant
  d_dec_stop[is.na(stopped_early), stopped_early := F]
  # So now we know where every domain was stopped for any reason 
  # within each sim. Great.
  
  # Add in the other looks at the data so that we have a complete set
  d_dec_stop <- merge(
    d_dec_stop,
    unique(d_dec_2[, .(analys, sim, domain, N)]),
    by = c("sim", "domain"),
    all.y = T
  )
  
  # Merge in the parameter estimates (posterior means)
  d_dec_stop <- merge(
    d_dec_stop, 
    dcast(d_pars, sim + id_analys + domain ~ par, value.var = "mu"),
    by.x = c("analys", "sim", "domain"),
    by.y = c("id_analys", "sim", "domain")
  )
  
  # so now drop any records for which we had stopped the trial
  d_dec_stop <- d_dec_stop[!is.na(lor)]
  
  d_dec_stop <- merge(
    d_dec_stop,
    d_tru,
    by = c("sim", "analys", "domain")
  )
  
  # d_dec_stop[quant == "sup", mean(type_m_ratio), keyby = .(analys, domain, N)]
  
  # out of all the decision that were made, i.e. those where quant is not NA
  # what proportion 
  
  d_tbl_4 <- rbind(
    d_tbl_4,
    cbind(
      scenario = i, desc = l_cfg$desc,
      d_dec_stop[, .(sim, analys, domain, quant, N, lor, rd, stopped_early, N_stopped)]
      )
  )

}


```

@tbl-sim05-cumprobsup shows the cumulative probability of a superiority decision across each of the scenarios simulated.
This is only shown for the domains for which superiority is evaluated.
The futility of a superiority decision is included in parentheses.

Notes:

1. The 'average' surgical revision effect reaches about 65% (it was 70% in the previous simulations) when both one-stage and two-stage have a moderate effect, i.e. when both of these procedures increase the log-odds or response by the same $\log(1.75)$.
When one-stage or two-stage show an effect (the other having a zero effect) the weighted average effect of revision is lower and hence the power is lower.
The decisions are based on the aggregated effect of both revision types, not the methods selected by the clinician for revision.
2. AB duration of therapy is only indirectly relevant here because that domain assesses non-inferiority. I think that the revised rules for NI will influence other domains in that when AB duration is deemed NI, then all subsequent participants are assumed to get 6 weeks which redirects some of those that would have otherwise entered into the self-select group, which is effectively the group that inform decisions in the surgical domain. But note that this is a theory and I am yet to verify it.
3. AB extended prophylaxis receives entrants from acute, late and chronic silos and hence has more data to work with, leading to a higher overall cumulative probability of stopping. Ditto with the AB choice domain. So, in general, these have better overall power when effects are present, when contrasted with the surgical domain.


```{r}
#| label: tbl-sim05-cumprobsup
#| tbl-cap: 'Cumulative probability of superiority (futility in parentheses) decision at each interim (shown by total enrolment by interim)'
#| column: page
#| out-width: 70%

d_tbl_1_cur <- d_tbl_1[quant %in% c("sup", "fut_sup") & domain %in% c(1, 3, 4), .SD]
setorderv(d_tbl_1_cur, cols = c("scenario", "domain", "analys", "quant"), 
          order = c(1, 1, 1, -1))
d_tbl_1_cur <- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = "pr_val")
d_tbl_1_cur <- d_tbl_1_cur[, .SD, .SDcols = !c("scenario")]

d_tbl_1_cur[, domain := factor(domain, 
                               levels = c(1, 3, 4), 
                               labels = c("Surgical", "AB Ext-proph", "AB Choice"))]

g_tbl <- d_tbl_1_cur |> 
  gt(groupname_col = "desc") |> 
  gt::text_transform(
    locations = cells_row_groups(),
    fn = function(x) {
      lapply(x, function(x) {
        gt::md(paste0("*", x, "*"))
      })
    }
  ) |>
  cols_align(
    columns = 1,
    align = "left"
  )  |> 
  cols_align(
    columns = 2:ncol(d_tbl_1_cur),
    align = "center"
  )  |> 
  cols_merge(
    columns = c("sup_500", "fut_sup_500"
                ),
    pattern = "<<{1}>><< ({2})>>"
  )   |> 
  cols_merge(
    columns = c("sup_1000", "fut_sup_1000"
                ),
    pattern = "<<{1}>><< ({2})>>"
  ) |> 
  cols_merge(
    columns = c("sup_1500", "fut_sup_1500"
                ),
    pattern = "<<{1}>><< ({2})>>"
  )  |> 
  cols_merge(
    columns = c("sup_2000", "fut_sup_2000"
                ),
    pattern = "<<{1}>><< ({2})>>"
  )  |> 
  cols_merge(
    columns = c("sup_2500", "fut_sup_2500"
                ),
    pattern = "<<{1}>><< ({2})>>"
  ) |>
  tab_spanner(
    label = md("Cumulative probability of **superiority** (futility) decision"),
    columns = 3:ncol(d_tbl_1_cur)
  )  |>
  cols_label(
    domain = "Domain",
    sup_500 = html("500"),
    sup_1000 = html("1000"),
    sup_1500 = html("1500"),
    sup_2000 = html("2000"),
    sup_2500 = html("2500")
  ) |>
  tab_options(
    table.font.size = "70%"
  ) |>
  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)

g_tbl

```

@tbl-sim05-cumprobni shows the cumulative probability of a non-inferiority decision with futility shown in parentheses.
The results are only shown for the domains for which non-inferiority is evaluated.

Notes:

1. In this set of results the cumalative probability of claiming NI by 2500 is 0.76 when the effect size is OR 1.75 (contrasting with 0.67 from the last set of simulation results).
2. In the null case (when the 6 week and 12 week response are effectively identical) there is only a 10% cumulative probability of declaring NI. This is purely due to the thresholds we have selected. If equivalence is what we are actually thinking about, then we could potentially look towards evaluating that instead of non-inferiority (see the @fig-indiff below).

![Decision options based on posterior](indifference.png){#fig-indiff}

3. The higher power in the scenario where all domains have an effect arises because the surgical domain does not get shut down so you have more participants entering this AB duration domain.

```{r}
#| label: tbl-sim05-cumprobni
#| tbl-cap: 'Cumulative probability of NI (futility in parentheses) decision at each interim (shown by total enrolment by interim)'
#| column: page
#| out-width: 70%

d_tbl_1_cur <- d_tbl_1[quant %in% c("ni", "fut_ni") & domain %in% c(2), .SD]
setorderv(d_tbl_1_cur, cols = c("scenario", "domain", "analys", "quant"), 
          order = c(1, 1, 1, -1))
d_tbl_1_cur <- dcast(d_tbl_1_cur, scenario + desc + domain ~ quant + N, value.var = "pr_val")
d_tbl_1_cur <- d_tbl_1_cur[, .SD, .SDcols = !c("scenario")]

d_tbl_1_cur[, domain := factor(domain, 
                               levels = c(2), 
                               labels = c("AB Duration"))]

g_tbl <- d_tbl_1_cur |> 
  gt(groupname_col = "desc") |> 
  gt::text_transform(
    locations = cells_row_groups(),
    fn = function(x) {
      lapply(x, function(x) {
        gt::md(paste0("*", x, "*"))
      })
    }
  ) |>
  cols_align(
    columns = 1,
    align = "left"
  )  |> 
  cols_align(
    columns = 2:ncol(d_tbl_1_cur),
    align = "center"
  )  |> 
  cols_merge(
    columns = c("ni_500", "fut_ni_500"
                ),
    pattern = "<<{1}>><< ({2})>>"
  )   |> 
  cols_merge(
    columns = c("ni_1000", "fut_ni_1000"
                ),
    pattern = "<<{1}>><< ({2})>>"
  ) |> 
  cols_merge(
    columns = c("ni_1500", "fut_ni_1500"
                ),
    pattern = "<<{1}>><< ({2})>>"
  )  |> 
  cols_merge(
    columns = c("ni_2000", "fut_ni_2000"
                ),
    pattern = "<<{1}>><< ({2})>>"
  )  |> 
  cols_merge(
    columns = c("ni_2500", "fut_ni_2500"
                ),
    pattern = "<<{1}>><< ({2})>>"
  ) |>
  tab_spanner(
    label = md("Cumulative probability of **NI** (futility) decision"),
    columns = 3:ncol(d_tbl_1_cur)
  )  |>
  cols_label(
    domain = "Domain",
    ni_500 = html("500"),
    ni_1000 = html("1000"),
    ni_1500 = html("1500"),
    ni_2000 = html("2000"),
    ni_2500 = html("2500")
  ) |>
  tab_options(
    table.font.size = "70%"
  ) |>
  fmt_number(decimals = 3, drop_trailing_zeros = TRUE)

g_tbl

```

@tbl-sim05-stopn shows the number of enrolments when any stopping decision is made (including reaching the maximum 2500 sample size).

Notes

1. This is the total number of enrolments that are expected to have occurred, not how many are contributing to the inference in a given domain.

```{r}
#| label: tbl-sim05-stopn
#| tbl-cap: 'Expected number of enrolments to hit any stopping rule (including reaching maximum sample size) '
#| column: page
#| out-width: 70%

d_tbl_2_cur <- d_tbl_2[, .(N_mu = mean(N_stopped)), keyby = .(scenario, desc, domain)]
d_tbl_2_cur <- dcast(d_tbl_2_cur, scenario + desc ~ domain, value.var = "N_mu")
d_tbl_2_cur <- d_tbl_2_cur[, .SD, .SDcols = !c("scenario")]

g_tbl <- d_tbl_2_cur |> 
  gt(groupname_col = "desc") |> 
  gt::text_transform(
    locations = cells_row_groups(),
    fn = function(x) {
      lapply(x, function(x) {
        gt::md(paste0("*", x, "*"))
      })
    }
  ) |>
  cols_align(
    columns = 1,
    align = "left"
  )  |> 
  cols_align(
    columns = 2:ncol(d_tbl_2_cur),
    align = "center"
  )  |> 
  tab_spanner(
    label = html("Expected number of total enrolments to hit stopping rule by domain"),
    columns = 2:ncol(d_tbl_2_cur)
  )  |>
  cols_label(
    `1` = "Surgical",
    `2` = "AB Duration",
    `3` = "AB Ext-proph",
    `4` = "AB choice"
  ) |>
  tab_options(
    table.font.size = "70%"
  ) |>
  fmt_number(decimals = 0, drop_trailing_zeros = TRUE)

g_tbl
```


::: {.panel-tabset  .nav-pills}


## Treatment effects - odds ratios

@fig-expected-or shows the median value and 95% quantiles for the posterior means obtained from the simulations for each domain and scenario.
The estimates are unconditional, in that they ignore the stopping rule and propagate estimates forward with LOCF so that we are working from a random sample (albeit with static imputation) rather than a dependent sample of simulations.

Notes

1. The AB duration domain suffers from very high variance in the distribution of posterior means that we anticipate to observe. That is, when there is no true effect, we might still see effects as large as $\pm 25%$ on the absolute risk scale.


```{r}
#| label: fig-expected-or
#| fig-cap: 'Median value of posterior means for odds-ratio treatment effects by domain and simulation scenario'
#| fig-height: 10
#| fig-width: 6
#| column: page-right

# ggplot2::theme_update(text = element_text(size = 8))
# ggplot2::theme_update(legend.position = "bottom")
# # ggplot2::theme_update(legend.title = element_blank())
# ggplot2::theme_update(axis.text.x = element_text(size = 8))
# ggplot2::theme_update(axis.text.y = element_text(size = 8))

d_fig <- d_tbl_3[,
                 .(or = median(exp(mu_lor)),
                   q_025 = quantile(exp(mu_lor), prob = 0.025),
                   q_975 = quantile(exp(mu_lor), prob = 0.975)), 
                 keyby = .(scenario, desc, analys, domain, N)]
# setorderv(d_fig, cols = "scenario", order = -1L)
d_fig[, desc := factor(desc, levels = unique(d_fig$desc))]
d_fig[, domain := factor(domain, 
                         levels = 1:4, 
                         labels = c("Surgical", "AB Duration", "AB Ext-proph", "AB Choice"))]

# d_tbl_3[scenario == 8, range(lor)]

ggplot(data = d_fig,  
       aes(x = N, y = or)) +
  geom_line(lwd = 0.25) +
  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +
  scale_x_continuous("") +
  scale_y_continuous("OR") +
  facet_grid(desc ~ domain , 
             labeller = labeller(desc = label_wrap_gen(15)), scales = "free_y") +
  theme_minimal() +
  theme(text = element_text(size = 6),
        strip.text.y.right = element_text(angle = 0, size = 5),
        strip.text.x = element_text(angle = 0, size = 5),
        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),
        axis.text.y = element_text(size = 5))

```

## Treatment effects - risk difference


@fig-expected-rd shows the median value and 95% quantiles for the posterior means obtained from the simulations for each domain and scenario.
The estimates are unconditional, in that they ignore the stopping rule and propagate estimates forward with LOCF.

Notes

1. This plot focuses on the risk difference, and suggests that the odds ratios translate to effects in the order of 10-20% on the risk scale, dependent on the silo, domain etc. This variation is to be expected due to the non-linearity in the inverse logit transform. For example, if the baseline log-odds of response was -0.5 and you are contemplating an odds ratio of 2.5 this translates to a risk difference of about 0.23 but if your baseline log-odds of response is 0.2 then, with the same OR, this translates to a risk difference of about 0.2.

```{r}
#| label: fig-expected-rd
#| fig-cap: 'Median value of posterior means for risk difference treatment effects by domain and simulation scenario'
#| fig-cap-location: margin
#| fig-height: 10
#| fig-width: 6
#| column: page-right



d_fig <- d_tbl_3[,
                 .(rd = median(mu_rd),
                   q_025 = quantile(mu_rd, prob = 0.025),
                   q_975 = quantile(mu_rd, prob = 0.975)), 
                 keyby = .(scenario, desc, analys, domain, N)]
# setorderv(d_fig, cols = "scenario", order = -1L)
d_fig[, desc := factor(desc, levels = unique(d_fig$desc))]
d_fig[, domain := factor(domain, 
                         levels = 1:4, 
                         labels = c("Surgical", "AB Duration", "AB Ext-proph", "AB Choice"))]

# d_tbl_3[scenario == 8, range(lor)]

ggplot(data = d_fig,  
       aes(x = N, y = rd)) +
  geom_line(lwd = 0.25) +
  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +
  scale_x_continuous("") +
  scale_y_continuous("Risk difference") +
  facet_grid(desc ~ domain , 
             labeller = labeller(desc = label_wrap_gen(15)), scales = "free_y") +
  theme_minimal() +
  theme(text = element_text(size = 6),
        strip.text.y.right = element_text(angle = 0, size = 5),
        strip.text.x = element_text(angle = 0, size = 5),
        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),
        axis.text.y = element_text(size = 5))

```


:::



## Fraction of uncertainty resolved

@fig-uncertainty-1 shows the median value and 95% quantiles for the fraction of uncertainty resolved based on 

$$
\begin{aligned}
\text{Fraction \ Resolved} = 1 - \frac{Var(\beta_{post})}{Var(\beta_{pri})}
\end{aligned}
$$

where $Var(\beta_{post})$ and $Var(\beta_{pri})$ represent the variance associated with the prior and posterior belief for the relevant log-odds ratio for the treatment effects.
This is basically just a way to compare the prior and posterior variance.
When the posterior is based on negligible data, the variance will be similar to that of the prior and the fraction resolved will be very small.
A low fraction resolved (e.g. less than 0.5) suggests that any decision that was made was done so with a substantial amount of uncertainty remaining (you didn't move far from your prior belief) whereas values close to unity suggest that a lot of the uncertainty has been resolved.

1. What is obvious from the above plots is also obvious here, the decision made in the AB duration domain are subject to a substantial amount of uncertainty.


```{r}
#| label: fig-uncertainty-1
#| fig-cap: 'Median values and quantiles for fraction of uncertainty resolved'
#| fig-cap-location: margin
#| fig-height: 10
#| fig-width: 6
#| column: page-right

l_cfg <- copy(l[[1]]$cfg)

# initial uncertainty
v0 <- (l_cfg$pri$b_trt[2])^2

d_fig <- copy(d_tbl_3)
d_fig[, fr_unc := 1 - (se_lor/v0)]

d_fig <- d_fig[,
                 .(fr_unc = median(fr_unc),
                   q_025 = quantile(fr_unc, prob = 0.025),
                   q_975 = quantile(fr_unc, prob = 0.975)), 
                 keyby = .(scenario, desc, analys, domain, N)]
# setorderv(d_fig, cols = "scenario", order = -1L)
d_fig[, desc := factor(desc, levels = unique(d_fig$desc))]
d_fig[, domain := factor(domain, 
                         levels = 1:4, 
                         labels = c("Surgical", "AB Duration", "AB Ext-proph", "AB Choice"))]

# d_tbl_3[scenario == 8, range(lor)]

ggplot(data = d_fig,  
       aes(x = N, y = fr_unc)) +
  geom_line(lwd = 0.25) +
  geom_linerange(aes(ymin = q_025, ymax = q_975), lwd = 0.25) +
  scale_x_continuous("") +
  scale_y_continuous("Fraction of uncertainty resolved (1-(V_post/V_pri))") +
  facet_grid(desc ~ domain , 
             labeller = labeller(desc = label_wrap_gen(15)), scales = "free_y") +
  theme_minimal() +
  theme(text = element_text(size = 6),
        strip.text.y.right = element_text(angle = 0, size = 5),
        strip.text.x = element_text(angle = 0, size = 5),
        axis.text.x = element_text(angle = 45, vjust = 1, hjust=1, size = 5),
        axis.text.y = element_text(size = 5))

```




